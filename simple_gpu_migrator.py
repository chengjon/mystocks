#!/usr/bin/env python3
"""
ç®€åŒ–çš„GPUè¿ç§»å™¨
ä¸“æ³¨äºåŸºæœ¬çš„HALé›†æˆï¼Œæ›¿æ¢ç›´æ¥GPUè°ƒç”¨
"""

import os
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime


class SimpleGPUMigrator:
    """ç®€åŒ–çš„GPUè¿ç§»å™¨"""

    def __init__(self):
        self.project_root = Path(".")
        self.migration_log = []
        self.backup_dir = self.project_root / "gpu_simple_backups"

    def migrate_gpu_files(self) -> Dict[str, Any]:
        """è¿ç§»GPUæ–‡ä»¶"""
        print("ğŸš€ å¼€å§‹ç®€åŒ–GPUè¿ç§»...")

        # åˆ›å»ºå¤‡ä»½ç›®å½•
        self._create_backup_dir()

        # é€‰æ‹©è¦è¿ç§»çš„æ–‡ä»¶
        target_files = self._select_target_files()

        results = []
        for file_path in target_files:
            result = self._migrate_single_file(file_path)
            results.append(result)

        # ç”ŸæˆæŠ¥å‘Š
        report = self._generate_report(results)

        return report

    def _create_backup_dir(self):
        """åˆ›å»ºå¤‡ä»½ç›®å½•"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.backup_dir = self.project_root / f"gpu_simple_backups_{timestamp}"
        self.backup_dir.mkdir(exist_ok=True)

    def _select_target_files(self) -> List[str]:
        """é€‰æ‹©ç›®æ ‡æ–‡ä»¶"""
        # é€‰æ‹©å…³é”®GPUæ–‡ä»¶è¿›è¡Œè¿ç§»
        target_files = [
            "src/gpu/api_system/utils/gpu_acceleration_engine.py",
            "src/gpu/api_system/services/realtime_service.py",
            "src/gpu/api_system/utils/gpu_utils.py",
        ]

        # è¿‡æ»¤å­˜åœ¨çš„æ–‡ä»¶
        existing_files = []
        for file_path in target_files:
            if os.path.exists(file_path):
                existing_files.append(file_path)
                print(f"   ğŸ“‹ ç›®æ ‡æ–‡ä»¶: {os.path.basename(file_path)}")

        return existing_files

    def _migrate_single_file(self, file_path: str) -> Dict[str, Any]:
        """è¿ç§»å•ä¸ªæ–‡ä»¶"""
        file_name = os.path.basename(file_path)
        print(f"   ğŸ”§ è¿ç§»: {file_name}")

        try:
            # è¯»å–åŸæ–‡ä»¶
            with open(file_path, "r", encoding="utf-8") as f:
                original_content = f.read()

            # åˆ›å»ºå¤‡ä»½
            backup_path = self._create_backup(file_path, original_content)

            # æ‰§è¡ŒåŸºæœ¬è¿ç§»
            migrated_content, changes = self._perform_basic_migration(
                file_path, original_content
            )

            # å†™å…¥è¿ç§»åçš„å†…å®¹
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(migrated_content)

            return {
                "file_path": file_path,
                "file_name": file_name,
                "success": True,
                "changes": changes,
                "backup_path": str(backup_path),
                "original_lines": len(original_content.split("\n")),
                "modified_lines": len(migrated_content.split("\n")),
            }

        except Exception as e:
            return {
                "file_path": file_path,
                "file_name": os.path.basename(file_path),
                "success": False,
                "error": str(e),
                "changes": [],
            }

    def _create_backup(self, file_path: str, content: str) -> str:
        """åˆ›å»ºå¤‡ä»½"""
        relative_path = Path(file_path).relative_to(self.project_root)
        backup_path = self.backup_dir / relative_path
        backup_path.parent.mkdir(parents=True, exist_ok=True)

        with open(backup_path, "w", encoding="utf-8") as f:
            f.write(content)

        return str(backup_path)

    def _perform_basic_migration(
        self, file_path: str, content: str
    ) -> tuple[str, List[str]]:
        """æ‰§è¡ŒåŸºæœ¬è¿ç§»"""
        migrated_content = content
        changes = []

        # 1. æ·»åŠ HALå¯¼å…¥
        if "from src.gpu.core.hardware_abstraction" not in migrated_content:
            migrated_content, import_change = self._add_hal_import(migrated_content)
            if import_change:
                changes.extend(import_change)

        # 2. æ·»åŠ å†…æ ¸æ‰§è¡Œå™¨å¯¼å…¥
        if "from src.gpu.core.kernels" not in migrated_content:
            migrated_content, kernel_change = self._add_kernel_import(migrated_content)
            if kernel_change:
                changes.extend(kernel_change)

        # 3. æ›¿æ¢ç®€å•çš„GPUè°ƒç”¨
        migrated_content, call_changes = self._replace_simple_gpu_calls(
            migrated_content
        )
        changes.extend(call_changes)

        return migrated_content, changes

    def _add_hal_import(self, content: str) -> tuple[str, List[str]]:
        """æ·»åŠ HALå¯¼å…¥"""
        lines = content.split("\n")
        changes = []

        # æ‰¾åˆ°æœ€åä¸€ä¸ªimportè¯­å¥
        insert_index = 0
        for i, line in enumerate(lines):
            if line.strip().startswith(("import ", "from ")):
                insert_index = i + 1

        # æ·»åŠ HALå¯¼å…¥
        hal_import = (
            "from src.gpu.core.hardware_abstraction import get_gpu_resource_manager"
        )
        lines.insert(insert_index, hal_import)
        changes.append(f"Added HAL import: {hal_import}")

        return "\n".join(lines), changes

    def _add_kernel_import(self, content: str) -> tuple[str, List[str]]:
        """æ·»åŠ å†…æ ¸å¯¼å…¥"""
        lines = content.split("\n")
        changes = []

        # æ‰¾åˆ°HALå¯¼å…¥åçš„ä½ç½®
        insert_index = 0
        for i, line in enumerate(lines):
            if "from src.gpu.core.hardware_abstraction import" in line:
                insert_index = i + 1
                break

        # æ·»åŠ å†…æ ¸æ‰§è¡Œå™¨å¯¼å…¥
        kernel_import = "from src.gpu.core.kernels import get_kernel_executor"
        lines.insert(insert_index, kernel_import)
        changes.append(f"Added kernel import: {kernel_import}")

        return "\n".join(lines), changes

    def _replace_simple_gpu_calls(self, content: str) -> tuple[str, List[str]]:
        """æ›¿æ¢ç®€å•çš„GPUè°ƒç”¨"""
        migrated_content = content
        changes = []

        # ç®€å•æ›¿æ¢è§„åˆ™
        replacements = [
            # CuPyä½¿ç”¨
            ("cp.", "gpu_manager.", "Replace cp. with gpu_manager."),
            # PyTorch CUDA
            (
                ".cuda()",
                "await gpu_manager.to_device()",
                "Replace .cuda() with HAL device transfer",
            ),
            # ç›´æ¥æ•°ç»„åˆ›å»º
            (
                "cupy.array",
                "await gpu_manager.create_array",
                "Replace cupy.array with HAL creation",
            ),
        ]

        for old, new, description in replacements:
            if old in migrated_content and new not in migrated_content:
                migrated_content = migrated_content.replace(old, new)
                changes.append(description)

        # æ·»åŠ åˆå§‹åŒ–ä»£ç ï¼ˆå¦‚æœæœ‰GPUè°ƒç”¨ï¼‰
        if any(old in migrated_content for old, _, _ in replacements):
            init_code = """
# åˆå§‹åŒ–GPUèµ„æºç®¡ç†å™¨
gpu_manager = get_gpu_resource_manager()
await gpu_manager.initialize()

# åˆå§‹åŒ–å†…æ ¸æ‰§è¡Œå™¨
kernel_executor = get_kernel_executor()
await kernel_executor.initialize()
"""
            if "async def main(" in migrated_content:
                # åœ¨mainå‡½æ•°å¼€å¤´æ·»åŠ åˆå§‹åŒ–
                lines = migrated_content.split("\n")
                for i, line in enumerate(lines):
                    if line.strip().startswith("async def main("):
                        lines.insert(i + 1, init_code.strip())
                        break
                migrated_content = "\n".join(lines)
                changes.append("Added GPU initialization code")

        return migrated_content, changes

    def _generate_report(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆè¿ç§»æŠ¥å‘Š"""
        total_files = len(results)
        successful_files = sum(1 for r in results if r.get("success", False))
        failed_files = total_files - successful_files

        total_changes = sum(len(r.get("changes", [])) for r in results)

        return {
            "summary": {
                "total_files": total_files,
                "successful_files": successful_files,
                "failed_files": failed_files,
                "success_rate": (successful_files / total_files * 100)
                if total_files > 0
                else 0,
                "total_changes": total_changes,
            },
            "files": results,
        }

    def print_summary(self, report: Dict[str, Any]):
        """æ‰“å°æ‘˜è¦"""
        print("\n" + "=" * 50)
        print("ğŸ“Š ç®€åŒ–GPUè¿ç§»æ‘˜è¦")
        print("=" * 50)

        summary = report["summary"]
        print(f"ğŸ“ æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
        print(f"âœ… æˆåŠŸè¿ç§»: {summary['successful_files']}")
        print(f"âŒ å¤±è´¥è¿ç§»: {summary['failed_files']}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print(f"ğŸ”§ æ€»ä¿®æ”¹æ•°: {summary['total_changes']}")

        print("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
        for result in report["files"]:
            status = "âœ…" if result.get("success", False) else "âŒ"
            file_name = result.get("file_name", "Unknown")
            changes_count = len(result.get("changes", []))
            print(f"   {status} {file_name} ({changes_count} ä¿®æ”¹)")

        if summary["success_rate"] == 100:
            print("\nğŸ‰ è¿ç§»æˆåŠŸå®Œæˆï¼")
        else:
            print("\nâš ï¸ éƒ¨åˆ†è¿ç§»å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ã€‚")

        print("=" * 50)


def main():
    """ä¸»å‡½æ•°"""
    migrator = SimpleGPUMigrator()

    print("ğŸš€ Phase 6.2.4 ç®€åŒ–GPUè¿ç§»æ‰§è¡Œ...")

    # æ‰§è¡Œè¿ç§»
    report = migrator.migrate_gpu_files()

    # ä¿å­˜æŠ¥å‘Š
    report_path = "simple_gpu_migration_report.json"
    try:
        import json

        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

    # æ‰“å°æ‘˜è¦
    migrator.print_summary(report)

    return report


if __name__ == "__main__":
    main()
