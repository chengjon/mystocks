#æ­£å¸¸æ‰§è¡Œï¼ˆä¸åˆ é™¤å·²æœ‰è¡¨ï¼‰ï¼špython execute_sql_with_env.py
#å¼ºåˆ¶åˆ é™¤å¹¶é‡å»ºè¡¨ï¼špython execute_sql_with_env.py --drop-existing

import sqlalchemy
from sqlalchemy import text
from sqlalchemy.exc import SQLAlchemyError
import argparse
import os
import time
from loguru import logger

# é…ç½® loguru æ—¥å¿—
logger.remove()  # ç§»é™¤é»˜è®¤å¤„ç†å™¨
logger.add(
    "logs/db_monitor_init_{time:YYYY-MM-DD}.log",
    rotation="1 day",
    retention="30 days",
    level="INFO",
    format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} | {message}",
    encoding="utf-8"
)
logger.add(
    lambda msg: print(msg, end=""),
    level="INFO",
    format="<green>{time:HH:mm:ss.SSS}</green> | <level>{level: <8}</level> | <cyan>{function}</cyan> | {message}"
)

def find_env_file(default_path='mystocks/.env'):
    """
    æ™ºèƒ½æŸ¥æ‰¾ç¯å¢ƒå˜é‡æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§å·¥ä½œç›®å½•
    
    Args:
        default_path (str): é»˜è®¤ç›¸å¯¹è·¯å¾„
        
    Returns:
        str: æ‰¾åˆ°çš„ç¯å¢ƒæ–‡ä»¶ç»å¯¹è·¯å¾„
        
    Raises:
        FileNotFoundError: å¦‚æœæ‰€æœ‰è·¯å¾„éƒ½æ‰¾ä¸åˆ°æ–‡ä»¶
    """
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # å®šä¹‰å¤šä¸ªå¯èƒ½çš„è·¯å¾„ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    possible_paths = [
        # 1. å½“å‰å·¥ä½œç›®å½•çš„ç›¸å¯¹è·¯å¾„
        default_path,
        
        # 2. å½“å‰ç›®å½•çš„ .env æ–‡ä»¶
        '.env',
        
        # 3. ä¸Šçº§ç›®å½•çš„ mystocks/.env
        '../mystocks/.env',
        
        # 4. ä»è„šæœ¬ç›®å½•å‘ä¸Šæ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
        os.path.join(script_dir, '../../../mystocks/.env'),
        os.path.join(script_dir, '../../.env'),
        os.path.join(script_dir, '../.env'),
        
        # 5. å›ºå®šçš„å·²çŸ¥è·¯å¾„
        r'D:\MyData\GITHUB\mystocks\.env',
        
        # 6. è„šæœ¬ç›®å½•çš„å…„å¼Ÿç›®å½•
        os.path.join(os.path.dirname(script_dir), '.env'),
    ]
    
    logger.debug(f"ğŸ” å¼€å§‹æ™ºèƒ½æœç´¢ç¯å¢ƒæ–‡ä»¶ï¼Œé»˜è®¤è·¯å¾„: {default_path}")
    logger.debug(f"ğŸ“ è„šæœ¬æ‰€åœ¨ç›®å½•: {script_dir}")
    logger.debug(f"ğŸ“‚ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    
    for i, path in enumerate(possible_paths, 1):
        try:
            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            abs_path = os.path.abspath(path)
            logger.debug(f"ğŸ“‹ [{i}/{len(possible_paths)}] æ£€æŸ¥è·¯å¾„: {abs_path}")
            
            if os.path.exists(abs_path):
                logger.success(f"âœ… æ‰¾åˆ°ç¯å¢ƒæ–‡ä»¶: {abs_path}")
                return abs_path
            else:
                logger.debug(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {abs_path}")
                
        except Exception as e:
            logger.debug(f"âš ï¸ æ£€æŸ¥è·¯å¾„æ—¶å‡ºé”™: {path} - {str(e)}")
            continue
    
    # å¦‚æœæ‰€æœ‰è·¯å¾„éƒ½æ‰¾ä¸åˆ°ï¼ŒæŠ›å‡ºè¯¦ç»†é”™è¯¯
    error_msg = f"""
ç¯å¢ƒå˜é‡æ–‡ä»¶æœªæ‰¾åˆ°ï¼å·²å°è¯•ä»¥ä¸‹è·¯å¾„ï¼š
{''.join([f"  {i}. {os.path.abspath(path)}\n" for i, path in enumerate(possible_paths, 1)])}
è¯·ç¡®ä¿ï¼š
1. .env æ–‡ä»¶å­˜åœ¨äºæ­£ç¡®ä½ç½®
2. å½“å‰å·¥ä½œç›®å½•æ­£ç¡® (å½“å‰: {os.getcwd()})
3. æ–‡ä»¶è·¯å¾„æƒé™æ­£ç¡®
"""
    
    logger.error(error_msg)
    raise FileNotFoundError(error_msg)

def load_env_config(env_file=None):
    """ä»ç¯å¢ƒå˜é‡æ–‡ä»¶åŠ è½½é…ç½®"""
    # å¦‚æœæ²¡æœ‰æŒ‡å®šè·¯å¾„ï¼Œä½¿ç”¨æ™ºèƒ½æœç´¢
    if env_file is None:
        env_file = find_env_file()
    else:
        # å¦‚æœæŒ‡å®šäº†è·¯å¾„ï¼Œå…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™ä½¿ç”¨æ™ºèƒ½æœç´¢
        if not os.path.exists(env_file):
            logger.warning(f"âš ï¸ æŒ‡å®šçš„ç¯å¢ƒæ–‡ä»¶ä¸å­˜åœ¨: {env_file}ï¼Œå°è¯•æ™ºèƒ½æœç´¢...")
            env_file = find_env_file()
        else:
            env_file = os.path.abspath(env_file)
    
    logger.info(f"ğŸ” å¼€å§‹åŠ è½½ç¯å¢ƒé…ç½®æ–‡ä»¶: {env_file}")
    config = {}
    start_time = time.time()
    
    try:
        logger.success(f"âœ“ ç¯å¢ƒæ–‡ä»¶å­˜åœ¨: {env_file}")
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(env_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            logger.info(f"ğŸ“„ è¯»å–åˆ° {len(lines)} è¡Œé…ç½®")
            
            for line_num, line in enumerate(lines, 1):
                line = line.strip()
                # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
                if not line or line.startswith('#'):
                    continue
                
                # è§£æé”®å€¼å¯¹
                if '=' in line:
                    key, value = line.split('=', 1)
                    config[key.strip()] = value.strip()
                    logger.debug(f"ç¬¬{line_num}è¡Œ: åŠ è½½é…ç½® {key.strip()}")
        
        # éªŒè¯å¿…è¦çš„é…ç½®é¡¹
        required_keys = ['MYSQL_HOST', 'MYSQL_USER', 'MYSQL_PASSWORD', 'MYSQL_PORT']
        missing_keys = [key for key in required_keys if key not in config]
        
        if missing_keys:
            raise ValueError(f"ç¯å¢ƒå˜é‡æ–‡ä»¶ç¼ºå°‘å¿…è¦é…ç½®: {', '.join(missing_keys)}")
        
        # æ„å»ºæ•°æ®åº“é…ç½®
        db_config = {
            'user': config['MYSQL_USER'],
            'password': config['MYSQL_PASSWORD'],
            'host': config['MYSQL_HOST'],
            'port': int(config['MYSQL_PORT']),
            'database': 'mysql',  # åˆå§‹è¿æ¥ä½¿ç”¨çš„æ•°æ®åº“
            'charset': 'utf8mb4',
            'collation': 'utf8mb4_unicode_ci'
        }
        
        load_time = time.time() - start_time
        logger.success(f"âœ“ ç¯å¢ƒé…ç½®åŠ è½½æˆåŠŸ! è€—æ—¶: {load_time:.3f}s")
        logger.info(f"ğŸ”— æ•°æ®åº“è¿æ¥ä¿¡æ¯: {config['MYSQL_USER']}@{config['MYSQL_HOST']}:{config['MYSQL_PORT']}")
        
        return db_config
        
    except Exception as e:
        load_time = time.time() - start_time
        logger.error(f"âŒ åŠ è½½é…ç½®å¤±è´¥ (è€—æ—¶: {load_time:.3f}s): {str(e)}")
        raise

def get_sql_commands(drop_existing=False, charset='utf8mb4', collation='utf8mb4_unicode_ci'):
    """ç”ŸæˆSQLå‘½ä»¤ï¼Œæ”¯æŒåˆ é™¤å·²æœ‰è¡¨é€‰é¡¹"""
    drop_commands = ""
    if drop_existing:
        drop_commands = """
        DROP TABLE IF EXISTS table_validation_log;
        DROP TABLE IF EXISTS table_operation_log;
        DROP TABLE IF EXISTS column_definition_log;
        DROP TABLE IF EXISTS table_creation_log;
        """
    
    create_table_prefix = "CREATE TABLE IF NOT EXISTS" if not drop_existing else "CREATE TABLE"
    
    return f"""
CREATE DATABASE IF NOT EXISTS db_monitor 
    CHARACTER SET {charset} 
    COLLATE {collation};

USE db_monitor;

{drop_commands}

{create_table_prefix} table_creation_log (
    id INT AUTO_INCREMENT PRIMARY KEY COMMENT 'è‡ªå¢ä¸»é”®',
    table_name VARCHAR(255) NOT NULL COMMENT 'è¡¨å',
    database_type ENUM('TDengine', 'PostgreSQL', 'Redis', 'MySQL', 'MariaDB') NOT NULL COMMENT 'æ•°æ®åº“ç±»å‹',
    database_name VARCHAR(255) NOT NULL COMMENT 'æ•°æ®åº“åç§°',
    creation_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
    modification_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'ä¿®æ”¹æ—¶é—´',
    status ENUM('success', 'failed') NOT NULL COMMENT 'åˆ›å»ºçŠ¶æ€',
    table_parameters JSON NOT NULL COMMENT 'è¡¨å‚æ•°é…ç½®ï¼ˆJSONæ ¼å¼ï¼‰',
    ddl_command TEXT NOT NULL COMMENT 'æ‰§è¡Œçš„DDLå‘½ä»¤',
    error_message TEXT COMMENT 'é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœ‰ï¼‰',
    INDEX idx_database_type (database_type),
    INDEX idx_creation_time (creation_time)
) ENGINE=InnoDB DEFAULT CHARSET={charset} COMMENT='è¡¨åˆ›å»ºæ—¥å¿—è¡¨';

{create_table_prefix} column_definition_log (
    id INT AUTO_INCREMENT PRIMARY KEY COMMENT 'è‡ªå¢ä¸»é”®',
    table_log_id INT NOT NULL COMMENT 'å…³è”çš„è¡¨åˆ›å»ºæ—¥å¿—ID',
    column_name VARCHAR(255) NOT NULL COMMENT 'åˆ—å',
    data_type VARCHAR(100) NOT NULL COMMENT 'æ•°æ®ç±»å‹',
    col_length INT COMMENT 'åˆ—é•¿åº¦',
    col_precision INT COMMENT 'ç²¾åº¦',
    col_scale INT COMMENT 'å°æ•°ä½æ•°',
    is_nullable BOOLEAN DEFAULT TRUE COMMENT 'æ˜¯å¦å…è®¸ä¸ºç©º',
    is_primary_key BOOLEAN DEFAULT FALSE COMMENT 'æ˜¯å¦ä¸ºä¸»é”®',
    default_value VARCHAR(255) COMMENT 'é»˜è®¤å€¼',
    comment TEXT COMMENT 'åˆ—å¤‡æ³¨',
    FOREIGN KEY (table_log_id) REFERENCES table_creation_log(id) ON DELETE CASCADE,
    INDEX idx_table_log_id (table_log_id)
) ENGINE=InnoDB DEFAULT CHARSET={charset} COMMENT='åˆ—å®šä¹‰æ—¥å¿—è¡¨';

-- æ–°å¢è¡¨æ“ä½œæ—¥å¿—è¡¨
{create_table_prefix} table_operation_log (
    id INT AUTO_INCREMENT PRIMARY KEY COMMENT 'è‡ªå¢ä¸»é”®',
    table_name VARCHAR(255) NOT NULL COMMENT 'è¡¨å',
    database_type ENUM('TDengine', 'PostgreSQL', 'Redis', 'MySQL', 'MariaDB') NOT NULL COMMENT 'æ•°æ®åº“ç±»å‹',
    database_name VARCHAR(255) NOT NULL COMMENT 'æ•°æ®åº“åç§°',
    operation_type ENUM('CREATE', 'ALTER', 'DROP', 'VALIDATE') NOT NULL COMMENT 'æ“ä½œç±»å‹',
    operation_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'æ“ä½œæ—¶é—´',
    operation_status ENUM('success', 'failed', 'processing') NOT NULL COMMENT 'æ“ä½œçŠ¶æ€',
    operation_details JSON NOT NULL COMMENT 'æ“ä½œè¯¦æƒ…ï¼ˆJSONæ ¼å¼ï¼‰',
    ddl_command TEXT COMMENT 'æ‰§è¡Œçš„DDLå‘½ä»¤',
    error_message TEXT COMMENT 'é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœ‰ï¼‰',
    INDEX idx_operation_time (operation_time),
    INDEX idx_operation_type (operation_type)
) ENGINE=InnoDB DEFAULT CHARSET={charset} COMMENT='è¡¨æ“ä½œæ—¥å¿—è¡¨';

-- æ–°å¢è¡¨ç»“æ„éªŒè¯æ—¥å¿—è¡¨
{create_table_prefix} table_validation_log (
    id INT AUTO_INCREMENT PRIMARY KEY COMMENT 'è‡ªå¢ä¸»é”®',
    table_name VARCHAR(255) NOT NULL COMMENT 'è¡¨å',
    database_type ENUM('TDengine', 'PostgreSQL', 'Redis', 'MySQL', 'MariaDB') NOT NULL COMMENT 'æ•°æ®åº“ç±»å‹',
    database_name VARCHAR(255) NOT NULL COMMENT 'æ•°æ®åº“åç§°',
    validation_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'éªŒè¯æ—¶é—´',
    validation_status ENUM('pass', 'fail') NOT NULL COMMENT 'éªŒè¯çŠ¶æ€',
    validation_details JSON NOT NULL COMMENT 'éªŒè¯è¯¦æƒ…ï¼ˆJSONæ ¼å¼ï¼‰',
    issues_found TEXT COMMENT 'å‘ç°çš„é—®é¢˜',
    INDEX idx_validation_time (validation_time)
) ENGINE=InnoDB DEFAULT CHARSET={charset} COMMENT='è¡¨ç»“æ„éªŒè¯æ—¥å¿—è¡¨';
"""

def create_database_and_tables(drop_existing=False):
    """åˆ›å»ºæ•°æ®åº“å’Œè¡¨ç»“æ„"""
    logger.info(f"ğŸš€ å¼€å§‹åˆ›å»ºæ•°æ®åº“å’Œè¡¨ç»“æ„ (drop_existing={drop_existing})")
    start_time = time.time()
    
    try:
        # ä» env æ–‡ä»¶åŠ è½½é…ç½®
        db_config = load_env_config()
        
        # åˆ›å»ºæ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²
        connection_str = (
            f"mysql+pymysql://{db_config['user']}:{db_config['password']}@"
            f"{db_config['host']}:{db_config['port']}/{db_config['database']}?"
            f"charset={db_config['charset']}"
        )
        
        logger.info(f"ğŸ”— è¿æ¥æ•°æ®åº“: {db_config['user']}@{db_config['host']}:{db_config['port']}")
        
        # å»ºç«‹æ•°æ®åº“è¿æ¥
        engine = sqlalchemy.create_engine(connection_str)
        with engine.connect() as connection:
            # ç¡®ä¿è‡ªåŠ¨æäº¤æ¨¡å¼å¼€å¯
            connection = connection.execution_options(autocommit=True)
            logger.success("âœ“ æ•°æ®åº“è¿æ¥æˆåŠŸ")
            
            # è·å– SQL å‘½ä»¤
            sql_commands = get_sql_commands(
                drop_existing=drop_existing,
                charset=db_config['charset'],
                collation=db_config['collation']
            ).split(';')
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_commands = len([cmd for cmd in sql_commands if cmd.strip()])
            executed_commands = 0
            failed_commands = 0
            
            logger.info(f"ğŸ“„ å°†æ‰§è¡Œ {total_commands} æ¡ SQL å‘½ä»¤")
            
            # æ‰§è¡Œ SQL å‘½ä»¤
            for i, cmd in enumerate(sql_commands, 1):
                cmd = cmd.strip()
                if cmd:  # è·³è¿‡ç©ºå‘½ä»¤
                    cmd_start_time = time.time()
                    try:
                        # åˆ¤æ–­å‘½ä»¤ç±»å‹
                        if 'CREATE DATABASE' in cmd:
                            logger.info(f"ğŸ“ [{i}/{total_commands}] åˆ›å»ºæ•°æ®åº“: db_monitor")
                        elif 'USE db_monitor' in cmd:
                            logger.info(f"ğŸ”„ [{i}/{total_commands}] åˆ‡æ¢åˆ°æ•°æ®åº“: db_monitor")
                        elif 'CREATE TABLE' in cmd:
                            table_name = extract_table_name(cmd)
                            logger.info(f"ğŸ“Š [{i}/{total_commands}] åˆ›å»ºè¡¨: {table_name}")
                        elif 'DROP TABLE' in cmd:
                            logger.warning(f"ğŸ—‘ï¸ [{i}/{total_commands}] åˆ é™¤è¡¨")
                        else:
                            logger.debug(f"ğŸ“‹ [{i}/{total_commands}] æ‰§è¡Œ SQL: {cmd[:50]}...")
                        
                        connection.execute(text(cmd))
                        cmd_time = time.time() - cmd_start_time
                        executed_commands += 1
                        
                        if cmd_time > 0.1:  # åªè®°å½•è¾ƒæ…¢çš„å‘½ä»¤
                            logger.debug(f"â±ï¸ å‘½ä»¤æ‰§è¡Œæ—¶é—´: {cmd_time:.3f}s")
                        
                    except Exception as cmd_error:
                        cmd_time = time.time() - cmd_start_time
                        failed_commands += 1
                        logger.error(f"âŒ [{i}/{total_commands}] SQLæ‰§è¡Œå¤±è´¥ (è€—æ—¶: {cmd_time:.3f}s): {str(cmd_error)}")
                        logger.debug(f"å¤±è´¥çš„SQL: {cmd[:100]}...")
        
        total_time = time.time() - start_time
        
        # è¾“å‡ºæˆåŠŸç»Ÿè®¡
        logger.success(f"âœ“ æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ!")
        logger.info(f"ğŸ“Š æ‰§è¡Œç»Ÿè®¡: æˆåŠŸ {executed_commands} / å¤±è´¥ {failed_commands} / æ€»è®¡ {total_commands}")
        logger.info(f"â±ï¸ æ€»æ‰§è¡Œæ—¶é—´: {total_time:.3f}s")
        
        # è¾“å‡ºåˆ›å»ºçš„èµ„æºæ±‡æ€»
        logger.info("ğŸ“¦ åˆ›å»ºçš„èµ„æºæ±‡æ€»:")
        logger.info("  â€¢ æ•°æ®åº“: db_monitor")
        logger.info("  â€¢ è¡¨ç»“æ„:")
        tables = [
            "table_creation_log - è¡¨åˆ›å»ºæ—¥å¿—è¡¨",
            "column_definition_log - åˆ—å®šä¹‰æ—¥å¿—è¡¨",
            "table_operation_log - è¡¨æ“ä½œæ—¥å¿—è¡¨",
            "table_validation_log - è¡¨ç»“æ„éªŒè¯æ—¥å¿—è¡¨"
        ]
        for table in tables:
            logger.info(f"    â–« {table}")
        
        return True
        
    except SQLAlchemyError as e:
        total_time = time.time() - start_time
        logger.error(f"âŒ æ‰§è¡Œ SQL æ—¶å‘ç”Ÿé”™è¯¯ (è€—æ—¶: {total_time:.3f}s): {str(e)}")
        return False
    except Exception as e:
        total_time = time.time() - start_time
        logger.error(f"âŒ å‘ç”Ÿæ„å¤–é”™è¯¯ (è€—æ—¶: {total_time:.3f}s): {str(e)}")
        return False

def init_monitoring_database(drop_existing=False):
    """
    åˆå§‹åŒ–ç›‘æ§æ•°æ®åº“ï¼ˆä¸“ç”¨äº Jupyter ç¯å¢ƒè°ƒç”¨ï¼‰
    
    Args:
        drop_existing (bool): æ˜¯å¦åˆ é™¤å·²å­˜åœ¨çš„è¡¨
    
    Returns:
        bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
    
    Examples:
        # åœ¨ Jupyter ä¸­ä½¿ç”¨
        success = init_monitoring_database()
        
        # åˆ é™¤å·²å­˜åœ¨çš„è¡¨å¹¶é‡å»º
        success = init_monitoring_database(drop_existing=True)
    """
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs("logs", exist_ok=True)
    
    logger.info("="*60)
    logger.info("ğŸ¯ æ•°æ®åº“ç›‘æ§åˆå§‹åŒ–ç¨‹åºå¯åŠ¨ (Jupyter API)")
    logger.info(f"âš™ï¸ å‚æ•°è®¾ç½®: drop_existing={drop_existing}")
    logger.info("="*60)
    
    # æ‰§è¡Œæ•°æ®åº“åˆå§‹åŒ–
    success = create_database_and_tables(drop_existing=drop_existing)
    
    # ç¨‹åºç»“æŸè®°å½•
    if success:
        logger.success("ğŸ‰ æ•°æ®åº“ç›‘æ§åˆå§‹åŒ–ç¨‹åºæ‰§è¡ŒæˆåŠŸ!")
    else:
        logger.error("ğŸ’¥ æ•°æ®åº“ç›‘æ§åˆå§‹åŒ–ç¨‹åºæ‰§è¡Œå¤±è´¥!")
    
    logger.info("="*60)
    return success

def extract_table_name(sql_cmd):
    """ä» CREATE TABLE å‘½ä»¤ä¸­æå–è¡¨å"""
    try:
        # åŒ¹é… CREATE TABLE [IF NOT EXISTS] table_name
        import re
        pattern = r'CREATE\s+TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?(\w+)'
        match = re.search(pattern, sql_cmd, re.IGNORECASE)
        return match.group(1) if match else "æœªçŸ¥è¡¨"
    except:
        return "æœªçŸ¥è¡¨"

if __name__ == "__main__":
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs("logs", exist_ok=True)
    
    # æ£€æµ‹æ˜¯å¦åœ¨ Jupyter ç¯å¢ƒä¸­è¿è¡Œ
    in_jupyter = False
    try:
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ ipykernel
        from IPython import get_ipython
        if get_ipython() is not None:
            in_jupyter = True
    except ImportError:
        pass
    
    if in_jupyter:
        # åœ¨ Jupyter ç¯å¢ƒä¸­ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°
        logger.info("ğŸ”¬ æ£€æµ‹åˆ° Jupyter ç¯å¢ƒï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
        drop_existing = False
    else:
        # åœ¨å‘½ä»¤è¡Œç¯å¢ƒä¸­ï¼Œè§£æå‘½ä»¤è¡Œå‚æ•°
        parser = argparse.ArgumentParser(description='åˆ›å»ºç›‘æ§æ•°æ®åº“å’Œè¡¨ç»“æ„')
        parser.add_argument('--drop-existing', action='store_true', 
                          help='åˆ é™¤å·²å­˜åœ¨çš„è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰')
        args = parser.parse_args()
        drop_existing = args.drop_existing
    
    # è®°å½•ç¨‹åºå¯åŠ¨
    logger.info("="*60)
    logger.info("ğŸ¯ æ•°æ®åº“ç›‘æ§åˆå§‹åŒ–ç¨‹åºå¯åŠ¨")
    logger.info(f"âš™ï¸ å‚æ•°è®¾ç½®: drop_existing={drop_existing}")
    logger.info(f"ğŸŒ è¿è¡Œç¯å¢ƒ: {'Jupyter' if in_jupyter else 'Command Line'}")
    logger.info("="*60)
    
    # æ‰§è¡Œæ•°æ®åº“åˆå§‹åŒ–
    success = create_database_and_tables(drop_existing=drop_existing)
    
    # ç¨‹åºç»“æŸè®°å½•
    if success:
        logger.success("ğŸ‰ æ•°æ®åº“ç›‘æ§åˆå§‹åŒ–ç¨‹åºæ‰§è¡ŒæˆåŠŸ!")
    else:
        logger.error("ğŸ’¥ æ•°æ®åº“ç›‘æ§åˆå§‹åŒ–ç¨‹åºæ‰§è¡Œå¤±è´¥!")
    
    logger.info("="*60)
    