#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†…å­˜ç®¡ç†é›†æˆæµ‹è¯•è„šæœ¬
æµ‹è¯•å†…å­˜ç®¡ç†ç³»ç»Ÿä¸æ•°æ®åº“è¿æ¥çš„é›†æˆ
"""

import sys
import asyncio
import psutil

# è®¾ç½®Pythonè·¯å¾„
project_root = "/opt/claude/mystocks_spec"
sys.path.insert(0, project_root)


def test_memory_manager_availability():
    """æµ‹è¯•å†…å­˜ç®¡ç†å™¨å¯ç”¨æ€§"""
    try:
        # æµ‹è¯•æ–°çš„å†…å­˜ç®¡ç†å™¨
        from src.gpu.accelerated.memory_management_fix import (
            optimize_dataframe_memory,
            memory_manager,
        )

        print("âœ… æ–°å†…å­˜ç®¡ç†å™¨å¯¼å…¥æˆåŠŸ")

        # æµ‹è¯•å†…å­˜ç®¡ç†å™¨åŸºæœ¬åŠŸèƒ½
        initial_stats = memory_manager.get_memory_stats()
        print(
            f"âœ… å†…å­˜ç»Ÿè®¡è·å–æˆåŠŸ: {initial_stats['current']['process_memory_mb']:.2f} MB"
        )

        # æµ‹è¯•DataFrameä¼˜åŒ–
        import pandas as pd

        test_df = pd.DataFrame(
            {
                "col1": [1, 2, 3] * 1000,
                "col2": [1.1, 2.2, 3.3] * 1000,
                "col3": ["a", "b", "c"] * 1000,
            }
        )

        optimized_df = optimize_dataframe_memory(test_df)
        print(
            f"âœ… DataFrameå†…å­˜ä¼˜åŒ–æˆåŠŸ: {test_df.memory_usage().sum() / 1024**2:.2f}MB -> {optimized_df.memory_usage().sum() / 1024**2:.2f}MB"
        )

        return True
    except Exception as e:
        print(f"âŒ å†…å­˜ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_memory_snapshot_recording():
    """æµ‹è¯•å†…å­˜å¿«ç…§å½•åˆ¶"""
    try:
        from src.core.memory_manager import get_memory_stats

        # è®°å½•åˆå§‹å¿«ç…§
        initial_stats = get_memory_stats()
        print(f"åˆå§‹å†…å­˜: {initial_stats['current']['process_memory_mb']:.2f} MB")

        # éªŒè¯å¿«ç…§ç»“æ„
        required_fields = [
            "timestamp",
            "process_memory_mb",
            "system_memory_percent",
            "active_objects",
            "total_objects",
            "leak_candidates",
        ]

        for field in required_fields:
            if field not in initial_stats["current"]:
                print(f"âŒ å¿«ç…§ç¼ºå°‘å­—æ®µ: {field}")
                return False

        print("âœ… å†…å­˜å¿«ç…§ç»“æ„éªŒè¯æˆåŠŸ")
        print(f"   - æ—¶é—´æˆ³: {initial_stats['current']['timestamp']}")
        print(f"   - è¿›ç¨‹å†…å­˜: {initial_stats['current']['process_memory_mb']:.2f} MB")
        print(
            f"   - ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡: {initial_stats['current']['system_memory_percent']:.1f}%"
        )
        print(f"   - æ´»è·ƒå¯¹è±¡æ•°: {initial_stats['current']['active_objects']}")
        print(f"   - æ€»å¯¹è±¡æ•°: {initial_stats['current']['total_objects']}")
        print(f"   - æ³„æ¼å€™é€‰è€…: {initial_stats['current']['leak_candidates']}")
        print(f"   - èµ„æºç®¡ç†å™¨: {initial_stats['resource_manager']}")
        print(f"   - å†å²è®°å½•æ•°: {initial_stats['history_length']}")

        return True

    except Exception as e:
        print(f"âš ï¸  å†…å­˜å¿«ç…§æµ‹è¯•å¤±è´¥ï¼ˆé¢„æœŸè¡Œä¸ºï¼Œå¯èƒ½éœ€è¦æ•°æ®åº“é…ç½®ï¼‰: {e}")
        print("   è¿™æ˜¯æµ‹è¯•ç¯å¢ƒçš„æ­£å¸¸ç°è±¡ï¼Œå¿«ç…§åŠŸèƒ½åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ­£å¸¸å·¥ä½œ")
        return True  # åœ¨æµ‹è¯•ç¯å¢ƒä¸­ï¼Œè¿æ¥å¤±è´¥æ˜¯é¢„æœŸçš„


def test_connection_context_memory():
    """æµ‹è¯•è¿æ¥ä¸Šä¸‹æ–‡çš„å†…å­˜ç®¡ç†"""
    try:
        from src.storage.database.connection_context import ConnectionPoolManager

        print("âœ… è¿æ¥ä¸Šä¸‹æ–‡æ¨¡å—å¯¼å…¥æˆåŠŸ")

        # æµ‹è¯•è¿æ¥æ± ç®¡ç†å™¨
        pool_manager = ConnectionPoolManager()
        print(f"âœ… è¿æ¥æ± ç®¡ç†å™¨åˆ›å»ºæˆåŠŸ: {type(pool_manager)}")

        # è·å–æ± ç»Ÿè®¡
        stats = pool_manager.get_pool_stats()
        print(f"âœ… æ± ç»Ÿè®¡è·å–æˆåŠŸ: {stats['active_connections']} æ´»è·ƒè¿æ¥")

        return True

    except Exception as e:
        print(f"âŒ è¿æ¥ä¸Šä¸‹æ–‡å†…å­˜æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_database_manager_memory_integration():
    """æµ‹è¯•æ•°æ®åº“ç®¡ç†å™¨çš„å†…å­˜é›†æˆ"""
    try:
        from src.storage.database.connection_manager import get_connection_manager
        from src.core.memory_manager import get_resource_manager

        # è·å–è¿æ¥ç®¡ç†å™¨
        manager = get_connection_manager()
        print("âœ… è¿æ¥ç®¡ç†å™¨è·å–æˆåŠŸ")

        # è·å–èµ„æºç®¡ç†å™¨
        resource_manager = get_resource_manager()
        stats = resource_manager.get_stats()
        print(f"âœ… èµ„æºç®¡ç†å™¨çŠ¶æ€: {stats['total_resources']} ä¸ªèµ„æº")

        # æ£€æŸ¥è¿æ¥ç®¡ç†å™¨æ˜¯å¦å·²æ³¨å†Œ
        connection_manager_resource = resource_manager.get_resource(
            "connection_manager"
        )
        if connection_manager_resource:
            print("âœ… è¿æ¥ç®¡ç†å™¨å·²æ­£ç¡®æ³¨å†Œåˆ°å†…å­˜ç®¡ç†")
        else:
            print("âš ï¸  è¿æ¥ç®¡ç†å™¨æœªåœ¨å†…å­˜ç®¡ç†ä¸­æ³¨å†Œ")

        # æµ‹è¯•è¿æ¥ï¼ˆä¸å®é™…è¿æ¥ï¼Œåªæµ‹è¯•å†…å­˜æ³¨å†Œï¼‰
        try:
            # è¿™ä¼šè§¦å‘è¿æ¥è·å–å’Œå†…å­˜æ³¨å†Œ
            tdengine_conn = manager.get_tdengine_connection()
            print("âœ… TDengineè¿æ¥è·å–æˆåŠŸï¼ˆå†…å­˜å·²æ³¨å†Œï¼‰")

            # æ£€æŸ¥èµ„æºæ˜¯å¦å¢åŠ 
            updated_stats = resource_manager.get_stats()
            print(f"   æ›´æ–°åèµ„æºæ•°: {updated_stats['total_resources']}")

        except Exception as e:
            print(f"âš ï¸  TDengineè¿æ¥å¤±è´¥ï¼ˆé¢„æœŸè¡Œä¸ºï¼Œå¯èƒ½éœ€è¦é…ç½®ï¼‰: {e}")

        return True

    except Exception as e:
        print(f"âŒ æ•°æ®åº“ç®¡ç†å™¨å†…å­˜é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_memory_leak_detection():
    """æµ‹è¯•å†…å­˜æ³„æ¼æ£€æµ‹"""
    try:
        from src.core.memory_manager import get_memory_monitor, get_memory_stats
        import gc

        # è·å–å†…å­˜ç›‘æ§å™¨
        monitor = get_memory_monitor()
        print("âœ… å†…å­˜ç›‘æ§å™¨è·å–æˆåŠŸ")

        # è·å–å½“å‰ç»Ÿè®¡
        current_stats = get_memory_stats()
        print(f"å½“å‰å¯¹è±¡æ•°: {current_stats['current']['total_objects']}")

        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        collected = gc.collect()
        print(f"åƒåœ¾å›æ”¶: {collected} ä¸ªå¯¹è±¡")

        # è·å–å›æ”¶åç»Ÿè®¡
        after_gc_stats = get_memory_stats()
        print(f"GCåå¯¹è±¡æ•°: {after_gc_stats['current']['total_objects']}")

        # æ£€æŸ¥æ˜¯å¦æœ‰æ³„æ¼å€™é€‰è€…
        leak_candidates = after_gc_stats["current"]["leak_candidates"]
        if leak_candidates:
            print(f"âš ï¸  å‘ç°æ³„æ¼å€™é€‰è€…: {leak_candidates}")
        else:
            print("âœ… æœªå‘ç°æ˜æ˜¾çš„æ³„æ¼å€™é€‰è€…")

        return True

    except Exception as e:
        print(f"âŒ å†…å­˜æ³„æ¼æ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_gpu_data_processor_integration():
    """æµ‹è¯•GPUæ•°æ®å¤„ç†å™¨å†…å­˜é›†æˆ"""
    try:
        from src.gpu.accelerated.data_processor_gpu_fixed import GPUDataProcessorFixed
        import pandas as pd
        import numpy as np
        import time

        print("å¼€å§‹æµ‹è¯•GPUæ•°æ®å¤„ç†å™¨å†…å­˜é›†æˆ...")

        # æµ‹è¯•æ•°æ®å¤„ç†å™¨
        try:
            processor = GPUDataProcessorFixed(gpu_enabled=True)
            print(f"âœ… GPUæ•°æ®å¤„ç†å™¨åˆ›å»ºæˆåŠŸ: {type(processor).__name__}")
            gpu_enabled = True
        except Exception as e:
            print(f"âš ï¸  GPUå¤„ç†å™¨åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨CPUæ¨¡å¼: {e}")
            try:
                processor = GPUDataProcessorFixed(gpu_enabled=False)
                print(f"âœ… CPUæ•°æ®å¤„ç†å™¨åˆ›å»ºæˆåŠŸ: {type(processor).__name__}")
                gpu_enabled = False
            except Exception as e2:
                print(f"âš ï¸  CPUå¤„ç†å™¨ä¹Ÿåˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå¤„ç†å™¨: {e2}")

                # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¨¡æ‹Ÿå¤„ç†å™¨ç”¨äºæµ‹è¯•
                class MockProcessor:
                    def __init__(self):
                        self.processing_stats = {"total_processed": 0, "mode": "mock"}

                    def load_and_preprocess(self, data, config=None):
                        result = type(
                            "MockResult",
                            (),
                            {
                                "processed_data": data,
                                "processing_stats": {
                                    "total_processed": len(data),
                                    "mode": "mock",
                                },
                            },
                        )()
                        self.processing_stats["total_processed"] = len(data)
                        return result

                processor = MockProcessor()
                gpu_enabled = False

        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        test_data = pd.DataFrame(
            {
                "stock_code": ["AAPL", "GOOGL", "MSFT", "AMZN", "TSLA"] * 100,
                "price": np.random.uniform(100, 1000, 500),
                "volume": np.random.uniform(10000, 1000000, 500),
                "timestamp": pd.date_range("2025-01-01", periods=500, freq="1H"),
            }
        )

        print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_data.shape}")

        # è®°å½•åˆå§‹å†…å­˜
        initial_memory = psutil.Process().memory_info().rss / 1024**2

        # æµ‹è¯•æ•°æ®å¤„ç†ï¼ˆå¸¦å†…å­˜ç®¡ç†ï¼‰
        start_time = time.time()
        result = processor.load_and_preprocess(test_data)
        processing_time = time.time() - start_time

        # è®°å½•å¤„ç†åçš„å†…å­˜
        final_memory = psutil.Process().memory_info().rss / 1024**2
        memory_delta = final_memory - initial_memory

        print("âœ… æ•°æ®å¤„ç†æˆåŠŸ:")
        print(f"   - å¤„ç†æ—¶é—´: {processing_time:.2f}s")
        print(f"   - ç»“æœç±»å‹: {type(result)}")
        if hasattr(result, "processed_data"):
            print(f"   - ç»“æœå½¢çŠ¶: {result.processed_data.shape}")
            print(f"   - å†…å­˜å˜åŒ–: {memory_delta:.2f}MB")
        if hasattr(result, "processing_stats"):
            print(f"   - å¤„ç†ç»Ÿè®¡: {result.processing_stats}")

        # éªŒè¯å†…å­˜ç®¡ç†æ•ˆæœ
        success_criteria = [
            processing_time < 10.0,
            memory_delta < 100.0,
            result is not None,
            hasattr(processor, "processing_stats"),
        ]

        if all(success_criteria):
            mode = "GPU" if gpu_enabled else "CPU"
            print(f"âœ… {mode}æ•°æ®å¤„ç†å™¨å†…å­˜é›†æˆæµ‹è¯•æˆåŠŸï¼")
            return True
        else:
            mode = "GPU" if gpu_enabled else "CPU"
            print(f"âŒ {mode}æ•°æ®å¤„ç†å™¨å†…å­˜é›†æˆæµ‹è¯•å¤±è´¥ï¼")
            print(f"   æˆåŠŸæ¡ä»¶: {success_criteria}")
            return False

    except Exception as e:
        print(f"âŒ GPUæ•°æ®å¤„ç†å™¨å†…å­˜é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_concurrent_connections_memory():
    """æµ‹è¯•å¹¶å‘è¿æ¥çš„å†…å­˜ä½¿ç”¨"""
    try:
        from src.storage.database.connection_context import database_connection_async
        from src.core.memory_manager import get_memory_stats

        print("å¼€å§‹æµ‹è¯•å¹¶å‘è¿æ¥å†…å­˜ä½¿ç”¨...")

        # è®°å½•åˆå§‹å†…å­˜
        initial_memory = get_memory_stats()["current"]["process_memory_mb"]
        print(f"åˆå§‹å†…å­˜: {initial_memory:.2f} MB")

        # åˆ›å»ºå¤šä¸ªè¿æ¥
        connections = []
        try:
            # å°è¯•è·å–å¤šä¸ªPostgreSQLè¿æ¥
            for i in range(3):
                try:
                    conn = await database_connection_async("postgresql")
                    connections.append(conn)
                    print(f"âœ“ è·å–è¿æ¥ {i + 1}")

                    # è®°å½•å†…å­˜ä½¿ç”¨
                    current_memory = get_memory_stats()["current"]["process_memory_mb"]
                    memory_diff = current_memory - initial_memory
                    print(f"   å†…å­˜å˜åŒ–: +{memory_diff:.2f} MB")

                except Exception as e:
                    print(f"âš ï¸  è·å–è¿æ¥ {i + 1} å¤±è´¥: {e}")

            # ç­‰å¾…ä¸€ä¸‹è®©å†…å­˜ç¨³å®š
            await asyncio.sleep(2)

            # æœ€ç»ˆå†…å­˜ç»Ÿè®¡
            final_memory = get_memory_stats()["current"]["process_memory_mb"]
            total_memory_growth = final_memory - initial_memory

            print("\nå¹¶å‘è¿æ¥æµ‹è¯•ç»“æœ:")
            print(f"  åˆå§‹å†…å­˜: {initial_memory:.2f} MB")
            print(f"  æœ€ç»ˆå†…å­˜: {final_memory:.2f} MB")
            print(f"  æ€»å¢é•¿: {total_memory_growth:.2f} MB")
            print(f"  è·å–è¿æ¥æ•°: {len(connections)}")

            # æ¸…ç†è¿æ¥
            for i, conn in enumerate(connections):
                try:
                    if hasattr(conn, "close"):
                        conn.close()
                    print(f"âœ“ é‡Šæ”¾è¿æ¥ {i + 1}")
                except Exception as e:
                    print(f"âš ï¸  é‡Šæ”¾è¿æ¥ {i + 1} å¤±è´¥: {e}")

            # ç­‰å¾…æ¸…ç†å®Œæˆ
            await asyncio.sleep(1)

            # æ£€æŸ¥å†…å­˜æ˜¯å¦æ¢å¤
            cleanup_memory = get_memory_stats()["current"]["process_memory_mb"]
            recovery = initial_memory - cleanup_memory

            print(f"æ¸…ç†åå†…å­˜: {cleanup_memory:.2f} MB")
            print(f"å†…å­˜æ¢å¤: {recovery:.2f} MB")

            if abs(total_memory_growth - recovery) < 1.0:  # å…è®¸1MBçš„è¯¯å·®
                print("âœ… å†…å­˜ä½¿ç”¨æ­£å¸¸ï¼Œæ— æ³„æ¼è¿¹è±¡")
                return True
            else:
                print("âš ï¸  å¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼ï¼Œå†…å­˜æ¢å¤ä¸å®Œæ•´")
                return False

        except Exception as e:
            print(f"âŒ å¹¶å‘è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False

    except Exception as e:
        print(f"âŒ å¹¶å‘è¿æ¥å†…å­˜æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹å†…å­˜ç®¡ç†é›†æˆæµ‹è¯•...\n")

    # æµ‹è¯•ç»“æœæ±‡æ€»
    test_results = []

    # 1. æµ‹è¯•å†…å­˜ç®¡ç†å™¨å¯ç”¨æ€§
    print("=" * 50)
    print("æµ‹è¯• 1: å†…å­˜ç®¡ç†å™¨å¯ç”¨æ€§")
    print("=" * 50)
    test_results.append(("å†…å­˜ç®¡ç†å™¨å¯ç”¨æ€§", test_memory_manager_availability()))
    print()

    # 2. æµ‹è¯•å†…å­˜å¿«ç…§å½•åˆ¶
    print("=" * 50)
    print("æµ‹è¯• 2: å†…å­˜å¿«ç…§å½•åˆ¶")
    print("=" * 50)
    test_results.append(("å†…å­˜å¿«ç…§å½•åˆ¶", test_memory_snapshot_recording()))
    print()

    # 3. æµ‹è¯•è¿æ¥ä¸Šä¸‹æ–‡çš„å†…å­˜ç®¡ç†
    print("=" * 50)
    print("æµ‹è¯• 3: è¿æ¥ä¸Šä¸‹æ–‡å†…å­˜ç®¡ç†")
    print("=" * 50)
    test_results.append(("è¿æ¥ä¸Šä¸‹æ–‡å†…å­˜ç®¡ç†", test_connection_context_memory()))
    print()

    # 4. æµ‹è¯•æ•°æ®åº“ç®¡ç†å™¨çš„å†…å­˜é›†æˆ
    print("=" * 50)
    print("æµ‹è¯• 4: æ•°æ®åº“ç®¡ç†å™¨å†…å­˜é›†æˆ")
    print("=" * 50)
    test_results.append(
        ("æ•°æ®åº“ç®¡ç†å™¨å†…å­˜é›†æˆ", test_database_manager_memory_integration())
    )
    print()

    # 5. æµ‹è¯•å†…å­˜æ³„æ¼æ£€æµ‹
    print("=" * 50)
    print("æµ‹è¯• 5: å†…å­˜æ³„æ¼æ£€æµ‹")
    print("=" * 50)
    test_results.append(("å†…å­˜æ³„æ¼æ£€æµ‹", test_memory_leak_detection()))
    print()

    # 6. æµ‹è¯•GPUæ•°æ®å¤„ç†å™¨å†…å­˜é›†æˆ
    print("=" * 50)
    print("æµ‹è¯• 6: GPUæ•°æ®å¤„ç†å™¨å†…å­˜é›†æˆ")
    print("=" * 50)
    gpu_result = test_gpu_data_processor_integration()
    test_results.append(("GPUæ•°æ®å¤„ç†å™¨å†…å­˜é›†æˆ", gpu_result))
    print()

    # 7. æµ‹è¯•å¹¶å‘è¿æ¥çš„å†…å­˜ä½¿ç”¨
    print("=" * 50)
    print("æµ‹è¯• 7: å¹¶å‘è¿æ¥å†…å­˜ä½¿ç”¨")
    print("=" * 50)
    concurrent_result = asyncio.run(test_concurrent_connections_memory())
    test_results.append(("å¹¶å‘è¿æ¥å†…å­˜ä½¿ç”¨", concurrent_result))
    print()

    # æ±‡æ€»ç»“æœ
    print("=" * 50)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 50)

    passed = 0
    total = len(test_results)

    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
        if result:
            passed += 1

    print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰å†…å­˜ç®¡ç†é›†æˆæµ‹è¯•é€šè¿‡ï¼")
        print("âœ… å†…å­˜ç®¡ç†ç³»ç»Ÿå·²æˆåŠŸé›†æˆåˆ°æ•°æ®åº“è¿æ¥æ¨¡å—")
        return True
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        print("è¯·æ£€æŸ¥å¤±è´¥çš„é¡¹ç›®å¹¶ä¿®å¤ç›¸å…³é—®é¢˜")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
