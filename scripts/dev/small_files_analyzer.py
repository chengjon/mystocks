#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MyStocks ä»£ç ä¼˜åŒ– - å°æ–‡ä»¶åˆ†æè„šæœ¬
åˆ†æå’Œå¤„ç†å°äº50è¡Œçš„Pythonæ–‡ä»¶ï¼Œæå‡ºåˆå¹¶å»ºè®®

ä¼˜åŒ–ç­–ç•¥ï¼š
1. å°äº10è¡Œçš„æ–‡ä»¶ï¼šç›´æ¥åˆå¹¶åˆ°ç›¸å…³æ–‡ä»¶ä¸­
2. 10-30è¡Œçš„æ–‡ä»¶ï¼šè¯„ä¼°æ˜¯å¦éœ€è¦ç‹¬ç«‹æ–‡ä»¶
3. 30-50è¡Œçš„æ–‡ä»¶ï¼šæ ¹æ®å¤æ‚åº¦å†³å®šæ˜¯å¦ä¿ç•™

åˆ›å»ºæ—¥æœŸ: 2025-11-25
ç‰ˆæœ¬: 1.0.0
"""

import os
import re
from pathlib import Path
from typing import List, Dict, Tuple
from dataclasses import dataclass

@dataclass
class SmallFileInfo:
    path: Path
    line_count: int
    class_count: int
    function_count: int
    is_init_file: bool
    complexity_score: int

class SmallFilesAnalyzer:
    def __init__(self):
        self.project_root = Path("/opt/claude/mystocks_spec")
        self.src_path = self.project_root / "src"
        
    def count_lines(self, file_path: Path) -> int:
        """è®¡ç®—æ–‡ä»¶çš„è¡Œæ•°"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return len(f.readlines())
        except Exception:
            return 0
            
    def count_elements(self, content: str) -> Tuple[int, int]:
        """è®¡ç®—ç±»å’Œå‡½æ•°çš„æ•°é‡"""
        classes = len(re.findall(r'^class\s+\w+', content, re.MULTILINE))
        functions = len(re.findall(r'^def\s+\w+', content, re.MULTILINE))
        return classes, functions
        
    def calculate_complexity_score(self, line_count: int, class_count: int, function_count: int) -> int:
        """è®¡ç®—æ–‡ä»¶å¤æ‚åº¦è¯„åˆ†"""
        base_score = line_count
        
        # æ¯å¢åŠ ä¸€ä¸ªç±»ï¼Œå¤æ‚åº¦å¢åŠ 50åˆ†
        class_bonus = class_count * 50
        
        # æ¯å¢åŠ ä¸€ä¸ªå‡½æ•°ï¼Œå¤æ‚åº¦å¢åŠ 10åˆ†
        function_bonus = function_count * 10
        
        return base_score + class_bonus + function_bonus
        
    def analyze_small_files(self) -> List[SmallFileInfo]:
        """åˆ†ææ‰€æœ‰å°æ–‡ä»¶"""
        print("=" * 60)
        print("MyStocks å°æ–‡ä»¶åˆ†æ")
        print("=" * 60)
        
        small_files = []
        total_files = 0
        
        # éå†æ‰€æœ‰Pythonæ–‡ä»¶
        for py_file in self.src_path.rglob("*.py"):
            if "__pycache__" in str(py_file):
                continue
                
            total_files += 1
            line_count = self.count_lines(py_file)
            
            # åªåˆ†æå°äº50è¡Œçš„æ–‡ä»¶
            if line_count > 0 and line_count < 50:
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                    class_count, function_count = self.count_elements(content)
                    is_init_file = py_file.name == "__init__.py"
                    complexity_score = self.calculate_complexity_score(
                        line_count, class_count, function_count
                    )
                    
                    file_info = SmallFileInfo(
                        path=py_file,
                        line_count=line_count,
                        class_count=class_count,
                        function_count=function_count,
                        is_init_file=is_init_file,
                        complexity_score=complexity_score
                    )
                    
                    small_files.append(file_info)
                    
                except Exception as e:
                    print(f"   âš ï¸  åˆ†ææ–‡ä»¶å¤±è´¥ {py_file}: {e}")
                    
        print(f"ğŸ“Š æ€»æ–‡ä»¶æ•°: {total_files}")
        print(f"ğŸ“Š å°æ–‡ä»¶æ•°: {len(small_files)}")
        
        return small_files
        
    def categorize_small_files(self, small_files: List[SmallFileInfo]) -> Dict[str, List[SmallFileInfo]]:
        """å¯¹å°æ–‡ä»¶è¿›è¡Œåˆ†ç±»"""
        categories = {
            "tiny_files": [],      # < 10è¡Œ
            "small_files": [],     # 10-20è¡Œ
            "medium_files": [],    # 20-30è¡Œ
            "large_files": [],     # 30-50è¡Œ
            "init_files": []       # __init__.pyæ–‡ä»¶
        }
        
        for file_info in small_files:
            if file_info.is_init_file:
                categories["init_files"].append(file_info)
            elif file_info.line_count < 10:
                categories["tiny_files"].append(file_info)
            elif file_info.line_count < 20:
                categories["small_files"].append(file_info)
            elif file_info.line_count < 30:
                categories["medium_files"].append(file_info)
            else:
                categories["large_files"].append(file_info)
                
        return categories
        
    def print_category_analysis(self, categories: Dict[str, List[SmallFileInfo]]):
        """æ‰“å°åˆ†ç±»åˆ†æç»“æœ"""
        print(f"\nğŸ“‹ å°æ–‡ä»¶åˆ†ç±»åˆ†æ:")
        print("=" * 50)
        
        for category_name, files in categories.items():
            print(f"\nğŸ” {category_name.upper()} ({len(files)} ä¸ªæ–‡ä»¶):")
            
            if not files:
                print("   (æ— )")
                continue
                
            # æŒ‰æ–‡ä»¶å¤§å°æ’åº
            files.sort(key=lambda x: x.line_count)
            
            for file_info in files:
                relative_path = file_info.path.relative_to(self.project_root)
                print(f"   ğŸ“„ {relative_path}")
                print(f"      â””â”€ {file_info.line_count} è¡Œ, {file_info.class_count} ç±», {file_info.function_count} å‡½æ•°")
                
    def get_merge_recommendations(self, categories: Dict[str, List[SmallFileInfo]]) -> List[Tuple[SmallFileInfo, str]]:
        """è·å–åˆå¹¶å»ºè®®"""
        recommendations = []
        
        # æå°æ–‡ä»¶ï¼ˆ< 10è¡Œï¼‰å»ºè®®åˆå¹¶
        for file_info in categories["tiny_files"]:
            if not file_info.is_init_file:
                reason = f"æå°æ–‡ä»¶ï¼ˆ{file_info.line_count}è¡Œï¼‰ï¼Œå»ºè®®åˆå¹¶åˆ°åŒçº§ç›®å½•çš„ç›¸å…³æ–‡ä»¶ä¸­"
                recommendations.append((file_info, reason))
                
        # __init__.pyæ–‡ä»¶ä¿ç•™ï¼Œä¸å»ºè®®åˆå¹¶
        for file_info in categories["init_files"]:
            if file_info.line_count < 5:  # å¦‚æœ__init__.pyå¤ªå°ï¼Œå¯ä»¥è€ƒè™‘ç®€åŒ–
                reason = f"è¿‡å°çš„__init__.pyæ–‡ä»¶ï¼ˆ{file_info.line_count}è¡Œï¼‰ï¼Œå¯è€ƒè™‘ç®€åŒ–æˆ–ç§»é™¤"
                recommendations.append((file_info, reason))
                
        # å¤æ‚å°æ–‡ä»¶è¯„ä¼°
        for file_info in categories["small_files"] + categories["medium_files"]:
            if file_info.complexity_score > 200:  # é«˜å¤æ‚åº¦å°æ–‡ä»¶åº”è¯¥ä¿ç•™
                reason = f"é«˜å¤æ‚åº¦å°æ–‡ä»¶ï¼ˆ{file_info.complexity_score}åˆ†ï¼‰ï¼Œå»ºè®®ä¿ç•™"
            else:
                reason = f"ä¸­ç­‰å°æ–‡ä»¶ï¼ˆ{file_info.line_count}è¡Œï¼‰ï¼Œå¯è€ƒè™‘åˆå¹¶åˆ°ç›¸å…³æ–‡ä»¶ä¸­"
                recommendations.append((file_info, reason))
                
        return recommendations
        
    def print_recommendations(self, recommendations: List[Tuple[SmallFileInfo, str]]):
        """æ‰“å°åˆå¹¶å»ºè®®"""
        print(f"\nğŸ’¡ åˆå¹¶å»ºè®® ({len(recommendations)} æ¡):")
        print("=" * 50)
        
        for file_info, reason in recommendations:
            relative_path = file_info.path.relative_to(self.project_root)
            print(f"\nğŸ“„ æ–‡ä»¶: {relative_path}")
            print(f"   ğŸ“Š å¤§å°: {file_info.line_count} è¡Œ, å¤æ‚åº¦: {file_info.complexity_score}")
            print(f"   ğŸ’­ å»ºè®®: {reason}")
            
    def calculate_optimization_potential(self, categories: Dict[str, List[SmallFileInfo]]) -> Dict:
        """è®¡ç®—ä¼˜åŒ–æ½œåŠ›"""
        total_small_lines = sum(f.line_count for files in categories.values() for f in files)
        total_files = sum(len(files) for files in categories.values())
        
        optimization_potential = {
            "total_small_files": total_files,
            "total_small_lines": total_small_lines,
            "potential_file_reduction": 0,
            "potential_line_reduction": 0,
            "reduction_percentage": 0
        }
        
        # è®¡ç®—å¯ä»¥åˆ é™¤çš„æ–‡ä»¶æ•°ï¼ˆä¸»è¦æ˜¯tiny fileså’Œè¿‡å°çš„initæ–‡ä»¶ï¼‰
        deletable_files = len(categories["tiny_files"])
        deletable_lines = sum(f.line_count for f in categories["tiny_files"])
        
        # è¿‡å°çš„__init__.pyä¹Ÿå¯ä»¥è€ƒè™‘åˆ é™¤
        small_init_files = [f for f in categories["init_files"] if f.line_count < 5]
        deletable_files += len(small_init_files)
        deletable_lines += sum(f.line_count for f in small_init_files)
        
        optimization_potential["potential_file_reduction"] = deletable_files
        optimization_potential["potential_line_reduction"] = deletable_lines
        optimization_potential["reduction_percentage"] = (deletable_lines / total_small_lines * 100) if total_small_lines > 0 else 0
        
        return optimization_potential
        
    def print_optimization_summary(self, optimization_potential: Dict):
        """æ‰“å°ä¼˜åŒ–æ€»ç»“"""
        print(f"\nğŸ“ˆ ä¼˜åŒ–æ½œåŠ›åˆ†æ:")
        print("=" * 50)
        print(f"   ğŸ“Š å°æ–‡ä»¶æ€»æ•°: {optimization_potential['total_small_files']} ä¸ª")
        print(f"   ğŸ“Š å°æ–‡ä»¶è¡Œæ•°: {optimization_potential['total_small_lines']} è¡Œ")
        print(f"   ğŸ¯ å¯å‡å°‘æ–‡ä»¶: {optimization_potential['potential_file_reduction']} ä¸ª")
        print(f"   ğŸ¯ å¯å‡å°‘è¡Œæ•°: {optimization_potential['potential_line_reduction']} è¡Œ")
        print(f"   ğŸ“ˆ å‡å°‘æ¯”ä¾‹: {optimization_potential['reduction_percentage']:.1f}%")
        
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        small_files = self.analyze_small_files()
        categories = self.categorize_small_files(small_files)
        recommendations = self.get_merge_recommendations(categories)
        optimization_potential = self.calculate_optimization_potential(categories)
        
        self.print_category_analysis(categories)
        self.print_recommendations(recommendations)
        self.print_optimization_summary(optimization_potential)
        
        print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("   1. ä¼˜å…ˆå¤„ç†æå°æ–‡ä»¶ï¼ˆ<10è¡Œï¼‰çš„åˆå¹¶")
        print("   2. è¯„ä¼°å¹¶ç®€åŒ–è¿‡å°çš„__init__.pyæ–‡ä»¶")
        print("   3. è€ƒè™‘å°†ç›¸å…³åŠŸèƒ½åˆå¹¶åˆ°åŒä¸€æ–‡ä»¶ä¸­")
        print("   4. ä¿æŒä»£ç ç»“æ„æ¸…æ™°ï¼Œé¿å…è¿‡åº¦åˆå¹¶")
        
        return {
            "small_files": small_files,
            "categories": categories,
            "recommendations": recommendations,
            "optimization_potential": optimization_potential
        }

if __name__ == "__main__":
    analyzer = SmallFilesAnalyzer()
    results = analyzer.run_analysis()
