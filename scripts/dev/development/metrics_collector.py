#!/usr/bin/env python3
"""
CLIæ€§èƒ½æŒ‡æ ‡æ”¶é›†è„šæœ¬

æ”¶é›†å’Œåˆ†æCLIçš„æ€§èƒ½æŒ‡æ ‡ï¼ŒåŒ…æ‹¬ï¼š
- ä»»åŠ¡æ‰§è¡ŒæŒ‡æ ‡ï¼ˆå®Œæˆæ—¶é—´ã€é˜»å¡æ—¶é—´ï¼‰
- èµ„æºä½¿ç”¨æŒ‡æ ‡ï¼ˆå†…å­˜ã€CPUï¼‰
- ä»£ç è´¨é‡æŒ‡æ ‡ï¼ˆESLintã€Pylintã€æµ‹è¯•è¦†ç›–ç‡ï¼‰
- åè°ƒæ•ˆç‡æŒ‡æ ‡

Usage:
    # æ”¶é›†æ‰€æœ‰CLIçš„æŒ‡æ ‡
    python scripts/dev/metrics_collector.py --all

    # ç”ŸæˆMETRICS.mdæŠ¥å‘Š
    python scripts/dev/metrics_collector.py --generate-report
"""

import os
import json
import argparse
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List


class MetricsCollector:
    """æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self, clis_dir: str = "CLIS"):
        self.clis_dir = Path(clis_dir)
        self.cli_list = self._discover_clis()
        self.metrics_data = {}

    def _discover_clis(self) -> List[str]:
        """å‘ç°æ‰€æœ‰CLIç›®å½•"""
        clis = []
        for item in self.clis_dir.iterdir():
            if item.is_dir() and not item.name.startswith('_'):
                if (item / "STATUS.md").exists():
                    clis.append(item.name)
        return sorted(clis)

    def collect_task_metrics(self, cli_name: str) -> Dict:
        """æ”¶é›†ä»»åŠ¡æ‰§è¡ŒæŒ‡æ ‡"""
        task_file = self.clis_dir / cli_name / "TASK.md"

        if not task_file.exists():
            return {
                "total_tasks": 0,
                "completed_tasks": 0,
                "in_progress_tasks": 0,
                "pending_tasks": 0,
                "completion_rate": 0.0,
                "avg_completion_hours": 0.0
            }

        content = task_file.read_text(encoding='utf-8')
        total_tasks = 0
        completed_tasks = 0
        in_progress_tasks = 0
        pending_tasks = 0
        total_hours = 0
        completed_hours = 0

        task_pattern = r'- \[(.*?)\] (task-[\d.]+)[:ï¼š](.*?)(?:\n|$)'
        for match in re.finditer(task_pattern, content):
            total_tasks += 1
            status = match.group(1)

            if status.lower() in ['x', 'âœ…', 'done', 'å®Œæˆ']:
                completed_tasks += 1
            elif status.lower() in ['>', 'ğŸ”„', 'wip', 'è¿›è¡Œä¸­']:
                in_progress_tasks += 1
            else:
                pending_tasks += 1

            task_text = match.group(3)
            hours_match = re.search(r'(\d+(?:\.\d+)?)\s*[hå°æ—¶]', task_text)
            if hours_match:
                hours = float(hours_match.group(1))
                total_hours += hours
                if status.lower() in ['x', 'âœ…', 'done', 'å®Œæˆ']:
                    completed_hours += hours

        completion_rate = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0.0
        avg_completion_hours = (completed_hours / completed_tasks) if completed_tasks > 0 else 0.0

        return {
            "total_tasks": total_tasks,
            "completed_tasks": completed_tasks,
            "in_progress_tasks": in_progress_tasks,
            "pending_tasks": pending_tasks,
            "completion_rate": completion_rate,
            "estimated_total_hours": total_hours,
            "completed_hours": completed_hours,
            "remaining_hours": total_hours - completed_hours,
            "avg_completion_hours": avg_completion_hours
        }

    def collect_resource_metrics(self, cli_name: str) -> Dict:
        """æ”¶é›†èµ„æºä½¿ç”¨æŒ‡æ ‡"""
        cli_dir = self.clis_dir / cli_name
        total_files = 0
        total_size_kb = 0

        for root, dirs, files in os.walk(cli_dir):
            dirs[:] = [d for d in dirs if d not in ['__pycache__', 'node_modules', '.git']]
            for file in files:
                file_path = Path(root) / file
                if file_path.is_file():
                    total_files += 1
                    try:
                        total_size_kb += file_path.stat().st_size / 1024
                    except:
                        pass

        mailbox_count = len(list((cli_dir / "mailbox").glob('*'))) if (cli_dir / "mailbox").exists() else 0
        archive_count = len(list((cli_dir / "archive").glob('*'))) if (cli_dir / "archive").exists() else 0

        return {
            "total_files": total_files,
            "total_size_kb": round(total_size_kb, 2),
            "total_size_mb": round(total_size_kb / 1024, 2),
            "mailbox_messages": mailbox_count,
            "archived_messages": archive_count,
            "archive_ratio": round(archive_count / (mailbox_count + archive_count) * 100, 1) if (mailbox_count + archive_count) > 0 else 0.0
        }

    def collect_quality_metrics(self, cli_name: str) -> Dict:
        """æ”¶é›†ä»£ç è´¨é‡æŒ‡æ ‡"""
        cli_dir = self.clis_dir / cli_name
        metrics = {
            "has_rules": False,
            "has_status": False,
            "has_config": False,
            "rule_lines": 0,
            "documentation_completeness": 0.0
        }

        if (cli_dir / "RULES.md").exists():
            metrics["has_rules"] = True
            metrics["rule_lines"] = len((cli_dir / "RULES.md").read_text(encoding='utf-8').split('\n'))

        if (cli_dir / "STATUS.md").exists():
            metrics["has_status"] = True

        if (cli_dir / ".cli_config").exists():
            metrics["has_config"] = True

        required_files = ["TASK.md", "RULES.md", "STATUS.md"]
        optional_files = ["REPORT.md", ".cli_config", "watcher.log"]
        existing_required = sum(1 for f in required_files if (cli_dir / f).exists())
        existing_optional = sum(1 for f in optional_files if (cli_dir / f).exists())

        metrics["documentation_completeness"] = round(
            (existing_required / len(required_files) * 70) +
            (existing_optional / len(optional_files) * 30),
            1
        )

        return metrics

    def collect_coordination_metrics(self) -> Dict:
        """æ”¶é›†åè°ƒæ•ˆç‡æŒ‡æ ‡"""
        coord_log = self.clis_dir / "SHARED" / "COORDINATION_LOG.md"

        if not coord_log.exists():
            return {
                "total_coordinations": 0,
                "coordinations_today": 0,
                "last_coordination": None,
                "avg_coordination_interval_hours": 0.0
            }

        content = coord_log.read_text(encoding='utf-8')
        coord_sections = re.findall(r'## è‡ªåŠ¨åè°ƒ:', content)
        total_coordinations = len(coord_sections)

        today = datetime.now().strftime('%Y-%m-%d')
        coordinations_today = len(re.findall(rf'{today}', content))

        last_coord_match = re.search(r'(\d{{4}}-\d{{2}}-\d{{2}} \d{{2}}:\d{{2}})', content[-500:])
        last_coordination = last_coord_match.group(1) if last_coord_match else None

        return {
            "total_coordinations": total_coordinations,
            "coordinations_today": coordinations_today,
            "last_coordination": last_coordination,
            "coordination_activity": "High" if coordinations_today >= 3 else "Medium" if coordinations_today >= 1 else "Low"
        }

    def collect_all_metrics(self) -> Dict:
        """æ”¶é›†æ‰€æœ‰CLIçš„æŒ‡æ ‡"""
        all_metrics = {
            "generated_at": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "clis": {}
        }

        for cli in self.cli_list:
            all_metrics["clis"][cli] = {
                "tasks": self.collect_task_metrics(cli),
                "resources": self.collect_resource_metrics(cli),
                "quality": self.collect_quality_metrics(cli)
            }

        all_metrics["coordination"] = self.collect_coordination_metrics()
        all_metrics["summary"] = self._calculate_summary(all_metrics)

        return all_metrics

    def _calculate_summary(self, metrics: Dict) -> Dict:
        """è®¡ç®—æ±‡æ€»ç»Ÿè®¡"""
        summary = {
            "total_tasks": 0,
            "total_completed": 0,
            "overall_completion_rate": 0.0,
            "active_clis": 0,
            "total_files": 0,
            "total_size_mb": 0.0
        }

        for cli_data in metrics["clis"].values():
            task_data = cli_data["tasks"]
            resource_data = cli_data["resources"]

            summary["total_tasks"] += task_data["total_tasks"]
            summary["total_completed"] += task_data["completed_tasks"]
            summary["total_files"] += resource_data["total_files"]
            summary["total_size_mb"] += resource_data["total_size_mb"]

            if task_data["in_progress_tasks"] > 0 or task_data["pending_tasks"] > 0:
                summary["active_clis"] += 1

        if summary["total_tasks"] > 0:
            summary["overall_completion_rate"] = round(
                summary["total_completed"] / summary["total_tasks"] * 100,
                1
            )

        return summary

    def generate_metrics_report(self) -> str:
        """ç”ŸæˆMETRICS.mdæŠ¥å‘Š"""
        metrics = self.collect_all_metrics()

        lines = []
        lines.append("# CLIæ€§èƒ½æŒ‡æ ‡æŠ¥å‘Š")
        lines.append("")
        lines.append(f"**ç”Ÿæˆæ—¶é—´**: {metrics['generated_at']}")
        lines.append(f"**ç›‘æ§CLIæ•°é‡**: {len(metrics['clis'])}")
        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append("## ğŸ“Š æ€»ä½“æ€§èƒ½æŒ‡æ ‡")
        lines.append("")
        lines.append("### ä»»åŠ¡æ‰§è¡Œç»Ÿè®¡")
        lines.append(f"- **æ€»ä»»åŠ¡æ•°**: {metrics['summary']['total_tasks']}")
        lines.append(f"- **å·²å®Œæˆ**: {metrics['summary']['total_completed']}")
        lines.append(f"- **æ€»ä½“å®Œæˆç‡**: {metrics['summary']['overall_completion_rate']}%")
        lines.append(f"- **æ´»è·ƒCLI**: {metrics['summary']['active_clis']}")
        lines.append("")
        lines.append("### èµ„æºä½¿ç”¨ç»Ÿè®¡")
        lines.append(f"- **æ€»æ–‡ä»¶æ•°**: {metrics['summary']['total_files']}")
        lines.append(f"- **æ€»å­˜å‚¨**: {metrics['summary']['total_size_mb']:.2f} MB")
        lines.append("")
        lines.append("### åè°ƒæ´»åŠ¨")
        lines.append(f"- **æ€»åè°ƒæ¬¡æ•°**: {metrics['coordination']['total_coordinations']}")
        lines.append(f"- **ä»Šæ—¥åè°ƒ**: {metrics['coordination']['coordinations_today']}")
        lines.append(f"- **åè°ƒæ´»è·ƒåº¦**: {metrics['coordination']['coordination_activity']}")

        if metrics['coordination']['last_coordination']:
            lines.append("")
            lines.append(f"- **æœ€ååè°ƒ**: {metrics['coordination']['last_coordination']}")

        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append("## ğŸ“ˆ å„CLIè¯¦ç»†æŒ‡æ ‡")
        lines.append("")

        for cli, cli_metrics in metrics["clis"].items():
            lines.append(f"### {cli.upper()} CLI")
            lines.append("")

            task_data = cli_metrics["tasks"]
            lines.append("#### ä»»åŠ¡æ‰§è¡Œ")
            lines.append(f"- **ä»»åŠ¡æ€»æ•°**: {task_data['total_tasks']}")
            lines.append(f"- **å®Œæˆ**: {task_data['completed_tasks']} | **è¿›è¡Œä¸­**: {task_data['in_progress_tasks']} | **å¾…å¼€å§‹**: {task_data['pending_tasks']}")
            lines.append(f"- **å®Œæˆç‡**: {task_data['completion_rate']:.1f}%")
            lines.append(f"- **é¢„è®¡æ€»å·¥æ—¶**: {task_data['estimated_total_hours']:.1f}å°æ—¶")
            lines.append(f"- **å·²å®Œæˆå·¥æ—¶**: {task_data['completed_hours']:.1f}å°æ—¶")
            lines.append(f"- **å‰©ä½™å·¥æ—¶**: {task_data['remaining_hours']:.1f}å°æ—¶")
            lines.append("")

            resource_data = cli_metrics["resources"]
            lines.append("#### èµ„æºä½¿ç”¨")
            lines.append(f"- **æ–‡ä»¶æ•°**: {resource_data['total_files']}")
            lines.append(f"- **å­˜å‚¨å¤§å°**: {resource_data['total_size_mb']:.2f} MB")
            lines.append(f"- **Mailboxæ¶ˆæ¯**: {resource_data['mailbox_messages']}")
            lines.append(f"- **å·²å½’æ¡£**: {resource_data['archived_messages']} ({resource_data['archive_ratio']}%)")
            lines.append("")

            quality_data = cli_metrics["quality"]
            lines.append("#### æ–‡æ¡£è´¨é‡")
            lines.append(f"- **æ–‡æ¡£å®Œæ•´æ€§**: {quality_data['documentation_completeness']}%")
            lines.append(f"- **è§„åˆ™æ–‡ä»¶**: {'âœ…' if quality_data['has_rules'] else 'âŒ'} ({quality_data['rule_lines']}è¡Œ)")
            lines.append(f"- **é…ç½®æ–‡ä»¶**: {'âœ…' if quality_data['has_config'] else 'âŒ'}")
            lines.append("")
            lines.append("---")
            lines.append("")

        lines.append("## ğŸ“‰ æ€§èƒ½åˆ†æ")
        lines.append("")
        lines.append("### ğŸ¯ é«˜æ•ˆæŒ‡æ ‡")
        lines.append("")

        best_cli = max(metrics["clis"].items(), key=lambda x: x[1]["tasks"]["completion_rate"])
        lines.append(f"**æœ€ä½³ä»»åŠ¡å®Œæˆç‡**: {best_cli[0].upper()} CLI ({best_cli[1]['tasks']['completion_rate']:.1f}%)")

        best_docs = max(metrics["clis"].items(), key=lambda x: x[1]["quality"]["documentation_completeness"])
        lines.append(f"**æœ€ä½³æ–‡æ¡£è´¨é‡**: {best_docs[0].upper()} CLI ({best_docs[1]['quality']['documentation_completeness']}%)")

        lines.append("")
        lines.append("### âš ï¸ éœ€è¦å…³æ³¨")
        lines.append("")

        for cli, cli_metrics in metrics["clis"].items():
            if cli_metrics["tasks"]["total_tasks"] == 0:
                lines.append(f"- **{cli.upper()} CLI**: æ— ä»»åŠ¡åˆ†é…")

        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append("## ğŸ’¡ ä¼˜åŒ–å»ºè®®")
        lines.append("")
        lines.append("åŸºäºå½“å‰æŒ‡æ ‡ï¼Œå»ºè®®å…³æ³¨ä»¥ä¸‹æ–¹é¢ï¼š")
        lines.append("")
        lines.append("1. **ä»»åŠ¡æ‰§è¡Œæ•ˆç‡**: ç›‘æ§ä»»åŠ¡å®Œæˆæ—¶é—´ï¼ŒåŠæ—¶è¯†åˆ«é˜»å¡é—®é¢˜")
        lines.append("2. **æ–‡æ¡£ç»´æŠ¤**: å®šæœŸæ›´æ–°STATUS.mdå’ŒREPORT.md")
        lines.append("3. **èµ„æºç®¡ç†**: å®šæœŸæ¸…ç†archiveç›®å½•ï¼Œé¿å…æ–‡ä»¶å †ç§¯")
        lines.append("4. **åè°ƒä¼˜åŒ–**: æé«˜åè°ƒé¢‘ç‡ï¼ŒåŠæ—¶å‘ç°å’Œè§£å†³é—®é¢˜")
        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append(f"**æŠ¥å‘Šç”Ÿæˆ**: {metrics['generated_at']}")
        lines.append("**è„šæœ¬**: `scripts/dev/metrics_collector.py`")

        return '\n'.join(lines)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='CLIæ€§èƒ½æŒ‡æ ‡æ”¶é›†å·¥å…·')
    parser.add_argument('--cli', type=str, help='æ”¶é›†æŒ‡å®šCLIçš„æŒ‡æ ‡')
    parser.add_argument('--all', action='store_true', help='æ”¶é›†æ‰€æœ‰CLIçš„æŒ‡æ ‡')
    parser.add_argument('--generate-report', action='store_true', help='ç”ŸæˆMETRICS.mdæŠ¥å‘Š')
    parser.add_argument('--export-json', type=str, help='å¯¼å‡ºJSONæ ¼å¼åˆ°æŒ‡å®šæ–‡ä»¶')
    parser.add_argument('--clis-dir', default='CLIS', help='CLIç›®å½•è·¯å¾„')

    args = parser.parse_args()

    collector = MetricsCollector(args.clis_dir)

    if args.generate_report:
        print("ğŸ“Š æ­£åœ¨ç”Ÿæˆæ€§èƒ½æŒ‡æ ‡æŠ¥å‘Š...")
        report = collector.generate_metrics_report()

        output_file = Path(args.clis_dir) / "main" / "METRICS.md"
        output_file.parent.mkdir(parents=True, exist_ok=True)
        output_file.write_text(report, encoding='utf-8')

        print(f"âœ… æŒ‡æ ‡æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
        return

    if args.export_json:
        print("ğŸ“Š æ­£åœ¨å¯¼å‡ºæŒ‡æ ‡æ•°æ®...")
        metrics = collector.collect_all_metrics()

        output_file = Path(args.export_json)
        output_file.write_text(json.dumps(metrics, indent=2, ensure_ascii=False), encoding='utf-8')

        print(f"âœ… JSONæ•°æ®å·²å¯¼å‡º: {output_file}")
        return

    if args.cli or args.all:
        cli_list = [args.cli] if args.cli else collector.cli_list

        print(f"\n{'='*70}")
        print("ğŸ“Š CLIæ€§èƒ½æŒ‡æ ‡")
        print(f"{'='*70}\n")

        for cli in cli_list:
            task_metrics = collector.collect_task_metrics(cli)
            resource_metrics = collector.collect_resource_metrics(cli)
            quality_metrics = collector.collect_quality_metrics(cli)

            print(f"### {cli.upper()} CLI")
            print(f"ä»»åŠ¡: {task_metrics['completed_tasks']}/{task_metrics['total_tasks']} ({task_metrics['completion_rate']:.1f}%)")
            print(f"å­˜å‚¨: {resource_metrics['total_size_mb']:.2f} MB ({resource_metrics['total_files']} æ–‡ä»¶)")
            print(f"æ–‡æ¡£: {quality_metrics['documentation_completeness']}% å®Œæ•´")
            print()

    else:
        parser.print_help()


if __name__ == '__main__':
    main()
