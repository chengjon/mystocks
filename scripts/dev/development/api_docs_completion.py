#!/usr/bin/env python3
"""
APIæ–‡æ¡£å®Œæ•´æ€§æ£€æŸ¥å’Œè¡¥å……å·¥å…·
API Documentation Completion Tool

Phase 6-3: è¡¥å……APIæ–‡æ¡£å®Œæ•´æ€§

åŠŸèƒ½ç‰¹æ€§:
- æ‰«ææ‰€æœ‰APIç«¯ç‚¹
- æ£€æŸ¥æ–‡æ¡£å®Œæ•´æ€§
- ç”Ÿæˆç¼ºå¤±çš„APIæ–‡æ¡£
- æ›´æ–°OpenAPIè§„èŒƒ
- åˆ›å»ºAPIä½¿ç”¨ç¤ºä¾‹
- ç”Ÿæˆæ–‡æ¡£è¦†ç›–ç‡æŠ¥å‘Š

Author: Claude Code
Date: 2025-11-13
"""

import json
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import ast
from dataclasses import dataclass


@dataclass
class APIEndpoint:
    """APIç«¯ç‚¹ä¿¡æ¯"""

    file_path: str
    function_name: str
    http_method: str
    path: str
    summary: Optional[str]
    description: Optional[str]
    parameters: List[Dict[str, Any]]
    responses: Dict[str, Any]
    has_docstring: bool
    docstring_quality: str  # excellent/good/fair/poor/missing


@dataclass
class DocumentationCoverage:
    """æ–‡æ¡£è¦†ç›–ç‡ç»Ÿè®¡"""

    total_endpoints: int
    documented_endpoints: int
    partially_documented: int
    undocumented: int
    coverage_percentage: float
    missing_endpoints: List[str]
    quality_distribution: Dict[str, int]


class APIDocumentationAnalyzer:
    """APIæ–‡æ¡£åˆ†æå™¨"""

    def __init__(self, api_directory: str):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            api_directory: APIç›®å½•è·¯å¾„
        """
        self.api_directory = Path(api_directory)
        self.endpoints: List[APIEndpoint] = []
        self.coverage_stats = None

    def scan_api_endpoints(self) -> List[APIEndpoint]:
        """
        æ‰«ææ‰€æœ‰APIç«¯ç‚¹

        Returns:
            APIç«¯ç‚¹åˆ—è¡¨
        """
        print("ğŸ” æ‰«æAPIç«¯ç‚¹...")

        for file_path in self.api_directory.rglob("*.py"):
            if file_path.name.startswith("_"):
                continue

            try:
                endpoints = self._extract_endpoints_from_file(file_path)
                self.endpoints.extend(endpoints)
            except Exception as e:
                print(f"âš ï¸ æ‰«ææ–‡ä»¶å¤±è´¥: {file_path} - {e}")

        print(f"âœ… å‘ç° {len(self.endpoints)} ä¸ªAPIç«¯ç‚¹")
        return self.endpoints

    def _extract_endpoints_from_file(self, file_path: Path) -> List[APIEndpoint]:
        """ä»æ–‡ä»¶ä¸­æå–APIç«¯ç‚¹"""
        endpoints = []

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # è§£æAST
            tree = ast.parse(content)

            for node in ast.walk(tree):
                # æ£€æŸ¥æ™®é€šå‡½æ•°å’Œå¼‚æ­¥å‡½æ•°
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    endpoint = self._analyze_function(node, file_path, content)
                    if endpoint:
                        endpoints.append(endpoint)

        except Exception as e:
            print(f"âš ï¸ è§£ææ–‡ä»¶å¤±è´¥: {file_path} - {e}")

        return endpoints

    def _analyze_function(
        self, node: ast.AST, file_path: Path, content: str
    ) -> Optional[APIEndpoint]:
        """åˆ†æå‡½æ•°ï¼Œæå–APIä¿¡æ¯"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯APIè·¯ç”±å‡½æ•°
        if not self._is_api_function(node):
            return None

        # æå–å‡½æ•°ä¿¡æ¯
        http_method, path = self._extract_route_info(node, content)
        if not http_method or not path:
            return None

        # åˆ†ææ–‡æ¡£å­—ç¬¦ä¸²
        docstring_info = self._analyze_docstring(node)

        # æå–å‚æ•°ä¿¡æ¯
        parameters = self._extract_parameters(node)

        # æå–å“åº”ä¿¡æ¯
        responses = self._extract_responses(node, content)

        return APIEndpoint(
            file_path=str(file_path.relative_to(self.api_directory)),
            function_name=node.name,
            http_method=http_method,
            path=path,
            summary=docstring_info["summary"],
            description=docstring_info["description"],
            parameters=parameters,
            responses=responses,
            has_docstring=docstring_info["has_docstring"],
            docstring_quality=docstring_info["quality"],
        )

    def _is_api_function(self, node: ast.FunctionDef) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯APIè·¯ç”±å‡½æ•°"""
        # æŸ¥æ‰¾@routerè£…é¥°å™¨
        for decorator in node.decorator_list:
            if isinstance(decorator, ast.Call):
                if isinstance(decorator.func, ast.Attribute):
                    # æ£€æŸ¥ @router.get(), @router.post() ç­‰
                    if decorator.func.attr in ["get", "post", "put", "delete", "patch"]:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯routerå®ä¾‹çš„è°ƒç”¨
                        if isinstance(decorator.func.value, ast.Name):
                            if decorator.func.value.id == "router":
                                return True
                elif isinstance(decorator.func, ast.Name):
                    if decorator.func.id == "router":
                        return True
        return False

    def _extract_route_info(
        self, node: ast.FunctionDef, content: str
    ) -> Tuple[Optional[str], Optional[str]]:
        """æå–è·¯ç”±ä¿¡æ¯"""
        http_method = None
        path = None

        # æŸ¥æ‰¾è£…é¥°å™¨
        for decorator in node.decorator_list:
            if isinstance(decorator, ast.Call):
                if isinstance(decorator.func, ast.Attribute):
                    # æ£€æŸ¥ @router.get(...) æ¨¡å¼
                    method = decorator.func.attr
                    if method in ["get", "post", "put", "delete", "patch"]:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯routerå®ä¾‹
                        if isinstance(decorator.func.value, ast.Name):
                            if decorator.func.value.id == "router":
                                http_method = method.upper()
                                if decorator.args:
                                    if isinstance(decorator.args[0], ast.Constant):
                                        path = decorator.args[0].value
                                break

        return http_method, path

    def _analyze_docstring(self, node: ast.FunctionDef) -> Dict[str, Any]:
        """åˆ†ææ–‡æ¡£å­—ç¬¦ä¸²"""
        if (
            not node.body
            or not isinstance(node.body[0], ast.Expr)
            or not isinstance(node.body[0].value, ast.Constant)
        ):
            return {
                "has_docstring": False,
                "summary": None,
                "description": None,
                "quality": "missing",
            }

        docstring = node.body[0].value.value

        # ç®€å•åˆ†ææ–‡æ¡£å­—ç¬¦ä¸²è´¨é‡
        lines = docstring.split("\n")
        summary = lines[0].strip() if lines else None

        # åˆ¤æ–­è´¨é‡
        if not docstring.strip():
            quality = "missing"
        elif len(docstring) < 50:
            quality = "poor"
        elif len(docstring) < 200:
            quality = "fair"
        elif len(docstring) < 500:
            quality = "good"
        else:
            quality = "excellent"

        return {
            "has_docstring": bool(docstring.strip()),
            "summary": summary,
            "description": docstring,
            "quality": quality,
        }

    def _extract_parameters(self, node: ast.FunctionDef) -> List[Dict[str, Any]]:
        """æå–å‚æ•°ä¿¡æ¯"""
        parameters = []

        for arg in node.args.args:
            if arg.arg in ["self", "cls"]:
                continue

            param_info = {
                "name": arg.arg,
                "type": "unknown",
                "required": True,
                "description": None,
            }

            # ç®€å•çš„ç±»å‹æ¨æ–­
            if hasattr(node, "returns") and node.returns:
                if isinstance(node.returns, ast.Name):
                    param_info["type"] = node.returns.id

            parameters.append(param_info)

        return parameters

    def _extract_responses(self, node: ast.FunctionDef, content: str) -> Dict[str, Any]:
        """æå–å“åº”ä¿¡æ¯"""
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œå®é™…ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„åˆ†æ
        return {"200": {"description": "Success"}}

    def calculate_coverage(self) -> DocumentationCoverage:
        """è®¡ç®—æ–‡æ¡£è¦†ç›–ç‡"""
        # åˆ›å»ºé»˜è®¤çš„è¦†ç›–ç»Ÿè®¡
        default_coverage = DocumentationCoverage(
            total_endpoints=0,
            documented_endpoints=0,
            partially_documented=0,
            undocumented=0,
            coverage_percentage=0.0,
            missing_endpoints=[],
            quality_distribution={},
        )

        if not self.endpoints:
            self.coverage_stats = default_coverage
            return default_coverage

        documented = sum(1 for e in self.endpoints if e.has_docstring)
        partially = sum(
            1
            for e in self.endpoints
            if e.has_docstring and e.docstring_quality in ["poor", "fair"]
        )
        undocumented = len(self.endpoints) - documented
        coverage_percentage = (documented / len(self.endpoints)) * 100

        # è´¨é‡åˆ†å¸ƒç»Ÿè®¡
        quality_dist = {}
        for endpoint in self.endpoints:
            quality = endpoint.docstring_quality
            quality_dist[quality] = quality_dist.get(quality, 0) + 1

        # ç¼ºå¤±æ–‡æ¡£çš„ç«¯ç‚¹
        missing_endpoints = [
            f"{e.http_method} {e.path} ({e.function_name})"
            for e in self.endpoints
            if not e.has_docstring
        ]

        self.coverage_stats = DocumentationCoverage(
            total_endpoints=len(self.endpoints),
            documented_endpoints=documented,
            partially_documented=partially,
            undocumented=undocumented,
            coverage_percentage=coverage_percentage,
            missing_endpoints=missing_endpoints,
            quality_distribution=quality_dist,
        )

        return self.coverage_stats

    def generate_coverage_report(self) -> str:
        """ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š"""
        if not self.coverage_stats:
            self.calculate_coverage()

        stats = self.coverage_stats

        report = f"""
# APIæ–‡æ¡£è¦†ç›–ç‡æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ğŸ“Š æ€»ä½“ç»Ÿè®¡

- **æ€»ç«¯ç‚¹æ•°**: {stats.total_endpoints}
- **å·²æ–‡æ¡£åŒ–**: {stats.documented_endpoints} ({stats.coverage_percentage:.1f}%)
- **éƒ¨åˆ†æ–‡æ¡£åŒ–**: {stats.partially_documented}
- **æœªæ–‡æ¡£åŒ–**: {stats.undocumented}

## ğŸ“ˆ æ–‡æ¡£è´¨é‡åˆ†å¸ƒ

"""

        for quality, count in stats.quality_distribution.items():
            percentage = (count / stats.total_endpoints) * 100
            status_icon = {
                "excellent": "ğŸŸ¢",
                "good": "ğŸŸ¡",
                "fair": "ğŸŸ ",
                "poor": "ğŸ”´",
                "missing": "âš«",
            }.get(quality, "âšª")

            report += (
                f"- {status_icon} **{quality.title()}**: {count} ({percentage:.1f}%)\n"
            )

        if stats.missing_endpoints:
            report += "\n## âŒ ç¼ºå¤±æ–‡æ¡£çš„ç«¯ç‚¹\n\n"
            for endpoint in stats.missing_endpoints[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                report += f"- `{endpoint}`\n"

            if len(stats.missing_endpoints) > 10:
                report += f"- ... è¿˜æœ‰ {len(stats.missing_endpoints) - 10} ä¸ªç«¯ç‚¹\n"

        return report

    def identify_documentation_gaps(self) -> Dict[str, List[str]]:
        """è¯†åˆ«æ–‡æ¡£ç¼ºå£"""
        gaps = {
            "missing_docstrings": [],
            "poor_quality": [],
            "incomplete_parameters": [],
            "missing_responses": [],
            "inconsistent_style": [],
        }

        for endpoint in self.endpoints:
            # ç¼ºå¤±æ–‡æ¡£å­—ç¬¦ä¸²
            if not endpoint.has_docstring:
                gaps["missing_docstrings"].append(
                    f"{endpoint.http_method} {endpoint.path}"
                )

            # æ–‡æ¡£è´¨é‡å·®
            elif endpoint.docstring_quality in ["poor", "missing"]:
                gaps["poor_quality"].append(
                    f"{endpoint.http_method} {endpoint.path} (è´¨é‡: {endpoint.docstring_quality})"
                )

            # å‚æ•°ä¿¡æ¯ä¸å®Œæ•´
            if endpoint.parameters and not all(
                p.get("description") for p in endpoint.parameters
            ):
                gaps["incomplete_parameters"].append(
                    f"{endpoint.http_method} {endpoint.path}"
                )

        return gaps

    def generate_missing_docs(self, output_dir: str):
        """ç”Ÿæˆç¼ºå¤±çš„æ–‡æ¡£"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        gaps = self.identify_documentation_gaps()

        # ç”Ÿæˆç¼ºå¤±æ–‡æ¡£çš„æ¨¡æ¿
        if gaps["missing_docstrings"]:
            missing_docs_file = output_path / "missing_docstrings.md"
            with open(missing_docs_file, "w", encoding="utf-8") as f:
                f.write("# ç¼ºå¤±æ–‡æ¡£çš„APIç«¯ç‚¹\n\n")
                f.write("ä»¥ä¸‹ç«¯ç‚¹éœ€è¦æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²ï¼š\n\n")

                for endpoint_path in gaps["missing_docstrings"]:
                    f.write(f"## {endpoint_path}\n\n")
                    f.write("```python\n")
                    f.write(
                        f'@router.{endpoint_path.split()[0].lower()}("{endpoint_path.split()[1]}")\n'
                    )
                    f.write("async def some_function():\n")
                    f.write('    """\n')
                    f.write("    TODO: æ·»åŠ å‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²\n\n")
                    f.write("    Returns:\n")
                    f.write("        TODO: æè¿°è¿”å›å€¼\n")
                    f.write('    """\n')
                    f.write("    pass\n")
                    f.write("```\n\n")

            print(f"ğŸ“ å·²ç”Ÿæˆç¼ºå¤±æ–‡æ¡£æ¨¡æ¿: {missing_docs_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ APIæ–‡æ¡£å®Œæ•´æ€§æ£€æŸ¥å·¥å…·")
    print("=" * 50)

    # åˆå§‹åŒ–åˆ†æå™¨
    api_dir = "/opt/claude/mystocks_spec/web/backend/app/api"
    analyzer = APIDocumentationAnalyzer(api_dir)

    # æ‰«æç«¯ç‚¹
    endpoints = analyzer.scan_api_endpoints()

    # è®¡ç®—è¦†ç›–ç‡
    coverage = analyzer.calculate_coverage()

    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_coverage_report()
    print(report)

    # è¯†åˆ«ç¼ºå£
    gaps = analyzer.identify_documentation_gaps()

    print("\nğŸ“‹ æ–‡æ¡£ç¼ºå£åˆ†æ:")
    for gap_type, items in gaps.items():
        if items:
            print(f"  {gap_type}: {len(items)} ä¸ªé—®é¢˜")

    # ç”Ÿæˆè¡¥å……æ–‡æ¡£
    output_dir = "/opt/claude/mystocks_spec/logs/api_docs_gaps"
    analyzer.generate_missing_docs(output_dir)

    # ä¿å­˜è¯¦ç»†ç»“æœ
    results = {
        "timestamp": datetime.now().isoformat(),
        "total_endpoints": len(endpoints),
        "coverage": {
            "total_endpoints": coverage.total_endpoints,
            "documented_endpoints": coverage.documented_endpoints,
            "coverage_percentage": coverage.coverage_percentage,
            "quality_distribution": coverage.quality_distribution,
        },
        "endpoints": [
            {
                "file": e.file_path,
                "function": e.function_name,
                "method": e.http_method,
                "path": e.path,
                "has_docstring": e.has_docstring,
                "quality": e.docstring_quality,
            }
            for e in endpoints
        ],
        "gaps": gaps,
    }

    results_file = f"/opt/claude/mystocks_spec/logs/api_docs_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(results_file, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ è¯¦ç»†åˆ†æç»“æœå·²ä¿å­˜: {results_file}")

    # è¿”å›ç»“æœ
    return coverage.coverage_percentage


if __name__ == "__main__":
    main()
