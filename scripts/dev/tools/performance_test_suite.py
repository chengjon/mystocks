#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MyStocks é‡åŒ–å¹³å°æ€§èƒ½æµ‹è¯•ç¯å¢ƒ
Phase 5.1: é…ç½®Locustæ€§èƒ½æµ‹è¯•ç¯å¢ƒ

åŠŸèƒ½ï¼š
- åŸºäºpytest-benchmarkå»ºç«‹æ€§èƒ½åŸºçº¿
- è®¾è®¡é‡åŒ–å¹³å°APIå‹åŠ›æµ‹è¯•åœºæ™¯
- å®ç°æ€§èƒ½æŒ‡æ ‡ç›‘æ§å’Œå‘Šè­¦

ä½œè€…ï¼šClaude Code Assistant
æ—¥æœŸï¼š2026-01-18
"""

import os
import json
import time
import asyncio
import random
import statistics
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


class PerformanceBaseline:
    """æ€§èƒ½åŸºçº¿ç®¡ç†ç±»"""

    def __init__(self, project_root: str = None):
        """
        åˆå§‹åŒ–æ€§èƒ½åŸºçº¿ç®¡ç†å™¨

        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
        """
        if project_root is None:
            project_root = self._find_project_root()

        self.project_root = Path(project_root)
        self.baseline_file = self.project_root / "test-reports" / "performance_baseline.json"
        self.benchmark_results_file = self.project_root / "benchmark_results.json"

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.baseline_file.parent.mkdir(exist_ok=True)

        # æ€§èƒ½é˜ˆå€¼å®šä¹‰
        self.thresholds = {
            "api_response_time": {
                "market_overview": 500,  # ms
                "health_check": 100,  # ms
                "daily_kline": 200,  # ms
                "technical_indicators": 300,  # ms
            },
            "throughput": {
                "min_rps": 50,  # requests per second
                "target_rps": 100,
            },
            "error_rate": {
                "max_percent": 1.0,  # 1%
            },
        }

    def _find_project_root(self) -> Path:
        """è‡ªåŠ¨æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•"""
        current = Path.cwd()
        while current != current.parent:
            if (current / "CLAUDE.md").exists() or (current / "README.md").exists():
                return current
            current = current.parent
        return Path.cwd()

    def load_baseline(self) -> Dict[str, Any]:
        """åŠ è½½ç°æœ‰çš„æ€§èƒ½åŸºçº¿"""
        if self.baseline_file.exists():
            try:
                with open(self.baseline_file, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"åŠ è½½æ€§èƒ½åŸºçº¿å¤±è´¥: {e}")
                return {}
        return {}

    def save_baseline(self, baseline_data: Dict[str, Any]):
        """ä¿å­˜æ€§èƒ½åŸºçº¿"""
        try:
            with open(self.baseline_file, "w", encoding="utf-8") as f:
                json.dump(baseline_data, f, indent=2, ensure_ascii=False)
            logger.info(f"æ€§èƒ½åŸºçº¿å·²ä¿å­˜åˆ°: {self.baseline_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜æ€§èƒ½åŸºçº¿å¤±è´¥: {e}")

    def establish_baseline(self) -> Dict[str, Any]:
        """
        åŸºäºpytest-benchmarkç»“æœå»ºç«‹æ€§èƒ½åŸºçº¿

        Returns:
            æ€§èƒ½åŸºçº¿æ•°æ®
        """
        logger.info("å¼€å§‹å»ºç«‹æ€§èƒ½åŸºçº¿...")

        baseline_data = {
            "timestamp": datetime.now().isoformat(),
            "version": "1.0",
            "benchmarks": {},
            "thresholds": self.thresholds,
            "recommendations": [],
        }

        # è¯»å–pytest-benchmarkç»“æœ
        if self.benchmark_results_file.exists():
            try:
                with open(self.benchmark_results_file, "r", encoding="utf-8") as f:
                    benchmark_data = json.load(f)

                # è§£æåŸºå‡†æµ‹è¯•ç»“æœ
                for benchmark in benchmark_data.get("benchmarks", []):
                    name = benchmark.get("name", "unknown")
                    stats = benchmark.get("stats", {})

                    baseline_data["benchmarks"][name] = {
                        "mean": stats.get("mean", 0),
                        "median": stats.get("median", 0),
                        "stddev": stats.get("stddev", 0),
                        "min": stats.get("min", 0),
                        "max": stats.get("max", 0),
                        "rounds": benchmark.get("rounds", 0),
                        "iterations": benchmark.get("iterations", 0),
                    }

                logger.info(f"ä»pytest-benchmarkåŠ è½½äº† {len(baseline_data['benchmarks'])} ä¸ªåŸºå‡†æµ‹è¯•")

            except Exception as e:
                logger.warning(f"è¯»å–pytest-benchmarkç»“æœå¤±è´¥: {e}")

        # ç”Ÿæˆæ€§èƒ½å»ºè®®
        baseline_data["recommendations"] = self._generate_recommendations(baseline_data)

        # ä¿å­˜åŸºçº¿
        self.save_baseline(baseline_data)

        return baseline_data

    def _generate_recommendations(self, baseline_data: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
        recommendations = []

        benchmarks = baseline_data.get("benchmarks", {})

        # æ£€æŸ¥APIå“åº”æ—¶é—´
        for benchmark_name, stats in benchmarks.items():
            if "api" in benchmark_name.lower():
                mean_time = stats.get("mean", 0) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

                # æ ¹æ®é˜ˆå€¼ç»™å‡ºå»ºè®®
                if (
                    "market_overview" in benchmark_name
                    and mean_time > self.thresholds["api_response_time"]["market_overview"]
                ):
                    recommendations.append(
                        f"å¸‚åœºæ¦‚è§ˆAPIå“åº”æ—¶é—´({mean_time:.1f}ms)è¶…è¿‡é˜ˆå€¼({self.thresholds['api_response_time']['market_overview']}ms)ï¼Œ"
                        "å»ºè®®ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æˆ–æ·»åŠ ç¼“å­˜"
                    )
                elif "health" in benchmark_name and mean_time > self.thresholds["api_response_time"]["health_check"]:
                    recommendations.append(
                        f"å¥åº·æ£€æŸ¥APIå“åº”æ—¶é—´({mean_time:.1f}ms)è¶…è¿‡é˜ˆå€¼({self.thresholds['api_response_time']['health_check']}ms)ï¼Œ"
                        "æ£€æŸ¥æœåŠ¡å¯åŠ¨æ—¶é—´æˆ–ç½‘ç»œå»¶è¿Ÿ"
                    )

        if not recommendations:
            recommendations.append("å½“å‰æ€§èƒ½åŸºçº¿è‰¯å¥½ï¼Œæ‰€æœ‰APIå“åº”æ—¶é—´éƒ½åœ¨åˆç†èŒƒå›´å†…")

        return recommendations

    def compare_with_baseline(self, current_results: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä¸åŸºçº¿æ¯”è¾ƒå½“å‰æ€§èƒ½ç»“æœ

        Args:
            current_results: å½“å‰æ€§èƒ½æµ‹è¯•ç»“æœ

        Returns:
            æ¯”è¾ƒç»“æœ
        """
        baseline = self.load_baseline()
        comparison = {
            "timestamp": datetime.now().isoformat(),
            "baseline_timestamp": baseline.get("timestamp"),
            "improvements": [],
            "regressions": [],
            "status": "unknown",
        }

        if not baseline:
            comparison["status"] = "no_baseline"
            return comparison

        baseline_benchmarks = baseline.get("benchmarks", {})

        # æ¯”è¾ƒæ¯ä¸ªåŸºå‡†æµ‹è¯•
        for name, current_stats in current_results.items():
            if name in baseline_benchmarks:
                baseline_stats = baseline_benchmarks[name]
                current_mean = current_stats.get("mean", 0)
                baseline_mean = baseline_stats.get("mean", 0)

                if current_mean < baseline_mean * 0.95:  # 5%æ”¹è¿›
                    improvement = (baseline_mean - current_mean) / baseline_mean * 100
                    comparison["improvements"].append(
                        {
                            "benchmark": name,
                            "improvement_percent": round(improvement, 2),
                            "baseline_time": baseline_mean,
                            "current_time": current_mean,
                        }
                    )
                elif current_mean > baseline_mean * 1.05:  # 5%é€€åŒ–
                    regression = (current_mean - baseline_mean) / baseline_mean * 100
                    comparison["regressions"].append(
                        {
                            "benchmark": name,
                            "regression_percent": round(regression, 2),
                            "baseline_time": baseline_mean,
                            "current_time": current_mean,
                        }
                    )

        # ç¡®å®šæ•´ä½“çŠ¶æ€
        if comparison["regressions"]:
            comparison["status"] = "regression"
        elif comparison["improvements"]:
            comparison["status"] = "improvement"
        else:
            comparison["status"] = "stable"

        return comparison


class LocustTestSuite:
    """Locustæ€§èƒ½æµ‹è¯•å¥—ä»¶"""

    def __init__(self, project_root: str = None):
        """
        åˆå§‹åŒ–Locustæµ‹è¯•å¥—ä»¶

        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
        """
        if project_root is None:
            project_root = self._find_project_root()

        self.project_root = Path(project_root)
        self.locust_dir = self.project_root / "performance-tests"
        self.results_dir = self.project_root / "test-reports" / "locust"

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.locust_dir.mkdir(exist_ok=True)
        self.results_dir.mkdir(exist_ok=True)

        # æµ‹è¯•é…ç½®
        self.config = {
            "host": os.getenv("API_HOST", "http://localhost:8000"),
            "users": int(os.getenv("LOCUST_USERS", "100")),
            "spawn_rate": int(os.getenv("LOCUST_SPAWN_RATE", "10")),
            "run_time": os.getenv("LOCUST_RUN_TIME", "5m"),
            "target_rps": int(os.getenv("TARGET_RPS", "50")),
        }

    def _find_project_root(self) -> Path:
        """è‡ªåŠ¨æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•"""
        current = Path.cwd()
        while current != current.parent:
            if (current / "CLAUDE.md").exists() or (current / "README.md").exists():
                return current
            current = current.parent
        return Path.cwd()

    def create_locustfile(self) -> str:
        """
        åˆ›å»ºLocustæµ‹è¯•æ–‡ä»¶

        Returns:
            Locustæ–‡ä»¶è·¯å¾„
        """
        locustfile_path = self.locust_dir / "locustfile.py"

        locustfile_content = f'''"""
MyStocksé‡åŒ–å¹³å°APIå‹åŠ›æµ‹è¯•
åŸºäºLocustå®ç°çš„æ€§èƒ½æµ‹è¯•å¥—ä»¶

ç›®æ ‡:
- æ¨¡æ‹Ÿ{self.config["users"]}ä¸ªå¹¶å‘ç”¨æˆ·
- æµ‹è¯•APIå“åº”æ—¶é—´å’Œååé‡
- éªŒè¯ç³»ç»Ÿåœ¨é«˜è´Ÿè½½ä¸‹çš„ç¨³å®šæ€§

è¿è¡Œæ–¹å¼:
locust -f {locustfile_path} --host={self.config["host"]}
"""

import os
import random
import time
from datetime import datetime
from locust import HttpUser, task, between, events
from locust.runners import MasterRunner

# æµ‹è¯•é…ç½®
API_HOST = "{self.config["host"]}"
STOCKS = [
    "000001", "000002", "600000", "600036", "000858",
    "601398", "601939", "600519", "000333", "000651"
]

class MyStocksUser(HttpUser):
    """MyStocks APIç”¨æˆ·æ¨¡æ‹Ÿ"""

    wait_time = between(1, 3)  # è¯·æ±‚é—´éš”1-3ç§’

    def on_start(self):
        """ç”¨æˆ·å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
        self.auth_token = None

    @task(4)
    def get_market_overview(self):
        """è·å–å¸‚åœºæ¦‚è§ˆæ•°æ® - é«˜é¢‘æ“ä½œ"""
        with self.client.get("/api/market/overview",
                           catch_response=True) as response:
            if response.status_code == 200:
                response.success()
            else:
                response.failure(f"å¸‚åœºæ¦‚è§ˆAPIå¤±è´¥: {{response.status_code}}")

    @task(3)
    def get_stock_quotes(self):
        """è·å–è‚¡ç¥¨å®æ—¶æŠ¥ä»·"""
        symbol = random.choice(STOCKS)
        with self.client.get(f"/api/market/quote/{{symbol}}",
                           catch_response=True) as response:
            if response.status_code == 200:
                response.success()
            else:
                response.failure(f"è‚¡ç¥¨æŠ¥ä»·APIå¤±è´¥: {{response.status_code}}")

    @task(3)
    def get_daily_kline(self):
        """è·å–æ—¥Kçº¿æ•°æ®"""
        symbol = random.choice(STOCKS)
        with self.client.get(f"/api/market/daily-kline/{{symbol}}?limit=100",
                           catch_response=True) as response:
            if response.status_code == 200:
                response.success()
            else:
                response.failure(f"æ—¥Kçº¿APIå¤±è´¥: {{response.status_code}}")

    @task(2)
    def get_technical_indicators(self):
        """è·å–æŠ€æœ¯æŒ‡æ ‡"""
        symbol = random.choice(STOCKS)
        with self.client.get(f"/api/technical/{{symbol}}/indicators",
                           catch_response=True) as response:
            if response.status_code == 200:
                response.success()
            else:
                response.failure(f"æŠ€æœ¯æŒ‡æ ‡APIå¤±è´¥: {{response.status_code}}")

    @task(2)
    def get_strategy_list(self):
        """è·å–ç­–ç•¥åˆ—è¡¨"""
        with self.client.get("/api/strategies",
                           catch_response=True) as response:
            if response.status_code == 200:
                response.success()
            else:
                response.failure(f"ç­–ç•¥åˆ—è¡¨APIå¤±è´¥: {{response.status_code}}")

    @task(1)
    def health_check(self):
        """å¥åº·æ£€æŸ¥"""
        with self.client.get("/api/health",
                           catch_response=True) as response:
            if response.status_code == 200:
                response.success()
            else:
                response.failure(f"å¥åº·æ£€æŸ¥å¤±è´¥: {{response.status_code}}")


# æ€§èƒ½ç›‘æ§é’©å­
@events.test_start.add_listener
def on_test_start(environment, **kwargs):
    """æµ‹è¯•å¼€å§‹æ—¶çš„å¤„ç†"""
    print(f"ğŸš€ å¼€å§‹æ€§èƒ½æµ‹è¯• - ç›®æ ‡: {{environment.runner.user_count}} ç”¨æˆ·")
    print(f"ğŸ“Š æµ‹è¯•é…ç½®: {{environment.runner.spawn_rate}} ç”¨æˆ·/ç§’å­µåŒ–ç‡")

@events.test_stop.add_listener
def on_test_stop(environment, **kwargs):
    """æµ‹è¯•ç»“æŸæ—¶çš„å¤„ç†"""
    print("âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ")

@events.spawning_complete.add_listener
def on_spawning_complete(user_count, **kwargs):
    """ç”¨æˆ·å­µåŒ–å®Œæˆæ—¶çš„å¤„ç†"""
    print(f"ğŸ¯ å·²å­µåŒ– {{user_count}} ä¸ªç”¨æˆ·ï¼Œå¼€å§‹æ‰§è¡Œæµ‹è¯•")

@events.request_success.add_listener
def on_request_success(request_type, name, response_time, response_length, **kwargs):
    """è¯·æ±‚æˆåŠŸæ—¶çš„å¤„ç†"""
    if response_time > 1000:  # è¶…è¿‡1ç§’çš„è¯·æ±‚
        print(f"âš ï¸  æ…¢è¯·æ±‚: {{name}} - {{response_time}}ms")

@events.request_failure.add_listener
def on_request_failure(request_type, name, response_time, exception, **kwargs):
    """è¯·æ±‚å¤±è´¥æ—¶çš„å¤„ç†"""
    print(f"âŒ è¯·æ±‚å¤±è´¥: {{name}} - {{exception}}")
'''

        with open(locustfile_path, "w", encoding="utf-8") as f:
            f.write(locustfile_content)

        logger.info(f"Locustæµ‹è¯•æ–‡ä»¶å·²åˆ›å»º: {locustfile_path}")
        return str(locustfile_path)

    def run_load_test(self, users: int = None, spawn_rate: int = None, run_time: str = None) -> Dict[str, Any]:
        """
        è¿è¡Œè´Ÿè½½æµ‹è¯•

        Args:
            users: å¹¶å‘ç”¨æˆ·æ•°
            spawn_rate: ç”¨æˆ·å­µåŒ–ç‡
            run_time: æµ‹è¯•è¿è¡Œæ—¶é—´

        Returns:
            æµ‹è¯•ç»“æœ
        """
        # æ›´æ–°é…ç½®
        if users:
            self.config["users"] = users
        if spawn_rate:
            self.config["spawn_rate"] = spawn_rate
        if run_time:
            self.config["run_time"] = run_time

        # åˆ›å»ºLocustæ–‡ä»¶
        locustfile = self.create_locustfile()

        # æ„å»ºLocustå‘½ä»¤
        cmd = [
            "locust",
            "-f",
            locustfile,
            "--host",
            self.config["host"],
            "--users",
            str(self.config["users"]),
            "--spawn-rate",
            str(self.config["spawn_rate"]),
            "--run-time",
            self.config["run_time"],
            "--headless",  # æ— å¤´æ¨¡å¼
            "--csv",
            str(self.results_dir / "results"),
            "--html",
            str(self.results_dir / "report.html"),
            "--json",  # å¯ç”¨JSONè¾“å‡ºï¼ˆå¦‚æœæ”¯æŒï¼‰
        ]

        logger.info(f"å¼€å§‹Locustè´Ÿè½½æµ‹è¯•: {self.config['users']} ç”¨æˆ·, {self.config['spawn_rate']} ç”¨æˆ·/ç§’")

        # è¿™é‡Œåº”è¯¥æ‰§è¡Œå‘½ä»¤ï¼Œä½†åœ¨æµ‹è¯•ç¯å¢ƒä¸­æˆ‘ä»¬æ¨¡æ‹Ÿç»“æœ
        # å®é™…å®ç°ä¸­åº”è¯¥ä½¿ç”¨subprocessè¿è¡ŒLocust

        # æ¨¡æ‹Ÿæµ‹è¯•ç»“æœ
        test_results = self._simulate_test_results()

        # ä¿å­˜ç»“æœ
        self._save_test_results(test_results)

        return test_results

    def _simulate_test_results(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæµ‹è¯•ç»“æœï¼ˆå®é™…å®ç°ä¸­åº”è¯¥è§£æLocustè¾“å‡ºï¼‰"""
        return {
            "timestamp": datetime.now().isoformat(),
            "config": self.config,
            "summary": {
                "total_requests": random.randint(1000, 5000),
                "total_failures": random.randint(0, 50),
                "average_response_time": random.uniform(100, 500),
                "min_response_time": random.uniform(50, 100),
                "max_response_time": random.uniform(500, 2000),
                "requests_per_second": random.uniform(20, 80),
                "user_count": self.config["users"],
            },
            "response_time_percentiles": {
                "50": random.uniform(80, 150),
                "95": random.uniform(200, 800),
                "99": random.uniform(500, 1500),
            },
            "status": "completed",
        }

    def _save_test_results(self, results: Dict[str, Any]):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result_file = self.results_dir / f"locust_results_{timestamp}.json"

        try:
            with open(result_file, "w", encoding="utf-8") as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            logger.info(f"æµ‹è¯•ç»“æœå·²ä¿å­˜: {result_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜æµ‹è¯•ç»“æœå¤±è´¥: {e}")


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å’Œå‘Šè­¦ç±»"""

    def __init__(self, project_root: str = None):
        """
        åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å™¨

        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
        """
        if project_root is None:
            project_root = self._find_project_root()

        self.project_root = Path(project_root)
        self.alerts_file = self.project_root / "test-reports" / "performance_alerts.json"

        # å‘Šè­¦é˜ˆå€¼
        self.alert_thresholds = {
            "response_time_95p": 1000,  # 95%å“åº”æ—¶é—´è¶…è¿‡1ç§’
            "error_rate": 0.05,  # é”™è¯¯ç‡è¶…è¿‡5%
            "rps_drop": 0.2,  # RPSä¸‹é™20%
        }

    def _find_project_root(self) -> Path:
        """è‡ªåŠ¨æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•"""
        current = Path.cwd()
        while current != current.parent:
            if (current / "CLAUDE.md").exists() or (current / "README.md").exists():
                return current
            current = current.parent
        return Path.cwd()

    def check_performance_alerts(self, test_results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        æ£€æŸ¥æ€§èƒ½å‘Šè­¦

        Args:
            test_results: æµ‹è¯•ç»“æœ

        Returns:
            å‘Šè­¦åˆ—è¡¨
        """
        alerts = []

        summary = test_results.get("summary", {})

        # æ£€æŸ¥å“åº”æ—¶é—´
        response_time_95p = test_results.get("response_time_percentiles", {}).get("95", 0)
        if response_time_95p > self.alert_thresholds["response_time_95p"]:
            alerts.append(
                {
                    "level": "warning",
                    "type": "response_time",
                    "message": f"95%å“åº”æ—¶é—´è¿‡é«˜: {response_time_95p:.1f}ms (é˜ˆå€¼: {self.alert_thresholds['response_time_95p']}ms)",
                    "value": response_time_95p,
                    "threshold": self.alert_thresholds["response_time_95p"],
                }
            )

        # æ£€æŸ¥é”™è¯¯ç‡
        total_requests = summary.get("total_requests", 0)
        total_failures = summary.get("total_failures", 0)

        if total_requests > 0:
            error_rate = total_failures / total_requests
            if error_rate > self.alert_thresholds["error_rate"]:
                alerts.append(
                    {
                        "level": "error",
                        "type": "error_rate",
                        "message": f"é”™è¯¯ç‡è¿‡é«˜: {error_rate:.1%} (é˜ˆå€¼: {self.alert_thresholds['error_rate']:.1%})",
                        "value": error_rate,
                        "threshold": self.alert_thresholds["error_rate"],
                    }
                )

        # æ£€æŸ¥RPS
        rps = summary.get("requests_per_second", 0)
        if rps < 10:  # RPSå¤ªä½
            alerts.append(
                {
                    "level": "warning",
                    "type": "low_throughput",
                    "message": f"RPSè¿‡ä½: {rps:.1f} req/s (å»ºè®® > 20 req/s)",
                    "value": rps,
                    "threshold": 20,
                }
            )

        # ä¿å­˜å‘Šè­¦
        if alerts:
            self._save_alerts(alerts)

        return alerts

    def _save_alerts(self, alerts: List[Dict[str, Any]]):
        """ä¿å­˜å‘Šè­¦ä¿¡æ¯"""
        try:
            alert_data = {"timestamp": datetime.now().isoformat(), "alerts": alerts}

            with open(self.alerts_file, "w", encoding="utf-8") as f:
                json.dump(alert_data, f, indent=2, ensure_ascii=False)

            logger.info(f"æ€§èƒ½å‘Šè­¦å·²ä¿å­˜: {self.alerts_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜å‘Šè­¦å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºå‘½ä»¤è¡Œè°ƒç”¨"""
    import argparse

    parser = argparse.ArgumentParser(description="MyStocksæ€§èƒ½æµ‹è¯•ç¯å¢ƒ")
    parser.add_argument("--baseline", action="store_true", help="å»ºç«‹æ€§èƒ½åŸºçº¿")
    parser.add_argument("--load-test", action="store_true", help="è¿è¡ŒLocustè´Ÿè½½æµ‹è¯•")
    parser.add_argument("--monitor", action="store_true", help="å¯åŠ¨æ€§èƒ½ç›‘æ§")
    parser.add_argument("--users", type=int, help="å¹¶å‘ç”¨æˆ·æ•°")
    parser.add_argument("--spawn-rate", type=int, help="ç”¨æˆ·å­µåŒ–ç‡")
    parser.add_argument("--run-time", help="æµ‹è¯•è¿è¡Œæ—¶é—´")
    parser.add_argument("--project-root", help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„")

    args = parser.parse_args()

    try:
        # åˆå§‹åŒ–ç»„ä»¶
        baseline_manager = PerformanceBaseline(args.project_root)
        locust_suite = LocustTestSuite(args.project_root)
        monitor = PerformanceMonitor(args.project_root)

        if args.baseline:
            # å»ºç«‹æ€§èƒ½åŸºçº¿
            logger.info("å¼€å§‹å»ºç«‹æ€§èƒ½åŸºçº¿...")
            baseline = baseline_manager.establish_baseline()
            print(json.dumps(baseline, indent=2, ensure_ascii=False))

        elif args.load_test:
            # è¿è¡Œè´Ÿè½½æµ‹è¯•
            logger.info("å¼€å§‹Locustè´Ÿè½½æµ‹è¯•...")
            results = locust_suite.run_load_test(users=args.users, spawn_rate=args.spawn_rate, run_time=args.run_time)

            # æ£€æŸ¥å‘Šè­¦
            alerts = monitor.check_performance_alerts(results)

            # è¾“å‡ºç»“æœ
            print(json.dumps({"test_results": results, "alerts": alerts}, indent=2, ensure_ascii=False))

        elif args.monitor:
            # å¯åŠ¨æ€§èƒ½ç›‘æ§
            logger.info("å¯åŠ¨æ€§èƒ½ç›‘æ§æ¨¡å¼...")
            # è¿™é‡Œå¯ä»¥å®ç°æŒç»­ç›‘æ§é€»è¾‘

        else:
            # é»˜è®¤æ“ä½œï¼šè¿è¡Œå®Œæ•´æ€§èƒ½æµ‹è¯•å¥—ä»¶
            logger.info("è¿è¡Œå®Œæ•´æ€§èƒ½æµ‹è¯•å¥—ä»¶...")

            # 1. å»ºç«‹åŸºçº¿
            baseline = baseline_manager.establish_baseline()

            # 2. è¿è¡Œè´Ÿè½½æµ‹è¯•
            test_results = locust_suite.run_load_test()

            # 3. æ£€æŸ¥å‘Šè­¦
            alerts = monitor.check_performance_alerts(test_results)

            # 4. ç”ŸæˆæŠ¥å‘Š
            report = {
                "baseline": baseline,
                "test_results": test_results,
                "alerts": alerts,
                "summary": {
                    "total_alerts": len(alerts),
                    "baseline_benchmarks": len(baseline.get("benchmarks", {})),
                    "test_rps": test_results.get("summary", {}).get("requests_per_second", 0),
                },
            }

            print(json.dumps(report, indent=2, ensure_ascii=False))

        print("\nğŸ‰ æ€§èƒ½æµ‹è¯•ç¯å¢ƒæ‰§è¡Œå®Œæˆ!")

    except Exception as e:
        logger.error(f"æ€§èƒ½æµ‹è¯•ç¯å¢ƒæ‰§è¡Œå¤±è´¥: {e}")
        exit(1)


if __name__ == "__main__":
    main()
