#!/usr/bin/env python3
"""
æ—¥å¿—ç³»ç»Ÿç»Ÿä¸€åŒ–è„šæœ¬

å°†é¡¹ç›®ä¸­çš„print()è¯­å¥æ›¿æ¢ä¸ºloggingè°ƒç”¨
å»ºç«‹ç»Ÿä¸€çš„æ—¥å¿—æ ‡å‡†å’Œé…ç½®
"""

import re
import sys
from pathlib import Path
from typing import Dict, List, Optional
import argparse


class LoggingUnifier:
    """æ—¥å¿—ç»Ÿä¸€åŒ–å·¥å…·"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.src_dir = self.project_root / "src"
        self.stats = {
            "files_processed": 0,
            "print_statements_found": 0,
            "print_statements_replaced": 0,
            "files_with_logging": 0,
            "issues_found": 0,
        }

    def analyze_print_usage(self) -> Dict[str, any]:
        """åˆ†æprintè¯­å¥ä½¿ç”¨æƒ…å†µ"""
        print("ğŸ” åˆ†æé¡¹ç›®ä¸­çš„printè¯­å¥ä½¿ç”¨æƒ…å†µ...")

        print_patterns = [
            r"print\([^)]*\)",  # åŸºæœ¬printè¯­å¥
            r'print\s*\([^)]*f[\'"][^\'"]*[\'"]',  # f-string print
        ]

        analysis = {
            "total_prints": 0,
            "by_file": {},
            "by_directory": {},
            "common_patterns": {},
            "problematic_cases": [],
        }

        # éå†æ‰€æœ‰Pythonæ–‡ä»¶
        for py_file in self.src_dir.rglob("*.py"):
            if py_file.is_file() and not any(
                skip in str(py_file) for skip in ["__pycache__", ".pytest_cache"]
            ):
                try:
                    with open(py_file, "r", encoding="utf-8") as f:
                        content = f.read()

                    file_prints = 0
                    file_issues = []

                    # æŸ¥æ‰¾æ‰€æœ‰printè¯­å¥
                    lines = content.split("\n")
                    for i, line in enumerate(lines, 1):
                        for pattern in print_patterns:
                            matches = re.finditer(pattern, line)
                            for match in matches:
                                file_prints += 1

                                # åˆ†æé—®é¢˜
                                self._analyze_print_statement(
                                    line, i, py_file, file_issues
                                )

                    if file_prints > 0:
                        analysis["by_file"][str(py_file)] = file_prints
                        analysis["total_prints"] += file_prints

                        # æŒ‰ç›®å½•ç»Ÿè®¡
                        parent_dir = py_file.parent.name
                        analysis["by_directory"][parent_dir] = (
                            analysis["by_directory"].get(parent_dir, 0) + file_prints
                        )

                        if file_issues:
                            analysis["problematic_cases"].extend(file_issues)

                except Exception as e:
                    print(f"âš ï¸  å¤„ç†æ–‡ä»¶å¤±è´¥ {py_file}: {e}")

        return analysis

    def _analyze_print_statement(
        self, line: str, line_num: int, file_path: Path, issues: List[str]
    ):
        """åˆ†æå•ä¸ªprintè¯­å¥çš„é—®é¢˜"""
        # æ£€æŸ¥è°ƒè¯•ç›¸å…³print
        if any(
            debug_word in line.lower()
            for debug_word in ["debug", "æµ‹è¯•", "test", "æš‚æ—¶", "temp"]
        ):
            issues.append(f"{file_path}:{line_num} - è°ƒè¯•printè¯­å¥")

        # æ£€æŸ¥æ•æ„Ÿä¿¡æ¯
        if any(
            sensitive_word in line.lower()
            for sensitive_word in ["password", "secret", "key", "token"]
        ):
            issues.append(f"{file_path}:{line_num} - å¯èƒ½åŒ…å«æ•æ„Ÿä¿¡æ¯çš„print")

        # æ£€æŸ¥é‡å¤çš„printæ¨¡å¼
        if 'print("="*50)' in line or 'print("-"*50)' in line:
            issues.append(f"{file_path}:{line_num} - è£…é¥°æ€§printè¯­å¥")

    def generate_logging_import(self) -> str:
        """ç”Ÿæˆloggingå¯¼å…¥è¯­å¥"""
        return """# ç»Ÿä¸€æ—¥å¿—é…ç½®
import logging
from typing import Optional

# è·å–æˆ–åˆ›å»ºlogger
logger = logging.getLogger(__name__)

# ç¡®ä¿æ—¥å¿—é…ç½®å·²è®¾ç½®
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)
"""

    def replace_print_with_logging(
        self, file_path: Path, dry_run: bool = False
    ) -> bool:
        """å°†printè¯­å¥æ›¿æ¢ä¸ºloggingè°ƒç”¨"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            original_content = content
            modified = False

            # æ£€æŸ¥æ˜¯å¦å·²æœ‰loggingå¯¼å…¥
            has_logging_import = "import logging" in content

            # æ·»åŠ loggingå¯¼å…¥ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if not has_logging_import and "print(" in content:
                # åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ loggingå¯¼å…¥
                lines = content.split("\n")
                import_index = 0

                # æ‰¾åˆ°åˆé€‚çš„ä½ç½®æ’å…¥import
                for i, line in enumerate(lines):
                    if line.startswith("import ") or line.startswith("from "):
                        import_index = i + 1
                    elif line.startswith("#") and i == 0:
                        import_index = 1
                        break

                lines.insert(import_index, self.generate_logging_import())
                content = "\n".join(lines)
                modified = True
                has_logging_import = True

            if "print(" not in content:
                return False

            # æ›¿æ¢printè¯­å¥
            patterns_replacements = [
                # æ›¿æ¢ç®€å•çš„printè¯­å¥
                (r'print\("([^"]+)"\)', r'logger.info(r"\1")'),
                (r"print\('([^']+)'\)", r'logger.info(r"\1")'),
                # æ›¿æ¢f-string print
                (r'print\(f"([^"]+)"\)', r'logger.info(f"\1")'),
                (r"print\(f'([^']+)'\)", r'logger.info(f"\1")'),
                # æ›¿æ¢å¸¦å‚æ•°çš„print
                (r"print\(([^f][^)]+)\)", r"logger.info(str(\1))"),
            ]

            for pattern, replacement in patterns_replacements:
                new_content = re.sub(pattern, replacement, content)
                if new_content != content:
                    content = new_content
                    modified = True

            # æ£€æŸ¥æ—¥å¿—çº§åˆ«
            content = self._adjust_log_levels(content)

            if modified and not dry_run:
                with open(file_path, "w", encoding="utf-8") as f:
                    f.write(content)

                print(f"âœ… æ›´æ–°æ–‡ä»¶: {file_path}")

            self.stats["files_processed"] += 1
            if modified:
                self.stats["print_statements_replaced"] += original_content.count(
                    "print("
                )
                self.stats["files_with_logging"] += 1

            return modified

        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return False

    def _adjust_log_levels(self, content: str) -> str:
        """è°ƒæ•´æ—¥å¿—çº§åˆ«"""
        # æ ¹æ®å†…å®¹è°ƒæ•´æ—¥å¿—çº§åˆ«
        level_adjustments = [
            # é”™è¯¯ä¿¡æ¯
            (
                r"logger\.info\((.*(?:error|é”™è¯¯|å¤±è´¥|å¼‚å¸¸|exception|é”™è¯¯).*?)\)",
                r"logger.error(\1)",
            ),
            (r"logger\.info\((.*(?:warning|è­¦å‘Š|warn).*?)\)", r"logger.warning(\1)"),
            # è°ƒè¯•ä¿¡æ¯
            (
                r"logger\.info\((.*(?:debug|è°ƒè¯•|æµ‹è¯•|test|debug).*?)\)",
                r"logger.debug(\1)",
            ),
            # æˆåŠŸä¿¡æ¯
            (
                r"logger\.info\((.*(?:âœ“|âœ…|success|æˆåŠŸ|å®Œæˆ|complete).*?)\)",
                r"logger.info(\1)",
            ),
            # è¿›åº¦ä¿¡æ¯ä¿æŒinfo
        ]

        for pattern, replacement in level_adjustments:
            content = re.sub(pattern, replacement, content, flags=re.IGNORECASE)

        return content

    def create_logging_config(self):
        """åˆ›å»ºç»Ÿä¸€çš„æ—¥å¿—é…ç½®æ–‡ä»¶"""
        config_file = self.project_root / "src" / "utils" / "logging_config.py"

        config_content = '''"""
MyStocks ç»Ÿä¸€æ—¥å¿—é…ç½®

æä¾›ç»Ÿä¸€çš„æ—¥å¿—é…ç½®å’Œç®¡ç†
"""

import logging
import os
import sys
from pathlib import Path
from typing import Optional
from datetime import datetime


class ColoredFormatter(logging.Formatter):
    """å½©è‰²æ—¥å¿—æ ¼å¼åŒ–å™¨"""

    # é¢œè‰²ä»£ç 
    COLORS = {
        'DEBUG': '\\033[36m',    # é’è‰²
        'INFO': '\\033[32m',     # ç»¿è‰²
        'WARNING': '\\033[33m',  # é»„è‰²
        'ERROR': '\\033[31m',    # çº¢è‰²
        'CRITICAL': '\\033[35m', # ç´«è‰²
        'RESET': '\\033[0m'      # é‡ç½®
    }

    def format(self, record):
        # æ·»åŠ é¢œè‰²
        if hasattr(record, 'levelname'):
            color = self.COLORS.get(record.levelname, self.COLORS['RESET'])
            record.levelname = f"{color}{record.levelname}{self.COLORS['RESET']}"

        return super().format(record)


def setup_logging(
    level: str = "INFO",
    log_file: Optional[str] = None,
    use_colors: bool = True
) -> None:
    """
    è®¾ç½®é¡¹ç›®æ—¥å¿—é…ç½®

    Args:
        level: æ—¥å¿—çº§åˆ« (DEBUG, INFO, WARNING, ERROR, CRITICAL)
        log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„ (å¯é€‰)
        use_colors: æ˜¯å¦ä½¿ç”¨å½©è‰²è¾“å‡º
    """

    # æ ¹ç¯å¢ƒå˜é‡
    log_level = os.getenv('LOG_LEVEL', level)

    # åˆ›å»ºæ ¹logger
    root_logger = logging.getLogger()
    root_logger.setLevel(getattr(logging, log_level.upper()))

    # æ¸…é™¤ç°æœ‰handlers
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)

    # æ§åˆ¶å°handler
    console_handler = logging.StreamHandler(sys.stdout)

    # æ ¼å¼åŒ–å™¨
    if use_colors and sys.stdout.isatty():
        formatter = ColoredFormatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
    else:
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )

    console_handler.setFormatter(formatter)
    console_handler.setLevel(getattr(logging, log_level.upper()))
    root_logger.addHandler(console_handler)

    # æ–‡ä»¶handler (å¦‚æœæŒ‡å®š)
    if log_file:
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        log_path = Path(log_file)
        log_path.parent.mkdir(parents=True, exist_ok=True)

        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
        )
        file_handler.setFormatter(file_formatter)
        root_logger.addHandler(file_handler)


def get_logger(name: str) -> logging.Logger:
    """
    è·å–loggerå®ä¾‹

    Args:
        name: loggeråç§°ï¼Œé€šå¸¸ä½¿ç”¨ __name__

    Returns:
        é…ç½®å¥½çš„loggerå®ä¾‹
    """
    return logging.getLogger(name)


# é»˜è®¤é…ç½®
if not logging.getLogger().handlers:
    setup_logging()

# å¯¼å‡ºçš„ä¾¿æ·å‡½æ•°
def log_info(message: str, logger_name: Optional[str] = None):
    """è®°å½•INFOçº§åˆ«æ—¥å¿—"""
    if logger_name:
        logging.getLogger(logger_name).info(message)
    else:
        logging.getLogger(__info__).info(message)


def log_error(message: str, logger_name: Optional[str] = None):
    """è®°å½•ERRORçº§åˆ«æ—¥å¿—"""
    if logger_name:
        logging.getLogger(logger_name).error(message)
    else:
        logging.getLogger(__info__).error(message)


def log_warning(message: str, logger_name: Optional[str] = None):
    """è®°å½•WARNINGçº§åˆ«æ—¥å¿—"""
    if logger_name:
        logging.getLogger(logger_name).warning(message)
    else:
        logging.getLogger(__info__).warning(message)


def log_debug(message: str, logger_name: Optional[str] = None):
    """è®°å½•DEBUGçº§åˆ«æ—¥å¿—"""
    if logger_name:
        logging.getLogger(logger_name).debug(message)
    else:
        logging.getLogger(__info__).debug(message)
'''

        config_file.parent.mkdir(parents=True, exist_ok=True)
        with open(config_file, "w", encoding="utf-8") as f:
            f.write(config_content)

        print(f"âœ… åˆ›å»ºæ—¥å¿—é…ç½®æ–‡ä»¶: {config_file}")

    def run_unification(self, dry_run: bool = False, target_file: Optional[str] = None):
        """è¿è¡Œæ—¥å¿—ç»Ÿä¸€åŒ–"""
        print("ğŸš€ å¼€å§‹æ—¥å¿—ç³»ç»Ÿç»Ÿä¸€åŒ–...")

        # åˆ›å»ºæ—¥å¿—é…ç½®
        self.create_logging_config()

        if target_file:
            # å¤„ç†å•ä¸ªæ–‡ä»¶
            file_path = Path(target_file)
            if file_path.exists():
                self.replace_print_with_logging(file_path, dry_run)
            else:
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {target_file}")
        else:
            # å¤„ç†æ‰€æœ‰æ–‡ä»¶
            print("ğŸ“ å¤„ç†æ‰€æœ‰Pythonæ–‡ä»¶...")

            for py_file in self.src_dir.rglob("*.py"):
                if py_file.is_file() and not any(
                    skip in str(py_file) for skip in ["__pycache__", ".pytest_cache"]
                ):
                    try:
                        self.replace_print_with_logging(py_file, dry_run)
                    except Exception as e:
                        print(f"âš ï¸  å¤„ç†æ–‡ä»¶å¤±è´¥ {py_file}: {e}")
                        self.stats["issues_found"] += 1

        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        self._print_stats(dry_run)

    def _print_stats(self, dry_run: bool):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        mode = "æ¨¡æ‹Ÿ" if dry_run else "å®é™…"
        print(f"\nğŸ“Š æ—¥å¿—ç»Ÿä¸€åŒ–ç»Ÿè®¡ ({mode}æ¨¡å¼):")
        print(f"  å¤„ç†æ–‡ä»¶æ•°: {self.stats['files_processed']}")
        print(f"  æ›¿æ¢printè¯­å¥: {self.stats['print_statements_replaced']}")
        print(f"  æ·»åŠ æ—¥å¿—é…ç½®çš„æ–‡ä»¶: {self.stats['files_with_logging']}")
        print(f"  å‘ç°é—®é¢˜æ•°: {self.stats['issues_found']}")

        if not dry_run:
            print("\nâœ… æ—¥å¿—ç»Ÿä¸€åŒ–å®Œæˆ!")
            print("\nğŸ“‹ åç»­å»ºè®®:")
            print("1. æ£€æŸ¥æ›¿æ¢åçš„æ—¥å¿—çº§åˆ«æ˜¯å¦åˆé€‚")
            print("2. è¿è¡Œæµ‹è¯•ç¡®ä¿åŠŸèƒ½æ­£å¸¸")
            print("3. æäº¤æ›´æ”¹å‰è¿è¡Œä»£ç è´¨é‡æ£€æŸ¥")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="MyStocks æ—¥å¿—ç³»ç»Ÿç»Ÿä¸€åŒ–å·¥å…·")
    parser.add_argument(
        "--project-root", default=".", help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ (é»˜è®¤: å½“å‰ç›®å½•)"
    )
    parser.add_argument(
        "--dry-run", "-n", action="store_true", help="æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸ä¿®æ”¹æ–‡ä»¶"
    )
    parser.add_argument("--file", "-f", help="åªå¤„ç†æŒ‡å®šæ–‡ä»¶")
    parser.add_argument("--analyze", "-a", action="store_true", help="åªåˆ†æï¼Œä¸ä¿®æ”¹")

    args = parser.parse_args()

    try:
        unifier = LoggingUnifier(args.project_root)

        if args.analyze:
            # åªåˆ†æ
            analysis = unifier.analyze_print_usage()
            print("\nğŸ“Š åˆ†æç»“æœ:")
            print(f"  æ€»printè¯­å¥: {analysis['total_prints']}")
            print(f"  æ¶‰åŠæ–‡ä»¶æ•°: {len(analysis['by_file'])}")

            print("\nğŸ“ æŒ‰ç›®å½•åˆ†å¸ƒ:")
            for dir_name, count in sorted(
                analysis["by_directory"].items(), key=lambda x: x[1], reverse=True
            ):
                print(f"  {dir_name}: {count}")

            if analysis["problematic_cases"]:
                print("\nâš ï¸  å‘ç°çš„é—®é¢˜:")
                for issue in analysis["problematic_cases"][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    print(f"  {issue}")
        else:
            # æ‰§è¡Œç»Ÿä¸€åŒ–
            unifier.run_unification(args.dry_run, args.file)

        return 0

    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
