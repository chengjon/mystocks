#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MyStocks AIæµ‹è¯•åŠ©æ‰‹é›†æˆæ¨¡å—
Phase 4.2: å®æ–½AIåŠ©æ‰‹é›†æˆä¼˜åŒ–

åŠŸèƒ½ï¼š
- é…ç½®AIåŠ©æ‰‹è®¿é—®æµ‹è¯•ç»“æœå’Œæ—¥å¿—
- å®ç°æ™ºèƒ½åŒ–é”™è¯¯è¯Šæ–­å’Œå»ºè®®ç”Ÿæˆ
- åˆ›å»ºæµ‹è¯•ä¼˜åŒ–æ¨èæœºåˆ¶

ä½œè€…ï¼šClaude Code Assistant
æ—¥æœŸï¼š2026-01-18
"""

import os
import json
import re
import glob
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœæ•°æ®ç±»"""

    phase: str
    test_type: str
    status: str
    duration: float
    errors: List[str]
    warnings: List[str]
    metrics: Dict[str, Any]
    timestamp: datetime
    file_path: str


@dataclass
class DiagnosticResult:
    """è¯Šæ–­ç»“æœæ•°æ®ç±»"""

    issue_type: str
    severity: str  # 'critical', 'high', 'medium', 'low'
    description: str
    root_cause: str
    suggestions: List[str]
    confidence: float  # 0.0 to 1.0


@dataclass
class OptimizationRecommendation:
    """ä¼˜åŒ–æ¨èæ•°æ®ç±»"""

    category: str
    priority: str
    title: str
    description: str
    impact: str
    effort: str
    implementation_steps: List[str]


class AITestAssistant:
    """AIæµ‹è¯•åŠ©æ‰‹ä¸»ç±»"""

    def __init__(self, project_root: str = None):
        """
        åˆå§‹åŒ–AIæµ‹è¯•åŠ©æ‰‹

        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹
        """
        if project_root is None:
            project_root = self._find_project_root()

        self.project_root = Path(project_root)
        self.test_reports_dir = self.project_root / "test-reports"
        self.logs_dir = self.project_root / "logs"
        self.scripts_dir = self.project_root / "scripts"

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.test_reports_dir.mkdir(exist_ok=True)
        self.logs_dir.mkdir(exist_ok=True)

        # è¯Šæ–­è§„åˆ™é…ç½®
        self.diagnostic_rules = self._load_diagnostic_rules()

        logger.info(f"AIæµ‹è¯•åŠ©æ‰‹åˆå§‹åŒ–å®Œæˆï¼Œé¡¹ç›®æ ¹ç›®å½•: {self.project_root}")

    def _find_project_root(self) -> Path:
        """è‡ªåŠ¨æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•"""
        current = Path.cwd()
        while current != current.parent:
            if (current / "CLAUDE.md").exists() or (current / "README.md").exists():
                return current
            current = current.parent
        return Path.cwd()  # å›é€€åˆ°å½“å‰ç›®å½•

    def _load_diagnostic_rules(self) -> Dict[str, Any]:
        """åŠ è½½è¯Šæ–­è§„åˆ™é…ç½®"""
        return {
            # ç«¯å£ç›¸å…³é”™è¯¯
            "port_conflicts": {
                "patterns": [
                    r"ç«¯å£ (\d+) å·²è¢«å ç”¨",
                    r"Port (\d+) is already in use",
                    r"Address already in use.*:(\d+)",
                ],
                "severity": "high",
                "category": "environment",
            },
            # æœåŠ¡å¯åŠ¨å¤±è´¥
            "service_failures": {
                "patterns": [
                    r"åç«¯æœåŠ¡.*å¯åŠ¨.*å¤±è´¥",
                    r"å‰ç«¯æœåŠ¡.*å¯åŠ¨.*å¤±è´¥",
                    r"Backend service.*failed to start",
                    r"Frontend service.*failed to start",
                ],
                "severity": "critical",
                "category": "service",
            },
            # ESMç›¸å…³é”™è¯¯
            "esm_errors": {
                "patterns": [r"does not provide an export named", r"ESM import.*failed", r"Cannot resolve module.*esm"],
                "severity": "high",
                "category": "compatibility",
            },
            # APIæµ‹è¯•å¤±è´¥
            "api_failures": {
                "patterns": [r"API.*failed", r"HTTP.*[45]\d{2}", r"Connection refused", r"Timeout"],
                "severity": "medium",
                "category": "api",
            },
            # æ€§èƒ½é—®é¢˜
            "performance_issues": {
                "patterns": [r"æµ‹è¯•æ‰§è¡Œæ—¶é—´.*è¶…æ—¶", r"Performance.*degraded", r"Slow.*response.*time"],
                "severity": "medium",
                "category": "performance",
            },
        }

    def collect_test_results(self) -> List[TestResult]:
        """
        æ”¶é›†æ‰€æœ‰æµ‹è¯•ç»“æœ

        Returns:
            æµ‹è¯•ç»“æœåˆ—è¡¨
        """
        results = []

        # æ”¶é›†ä¸åŒç±»å‹çš„æµ‹è¯•ç»“æœ
        result_patterns = {
            "esm": "**/esm-validation*.log",
            "environment": "**/start-environment*.log",
            "schemathesis": "**/schemathesis*.json",
            "playwright": "**/playwright*.json",
            "performance": "**/performance*.json",
            "orchestration": "**/orchestration*.log",
        }

        for test_type, pattern in result_patterns.items():
            for file_path in glob.glob(str(self.test_reports_dir / pattern), recursive=True):
                result = self._parse_test_result(file_path, test_type)
                if result:
                    results.append(result)

        # æŒ‰æ—¶é—´æˆ³æ’åº
        results.sort(key=lambda x: x.timestamp, reverse=True)

        logger.info(f"æ”¶é›†åˆ° {len(results)} ä¸ªæµ‹è¯•ç»“æœ")
        return results

    def _parse_test_result(self, file_path: str, test_type: str) -> Optional[TestResult]:
        """è§£æå•ä¸ªæµ‹è¯•ç»“æœæ–‡ä»¶"""
        try:
            file_path = Path(file_path)

            # æå–Phaseä¿¡æ¯ä»æ–‡ä»¶è·¯å¾„æˆ–å†…å®¹
            phase = self._extract_phase_from_path(file_path)

            # è¯»å–æ–‡ä»¶å†…å®¹
            if file_path.suffix == ".json":
                with open(file_path, "r", encoding="utf-8") as f:
                    content = json.load(f)
                status = content.get("status", "unknown")
                duration = content.get("duration", 0)
                errors = content.get("errors", [])
                warnings = content.get("warnings", [])
                metrics = content.get("metrics", {})
            else:
                # æ—¥å¿—æ–‡ä»¶å¤„ç†
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()

                # åˆ†ææ—¥å¿—å†…å®¹
                status, duration, errors, warnings, metrics = self._analyze_log_content(content)

            # æå–æ—¶é—´æˆ³
            timestamp = self._extract_timestamp_from_file(file_path)

            return TestResult(
                phase=phase,
                test_type=test_type,
                status=status,
                duration=duration,
                errors=errors,
                warnings=warnings,
                metrics=metrics,
                timestamp=timestamp,
                file_path=str(file_path),
            )

        except Exception as e:
            logger.warning(f"è§£ææµ‹è¯•ç»“æœå¤±è´¥ {file_path}: {e}")
            return None

    def _extract_phase_from_path(self, file_path: Path) -> str:
        """ä»æ–‡ä»¶è·¯å¾„æå–Phaseä¿¡æ¯"""
        path_str = str(file_path)
        phase_match = re.search(r"phase[_-](\d+)", path_str, re.IGNORECASE)
        if phase_match:
            return f"phase_{phase_match.group(1)}"

        # ä»æ–‡ä»¶åæˆ–å†…å®¹æ¨æ–­
        if "esm" in path_str.lower():
            return "phase_0"
        elif "environment" in path_str.lower():
            return "phase_1"
        elif "schemathesis" in path_str.lower():
            return "phase_2"
        elif "playwright" in path_str.lower():
            return "phase_3"
        elif "orchestration" in path_str.lower():
            return "phase_4"
        elif "performance" in path_str.lower():
            return "phase_5"

        return "unknown"

    def _analyze_log_content(self, content: str) -> Tuple[str, float, List[str], List[str], Dict[str, Any]]:
        """åˆ†ææ—¥å¿—æ–‡ä»¶å†…å®¹"""
        status = "unknown"
        duration = 0.0
        errors = []
        warnings = []
        metrics = {}

        lines = content.split("\n")

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # çŠ¶æ€åˆ¤æ–­
            if "âœ…" in line or "SUCCESS" in line or "æˆåŠŸ" in line:
                if status == "unknown":
                    status = "passed"
            elif "âŒ" in line or "ERROR" in line or "å¤±è´¥" in line:
                status = "failed"
            elif "âš ï¸" in line or "WARN" in line or "è­¦å‘Š" in line:
                if status != "failed":
                    status = "warning"

            # é”™è¯¯ä¿¡æ¯æå–
            if "ERROR" in line or "âŒ" in line or "å¤±è´¥" in line:
                errors.append(line)

            # è­¦å‘Šä¿¡æ¯æå–
            if "WARN" in line or "âš ï¸" in line or "è­¦å‘Š" in line:
                warnings.append(line)

            # æ—¶é—´ä¿¡æ¯æå–
            duration_match = re.search(r"è€—æ—¶[:\s]+([\d.]+)s", line)
            if duration_match:
                duration = float(duration_match.group(1))

        return status, duration, errors, warnings, metrics

    def _extract_timestamp_from_file(self, file_path: Path) -> datetime:
        """ä»æ–‡ä»¶åæå–æ—¶é—´æˆ³"""
        filename = file_path.name

        # å°è¯•åŒ¹é…æ—¶é—´æˆ³æ ¼å¼
        timestamp_patterns = [
            r"(\d{4})(\d{2})(\d{2})_(\d{2})(\d{2})(\d{2})",  # YYYYMMDD_HHMMSS
            r"(\d{4})-(\d{2})-(\d{2})T(\d{2}):(\d{2}):(\d{2})",  # ISOæ ¼å¼
        ]

        for pattern in timestamp_patterns:
            match = re.search(pattern, filename)
            if match:
                try:
                    if len(match.groups()) == 6:
                        year, month, day, hour, minute, second = map(int, match.groups())
                        return datetime(year, month, day, hour, minute, second)
                except ValueError:
                    continue

        # é»˜è®¤ä½¿ç”¨æ–‡ä»¶ä¿®æ”¹æ—¶é—´
        return datetime.fromtimestamp(file_path.stat().st_mtime)

    def diagnose_issues(self, test_results: List[TestResult]) -> List[DiagnosticResult]:
        """
        åŸºäºæµ‹è¯•ç»“æœè¿›è¡Œæ™ºèƒ½è¯Šæ–­

        Args:
            test_results: æµ‹è¯•ç»“æœåˆ—è¡¨

        Returns:
            è¯Šæ–­ç»“æœåˆ—è¡¨
        """
        diagnostics = []

        for result in test_results:
            # åˆ†æé”™è¯¯ä¿¡æ¯
            for error in result.errors:
                diagnostic = self._analyze_error(error, result)
                if diagnostic:
                    diagnostics.append(diagnostic)

            # åˆ†æè­¦å‘Šä¿¡æ¯
            for warning in result.warnings:
                diagnostic = self._analyze_warning(warning, result)
                if diagnostic:
                    diagnostics.append(diagnostic)

            # åˆ†ææ€§èƒ½æŒ‡æ ‡
            if result.metrics:
                perf_diagnostics = self._analyze_performance(result)
                diagnostics.extend(perf_diagnostics)

        # å»é‡å’Œæ’åº
        seen = set()
        unique_diagnostics = []
        for diag in diagnostics:
            key = (diag.issue_type, diag.description)
            if key not in seen:
                seen.add(key)
                unique_diagnostics.append(diag)

        unique_diagnostics.sort(
            key=lambda x: {"critical": 4, "high": 3, "medium": 2, "low": 1}[x.severity], reverse=True
        )

        logger.info(f"ç”Ÿæˆ {len(unique_diagnostics)} ä¸ªè¯Šæ–­ç»“æœ")
        return unique_diagnostics

    def _analyze_error(self, error: str, result: TestResult) -> Optional[DiagnosticResult]:
        """åˆ†æå•ä¸ªé”™è¯¯ä¿¡æ¯"""
        for rule_name, rule_config in self.diagnostic_rules.items():
            patterns = rule_config["patterns"]
            severity = rule_config["severity"]
            category = rule_config["category"]

            for pattern in patterns:
                if re.search(pattern, error, re.IGNORECASE):
                    return DiagnosticResult(
                        issue_type=rule_name,
                        severity=severity,
                        description=f"æ£€æµ‹åˆ°{category}é—®é¢˜: {error[:100]}...",
                        root_cause=self._get_root_cause(rule_name, error),
                        suggestions=self._get_suggestions(rule_name, result),
                        confidence=0.8,
                    )

        # é€šç”¨é”™è¯¯å¤„ç†
        return DiagnosticResult(
            issue_type="general_error",
            severity="medium",
            description=f"æœªçŸ¥é”™è¯¯: {error[:100]}...",
            root_cause="æ— æ³•ç¡®å®šå…·ä½“åŸå› ",
            suggestions=["æ£€æŸ¥è¯¦ç»†æ—¥å¿—æ–‡ä»¶", "æŸ¥çœ‹ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ", "å°è¯•é‡æ–°è¿è¡Œæµ‹è¯•"],
            confidence=0.5,
        )

    def _analyze_warning(self, warning: str, result: TestResult) -> Optional[DiagnosticResult]:
        """åˆ†æè­¦å‘Šä¿¡æ¯"""
        return DiagnosticResult(
            issue_type="warning",
            severity="low",
            description=f"è­¦å‘Šä¿¡æ¯: {warning[:100]}...",
            root_cause="ç³»ç»Ÿè­¦å‘Šï¼Œå¯èƒ½å½±å“ç¨³å®šæ€§",
            suggestions=["ç›‘æ§ç›¸å…³æŒ‡æ ‡", "è€ƒè™‘ä¼˜åŒ–é…ç½®", "æ£€æŸ¥æ—¥å¿—è¶‹åŠ¿"],
            confidence=0.6,
        )

    def _analyze_performance(self, result: TestResult) -> List[DiagnosticResult]:
        """åˆ†ææ€§èƒ½æŒ‡æ ‡"""
        diagnostics = []

        # æ£€æŸ¥æ‰§è¡Œæ—¶é—´
        if result.duration > 300:  # è¶…è¿‡5åˆ†é’Ÿ
            diagnostics.append(
                DiagnosticResult(
                    issue_type="slow_execution",
                    severity="medium",
                    description=f"{result.phase}æ‰§è¡Œæ—¶é—´è¿‡é•¿: {result.duration:.1f}ç§’",
                    root_cause="å¯èƒ½å­˜åœ¨æ€§èƒ½ç“¶é¢ˆæˆ–èµ„æºä¸è¶³",
                    suggestions=["æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ", "ä¼˜åŒ–æµ‹è¯•é…ç½®", "è€ƒè™‘å¹¶è¡Œæ‰§è¡Œ", "åˆ†ææ€§èƒ½ç“¶é¢ˆ"],
                    confidence=0.7,
                )
            )

        return diagnostics

    def _get_root_cause(self, rule_name: str, error: str) -> str:
        """æ ¹æ®è§„åˆ™è·å–æ ¹æœ¬åŸå› """
        causes = {
            "port_conflicts": "ç«¯å£è¢«å…¶ä»–è¿›ç¨‹å ç”¨æˆ–ä¸Šä¸€æ¬¡æµ‹è¯•æœªæ­£ç¡®æ¸…ç†",
            "service_failures": "æœåŠ¡ä¾èµ–æœªæ»¡è¶³æˆ–é…ç½®é”™è¯¯",
            "esm_errors": "ESMæ¨¡å—å¯¼å…¥é…ç½®ä¸æ­£ç¡®æˆ–ä¾èµ–ç‰ˆæœ¬å†²çª",
            "api_failures": "APIæœåŠ¡æœªå¯åŠ¨æˆ–ç½‘ç»œé…ç½®é—®é¢˜",
            "performance_issues": "ç³»ç»Ÿèµ„æºä¸è¶³æˆ–æµ‹è¯•é…ç½®ä¸ä¼˜",
        }
        return causes.get(rule_name, "æœªçŸ¥åŸå› ")

    def _get_suggestions(self, rule_name: str, result: TestResult) -> List[str]:
        """æ ¹æ®è§„åˆ™è·å–ä¿®å¤å»ºè®®"""
        suggestions_map = {
            "port_conflicts": [
                "è¿è¡Œ 'pkill -f \"vite|uvicorn\"' æ¸…ç†æ®‹ç•™è¿›ç¨‹",
                "æ£€æŸ¥ç«¯å£å ç”¨: 'lsof -i :ç«¯å£å·'",
                "ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„ç«¯å£è®¾ç½®",
                "ä½¿ç”¨ 'pm2 kill' åœæ­¢æ‰€æœ‰PM2è¿›ç¨‹",
            ],
            "service_failures": [
                "æ£€æŸ¥æœåŠ¡ä¾èµ–æ˜¯å¦å·²å®‰è£…",
                "éªŒè¯é…ç½®æ–‡ä»¶æ­£ç¡®æ€§",
                "æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—",
                "å°è¯•æ‰‹åŠ¨å¯åŠ¨æœåŠ¡è¿›è¡Œè°ƒè¯•",
            ],
            "esm_errors": [
                "æ£€æŸ¥Viteé…ç½®ä¸­çš„optimizeDepsè®¾ç½®",
                "éªŒè¯dayjsç‰ˆæœ¬æ˜¯å¦æ”¯æŒESM",
                "æ›´æ–°ç›¸å…³ä¾èµ–åŒ…",
                "æ£€æŸ¥importè¯­å¥è¯­æ³•",
            ],
            "api_failures": ["ç¡®ä¿åç«¯æœåŠ¡å·²å¯åŠ¨", "æ£€æŸ¥APIç«¯ç‚¹URLé…ç½®", "éªŒè¯ç½‘ç»œè¿æ¥", "æŸ¥çœ‹APIæœåŠ¡å™¨æ—¥å¿—"],
            "performance_issues": ["å¢åŠ ç³»ç»Ÿå†…å­˜æˆ–CPUèµ„æº", "ä¼˜åŒ–æµ‹è¯•å¹¶å‘é…ç½®", "å‡å°‘æµ‹è¯•æ•°æ®é‡", "ä½¿ç”¨æ€§èƒ½åˆ†æå·¥å…·"],
        }
        return suggestions_map.get(rule_name, ["æŸ¥çœ‹è¯¦ç»†æ—¥å¿—", "è”ç³»æŠ€æœ¯æ”¯æŒ"])

    def generate_optimization_recommendations(
        self, test_results: List[TestResult], diagnostics: List[DiagnosticResult]
    ) -> List[OptimizationRecommendation]:
        """
        ç”Ÿæˆæµ‹è¯•ä¼˜åŒ–æ¨è

        Args:
            test_results: æµ‹è¯•ç»“æœåˆ—è¡¨
            diagnostics: è¯Šæ–­ç»“æœåˆ—è¡¨

        Returns:
            ä¼˜åŒ–æ¨èåˆ—è¡¨
        """
        recommendations = []

        # åŸºäºæµ‹è¯•ç»“æœåˆ†æ
        failed_phases = [r.phase for r in test_results if r.status == "failed"]
        if failed_phases:
            recommendations.append(
                OptimizationRecommendation(
                    category="reliability",
                    priority="high",
                    title="ä¿®å¤å¤±è´¥çš„æµ‹è¯•é˜¶æ®µ",
                    description=f"ä»¥ä¸‹æµ‹è¯•é˜¶æ®µå­˜åœ¨å¤±è´¥: {', '.join(set(failed_phases))}",
                    impact="æé«˜æµ‹è¯•æˆåŠŸç‡å’Œç³»ç»Ÿç¨³å®šæ€§",
                    effort="medium",
                    implementation_steps=[
                        "åˆ†æå¤±è´¥åŸå› å’Œé”™è¯¯æ¨¡å¼",
                        "ä¿®å¤é…ç½®æˆ–ä»£ç é—®é¢˜",
                        "æ·»åŠ é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶",
                        "æ›´æ–°æµ‹è¯•è„šæœ¬å’Œé…ç½®",
                    ],
                )
            )

        # åŸºäºè¯Šæ–­ç»“æœåˆ†æ
        error_categories = {}
        for diag in diagnostics:
            error_categories[diag.issue_type] = error_categories.get(diag.issue_type, 0) + 1

        if error_categories.get("port_conflicts", 0) > 0:
            recommendations.append(
                OptimizationRecommendation(
                    category="environment",
                    priority="high",
                    title="ä¼˜åŒ–ç«¯å£ç®¡ç†",
                    description="æ£€æµ‹åˆ°å¤šæ¬¡ç«¯å£å†²çªï¼Œå½±å“æµ‹è¯•ç¨³å®šæ€§",
                    impact="å‡å°‘ç¯å¢ƒç›¸å…³å¤±è´¥ï¼Œæé«˜æµ‹è¯•æ•ˆç‡",
                    effort="low",
                    implementation_steps=[
                        "å®ç°è‡ªåŠ¨ç«¯å£æ¸…ç†è„šæœ¬",
                        "æ·»åŠ ç«¯å£å ç”¨æ£€æŸ¥å’Œç­‰å¾…æœºåˆ¶",
                        "ä¼˜åŒ–PM2è¿›ç¨‹ç®¡ç†é…ç½®",
                        "ä½¿ç”¨éšæœºç«¯å£åˆ†é…ç­–ç•¥",
                    ],
                )
            )

        if error_categories.get("performance_issues", 0) > 0:
            recommendations.append(
                OptimizationRecommendation(
                    category="performance",
                    priority="medium",
                    title="æ€§èƒ½ä¼˜åŒ–",
                    description="æµ‹è¯•æ‰§è¡Œæ—¶é—´è¿‡é•¿ï¼Œå­˜åœ¨æ€§èƒ½ç“¶é¢ˆ",
                    impact="åŠ å¿«æµ‹è¯•æ‰§è¡Œé€Ÿåº¦ï¼Œæé«˜å¼€å‘æ•ˆç‡",
                    effort="medium",
                    implementation_steps=[
                        "åˆ†ææ€§èƒ½ç“¶é¢ˆï¼ˆCPUã€å†…å­˜ã€ç½‘ç»œï¼‰",
                        "ä¼˜åŒ–æµ‹è¯•é…ç½®å’Œå¹¶å‘è®¾ç½®",
                        "å®ç°æµ‹è¯•ç»“æœç¼“å­˜",
                        "è€ƒè™‘åˆ†å¸ƒå¼æµ‹è¯•æ‰§è¡Œ",
                    ],
                )
            )

        # é€šç”¨ä¼˜åŒ–å»ºè®®
        recommendations.extend(
            [
                OptimizationRecommendation(
                    category="monitoring",
                    priority="medium",
                    title="å¢å¼ºæµ‹è¯•ç›‘æ§",
                    description="æ·»åŠ æ›´è¯¦ç»†çš„æµ‹è¯•æŒ‡æ ‡æ”¶é›†å’Œå¯è§†åŒ–",
                    impact="æ›´å¥½åœ°ç†è§£æµ‹è¯•è¡¨ç°å’Œé—®é¢˜è¶‹åŠ¿",
                    effort="low",
                    implementation_steps=["é›†æˆæµ‹è¯•æŒ‡æ ‡æ”¶é›†", "æ·»åŠ Grafanaä»ªè¡¨æ¿", "å®ç°å‘Šè­¦æœºåˆ¶", "ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"],
                ),
                OptimizationRecommendation(
                    category="automation",
                    priority="low",
                    title="æé«˜è‡ªåŠ¨åŒ–ç¨‹åº¦",
                    description="å‡å°‘æ‰‹åŠ¨å¹²é¢„ï¼Œå¢åŠ æµ‹è¯•æµç¨‹è‡ªåŠ¨åŒ–",
                    impact="é™ä½äººå·¥æˆæœ¬ï¼Œæé«˜ä¸€è‡´æ€§",
                    effort="medium",
                    implementation_steps=["å®ç°è‡ªåŠ¨ç¯å¢ƒæ¸…ç†", "æ·»åŠ æ™ºèƒ½é‡è¯•æœºåˆ¶", "ä¼˜åŒ–CI/CDé›†æˆ", "åˆ›å»ºä¸€é”®æµ‹è¯•è„šæœ¬"],
                ),
            ]
        )

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        priority_order = {"high": 3, "medium": 2, "low": 1}
        recommendations.sort(key=lambda x: priority_order[x.priority], reverse=True)

        logger.info(f"ç”Ÿæˆ {len(recommendations)} ä¸ªä¼˜åŒ–æ¨è")
        return recommendations

    def generate_report(self, output_file: str = None) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„AIåŠ©æ‰‹åˆ†ææŠ¥å‘Š

        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›å­—ç¬¦ä¸²

        Returns:
            åˆ†ææŠ¥å‘Šå†…å®¹
        """
        logger.info("å¼€å§‹ç”ŸæˆAIåŠ©æ‰‹åˆ†ææŠ¥å‘Š...")

        # æ”¶é›†æµ‹è¯•ç»“æœ
        test_results = self.collect_test_results()

        # è¿›è¡Œè¯Šæ–­åˆ†æ
        diagnostics = self.diagnose_issues(test_results)

        # ç”Ÿæˆä¼˜åŒ–æ¨è
        recommendations = self.generate_optimization_recommendations(test_results, diagnostics)

        # ç”ŸæˆæŠ¥å‘Š
        report = self._format_report(test_results, diagnostics, recommendations)

        if output_file:
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(report)
            logger.info(f"åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        else:
            logger.info("åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")

        return report

    def _format_report(
        self,
        test_results: List[TestResult],
        diagnostics: List[DiagnosticResult],
        recommendations: List[OptimizationRecommendation],
    ) -> str:
        """æ ¼å¼åŒ–åˆ†ææŠ¥å‘Š"""
        report_lines = []

        # æŠ¥å‘Šå¤´éƒ¨
        report_lines.append("# AIæµ‹è¯•åŠ©æ‰‹åˆ†ææŠ¥å‘Š")
        report_lines.append("")
        report_lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"**æµ‹è¯•ç»“æœæ•°é‡**: {len(test_results)}")
        report_lines.append(f"**è¯Šæ–­é—®é¢˜æ•°é‡**: {len(diagnostics)}")
        report_lines.append(f"**ä¼˜åŒ–å»ºè®®æ•°é‡**: {len(recommendations)}")
        report_lines.append("")

        # æµ‹è¯•ç»“æœæ‘˜è¦
        report_lines.append("## æµ‹è¯•ç»“æœæ‘˜è¦")
        report_lines.append("")

        status_counts = {}
        for result in test_results:
            status_counts[result.status] = status_counts.get(result.status, 0) + 1

        for status, count in status_counts.items():
            status_icon = {"passed": "âœ…", "failed": "âŒ", "warning": "âš ï¸", "unknown": "â“"}.get(status, "â“")
            report_lines.append(f"- {status_icon} {status}: {count} ä¸ª")

        report_lines.append("")

        # è¯¦ç»†æµ‹è¯•ç»“æœ
        report_lines.append("## è¯¦ç»†æµ‹è¯•ç»“æœ")
        report_lines.append("")

        for result in test_results[:10]:  # åªæ˜¾ç¤ºæœ€è¿‘10ä¸ª
            report_lines.append(f"### {result.phase} - {result.test_type}")
            report_lines.append(f"- **çŠ¶æ€**: {result.status}")
            report_lines.append(f"- **è€—æ—¶**: {result.duration:.1f}ç§’")
            report_lines.append(f"- **æ—¶é—´**: {result.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
            if result.errors:
                report_lines.append(f"- **é”™è¯¯**: {len(result.errors)} ä¸ª")
            if result.warnings:
                report_lines.append(f"- **è­¦å‘Š**: {len(result.warnings)} ä¸ª")
            report_lines.append("")

        # è¯Šæ–­ç»“æœ
        if diagnostics:
            report_lines.append("## è¯Šæ–­ç»“æœ")
            report_lines.append("")

            severity_icons = {"critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}

            for diag in diagnostics[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                icon = severity_icons.get(diag.severity, "âšª")
                report_lines.append(f"### {icon} {diag.issue_type} ({diag.severity})")
                report_lines.append(f"**æè¿°**: {diag.description}")
                report_lines.append(f"**æ ¹æœ¬åŸå› **: {diag.root_cause}")
                report_lines.append("**å»ºè®®**:")
                for suggestion in diag.suggestions[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªå»ºè®®
                    report_lines.append(f"  - {suggestion}")
                report_lines.append(f"**ç½®ä¿¡åº¦**: {diag.confidence:.1%}")
                report_lines.append("")

        # ä¼˜åŒ–æ¨è
        if recommendations:
            report_lines.append("## ä¼˜åŒ–æ¨è")
            report_lines.append("")

            priority_icons = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}

            for rec in recommendations[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                icon = priority_icons.get(rec.priority, "âšª")
                report_lines.append(f"### {icon} {rec.title} ({rec.category})")
                report_lines.append(f"**æè¿°**: {rec.description}")
                report_lines.append(f"**å½±å“**: {rec.impact}")
                report_lines.append(f"**éš¾åº¦**: {rec.effort}")
                report_lines.append("**å®æ–½æ­¥éª¤**:")
                for step in rec.implementation_steps[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªæ­¥éª¤
                    report_lines.append(f"  - {step}")
                report_lines.append("")

        # æ€»ç»“
        report_lines.append("## æ€»ç»“")
        report_lines.append("")
        report_lines.append("æ­¤æŠ¥å‘Šç”±AIæµ‹è¯•åŠ©æ‰‹è‡ªåŠ¨ç”Ÿæˆï¼ŒåŸºäºæµ‹è¯•ç»“æœçš„æ™ºèƒ½åˆ†æã€‚")
        report_lines.append("å»ºè®®ä¼˜å…ˆå¤„ç†é«˜ä¼˜å…ˆçº§çš„è¯Šæ–­é—®é¢˜å’Œä¼˜åŒ–æ¨èã€‚")

        return "\n".join(report_lines)


def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºå‘½ä»¤è¡Œè°ƒç”¨"""
    import argparse

    parser = argparse.ArgumentParser(description="MyStocks AIæµ‹è¯•åŠ©æ‰‹")
    parser.add_argument("--project-root", help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„")
    parser.add_argument("--output", "-o", help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡º")

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    try:
        # åˆå§‹åŒ–AIåŠ©æ‰‹
        assistant = AITestAssistant(args.project_root)

        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        report = assistant.generate_report(args.output)

        if not args.output:
            print(report)

        print("\nğŸ‰ AIæµ‹è¯•åŠ©æ‰‹åˆ†æå®Œæˆ!")
        print("å»ºè®®æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Šä»¥äº†è§£æµ‹è¯•é—®é¢˜å’Œä¼˜åŒ–å»ºè®®ã€‚")

    except Exception as e:
        logger.error(f"AIåŠ©æ‰‹æ‰§è¡Œå¤±è´¥: {e}")
        exit(1)


if __name__ == "__main__":
    main()
