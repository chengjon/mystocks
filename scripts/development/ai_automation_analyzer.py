#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MyStocks AIè‡ªåŠ¨åŒ–ç°çŠ¶åˆ†æè„šæœ¬
ç¬¬ä¸€é˜¶æ®µï¼šå…¨é¢è¯„ä¼°ç°æœ‰AIåŸºç¡€è®¾æ–½
"""

import os
import json
import time
import subprocess
import psutil
from pathlib import Path
from typing import Dict, List, Any
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class AIAutomationAnalyzer:
    """AIè‡ªåŠ¨åŒ–ç°çŠ¶åˆ†æå™¨"""

    def __init__(self, project_root: str = "/opt/claude/mystocks_spec"):
        self.project_root = Path(project_root)
        self.analysis_results = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "project_root": str(self.project_root),
            "system_status": {},
            "ai_infrastructure": {},
            "performance_metrics": {},
            "automation_capabilities": {},
            "recommendations": [],
        }

    def analyze_system_status(self) -> Dict[str, Any]:
        """åˆ†æç³»ç»ŸçŠ¶æ€"""
        logger.info("ğŸ” åˆ†æç³»ç»ŸçŠ¶æ€...")

        status = {
            "cpu_info": {
                "cores": psutil.cpu_count(),
                "usage_percent": psutil.cpu_percent(interval=1),
                "load_average": os.getloadavg() if hasattr(os, "getloadavg") else None,
            },
            "memory_info": {
                "total_gb": round(psutil.virtual_memory().total / (1024**3), 2),
                "available_gb": round(psutil.virtual_memory().available / (1024**3), 2),
                "usage_percent": psutil.virtual_memory().percent,
            },
            "disk_info": {
                "total_gb": round(
                    psutil.disk_usage(self.project_root).total / (1024**3), 2
                ),
                "free_gb": round(
                    psutil.disk_usage(self.project_root).free / (1024**3), 2
                ),
                "usage_percent": round(
                    (
                        psutil.disk_usage(self.project_root).used
                        / psutil.disk_usage(self.project_root).total
                    )
                    * 100,
                    2,
                ),
            },
            "gpu_info": self._check_gpu_status(),
            "database_status": self._check_database_status(),
        }

        self.analysis_results["system_status"] = status
        return status

    def _check_gpu_status(self) -> Dict[str, Any]:
        """æ£€æŸ¥GPUçŠ¶æ€"""
        try:
            import GPUtil

            gpus = GPUtil.getGPUs()
            gpu_info = []
            for gpu in gpus:
                gpu_info.append(
                    {
                        "name": gpu.name,
                        "memory_total": gpu.memoryTotal,
                        "memory_used": gpu.memoryUsed,
                        "memory_util": gpu.memoryUtil * 100,
                        "temperature": gpu.temperature,
                        "load": gpu.load * 100,
                    }
                )
            return {"available": True, "gpus": gpu_info}
        except ImportError:
            return {"available": False, "error": "GPUtil not installed"}
        except Exception as e:
            return {"available": False, "error": str(e)}

    def _check_database_status(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®åº“è¿æ¥çŠ¶æ€"""
        db_status = {"postgresql": False, "tdengine": False}

        # æ£€æŸ¥PostgreSQL
        try:
            result = subprocess.run(["which", "psql"], capture_output=True, text=True)
            if result.returncode == 0:
                db_status["postgresql"] = True
                db_status["postgresql_path"] = result.stdout.strip()
        except:
            pass

        # æ£€æŸ¥TDengine
        try:
            result = subprocess.run(["which", "taos"], capture_output=True, text=True)
            if result.returncode == 0:
                db_status["tdengine"] = True
                db_status["tdengine_path"] = result.stdout.strip()
        except:
            pass

        return db_status

    def analyze_ai_infrastructure(self) -> Dict[str, Any]:
        """åˆ†æAIåŸºç¡€è®¾æ–½"""
        logger.info("ğŸ§  åˆ†æAIåŸºç¡€è®¾æ–½...")

        ai_infra = {
            "gpu_api_system": self._check_gpu_api_system(),
            "ml_services": self._check_ml_services(),
            "data_sources": self._check_data_sources(),
            "api_endpoints": self._check_api_endpoints(),
            "monitoring_systems": self._check_monitoring_systems(),
        }

        self.analysis_results["ai_infrastructure"] = ai_infra
        return ai_infra

    def _check_gpu_api_system(self) -> Dict[str, Any]:
        """æ£€æŸ¥GPU APIç³»ç»Ÿ"""
        gpu_api_path = self.project_root / "src/gpu/api_system"

        if not gpu_api_path.exists():
            return {"exists": False, "path": str(gpu_api_path)}

        # æ£€æŸ¥å…³é”®æ–‡ä»¶
        key_files = [
            "main_server.py",
            "services/gpu_api_server.py",
            "services/integrated_ml_service.py",
            "utils/gpu_utils.py",
            "PROJECT_SUMMARY.md",
        ]

        files_found = {}
        for file in key_files:
            file_path = gpu_api_path / file
            files_found[file] = file_path.exists()

        # è®¡ç®—ä»£ç è¡Œæ•°
        try:
            total_lines = 0
            python_files = list(gpu_api_path.rglob("*.py"))
            for py_file in python_files:
                with open(py_file, "r", encoding="utf-8") as f:
                    total_lines += len(f.readlines())

            files_found["total_python_lines"] = total_lines
            files_found["python_file_count"] = len(python_files)
        except:
            files_found["line_count_error"] = "æ— æ³•è®¡ç®—ä»£ç è¡Œæ•°"

        return {
            "exists": True,
            "path": str(gpu_api_path),
            "files": files_found,
            "ready": all([files_found.get(f, False) for f in key_files[:4]]),
        }

    def _check_ml_services(self) -> Dict[str, Any]:
        """æ£€æŸ¥MLæœåŠ¡"""
        ml_path = self.project_root / "src/gpu/api_system/services"

        services = {
            "ml_service": False,
            "backtesting_service": False,
            "real_time_service": False,
        }

        if ml_path.exists():
            service_files = list(ml_path.glob("*_service.py"))
            for service_file in service_files:
                if "ml" in service_file.name.lower():
                    services["ml_service"] = True
                elif "backtest" in service_file.name.lower():
                    services["backtesting_service"] = True
                elif "real" in service_file.name.lower():
                    services["real_time_service"] = True

        return services

    def _check_data_sources(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®æº"""
        adapters_path = self.project_root / "src/adapters"

        data_sources = {
            "akshare": False,
            "tdx": False,
            "financial": False,
            "byapi": False,
            "baostock": False,
            "customer": False,
            "tushare": False,
        }

        if adapters_path.exists():
            adapter_files = list(adapters_path.glob("*_adapter.py"))
            for adapter_file in adapter_files:
                for source in data_sources.keys():
                    if source in adapter_file.name.lower():
                        data_sources[source] = True

        return data_sources

    def _check_api_endpoints(self) -> Dict[str, Any]:
        """æ£€æŸ¥APIç«¯ç‚¹"""
        api_path = self.project_root / "web/backend/app/api"

        endpoints = {
            "monitoring": False,
            "technical": False,
            "multi_source": False,
            "announcement": False,
        }

        if api_path.exists():
            endpoint_dirs = [d for d in api_path.iterdir() if d.is_dir()]
            for endpoint_dir in endpoint_dirs:
                endpoint_name = endpoint_dir.name
                if endpoint_name in endpoints:
                    endpoints[endpoint_name] = True

        return endpoints

    def _check_monitoring_systems(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç›‘æ§ç³»ç»Ÿ"""
        monitoring_path = self.project_root / "src/monitoring"

        monitoring_components = {
            "performance_monitor": False,
            "data_quality_monitor": False,
            "alert_manager": False,
            "monitoring_database": False,
        }

        if monitoring_path.exists():
            monitor_files = list(monitoring_path.glob("*.py"))
            for monitor_file in monitor_files:
                for component in monitoring_components.keys():
                    if component.replace("_", "") in monitor_file.name.replace("_", ""):
                        monitoring_components[component] = True

        return monitoring_components

    def analyze_performance_metrics(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½æŒ‡æ ‡"""
        logger.info("ğŸ“Š åˆ†ææ€§èƒ½æŒ‡æ ‡...")

        metrics = {
            "code_complexity": self._analyze_code_complexity(),
            "test_coverage": self._analyze_test_coverage(),
            "documentation": self._analyze_documentation(),
        }

        self.analysis_results["performance_metrics"] = metrics
        return metrics

    def _analyze_code_complexity(self) -> Dict[str, Any]:
        """åˆ†æä»£ç å¤æ‚åº¦"""
        src_path = self.project_root / "src"

        if not src_path.exists():
            return {"error": "srcç›®å½•ä¸å­˜åœ¨"}

        total_lines = 0
        file_count = 0
        language_stats = {}

        for file_path in src_path.rglob("*"):
            if file_path.is_file():
                ext = file_path.suffix
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        lines = len(f.readlines())
                        total_lines += lines
                        file_count += 1

                        if ext not in language_stats:
                            language_stats[ext] = {"files": 0, "lines": 0}
                        language_stats[ext]["files"] += 1
                        language_stats[ext]["lines"] += lines
                except:
                    continue

        return {
            "total_lines": total_lines,
            "total_files": file_count,
            "languages": language_stats,
        }

    def _analyze_test_coverage(self) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•è¦†ç›–ç‡"""
        tests_path = self.project_root / "tests"

        if not tests_path.exists():
            return {"tests_exist": False}

        test_files = list(tests_path.rglob("test_*.py"))

        return {
            "tests_exist": True,
            "test_file_count": len(test_files),
            "tests_path": str(tests_path),
        }

    def _analyze_documentation(self) -> Dict[str, Any]:
        """åˆ†ææ–‡æ¡£å®Œæ•´æ€§"""
        docs_path = self.project_root / "docs"

        if not docs_path.exists():
            return {"docs_exist": False}

        doc_files = list(docs_path.rglob("*.md"))

        return {
            "docs_exist": True,
            "doc_file_count": len(doc_files),
            "docs_path": str(docs_path),
        }

    def generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        # åŸºäºGPUç³»ç»ŸçŠ¶æ€
        gpu_status = self.analysis_results["system_status"].get("gpu_info", {})
        if gpu_status.get("available", False):
            recommendations.append("âœ… GPUåŠ é€Ÿç³»ç»Ÿå¯ç”¨ï¼Œå»ºè®®æ¿€æ´»GPUåŠ é€ŸAIè®¡ç®—")
        else:
            recommendations.append("âš ï¸  GPUåŠ é€Ÿä¸å¯ç”¨ï¼Œå»ºè®®å®‰è£…GPUtilåº“ä»¥å¯ç”¨GPUç›‘æ§")

        # åŸºäºAIåŸºç¡€è®¾æ–½
        ai_infra = self.analysis_results["ai_infrastructure"]
        if ai_infra.get("gpu_api_system", {}).get("ready", False):
            recommendations.append("âœ… GPU APIç³»ç»Ÿå·²å°±ç»ªï¼Œå¯ä»¥å¼€å§‹AIè‡ªåŠ¨åŒ–é›†æˆæµ‹è¯•")
        else:
            recommendations.append("ğŸ”§ GPU APIç³»ç»Ÿé…ç½®ä¸å®Œæ•´ï¼Œå»ºè®®å®Œå–„å…³é”®æ–‡ä»¶")

        # åŸºäºæ•°æ®åº“çŠ¶æ€
        db_status = self.analysis_results["system_status"].get("database_status", {})
        if all(db_status.values()):
            recommendations.append("âœ… æ•°æ®åº“ç¯å¢ƒå®Œæ•´ï¼Œæ”¯æŒAIè‡ªåŠ¨åŒ–æ•°æ®å¤„ç†")
        else:
            recommendations.append("ğŸ”§ æ•°æ®åº“ç¯å¢ƒä¸å®Œæ•´ï¼Œå»ºè®®å®‰è£…PostgreSQLå’ŒTDengine")

        # åŸºäºä»£ç å¤æ‚åº¦
        perf_metrics = self.analysis_results["performance_metrics"]
        code_complexity = perf_metrics.get("code_complexity", {})
        if code_complexity.get("total_lines", 0) > 10000:
            recommendations.append("ğŸ“š ä»£ç åº“è§„æ¨¡è¾ƒå¤§ï¼Œå»ºè®®å»ºç«‹å®Œå–„çš„è‡ªåŠ¨åŒ–æµ‹è¯•ä½“ç³»")

        self.analysis_results["recommendations"] = recommendations
        return recommendations

    def run_full_analysis(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        logger.info("ğŸš€ å¼€å§‹MyStocks AIè‡ªåŠ¨åŒ–ç°çŠ¶åˆ†æ...")

        try:
            # ç³»ç»ŸçŠ¶æ€åˆ†æ
            self.analyze_system_status()

            # AIåŸºç¡€è®¾æ–½åˆ†æ
            self.analyze_ai_infrastructure()

            # æ€§èƒ½æŒ‡æ ‡åˆ†æ
            self.analyze_performance_metrics()

            # ç”Ÿæˆå»ºè®®
            self.generate_recommendations()

            logger.info("âœ… åˆ†æå®Œæˆï¼")
            return self.analysis_results

        except Exception as e:
            logger.error(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            self.analysis_results["analysis_error"] = str(e)
            return self.analysis_results

    def save_results(self, output_file: str = None) -> str:
        """ä¿å­˜åˆ†æç»“æœ"""
        if not output_file:
            output_file = (
                self.project_root / f"ai_automation_analysis_{int(time.time())}.json"
            )

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(self.analysis_results, f, ensure_ascii=False, indent=2)

        return str(output_file)

    def print_summary(self):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ¯ MyStocks AIè‡ªåŠ¨åŒ–ç°çŠ¶åˆ†ææ‘˜è¦")
        print("=" * 60)

        # ç³»ç»ŸçŠ¶æ€
        system_status = self.analysis_results["system_status"]
        print("\nğŸ“Š ç³»ç»ŸçŠ¶æ€:")
        print(f"  CPUæ ¸å¿ƒæ•°: {system_status['cpu_info']['cores']}")
        print(f"  CPUä½¿ç”¨ç‡: {system_status['cpu_info']['usage_percent']}%")
        print(f"  å†…å­˜ä½¿ç”¨ç‡: {system_status['memory_info']['usage_percent']}%")
        print(f"  ç£ç›˜ä½¿ç”¨ç‡: {system_status['disk_info']['usage_percent']}%")

        gpu_info = system_status.get("gpu_info", {})
        if gpu_info.get("available"):
            print(f"  GPUçŠ¶æ€: âœ… å¯ç”¨ ({len(gpu_info.get('gpus', []))}ä¸ªGPU)")
        else:
            print("  GPUçŠ¶æ€: âŒ ä¸å¯ç”¨")

        # AIåŸºç¡€è®¾æ–½
        ai_infra = self.analysis_results["ai_infrastructure"]
        print("\nğŸ§  AIåŸºç¡€è®¾æ–½:")

        gpu_api = ai_infra.get("gpu_api_system", {})
        if gpu_api.get("ready"):
            print("  GPU APIç³»ç»Ÿ: âœ… å°±ç»ª")
        else:
            print("  GPU APIç³»ç»Ÿ: âŒ æœªå°±ç»ª")

        ml_services = ai_infra.get("ml_services", {})
        active_services = sum(1 for v in ml_services.values() if v)
        print(f"  MLæœåŠ¡: {active_services}/{len(ml_services)} ä¸ªæ´»è·ƒ")

        data_sources = ai_infra.get("data_sources", {})
        active_sources = sum(1 for v in data_sources.values() if v)
        print(f"  æ•°æ®æº: {active_sources}/{len(data_sources)} ä¸ªå¯ç”¨")

        # å»ºè®®
        print("\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        for i, rec in enumerate(self.analysis_results["recommendations"], 1):
            print(f"  {i}. {rec}")

        print("\nğŸ“ è¯¦ç»†åˆ†æç»“æœå·²ä¿å­˜")
        print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    analyzer = AIAutomationAnalyzer()

    # è¿è¡Œåˆ†æ
    results = analyzer.run_full_analysis()

    # ä¿å­˜ç»“æœ
    output_file = analyzer.save_results()
    print(f"ğŸ“„ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    # æ‰“å°æ‘˜è¦
    analyzer.print_summary()

    return results


if __name__ == "__main__":
    main()
