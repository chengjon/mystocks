#!/usr/bin/env python3
"""
è¯¦ç»†æŠ€æœ¯å€ºåŠ¡å¤æ‚åº¦è¯„ä¼°å™¨
ä¸“é—¨é’ˆå¯¹ç‰¹å®šæ–‡ä»¶è¿›è¡Œæ·±å…¥çš„æŠ€æœ¯å€ºåŠ¡åˆ†æ
"""

import ast
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import radon.complexity as radon_cc


class DetailedTechnicalDebtAssessment:
    """è¯¦ç»†æŠ€æœ¯å€ºåŠ¡è¯„ä¼°å™¨"""

    def __init__(self):
        self.project_root = Path.cwd()  # ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•
        self.assessment_results = {}

    def analyze_file_complexity(self, file_path: str) -> Dict[str, Any]:
        """
        åˆ†æå•ä¸ªæ–‡ä»¶çš„å¤æ‚åº¦

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            Dict[str, Any]: å¤æ‚åº¦åˆ†æç»“æœ
        """
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # åŸºç¡€ç»Ÿè®¡
            lines = content.split("\n")
            total_lines = len(lines)
            code_lines = len(
                [
                    line
                    for line in lines
                    if line.strip() and not line.strip().startswith("#")
                ]
            )
            comment_lines = len(
                [line for line in lines if line.strip().startswith("#")]
            )
            empty_lines = total_lines - code_lines - comment_lines

            # ASTè§£æ
            try:
                tree = ast.parse(content)

                # ç»Ÿè®¡ç±»å’Œå‡½æ•°
                classes = []
                functions = []
                imports = []

                for node in ast.walk(tree):
                    if isinstance(node, ast.ClassDef):
                        class_info = {
                            "name": node.name,
                            "line_start": node.lineno,
                            "line_end": node.end_lineno
                            if hasattr(node, "end_lineno")
                            else "unknown",
                            "methods": [
                                n.name
                                for n in node.body
                                if isinstance(n, ast.FunctionDef)
                            ],
                        }
                        classes.append(class_info)
                    elif isinstance(node, ast.FunctionDef):
                        func_info = {
                            "name": node.name,
                            "line_start": node.lineno,
                            "line_end": node.end_lineno
                            if hasattr(node, "end_lineno")
                            else "unknown",
                            "args": [arg.arg for arg in node.args.args],
                        }
                        functions.append(func_info)
                    elif isinstance(node, (ast.Import, ast.ImportFrom)):
                        if isinstance(node, ast.Import):
                            for alias in node.names:
                                imports.append(f"import {alias.name}")
                        else:
                            module = node.module or ""
                            for alias in node.names:
                                imports.append(f"from {module} import {alias.name}")

            except SyntaxError as e:
                return {
                    "error": f"Syntax error: {e}",
                    "total_lines": total_lines,
                    "file_path": file_path,
                }

            # ä½¿ç”¨radonè®¡ç®—åœˆå¤æ‚åº¦
            try:
                cc_results = radon_cc.cc_visit(content)
                max_complexity = max(
                    [result.complexity for result in cc_results], default=0
                )
                avg_complexity = (
                    sum([result.complexity for result in cc_results]) / len(cc_results)
                    if cc_results
                    else 0
                )

                complex_functions = [
                    result for result in cc_results if result.complexity > 10
                ]

            except Exception:
                cc_results = []
                max_complexity = 0
                avg_complexity = 0
                complex_functions = []

            # ä¾èµ–åˆ†æ
            dependencies = self._analyze_dependencies(file_path)

            # æµ‹è¯•è¦†ç›–ç‡åˆ†æ
            test_coverage = self._analyze_test_coverage(file_path)

            # ä»£ç è´¨é‡æŒ‡æ ‡
            quality_metrics = {
                "maintainability_index": self._calculate_maintainability_index(
                    cc_results
                ),
                "documentation_ratio": self._calculate_documentation_ratio(
                    classes, functions
                ),
                "function_length_avg": self._calculate_avg_function_length(functions),
                "class_method_avg": len([f for f in functions if "." in f["name"]])
                / len(classes)
                if classes
                else 0,
            }

            return {
                "file_path": file_path,
                "file_size": {
                    "total_lines": total_lines,
                    "code_lines": code_lines,
                    "comment_lines": comment_lines,
                    "empty_lines": empty_lines,
                },
                "structure": {
                    "classes_count": len(classes),
                    "functions_count": len(functions),
                    "imports_count": len(imports),
                    "classes": classes,
                    "functions": functions,
                    "imports": imports,
                },
                "complexity": {
                    "max_complexity": max_complexity,
                    "avg_complexity": avg_complexity,
                    "complex_functions": len(complex_functions),
                    "complex_functions_detail": [
                        {
                            "name": result.name,
                            "complexity": result.complexity,
                            "line": result.lineno,
                        }
                        for result in complex_functions
                    ],
                },
                "dependencies": dependencies,
                "test_coverage": test_coverage,
                "quality_metrics": quality_metrics,
                "risk_assessment": self._assess_risks(
                    max_complexity, len(classes), len(functions), dependencies
                ),
            }

        except Exception as e:
            return {"file_path": file_path, "error": f"Analysis failed: {str(e)}"}

    def _analyze_dependencies(self, file_path: str) -> Dict[str, Any]:
        """åˆ†ææ–‡ä»¶ä¾èµ–"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # è§£æå¯¼å…¥è¯­å¥
            tree = ast.parse(content)

            internal_deps = []  # é¡¹ç›®å†…éƒ¨ä¾èµ–
            external_deps = []  # å¤–éƒ¨åº“ä¾èµ–
            standard_deps = []  # æ ‡å‡†åº“ä¾èµ–

            project_modules = self._get_project_modules()

            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        if alias.name.startswith(
                            ("src.", "core.", "adapters.", "monitoring.")
                        ):
                            internal_deps.append(alias.name)
                        elif alias.name in [
                            "os",
                            "sys",
                            "json",
                            "time",
                            "datetime",
                            "pathlib",
                            "typing",
                            "collections",
                            "itertools",
                            "functools",
                        ]:
                            standard_deps.append(alias.name)
                        else:
                            external_deps.append(alias.name)

                elif isinstance(node, ast.ImportFrom):
                    module = node.module or ""
                    if module.startswith(("src.", "core.", "adapters.", "monitoring.")):
                        internal_deps.append(module)
                    elif module in [
                        "os",
                        "sys",
                        "json",
                        "time",
                        "datetime",
                        "pathlib",
                        "typing",
                        "collections",
                        "itertools",
                        "functools",
                    ]:
                        standard_deps.append(module)
                    else:
                        external_deps.append(module)

            return {
                "internal_dependencies": list(set(internal_deps)),
                "external_dependencies": list(set(external_deps)),
                "standard_dependencies": list(set(standard_deps)),
                "total_dependencies": len(
                    set(internal_deps + external_deps + standard_deps)
                ),
            }

        except Exception as e:
            return {"error": f"Dependency analysis failed: {str(e)}"}

    def _get_project_modules(self) -> List[str]:
        """è·å–é¡¹ç›®æ¨¡å—åˆ—è¡¨"""
        modules = []
        try:
            for root, dirs, files in os.walk(self.project_root):
                if "__pycache__" in root:
                    continue
                for file in files:
                    if file.endswith(".py") and not file.startswith("__"):
                        rel_path = os.path.relpath(
                            os.path.join(root, file), self.project_root
                        )
                        module_path = rel_path[:-3].replace(os.sep, ".")
                        modules.append(module_path)
        except Exception:
            pass
        return modules

    def _analyze_test_coverage(self, file_path: str) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•è¦†ç›–ç‡"""
        # æŸ¥æ‰¾å¯¹åº”çš„æµ‹è¯•æ–‡ä»¶
        file_path = Path(file_path).resolve()
        try:
            relative_path = file_path.relative_to(self.project_root)
        except ValueError:
            # å¦‚æœæ–‡ä»¶ä¸åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œä½¿ç”¨æ–‡ä»¶å
            relative_path = file_path

        # å¯èƒ½çš„æµ‹è¯•æ–‡ä»¶è·¯å¾„
        test_patterns = [
            f"tests/test_{file_path.stem}.py",
            f"tests/{file_path.stem}_test.py",
            f"tests/{file_path.parent.name}/test_{file_path.stem}.py",
            f"tests/unit/{file_path.parent.name}/test_{file_path.stem}.py",
            f"tests/integration/{file_path.parent.name}/test_{file_path.stem}.py",
        ]

        test_files = []
        for pattern in test_patterns:
            test_path = self.project_root / pattern
            if test_path.exists():
                test_files.append(str(test_path))

        # åˆ†ææµ‹è¯•å†…å®¹
        test_methods = []
        for test_file in test_files:
            try:
                with open(test_file, "r", encoding="utf-8") as f:
                    content = f.read()

                tree = ast.parse(content)
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef) and node.name.startswith(
                        "test_"
                    ):
                        test_methods.append(
                            {"name": node.name, "file": test_file, "line": node.lineno}
                        )
            except Exception:
                continue

        return {
            "test_files_found": test_files,
            "test_methods_count": len(test_methods),
            "test_methods": test_methods[:10],  # åªæ˜¾ç¤ºå‰10ä¸ª
            "coverage_estimate": "high"
            if len(test_methods) > 10
            else "medium"
            if len(test_methods) > 3
            else "low",
        }

    def _calculate_maintainability_index(self, cc_results) -> float:
        """è®¡ç®—å¯ç»´æŠ¤æ€§æŒ‡æ•°"""
        try:
            if not cc_results:
                return 85.0  # é»˜è®¤å€¼

            total_complexity = sum(result.complexity for result in cc_results)
            avg_complexity = total_complexity / len(cc_results)

            # ç®€åŒ–çš„å¯ç»´æŠ¤æ€§æŒ‡æ•°è®¡ç®—
            maintainability = max(0, 100 - (avg_complexity * 5))
            return min(100, maintainability)
        except Exception:
            return 50.0

    def _calculate_documentation_ratio(self, classes: List, functions: List) -> float:
        """è®¡ç®—æ–‡æ¡£è¦†ç›–ç‡"""
        try:
            total_items = len(classes) + len(functions)
            if total_items == 0:
                return 0.0

            documented = 0
            for item in classes + functions:
                # ç®€åŒ–æ£€æŸ¥ï¼šå¦‚æœç±»/å‡½æ•°åç§°æš—ç¤ºå…¶åŠŸèƒ½ï¼Œè®¤ä¸ºæœ‰ä¸€å®šæ–‡æ¡£ä»·å€¼
                if any(
                    keyword in item["name"].lower()
                    for keyword in ["test", "init", "main", "run"]
                ):
                    documented += 1

            return (documented / total_items) * 100
        except Exception:
            return 0.0

    def _calculate_avg_function_length(self, functions: List) -> float:
        """è®¡ç®—å¹³å‡å‡½æ•°é•¿åº¦"""
        try:
            if not functions:
                return 0.0

            total_length = 0
            count = 0
            for func in functions:
                if func["line_end"] != "unknown":
                    length = func["line_end"] - func["line_start"] + 1
                    total_length += length
                    count += 1

            return total_length / count if count > 0 else 0.0
        except Exception:
            return 0.0

    def _assess_risks(
        self,
        max_complexity: int,
        class_count: int,
        function_count: int,
        dependencies: Dict,
    ) -> Dict[str, Any]:
        """è¯„ä¼°é‡æ„é£é™©"""
        risk_score = 0
        risks = []

        # å¤æ‚åº¦é£é™©
        if max_complexity > 20:
            risk_score += 3
            risks.append("æé«˜å¤æ‚åº¦ï¼Œéœ€è¦ç«‹å³é‡æ„")
        elif max_complexity > 15:
            risk_score += 2
            risks.append("é«˜å¤æ‚åº¦ï¼Œå»ºè®®é‡æ„")
        elif max_complexity > 10:
            risk_score += 1
            risks.append("ä¸­ç­‰å¤æ‚åº¦ï¼Œåº”è€ƒè™‘é‡æ„")

        # ç»“æ„é£é™©
        if function_count > 50:
            risk_score += 2
            risks.append("å‡½æ•°è¿‡å¤šï¼Œæ¨¡å—èŒè´£ä¸æ¸…")
        elif function_count > 30:
            risk_score += 1
            risks.append("å‡½æ•°è¾ƒå¤šï¼Œå¯èƒ½éœ€è¦æ‹†åˆ†")

        if class_count > 10:
            risk_score += 2
            risks.append("ç±»è¿‡å¤šï¼Œè®¾è®¡å¯èƒ½å¤æ‚")

        # ä¾èµ–é£é™©
        total_deps = dependencies.get("total_dependencies", 0)
        if total_deps > 15:
            risk_score += 2
            risks.append("ä¾èµ–è¿‡å¤šï¼Œè€¦åˆåº¦é«˜")
        elif total_deps > 10:
            risk_score += 1
            risks.append("ä¾èµ–è¾ƒå¤šï¼Œéœ€è¦å…³æ³¨è€¦åˆåº¦")

        # é£é™©ç­‰çº§
        if risk_score >= 5:
            risk_level = "HIGH"
        elif risk_score >= 3:
            risk_level = "MEDIUM"
        else:
            risk_level = "LOW"

        return {
            "risk_score": risk_score,
            "risk_level": risk_level,
            "risks": risks,
            "refactoring_priority": "IMMEDIATE"
            if risk_level == "HIGH"
            else "HIGH"
            if risk_level == "MEDIUM"
            else "MEDIUM",
        }

    def generate_assessment_report(self, file_paths: List[str]) -> str:
        """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
        report_lines = []
        report_lines.append("# è¯¦ç»†æŠ€æœ¯å€ºåŠ¡å¤æ‚åº¦è¯„ä¼°æŠ¥å‘Š")
        report_lines.append("")
        report_lines.append(
            f"**è¯„ä¼°æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        )
        report_lines.append(f"**è¯„ä¼°æ–‡ä»¶æ•°**: {len(file_paths)}")
        report_lines.append("")

        for file_path in file_paths:
            print(f"åˆ†ææ–‡ä»¶: {file_path}")
            result = self.analyze_file_complexity(file_path)

            report_lines.append(f"## ğŸ“ æ–‡ä»¶: {file_path}")
            report_lines.append("")

            if "error" in result:
                report_lines.append(f"âŒ **åˆ†æé”™è¯¯**: {result['error']}")
                report_lines.append("")
                continue

            # æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
            size_info = result["file_size"]
            report_lines.append("### ğŸ“Š æ–‡ä»¶è§„æ¨¡")
            report_lines.append(f"- æ€»è¡Œæ•°: {size_info['total_lines']:,}")
            report_lines.append(f"- ä»£ç è¡Œæ•°: {size_info['code_lines']:,}")
            report_lines.append(f"- æ³¨é‡Šè¡Œæ•°: {size_info['comment_lines']:,}")
            report_lines.append(f"- ç©ºè¡Œæ•°: {size_info['empty_lines']:,}")
            report_lines.append("")

            # ç»“æ„ä¿¡æ¯
            structure_info = result["structure"]
            report_lines.append("### ğŸ—ï¸ ä»£ç ç»“æ„")
            report_lines.append(f"- ç±»æ•°é‡: {structure_info['classes_count']}")
            report_lines.append(f"- å‡½æ•°æ•°é‡: {structure_info['functions_count']}")
            report_lines.append(f"- å¯¼å…¥æ•°é‡: {structure_info['imports_count']}")
            report_lines.append("")

            if structure_info["classes"]:
                report_lines.append("**ç±»åˆ—è¡¨**:")
                for cls in structure_info["classes"]:
                    report_lines.append(
                        f"- {cls['name']} (è¡Œ {cls['line_start']}-{cls['line_end']}, æ–¹æ³•: {len(cls['methods'])})"
                    )
                report_lines.append("")

            # å¤æ‚åº¦ä¿¡æ¯
            complexity_info = result["complexity"]
            report_lines.append("### âš ï¸ å¤æ‚åº¦åˆ†æ")
            report_lines.append(f"- æœ€é«˜å¤æ‚åº¦: {complexity_info['max_complexity']}")
            report_lines.append(
                f"- å¹³å‡å¤æ‚åº¦: {complexity_info['avg_complexity']:.2f}"
            )
            report_lines.append(
                f"- å¤æ‚å‡½æ•°æ•°é‡: {complexity_info['complex_functions']}"
            )
            report_lines.append("")

            if complexity_info["complex_functions_detail"]:
                report_lines.append("**é«˜å¤æ‚åº¦å‡½æ•°** (å¤æ‚åº¦ > 10):")
                for func in complexity_info["complex_functions_detail"][
                    :5
                ]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    report_lines.append(
                        f"- {func['name']}: {func['complexity']} (è¡Œ {func['line']})"
                    )
                report_lines.append("")

            # ä¾èµ–ä¿¡æ¯
            dep_info = result["dependencies"]
            if "error" not in dep_info:
                report_lines.append("### ğŸ”— ä¾èµ–åˆ†æ")
                report_lines.append(f"- æ€»ä¾èµ–æ•°: {dep_info['total_dependencies']}")
                report_lines.append(
                    f"- å†…éƒ¨ä¾èµ–: {len(dep_info['internal_dependencies'])}"
                )
                report_lines.append(
                    f"- å¤–éƒ¨ä¾èµ–: {len(dep_info['external_dependencies'])}"
                )
                report_lines.append(
                    f"- æ ‡å‡†åº“ä¾èµ–: {len(dep_info['standard_dependencies'])}"
                )
                report_lines.append("")

            # æµ‹è¯•è¦†ç›–ç‡
            test_info = result["test_coverage"]
            report_lines.append("### ğŸ§ª æµ‹è¯•è¦†ç›–ç‡")
            report_lines.append(f"- æµ‹è¯•æ–‡ä»¶æ•°é‡: {len(test_info['test_files_found'])}")
            report_lines.append(f"- æµ‹è¯•æ–¹æ³•æ•°é‡: {test_info['test_methods_count']}")
            report_lines.append(f"- è¦†ç›–ç‡ä¼°ç®—: {test_info['coverage_estimate']}")
            report_lines.append("")

            # è´¨é‡æŒ‡æ ‡
            quality_info = result["quality_metrics"]
            report_lines.append("### ğŸ“ˆ è´¨é‡æŒ‡æ ‡")
            report_lines.append(
                f"- å¯ç»´æŠ¤æ€§æŒ‡æ•°: {quality_info['maintainability_index']:.1f}/100"
            )
            report_lines.append(
                f"- æ–‡æ¡£è¦†ç›–ç‡: {quality_info['documentation_ratio']:.1f}%"
            )
            report_lines.append(
                f"- å¹³å‡å‡½æ•°é•¿åº¦: {quality_info['function_length_avg']:.1f} è¡Œ"
            )
            report_lines.append("")

            # é£é™©è¯„ä¼°
            risk_info = result["risk_assessment"]
            report_lines.append("### ğŸš¨ é£é™©è¯„ä¼°")
            report_lines.append(f"- é£é™©ç­‰çº§: **{risk_info['risk_level']}**")
            report_lines.append(f"- é£é™©è¯„åˆ†: {risk_info['risk_score']}/10")
            report_lines.append(
                f"- é‡æ„ä¼˜å…ˆçº§: **{risk_info['refactoring_priority']}**"
            )
            report_lines.append("")

            if risk_info["risks"]:
                report_lines.append("**ä¸»è¦é£é™©**:")
                for risk in risk_info["risks"]:
                    report_lines.append(f"- âš ï¸ {risk}")
                report_lines.append("")

            report_lines.append("---")
            report_lines.append("")

        # æ€»ç»“å’Œå»ºè®®
        report_lines.append("## ğŸ“‹ æ€»ä½“è¯„ä¼°å’Œå»ºè®®")
        report_lines.append("")

        return "\n".join(report_lines)


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="è¯¦ç»†æŠ€æœ¯å€ºåŠ¡å¤æ‚åº¦è¯„ä¼°")
    parser.add_argument(
        "--target", required=True, help="ç›®æ ‡æ–‡ä»¶è·¯å¾„ (æ”¯æŒå¤šä¸ªæ–‡ä»¶ï¼Œç”¨é€—å·åˆ†éš”)"
    )
    parser.add_argument(
        "--output", help="è¾“å‡ºæŠ¥å‘Šè·¯å¾„ (é»˜è®¤: detailed_technical_debt_assessment.md)"
    )
    parser.add_argument("--detailed", action="store_true", help="ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š")

    args = parser.parse_args()

    # è§£æç›®æ ‡æ–‡ä»¶
    target_files = [f.strip() for f in args.target.split(",")]

    # éªŒè¯æ–‡ä»¶å­˜åœ¨
    existing_files = []
    for file_path in target_files:
        if os.path.exists(file_path):
            existing_files.append(file_path)
        else:
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    if not existing_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ç›®æ ‡æ–‡ä»¶")
        return 1

    # æ‰§è¡Œåˆ†æ
    assessor = DetailedTechnicalDebtAssessment()
    report = assessor.generate_assessment_report(existing_files)

    # è¾“å‡ºæŠ¥å‘Š
    if args.output:
        output_path = args.output
    else:
        output_path = "detailed_technical_debt_assessment.md"

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"âœ… è¯¦ç»†æŠ€æœ¯å€ºåŠ¡è¯„ä¼°æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
    print(f"ğŸ“ è¯„ä¼°æ–‡ä»¶æ•°: {len(existing_files)}")

    return 0


if __name__ == "__main__":
    sys.exit(main())
