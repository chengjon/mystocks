#!/usr/bin/env python3
"""
AIæµ‹è¯•ä¼˜åŒ–å™¨ä½¿ç”¨åé¦ˆåˆ†æå™¨
æ”¶é›†ã€åˆ†æå’ŒæŠ¥å‘ŠAIæµ‹è¯•ä¼˜åŒ–å™¨çš„ä½¿ç”¨æƒ…å†µï¼Œä¸ºå·¥å…·æ”¹è¿›æä¾›æ•°æ®æ”¯æŒ

åŠŸèƒ½:
1. ä½¿ç”¨æ•°æ®æ”¶é›†å’Œåˆ†æ
2. ç”¨æˆ·åé¦ˆè¶‹åŠ¿åˆ†æ
3. å·¥å…·æ•ˆæœè¯„ä¼°
4. æ”¹è¿›å»ºè®®ç”Ÿæˆ
5. ä½¿ç”¨æ¨¡å¼è¯†åˆ«

ä½œè€…: MyStocks AI Team
ç‰ˆæœ¬: 1.0
æ—¥æœŸ: 2025-01-22
"""

import sys
import sqlite3
import statistics
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List
import argparse
import logging
import matplotlib.pyplot as plt

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

try:
    from scripts.monitoring.ai_optimizer_monitor import AIOptimizerMonitor
    from scripts.feedback.ai_optimizer_feedback import FeedbackCollector
except ImportError as e:
    logger.warning(f"å¯¼å…¥ç›‘æ§ç³»ç»Ÿå¤±è´¥: {e}")
    AIOptimizerMonitor = None
    FeedbackCollector = None


class UsageFeedbackAnalyzer:
    """ä½¿ç”¨åé¦ˆåˆ†æå™¨"""

    def __init__(self):
        self.monitor = AIOptimizerMonitor() if AIOptimizerMonitor else None
        self.collector = FeedbackCollector() if FeedbackCollector else None
        self.analysis_dir = PROJECT_ROOT / "monitoring_data" / "analysis"
        self.analysis_dir.mkdir(exist_ok=True)

    def collect_usage_patterns(self, days: int = 30) -> Dict:
        """æ”¶é›†ä½¿ç”¨æ¨¡å¼æ•°æ®"""
        logger.info(f"ğŸ“Š æ”¶é›†æœ€è¿‘{days}å¤©çš„ä½¿ç”¨æ¨¡å¼æ•°æ®")

        if not self.monitor:
            logger.warning("ç›‘æ§ç³»ç»Ÿä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return self._generate_mock_usage_patterns(days)

        # ä»ç›‘æ§ç³»ç»Ÿè·å–ä½¿ç”¨æ•°æ®
        usage_stats = self.monitor.get_usage_stats(days)
        performance_stats = self.monitor.get_performance_stats(days)

        # æ·±åº¦åˆ†æä½¿ç”¨æ¨¡å¼
        patterns = {
            "basic_stats": usage_stats,
            "performance_stats": performance_stats,
            "usage_trends": self._analyze_usage_trends(days),
            "peak_usage_times": self._find_peak_usage_times(days),
            "most_used_commands": self._analyze_command_frequency(days),
            "success_patterns": self._analyze_success_patterns(days),
            "user_behavior": self._analyze_user_behavior(days),
        }

        return patterns

    def _generate_mock_usage_patterns(self, days: int) -> Dict:
        """ç”Ÿæˆæ¨¡æ‹Ÿä½¿ç”¨æ¨¡å¼æ•°æ®ï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        logger.info("ğŸ“ ç”Ÿæˆæ¨¡æ‹Ÿä½¿ç”¨æ¨¡å¼æ•°æ®")

        # ç”Ÿæˆæ¨¡æ‹Ÿçš„æ—¥å¸¸ä½¿ç”¨æ•°æ®
        patterns = {
            "basic_stats": {
                "total_usage": 150,
                "success_rate": 92.5,
                "avg_execution_time": 3.2,
                "daily_usage": self._generate_mock_daily_data(days),
            },
            "performance_stats": {
                "avg_cpu_usage": 25.3,
                "avg_memory_usage": 156.7,
                "avg_files_processed": 5.2,
            },
            "usage_trends": {
                "growth_rate": 15.2,  # æœˆå¢é•¿ç‡
                "adoption_rate": 85.0,  # å›¢é˜Ÿé‡‡ç”¨ç‡
                "retention_rate": 95.0,  # ç”¨æˆ·ç•™å­˜ç‡
            },
            "peak_usage_times": [
                {"time": "09:00", "usage_count": 25},
                {"time": "14:00", "usage_count": 18},
                {"time": "16:00", "usage_count": 22},
            ],
            "most_used_commands": {
                "--batch": 45,
                "--generate-tests": 38,
                "--report": 28,
                "--help": 15,
            },
            "success_patterns": {
                "success_by_time_of_day": {
                    "morning": 95.2,
                    "afternoon": 91.8,
                    "evening": 89.3,
                },
                "success_by_module": {
                    "core": 93.5,
                    "adapters": 90.2,
                    "monitoring": 94.8,
                },
            },
            "user_behavior": {
                "avg_session_length": 12.5,
                "repeat_users": 85.0,
                "feature_adoption": 78.5,
            },
        }

        return patterns

    def _generate_mock_daily_data(self, days: int) -> Dict:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ¯æ—¥æ•°æ®"""
        daily_data = {}
        for i in range(days):
            date = (datetime.now() - timedelta(days=i)).strftime("%Y-%m-%d")
            # æ¨¡æ‹Ÿå·¥ä½œæ—¥/å‘¨æœ«å·®å¼‚
            weekday = (datetime.now() - timedelta(days=i)).weekday()
            if weekday < 5:  # å·¥ä½œæ—¥
                usage_count = 20 + int(10 * (i % 3))  # 20-40
            else:  # å‘¨æœ«
                usage_count = 8 + int(5 * (i % 2))  # 8-18

            daily_data[date] = usage_count

        return daily_data

    def _analyze_usage_trends(self, days: int) -> Dict:
        """åˆ†æä½¿ç”¨è¶‹åŠ¿"""
        if not self.monitor:
            return {"trend": "stable", "growth_rate": 15.0}

        # è·å–è¯¦ç»†çš„æ¯æ—¥æ•°æ®
        try:
            with sqlite3.connect(self.monitor.db_path) as conn:
                # è·å–æ¯æ—¥ä½¿ç”¨é‡
                daily_query = f"""
                    SELECT DATE(timestamp) as date, COUNT(*) as count
                    FROM usage_logs
                    WHERE timestamp >= date('now', '-{days} days')
                    GROUP BY DATE(timestamp)
                    ORDER BY date
                """
                daily_data = conn.execute(daily_query).fetchall()

                if len(daily_data) < 2:
                    return {"trend": "insufficient_data", "growth_rate": 0}

                # è®¡ç®—è¶‹åŠ¿
                counts = [row[1] for row in daily_data]
                first_half = counts[: len(counts) // 2]
                second_half = counts[len(counts) // 2 :]

                first_avg = statistics.mean(first_half)
                second_avg = statistics.mean(second_half)

                if first_avg == 0:
                    trend = "stable"
                    growth_rate = 0
                elif second_avg > first_avg * 1.2:
                    trend = "growing"
                    growth_rate = ((second_avg / first_avg) - 1) * 100
                elif second_avg < first_avg * 0.8:
                    trend = "declining"
                    growth_rate = ((second_avg / first_avg) - 1) * 100
                else:
                    trend = "stable"
                    growth_rate = ((second_avg / first_avg) - 1) * 100

                return {
                    "trend": trend,
                    "growth_rate": growth_rate,
                    "data_points": len(daily_data),
                    "daily_data": dict(daily_data),
                }

        except Exception as e:
            logger.error(f"è¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
            return {"trend": "error", "growth_rate": 0}

    def _find_peak_usage_times(self, days: int) -> List[Dict]:
        """æ‰¾å‡ºä½¿ç”¨é«˜å³°æ—¶æ®µ"""
        if not self.monitor:
            return [
                {"time": "09:00-10:00", "usage_count": 25, "description": "æ—©é«˜å³°"},
                {"time": "14:00-15:00", "usage_count": 20, "description": "ä¸‹åˆé«˜å³°"},
                {"time": "16:00-17:00", "usage_count": 22, "description": "æ™šé«˜å³°"},
            ]

        try:
            with sqlite3.connect(self.monitor.db_path) as conn:
                # è·å–å°æ—¶çº§åˆ«çš„ä½¿ç”¨æ•°æ®
                hourly_query = f"""
                    SELECT
                        CASE
                            WHEN strftime('%H', timestamp) BETWEEN '09' AND '10' THEN '09:00-10:00'
                            WHEN strftime('%H', timestamp) BETWEEN '14' AND '15' THEN '14:00-15:00'
                            WHEN strftime('%H', timestamp) BETWEEN '16' AND '17' THEN '16:00-17:00'
                            ELSE strftime('%H:00-', timestamp)
                        END as time_slot,
                        COUNT(*) as count
                    FROM usage_logs
                    WHERE timestamp >= date('now', '-{days} days')
                    GROUP BY time_slot
                    ORDER BY count DESC
                    LIMIT 5
                """
                peak_data = conn.execute(hourly_query).fetchall()

                return [
                    {
                        "time": row[0],
                        "usage_count": row[1],
                        "description": self._get_time_description(row[0]),
                    }
                    for row in peak_data
                ]

        except Exception as e:
            logger.error(f"é«˜å³°æ—¶æ®µåˆ†æå¤±è´¥: {e}")
            return []

    def _get_time_description(self, time_slot: str) -> str:
        """è·å–æ—¶é—´æ®µæè¿°"""
        descriptions = {
            "09:00-10:00": "æ—©é«˜å³°",
            "14:00-15:00": "ä¸‹åˆé«˜å³°",
            "16:00-17:00": "æ™šé«˜å³°",
            "10:00-11:00": "ä¸Šåˆ",
            "11:00-12:00": "ä¸­åˆ",
            "13:00-14:00": "ä¸‹åˆ",
        }
        return descriptions.get(time_slot, "å…¶ä»–æ—¶æ®µ")

    def _analyze_command_frequency(self, days: int) -> Dict:
        """åˆ†æå‘½ä»¤ä½¿ç”¨é¢‘ç‡"""
        if not self.monitor:
            return {
                "--batch": 45,
                "--generate-tests": 38,
                "--report": 28,
                "--help": 15,
                "--config": 12,
                "--verbose": 10,
            }

        try:
            with sqlite3.connect(self.monitor.db_path) as conn:
                command_query = f"""
                    SELECT
                        command,
                        COUNT(*) as usage_count,
                        AVG(execution_time) as avg_time
                    FROM usage_logs
                    WHERE timestamp >= date('now', '-{days} days')
                    GROUP BY command
                    ORDER BY usage_count DESC
                """
                command_data = conn.execute(command_query).fetchall()

                return {
                    "detailed": dict(
                        (row[0], {"count": row[1], "avg_time": row[2] if row[2] else 0})
                        for row in command_data
                    ),
                    "top_commands": dict((row[0], row[1]) for row in command_data[:5]),
                }

        except Exception as e:
            logger.error(f"å‘½ä»¤é¢‘ç‡åˆ†æå¤±è´¥: {e}")
            return {}

    def _analyze_success_patterns(self, days: int) -> Dict:
        """åˆ†ææˆåŠŸæ¨¡å¼"""
        if not self.monitor:
            return {
                "overall_rate": 92.5,
                "by_time_of_day": {"morning": 95.2, "afternoon": 91.8, "evening": 89.3},
                "by_module": {"core": 93.5, "adapters": 90.2, "monitoring": 94.8},
            }

        try:
            with sqlite3.connect(self.monitor.db_path) as conn:
                # æŒ‰æ—¶é—´æ®µåˆ†ææˆåŠŸç‡
                time_query = f"""
                    SELECT
                        CASE
                            WHEN CAST(strftime('%H', timestamp) AS INTEGER) BETWEEN 6 AND 12 THEN 'morning'
                            WHEN CAST(strftime('%H', timestamp) AS INTEGER) BETWEEN 12 AND 18 THEN 'afternoon'
                            ELSE 'evening'
                        END as time_period,
                        COUNT(*) as total,
                        SUM(CASE WHEN exit_code = 0 THEN 1 ELSE 0 END) as success
                    FROM usage_logs
                    WHERE timestamp >= date('now', '-{days} days')
                    GROUP BY time_period
                """
                time_data = conn.execute(time_query).fetchall()

                success_by_time = {}
                for period, total, success in time_data:
                    success_by_time[period] = (
                        (success / total * 100) if total > 0 else 0
                    )

                # è®¡ç®—æ€»ä½“æˆåŠŸç‡
                total_success = conn.execute(f"""
                    SELECT COUNT(*), SUM(CASE WHEN exit_code = 0 THEN 1 ELSE 0 END)
                    FROM usage_logs
                    WHERE timestamp >= date('now', '-{days} days')
                """).fetchone()

                overall_rate = (
                    (total_success[1] / total_success[0] * 100)
                    if total_success[0] > 0
                    else 0
                )

                return {"overall_rate": overall_rate, "by_time_of_day": success_by_time}

        except Exception as e:
            logger.error(f"æˆåŠŸæ¨¡å¼åˆ†æå¤±è´¥: {e}")
            return {"overall_rate": 0}

    def _analyze_user_behavior(self, days: int) -> Dict:
        """åˆ†æç”¨æˆ·è¡Œä¸º"""
        if not self.monitor:
            return {
                "avg_session_length": 12.5,
                "repeat_users": 85.0,
                "feature_adoption": 78.5,
                "user_types": {
                    "power_users": 25.0,
                    "regular_users": 55.0,
                    "casual_users": 20.0,
                },
            }

        try:
            if self.monitor:
                db_path = self.monitor.db_path
            else:
                db_path = PROJECT_ROOT / "monitoring_data" / "ai_optimizer_monitor.db"

            with sqlite3.connect(db_path) as conn:
                # åˆ†æç”¨æˆ·ä¼šè¯é•¿åº¦ï¼ˆå‡è®¾æ¯æ¬¡ä½¿ç”¨ä¸ºä¸€æ¬¡ä¼šè¯ï¼‰
                session_query = f"""
                    SELECT
                        user_id,
                        COUNT(*) as usage_count,
                        AVG(execution_time) as avg_time
                    FROM usage_logs
                    WHERE timestamp >= date('now', '-{days} days')
                    AND user_id IS NOT NULL
                    GROUP BY user_id
                """
                session_data = conn.execute(session_query).fetchall()

                if session_data:
                    avg_session_length = statistics.mean(
                        [row[2] for row in session_data]
                    )
                    repeat_users = (
                        len([row for row in session_data if row[1] > 1])
                        / len(session_data)
                        * 100
                    )
                else:
                    avg_session_length = 0
                    repeat_users = 0

                return {
                    "avg_session_length": avg_session_length,
                    "repeat_users": repeat_users,
                    "user_diversity": len(session_data) if session_data else 0,
                }

        except Exception as e:
            logger.error(f"ç”¨æˆ·è¡Œä¸ºåˆ†æå¤±è´¥: {e}")
            return {}

    def analyze_feedback_patterns(self, days: int = 30) -> Dict:
        """åˆ†æåé¦ˆæ¨¡å¼"""
        logger.info(f"ğŸ“ åˆ†ææœ€è¿‘{days}å¤©çš„ç”¨æˆ·åé¦ˆ")

        if not self.monitor:
            logger.warning("ç›‘æ§ç³»ç»Ÿä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿåé¦ˆæ•°æ®")
            return self._generate_mock_feedback_patterns(days)

        # è·å–åé¦ˆæ•°æ®
        feedback_summary = self.monitor.get_feedback_summary(days)

        # æ·±åº¦åˆ†æåé¦ˆæ¨¡å¼
        patterns = {
            "basic_stats": feedback_summary,
            "feedback_trends": self._analyze_feedback_trends(days),
            "sentiment_analysis": self._analyze_sentiment(days),
            "issue_categories": self._categorize_issues(days),
            "improvement_areas": self._identify_improvement_areas(days),
            "user_satisfaction": self._calculate_satisfaction(days),
        }

        return patterns

    def _generate_mock_feedback_patterns(self, days: int) -> Dict:
        """ç”Ÿæˆæ¨¡æ‹Ÿåé¦ˆæ¨¡å¼æ•°æ®"""
        logger.info("ğŸ“ ç”Ÿæˆæ¨¡æ‹Ÿåé¦ˆæ¨¡å¼æ•°æ®")

        patterns = {
            "basic_stats": {
                "feedback_by_type": [
                    {
                        "type": "suggestion",
                        "category": "performance",
                        "count": 25,
                        "avg_rating": 4.2,
                    },
                    {
                        "type": "bug",
                        "category": "accuracy",
                        "count": 15,
                        "avg_rating": 3.8,
                    },
                    {
                        "type": "feature_request",
                        "category": "usability",
                        "count": 12,
                        "avg_rating": 4.5,
                    },
                    {
                        "type": "general",
                        "category": "documentation",
                        "count": 8,
                        "avg_rating": 4.0,
                    },
                ],
                "rating_distribution": {5: 35, 4: 42, 3: 15, 2: 5, 1: 3},
            },
            "feedback_trends": {
                "monthly_feedback_rate": 88.5,
                "positive_trend": True,
                "main_concerns": ["performance", "documentation"],
                "improving_areas": ["UI usability", "error messages"],
            },
            "sentiment_analysis": {
                "positive_sentiment": 75.5,
                "neutral_sentiment": 18.5,
                "negative_sentiment": 6.0,
                "sentiment_trend": "improving",
            },
            "issue_categories": {
                "performance_issues": 45,
                "usability_issues": 28,
                "documentation_issues": 20,
                "bug_reports": 15,
                "feature_requests": 12,
            },
            "improvement_areas": [
                {
                    "area": "Performance optimization",
                    "priority": "high",
                    "impact": "High",
                },
                {
                    "area": "Documentation enhancement",
                    "priority": "medium",
                    "impact": "Medium",
                },
                {"area": "UI/UX improvement", "priority": "medium", "impact": "Medium"},
            ],
            "user_satisfaction": {
                "overall_score": 4.2,
                "satisfaction_level": "Good",
                "satisfaction_trend": "Stable",
            },
        }

        return patterns

    def _analyze_feedback_trends(self, days: int) -> Dict:
        """åˆ†æåé¦ˆè¶‹åŠ¿"""
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„è¶‹åŠ¿åˆ†æ
        return {
            "monthly_feedback_rate": 88.5,
            "positive_trend": True,
            "main_concerns": ["performance", "documentation"],
            "improving_areas": ["UI usability", "error messages"],
        }

    def _analyze_sentiment(self, days: int) -> Dict:
        """åˆ†æç”¨æˆ·æƒ…ç»ª"""
        if not self.monitor:
            return {
                "positive_sentiment": 75.5,
                "neutral_sentiment": 18.5,
                "negative_sentiment": 6.0,
                "sentiment_trend": "improving",
            }

        try:
            with sqlite3.connect(self.monitor.db_path) as conn:
                # è·å–è¯„åˆ†æ•°æ®
                rating_query = f"""
                    SELECT rating, COUNT(*) as count
                    FROM user_feedback
                    WHERE timestamp >= date('now', '-{days} days')
                    AND rating IS NOT NULL
                    GROUP BY rating
                """
                rating_data = conn.execute(rating_query).fetchall()

                if not rating_data:
                    return {
                        "positive_sentiment": 0,
                        "neutral_sentiment": 0,
                        "negative_sentiment": 0,
                        "sentiment_trend": "no_data",
                    }

                # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                rating_dict = dict(rating_data)
                total_feedbacks = sum(rating_dict.values())

                # è®¡ç®—æƒ…ç»ªåˆ†å¸ƒ
                positive_sentiment = sum(
                    count for rating, count in rating_dict.items() if rating >= 4
                )
                neutral_sentiment = sum(
                    count for rating, count in rating_dict.items() if rating == 3
                )
                negative_sentiment = sum(
                    count for rating, count in rating_dict.items() if rating <= 2
                )

                return {
                    "positive_sentiment": (positive_sentiment / total_feedbacks) * 100,
                    "neutral_sentiment": (neutral_sentiment / total_feedbacks) * 100,
                    "negative_sentiment": (negative_sentiment / total_feedbacks) * 100,
                    "sentiment_distribution": dict(rating_data),
                }

        except Exception as e:
            logger.error(f"æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            return {
                "positive_sentiment": 0,
                "neutral_sentiment": 0,
                "negative_sentiment": 0,
                "sentiment_trend": "error",
            }

    def _categorize_issues(self, days: int) -> Dict:
        """åˆ†ç±»é—®é¢˜ç±»å‹"""
        if not self.monitor:
            return {
                "performance_issues": 45,
                "usability_issues": 28,
                "documentation_issues": 20,
                "bug_reports": 15,
                "feature_requests": 12,
            }

        try:
            with sqlite3.connect(self.monitor.db_path) as conn:
                # è·å–åé¦ˆåˆ†ç±»ç»Ÿè®¡
                category_query = f"""
                    SELECT category, COUNT(*) as count
                    FROM user_feedback
                    WHERE timestamp >= date('now', '-{days} days')
                    GROUP BY category
                """
                category_data = conn.execute(category_query).fetchall()

                issues = {}
                for category, count in category_data:
                    if category in [
                        "performance",
                        "usability",
                        "documentation",
                        "accuracy",
                    ]:
                        issues[f"{category}_issues"] = count

                return issues

        except Exception as e:
            logger.error(f"é—®é¢˜åˆ†ç±»å¤±è´¥: {e}")
            return {}

    def _identify_improvement_areas(self, days: int) -> List[Dict]:
        """è¯†åˆ«æ”¹è¿›é¢†åŸŸ"""
        # è¿™é‡Œå¯ä»¥å®ç°åŸºäºåé¦ˆçš„æ”¹è¿›é¢†åŸŸè¯†åˆ«
        improvement_areas = [
            {"area": "Performance optimization", "priority": "high", "impact": "High"},
            {
                "area": "Documentation enhancement",
                "priority": "medium",
                "impact": "Medium",
            },
            {"area": "UI/UX improvement", "priority": "medium", "impact": "Medium"},
            {"area": "Error message clarity", "priority": "low", "impact": "Low"},
            {"area": "Feature expansion", "priority": "low", "impact": "Low"},
        ]

        return improvement_areas

    def _calculate_satisfaction(self, days: int) -> Dict:
        """è®¡ç®—ç”¨æˆ·æ»¡æ„åº¦"""
        if not self.monitor:
            return {
                "overall_score": 4.2,
                "satisfaction_level": "Good",
                "satisfaction_trend": "Stable",
            }

        try:
            with sqlite3.connect(self.monitor.db_path) as conn:
                # è·å–å¹³å‡è¯„åˆ†
                avg_rating_query = f"""
                    SELECT AVG(rating) as avg_rating
                    FROM user_feedback
                    WHERE timestamp >= date('now', '-{days} days')
                    AND rating IS NOT NULL
                """
                avg_rating_data = conn.execute(avg_rating_query).fetchone()

                if avg_rating_data and avg_rating_data[0]:
                    avg_score = avg_rating_data[0]

                    if avg_score >= 4.5:
                        level = "Excellent"
                        trend = "Very Positive"
                    elif avg_score >= 4.0:
                        level = "Good"
                        trend = "Positive"
                    elif avg_score >= 3.5:
                        level = "Fair"
                        trend = "Neutral"
                    else:
                        level = "Poor"
                        trend = "Negative"
                else:
                    avg_score = 0
                    level = "No Data"
                    trend = "Unknown"

                return {
                    "overall_score": avg_score,
                    "satisfaction_level": level,
                    "satisfaction_trend": trend,
                }

        except Exception as e:
            logger.error(f"æ»¡æ„åº¦è®¡ç®—å¤±è´¥: {e}")
            return {
                "overall_score": 0,
                "satisfaction_level": "Error",
                "satisfaction_trend": "Error",
            }

    def generate_usage_report(self, days: int = 30) -> str:
        """ç”Ÿæˆä½¿ç”¨åé¦ˆåˆ†ææŠ¥å‘Š"""
        logger.info(f"ğŸ“Š ç”Ÿæˆä½¿ç”¨åé¦ˆåˆ†ææŠ¥å‘Š (æœ€è¿‘{days}å¤©)")

        # æ”¶é›†æ•°æ®
        usage_patterns = self.collect_usage_patterns(days)
        feedback_patterns = self.analyze_feedback_patterns(days)

        # ç”ŸæˆæŠ¥å‘Š
        report = f"""# AIæµ‹è¯•ä¼˜åŒ–å™¨ä½¿ç”¨åé¦ˆåˆ†ææŠ¥å‘Š

**åˆ†ææ—¶é—´èŒƒå›´**: æœ€è¿‘{days}å¤©
**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ğŸ“Š ä½¿ç”¨æƒ…å†µç»Ÿè®¡

### æ•´ä½“ä½¿ç”¨æ¦‚å†µ
- **æ€»ä½¿ç”¨æ¬¡æ•°**: {usage_patterns["basic_stats"]["total_usage"]}
- **æˆåŠŸç‡**: {usage_patterns["basic_stats"]["success_rate"]:.1f}%
- **å¹³å‡æ‰§è¡Œæ—¶é—´**: {usage_patterns["basic_stats"]["avg_execution_time"]:.2f}ç§’

### æ€§èƒ½æŒ‡æ ‡
- **å¹³å‡CPUä½¿ç”¨**: {usage_patterns["performance_stats"]["avg_cpu_usage"]:.1f}%
- **å¹³å‡å†…å­˜ä½¿ç”¨**: {usage_patterns["performance_stats"]["avg_memory_usage"]:.1f}MB
- **å¹³å‡å¤„ç†æ–‡ä»¶æ•°**: {usage_patterns["performance_stats"]["avg_files_processed"]:.1f}

## ğŸ“ˆ ä½¿ç”¨è¶‹åŠ¿åˆ†æ

### è¶‹åŠ¿æŒ‡æ ‡
{self._format_usage_trends(usage_patterns)}

### ä½¿ç”¨é«˜å³°æ—¶æ®µ
{self._format_peak_times(usage_patterns["peak_usage_times"])}

### å‘½ä»¤ä½¿ç”¨é¢‘ç‡
{self._format_command_frequency(usage_patterns["most_used_commands"])}

### æˆåŠŸæ¨¡å¼åˆ†æ
{self._format_success_patterns(usage_patterns["success_patterns"])}

## ğŸ—£ï¸ ç”¨æˆ·åé¦ˆåˆ†æ

### åé¦ˆæ¦‚è§ˆ
{self._format_feedback_overview(feedback_patterns["basic_stats"])}

### åé¦ˆæƒ…ç»ªåˆ†æ
- **æ­£é¢åé¦ˆ**: {feedback_patterns["sentiment_analysis"]["positive_sentiment"]:.1f}%
- **ä¸­æ€§åé¦ˆ**: {feedback_patterns["sentiment_analysis"]["neutral_sentiment"]:.1f}%
- **è´Ÿé¢åé¦ˆ**: {feedback_patterns["sentiment_analysis"]["negative_sentiment"]:.1f}%
- **æƒ…ç»ªè¶‹åŠ¿**: {feedback_patterns["sentiment_analysis"].get("sentiment_trend", "unknown")}

### é—®é¢˜åˆ†ç±»ç»Ÿè®¡
{self._format_issue_categories(feedback_patterns["issue_categories"])}

### æ”¹è¿›é¢†åŸŸè¯†åˆ«
{self._format_improvement_areas(feedback_patterns["improvement_areas"])}

### ç”¨æˆ·æ»¡æ„åº¦
- **æ€»ä½“è¯„åˆ†**: {feedback_patterns["user_satisfaction"]["overall_score"]:.1f}/5.0
- **æ»¡æ„åº¦ç­‰çº§**: {feedback_patterns["user_satisfaction"]["satisfaction_level"]}
- **æ»¡æ„åº¦è¶‹åŠ¿**: {feedback_patterns["user_satisfaction"]["satisfaction_trend"]}

## ğŸ’¡ æ•°æ®é©±åŠ¨çš„æ”¹è¿›å»ºè®®

### é«˜ä¼˜å…ˆçº§æ”¹è¿›
{self._generate_high_priority_recommendations(usage_patterns, feedback_patterns)}

### ä¸­ä¼˜å…ˆçº§æ”¹è¿›
{self._generate_medium_priority_recommendations(usage_patterns, feedback_patterns)}

### ä½ä¼˜å…ˆçº§æ”¹è¿›
{self._generate_low_priority_recommendations(usage_patterns, feedback_patterns)}

## ğŸ“‹ è¡ŒåŠ¨è®¡åˆ’

### ç«‹å³è¡ŒåŠ¨é¡¹ (1-2å‘¨)
1. æ ¹æ®ç”¨æˆ·åé¦ˆä¼˜åŒ–é«˜é¢‘é—®é¢˜
2. æ”¹è¿›ä½¿ç”¨é«˜å³°æ—¶æ®µçš„æ€§èƒ½è¡¨ç°
3. å®Œå–„æœ€å—å…³æ³¨åŠŸèƒ½çš„æ–‡æ¡£

### çŸ­æœŸè®¡åˆ’ (1ä¸ªæœˆ)
1. å®æ–½è¯†åˆ«å‡ºçš„æ”¹è¿›æªæ–½
2. å»ºç«‹ç”¨æˆ·åé¦ˆå¿«é€Ÿå“åº”æœºåˆ¶
3. ä¼˜åŒ–ç”¨æˆ·ä½“éªŒå’Œä½¿ç”¨æµç¨‹

### é•¿æœŸè®¡åˆ’ (3ä¸ªæœˆ)
1. åŸºäºæ•°æ®è¶‹åŠ¿è§„åˆ’åŠŸèƒ½å‘å±•
2. å»ºç«‹æŒç»­çš„æ”¹è¿›å¾ªç¯æœºåˆ¶
3. æ‰©å±•å·¥å…·çš„ä½¿ç”¨è¦†ç›–é¢

---

*æŠ¥å‘Šç”±AIæµ‹è¯•ä¼˜åŒ–å™¨ä½¿ç”¨åé¦ˆåˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
"""

        return report

    def _format_usage_trends(self, patterns: Dict) -> str:
        """æ ¼å¼åŒ–ä½¿ç”¨è¶‹åŠ¿"""
        if "trend" in patterns:
            trend = patterns["trend"]
            if "growth_rate" in patterns:
                growth = patterns["growth_rate"]
                return f"- **è¶‹åŠ¿**: {trend.title()}\n- **å¢é•¿ç‡**: {growth:.1f}%"
        return "- **è¶‹åŠ¿**: ç¨³å®š\n- **å¢é•¿ç‡**: 0%"

    def _format_peak_times(self, peak_times: List[Dict]) -> str:
        """æ ¼å¼åŒ–é«˜å³°æ—¶æ®µ"""
        lines = ["| æ—¶æ®µ | ä½¿ç”¨æ¬¡æ•° | æè¿° |", "|------|----------|--------|"]
        for peak in peak_times:
            lines.append(
                f"| {peak['time']} | {peak['usage_count']} | {peak['description']} |"
            )
        return "\n".join(lines)

    def _format_command_frequency(self, commands: Dict) -> str:
        """æ ¼å¼åŒ–å‘½ä»¤é¢‘ç‡"""
        lines = ["| å‘½ä»¤ | ä½¿ç”¨æ¬¡æ•° | å¹³å‡æ—¶é—´ |", "|------|----------|----------|"]
        for cmd, data in commands.get("detailed", {}).items():
            avg_time = data.get("avg_time", 0)
            lines.append(f"| {cmd} | {data['count']} | {avg_time:.2f}ç§’ |")
        return "\n".join(lines)

    def _format_success_patterns(self, patterns: Dict) -> str:
        """æ ¼å¼åŒ–æˆåŠŸæ¨¡å¼"""
        lines = [f"- **æ€»ä½“æˆåŠŸç‡**: {patterns['overall_rate']:.1f}%"]

        if "by_time_of_day" in patterns:
            lines.append("\n### æŒ‰æ—¶æ®µæˆåŠŸç‡")
            for period, rate in patterns["by_time_of_day"].items():
                period_names = {
                    "morning": "æ—©æ™¨",
                    "afternoon": "ä¸‹åˆ",
                    "evening": "æ™šä¸Š",
                }
                lines.append(f"- **{period_names.get(period, period)}**: {rate:.1f}%")

        return "\n".join(lines)

    def _format_feedback_overview(self, feedback_stats: Dict) -> str:
        """æ ¼å¼åŒ–åé¦ˆæ¦‚è§ˆ"""
        if not feedback_stats.get("feedback_by_type"):
            return "- æš‚æ— åé¦ˆæ•°æ®"

        lines = []
        total_feedback = sum(
            item["count"] for item in feedback_stats["feedback_by_type"]
        )
        lines.append(f"- **æ€»åé¦ˆæ•°**: {total_feedback}")

        for feedback in feedback_stats["feedback_by_type"]:
            lines.append(
                f"- **{feedback['type']} ({feedback['category']}): {feedback['count']} æ¡"
            )
            if feedback["avg_rating"]:
                lines.append(f"  - å¹³å‡è¯„åˆ†: {feedback['avg_rating']:.1f}â­")

        return "\n".join(lines)

    def _format_issue_categories(self, issues: Dict) -> str:
        """æ ¼å¼åŒ–é—®é¢˜åˆ†ç±»"""
        if not issues:
            return "- æš‚æ— é—®é¢˜æŠ¥å‘Š"

        lines = []
        for issue_type, count in issues.items():
            lines.append(f"- **{issue_type}**: {count} ä¸ªé—®é¢˜")

        return "\n".join(lines)

    def _format_improvement_areas(self, areas: List[Dict]) -> str:
        """æ ¼å¼åŒ–æ”¹è¿›é¢†åŸŸ"""
        lines = []
        for i, area in enumerate(areas, 1):
            lines.append(
                f"{i}. **{area['area']}** (ä¼˜å…ˆçº§: {area['priority']}, å½±å“: {area['impact']})"
            )

        return "\n".join(lines)

    def _generate_high_priority_recommendations(
        self, usage_patterns: Dict, feedback_patterns: Dict
    ) -> List[str]:
        """ç”Ÿæˆé«˜ä¼˜å…ˆçº§æ”¹è¿›å»ºè®®"""
        recommendations = []

        # åŸºäºä½¿ç”¨æƒ…å†µ
        if usage_patterns["basic_stats"]["success_rate"] < 85:
            recommendations.append("ğŸ”§ ä¼˜å…ˆè§£å†³æˆåŠŸç‡ä½çš„é—®é¢˜ï¼Œæå‡å·¥å…·ç¨³å®šæ€§")

        if usage_patterns["basic_stats"]["avg_execution_time"] > 5:
            recommendations.append("âš¡ ä¼˜åŒ–å·¥å…·æ€§èƒ½ï¼Œå‡å°‘å¹³å‡æ‰§è¡Œæ—¶é—´")

        # åŸºäºç”¨æˆ·åé¦ˆ
        if feedback_patterns["sentiment_analysis"]["negative_sentiment"] > 10:
            recommendations.append("ğŸš¨ ç«‹å³è§£å†³ç”¨æˆ·è´Ÿé¢åé¦ˆï¼Œæ”¹å–„ç”¨æˆ·ä½“éªŒ")

        if feedback_patterns["issue_categories"].get("performance_issues", 0) > 20:
            recommendations.append("ğŸ’° é‡ç‚¹è§£å†³æ€§èƒ½é—®é¢˜ï¼Œè¿™æ˜¯ç”¨æˆ·æœ€å…³æ³¨çš„é—®é¢˜")

        return recommendations

    def _generate_medium_priority_recommendations(
        self, usage_patterns: Dict, feedback_patterns: Dict
    ) -> List[str]:
        """ç”Ÿæˆä¸­ä¼˜å…ˆçº§æ”¹è¿›å»ºè®®"""
        recommendations = []

        if usage_patterns["performance_stats"]["avg_memory_usage"] > 200:
            recommendations.append("ğŸ’¾ ä¼˜åŒ–å†…å­˜ä½¿ç”¨æ•ˆç‡")

        if feedback_patterns["issue_categories"].get("usability_issues", 0) > 10:
            recommendations.append("ğŸ–±ï¸ æ”¹è¿›ç”¨æˆ·ç•Œé¢å’Œä½¿ç”¨ä½“éªŒ")

        return recommendations

    def _generate_low_priority_recommendations(
        self, usage_patterns: Dict, feedback_patterns: Dict
    ) -> List[str]:
        """ç”Ÿæˆä½ä¼˜å…ˆçº§æ”¹è¿›å»ºè®®"""
        recommendations = []

        if usage_patterns["basic_stats"]["total_usage"] > 100:
            recommendations.append("ğŸ“ˆ è€ƒè™‘åŠŸèƒ½æ‰©å±•ä»¥æ»¡è¶³æ›´å¤šç”¨æˆ·éœ€æ±‚")

        if feedback_patterns["sentiment_analysis"]["positive_sentiment"] > 80:
            recommendations.append("ğŸ‰ ç»§ç»­ä¿æŒç”¨æˆ·æ»¡æ„åº¦ï¼Œå®šæœŸæ”¶é›†åé¦ˆ")

        return recommendations

    def save_analysis_report(self, report: str) -> Path:
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        today = datetime.now().strftime("%Y-%m-%d")
        report_path = self.analysis_dir / f"usage_feedback_analysis_{today}.md"

        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report)

        return report_path

    def create_visual_charts(self, days: int = 30) -> None:
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        try:
            # æ”¶é›†æ•°æ®
            usage_patterns = self.collect_usage_patterns(days)
            feedback_patterns = self.analyze_feedback_patterns(days)

            # è®¾ç½®ä¸­æ–‡å­—ä½“
            plt.rcParams["font.sans-serif"] = [
                "SimHei",
                "DejaVu Sans",
                "Arial Unicode MS",
            ]
            plt.rcParams["axes.unicode_minus"] = False

            # åˆ›å»ºå›¾è¡¨
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))

            # å›¾1: ä½¿ç”¨è¶‹åŠ¿
            if "daily_usage" in usage_patterns["basic_stats"]:
                daily_data = usage_patterns["basic_stats"]["daily_usage"]
                dates = list(daily_data.keys())[-14:]  # æœ€è¿‘14å¤©
                counts = list(daily_data.values())[-14:]

                ax1.plot(
                    dates,
                    counts,
                    marker="o",
                    linewidth=2,
                    markersize=8,
                    color="#2E86AB",
                )
                ax1.set_title("ä½¿ç”¨è¶‹åŠ¿ (æœ€è¿‘14å¤©)")
                ax1.set_xlabel("æ—¥æœŸ")
                ax1.set_ylabel("ä½¿ç”¨æ¬¡æ•°")
                ax1.tick_params(axis="x", rotation=45)
                ax1.grid(True, alpha=0.3)

            # å›¾2: åé¦ˆåˆ†å¸ƒ
            if "rating_distribution" in feedback_patterns["basic_stats"]:
                ratings = list(
                    feedback_patterns["basic_stats"]["rating_distribution"].keys()
                )
                counts = list(
                    feedback_patterns["basic_stats"]["rating_distribution"].values()
                )
                colors = ["#FF6B6B", "#4ECDC4", "#FFD700", "#87CEEB", "#F0E68C"]

                bars = ax2.bar(ratings, counts, color=colors)
                ax2.set_title("ç”¨æˆ·è¯„åˆ†åˆ†å¸ƒ")
                ax2.set_xlabel("è¯„åˆ†")
                ax2.set_ylabel("åé¦ˆæ•°é‡")

                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for bar, count in zip(bars, counts):
                    height = bar.get_height()
                    ax2.text(
                        bar.get_x() + bar.get_width() / 2,
                        height + 1,
                        str(count),
                        ha="center",
                        va="bottom",
                    )

            # å›¾3: æˆåŠŸç‡åˆ†å¸ƒ
            if "by_time_of_day" in usage_patterns["success_patterns"]:
                periods = list(
                    usage_patterns["success_patterns"]["by_time_of_day"].keys()
                )
                rates = list(
                    usage_patterns["success_patterns"]["by_time_of_day"].values()
                )

                colors = ["#90EE90", "#FFB6C1", "#FFDAB9"]
                bars = ax3.bar(periods, rates, color=colors)
                ax3.set_title("ä¸åŒæ—¶æ®µæˆåŠŸç‡")
                ax3.set_xlabel("æ—¶æ®µ")
                ax3.set_ylabel("æˆåŠŸç‡(%)")

                for bar, rate in zip(bars, rates):
                    height = bar.get_height()
                    ax3.text(
                        bar.get_x() + bar.get_width() / 2,
                        height + 1,
                        f"{rate:.1f}%",
                        ha="center",
                        va="bottom",
                    )

            # å›¾4: é—®é¢˜ç±»å‹åˆ†å¸ƒ
            if "issue_categories" in feedback_patterns["issue_categories"]:
                categories = list(feedback_patterns["issue_categories"].keys())
                counts = list(feedback_patterns["issue_categories"].values())

                bars = ax4.barh(categories, counts, color="#FF9999")
                ax4.set_title("é—®é¢˜ç±»å‹åˆ†å¸ƒ")
                ax4.set_xlabel("é—®é¢˜æ•°é‡")

                for bar, count in zip(bars, counts):
                    width = bar.get_width()
                    ax4.text(
                        width + 0.5,
                        bar.get_y() + bar.get_height() / 2,
                        str(count),
                        ha="left",
                        va="center",
                    )

            plt.tight_layout()

            # ä¿å­˜å›¾è¡¨
            chart_path = (
                self.analysis_dir
                / f"usage_feedback_charts_{datetime.now().strftime('%Y-%m-%d')}.png"
            )
            plt.savefig(chart_path, dpi=300, bbox_inches="tight")
            logger.info(f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {chart_path}")

            return chart_path

        except Exception as e:
            logger.error(f"åˆ›å»ºå¯è§†åŒ–å›¾è¡¨å¤±è´¥: {e}")
            return None


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="AIæµ‹è¯•ä¼˜åŒ–å™¨ä½¿ç”¨åé¦ˆåˆ†æå·¥å…·")
    parser.add_argument("--days", "-d", type=int, default=30, help="åˆ†ææœ€è¿‘Nå¤©çš„æ•°æ®")
    parser.add_argument(
        "--usage-only", "-u", action="store_true", help="åªåˆ†æä½¿ç”¨æ•°æ®ï¼Œä¸åŒ…æ‹¬åé¦ˆ"
    )
    parser.add_argument(
        "--feedback-only", "-f", action="store_true", help="åªåˆ†æåé¦ˆæ•°æ®ï¼Œä¸åŒ…æ‹¬ä½¿ç”¨"
    )
    parser.add_argument("--report", "-r", action="store_true", help="ç”Ÿæˆåˆ†ææŠ¥å‘Š")
    parser.add_argument("--charts", "-c", action="store_true", help="ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")

    args = parser.parse_args()

    try:
        analyzer = UsageFeedbackAnalyzer()

        if args.usage_only and args.feedback_only:
            print("âŒ ä¸èƒ½åŒæ—¶æŒ‡å®š --usage-only å’Œ --feedback-only")
            return 1

        if args.usage_only or not args.feedback_only:
            print("ğŸ“Š åˆ†æä½¿ç”¨æ•°æ®...")
            usage_patterns = analyzer.collect_usage_patterns(args.days)
            print("âœ… ä½¿ç”¨æ•°æ®åˆ†æå®Œæˆ")

        if args.feedback_only or not args.usage_only:
            print("ğŸ“ åˆ†æç”¨æˆ·åé¦ˆ...")
            feedback_patterns = analyzer.analyze_feedback_patterns(args.days)
            print("âœ… åé¦ˆåˆ†æå®Œæˆ")

        if args.report or not (args.usage_only or args.feedback_only):
            print("ğŸ“„ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
            report = analyzer.generate_usage_report(args.days)
            report_path = analyzer.save_analysis_report(report)
            print(f"âœ… åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

            # æ˜¾ç¤ºæŠ¥å‘Šæ‘˜è¦
            print("\nğŸ“Š æŠ¥å‘Šæ‘˜è¦:")
            if "basic_stats" in usage_patterns:
                print(f"  - æ€»ä½¿ç”¨æ¬¡æ•°: {usage_patterns['basic_stats']['total_usage']}")
                print(
                    f"  - æˆåŠŸç‡: {usage_patterns['basic_stats']['success_rate']:.1f}%"
                )
                print(
                    f"  - å¹³å‡æ‰§è¡Œæ—¶é—´: {usage_patterns['basic_stats']['avg_execution_time']:.2f}ç§’"
                )

            if "basic_stats" in feedback_patterns:
                total_feedback = sum(
                    item["count"]
                    for item in feedback_patterns["basic_stats"].get(
                        "feedback_by_type", []
                    )
                )
                print(f"  - æ€»åé¦ˆæ•°: {total_feedback}")

        if args.charts:
            print("ğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
            chart_path = analyzer.create_visual_charts(args.days)
            if chart_path:
                print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆ: {chart_path}")

    except KeyboardInterrupt:
        print("\nâ¹ï¸  åˆ†æå·²å–æ¶ˆ")
    except Exception as e:
        logger.error(f"ğŸ’¥ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback

        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    import sys

    sys.exit(main())
