# AI 代码修改规则与最佳实践

## 📋 目录
- [1. 概述](#1-概述)
- [2. 变更前置约束](#2-变更前置约束)
- [3. 分层验证机制](#3-分层验证机制)
- [4. 版本控制与回溯](#4-版本控制与回溯)
- [5. AI 交互优化](#5-ai-交互优化)
- [6. 质量保障体系](#6-质量保障体系)
- [7. 监控与反馈](#7-监控与反馈)
- [8. 快速参考](#8-快速参考)

---

## 1. 概述

### 1.1 问题背景
AI 修改代码时频繁出现 "改此坏彼" 的问题，本质是缺乏系统性的变更控制和验证机制。结合量化交易项目的严谨性，需要通过流程化方案避免来回救火。

### 1.2 核心原则
- **最小变更原则**：只修改目标相关的最小代码块
- **分层验证原则**：多层级验证确保修改质量
- **可回溯原则**：任何修改都必须能够快速回滚
- **透明化原则**：所有修改过程必须可追踪和可审计
- **架构合规原则**：100% 遵循配置驱动架构，严禁任何临时补救措施

### 1.3 适用场景
- 量化交易系统代码修改
- 跨模块功能开发
- 性能优化和bug修复
- 系统架构调整

---

## 2. 变更前置约束

### 2.1 保护范围定义

#### 2.1.1 创建 PROTECTED.md
在项目根目录创建 `PROTECTED.md`，列出禁止 AI 擅自修改的核心模块，例如：

```markdown
# 禁止AI自动修改的内容

## 核心交易模块
1. `/core/trade_executor.py` - 交易执行核心
2. `/core/risk_manager.py` - 风险控制核心
3. `/core/position_manager.py` - 仓位管理核心

## 数据库相关
4. `/db/schema/` - 数据库表结构定义
5. `/db/migrations/` - 数据库迁移脚本

## 配置与参数
6. `/config/risk_limits.yaml` - 风险控制参数
7. `/config/trading_params.yaml` - 交易参数配置

## 说明
以上内容修改需 JohnC 书面确认，AI 仅可提交修改建议。
```

#### 2.1.2 保护范围检查
- AI 每次修改前必须检查是否涉及保护范围
- 若涉及保护范围，自动终止并提示 "需人工确认"
- 提供修改建议而非直接修改

### 2.2 最小变更原则

#### 2.2.1 变更范围限制
- 只修改 "目标相关" 的最小代码块
- 修复函数 bug 时，不触碰其他无关函数
- 新增功能优先用 "扩展" 而非 "修改"

#### 2.2.2 扩展优先策略
```python
# ❌ 错误方式：直接修改原有函数
def crawl_a_data():
    # 原有逻辑 + 新增创业板逻辑
    pass

# ✅ 正确方式：新增扩展函数
def crawl_gem_data():
    # 创业板专用逻辑
    pass

def crawl_a_data():
    # 保持原有逻辑不变
    pass
```

### 2.3 变更影响评估

#### 2.3.1 影响范围分析
AI 修改前必须输出：
- 直接影响的文件和函数
- 间接影响的模块和依赖
- 潜在的风险传播路径

#### 2.3.2 风险评估矩阵
| 影响范围 | 风险等级 | 处理方式 |
|---------|---------|---------|
| 单个函数 | 低 | 直接修改 |
| 单个模块 | 中 | 需要测试验证 |
| 跨模块 | 高 | 需要人工审核 |
| 核心模块 | 极高 | 禁止修改 |

### 2.4 架构模式遵循检查

#### 2.4.1 配置驱动模式检查
在项目采用配置驱动架构时，AI 必须检查：
- 是否所有配置项都在配置文件中定义
- 是否通过配置管理器进行操作
- 是否存在硬编码绕过配置的情况

**示例场景**：
- 数据库表结构：必须在 `table_config.yaml` 中定义
- 系统参数：必须在 `config.yaml` 中配置
- 路由规则：必须在路由配置文件中声明

### 2.5 架构合规性原则（ConfigDriven 模式）

#### 2.5.1 核心要求
**配置驱动架构的铁律**：
- ✅ 所有表结构定义在配置文件中（如 `table_config.yaml`）
- ✅ 所有表创建通过配置管理器完成（如 `ConfigDrivenTableManager.batch_create_tables()`）
- ❌ **严禁**使用独立 SQL 脚本绕过配置驱动架构
- ❌ **严禁**任何临时补救措施违背架构原则

#### 2.5.2 禁止临时补救的典型案例

**场景**：ConfigDrivenTableManager 报错，表无法创建

**❌ 错误做法**（违背架构）：
```python
# 遇到 ConfigDrivenTableManager 报错时，绕过架构直接用 SQL
conn = psycopg2.connect(...)
conn.execute("""
    CREATE TABLE strategies (
        id SERIAL PRIMARY KEY,
        name VARCHAR(100) NOT NULL,
        ...
    )
""")  # ❌ 违背架构原则，破坏配置单一数据源
```

**✅ 正确做法**：
```python
# 1. 诊断 ConfigDrivenTableManager 的错误根因
# 2. 修复 bug（例如：ENUM 缺少 name、类型转换问题）
# 3. 删除所有表
# 4. 重新通过 ConfigDrivenTableManager 创建

mgr = DatabaseTableManager()
mgr.batch_create_tables('table_config.yaml')  # ✅ 遵循架构原则
```

#### 2.5.3 架构合规的价值

**为什么必须 100% 合规？**

| 维度 | 临时补救的后果 | 架构合规的收益 |
|------|----------------|----------------|
| **可追溯性** | 数据结构定义分散，无法追溯真实状态 | 配置文件是单一数据源，所有状态可查 |
| **可维护性** | 后续开发者不知道哪些表是手动创建的 | 新团队成员一目了然，快速上手 |
| **一致性** | 开发/测试/生产环境可能不一致 | 通过配置文件保证环境一致性 |
| **自动化** | 无法通过脚本批量重建 | 一键重建所有表，支持 CI/CD |

**核心原则**：
> **短期痛苦（修复 bug）> 长期技术债务（临时补救）**

临时补救看似"快速解决问题"，实则埋下无数隐患：
- 配置文件失去单一数据源的意义
- 系统可维护性急剧下降
- 团队协作成本指数级上升

#### 2.5.4 AI 自检清单

在修改涉及配置驱动架构的代码时，AI 必须问自己：

- [ ] 这个修改是否绕过了配置管理器？
- [ ] 是否存在"临时补救"的倾向？
- [ ] 如果遇到工具报错，是否优先考虑修复工具而非绕过？
- [ ] 修改后配置文件是否仍是唯一真实数据源？

**金标准**：
```
如果有人删除整个数据库，能否仅通过配置文件 100% 重建？
```

如果答案是"否"，说明架构已被破坏。

---

## 3. 分层验证机制

### 3.1 AI 自验证（第一层）

#### 3.1.1 基础检查清单
AI 每次修改后必须执行：

- [ ] **语法合规性**：pylint/flake8 检查
- [ ] **依赖兼容性**：requirements.txt 冲突检查
- [ ] **业务规则校验**：项目开发规范检查
- [ ] **核心功能测试**：保护范围核心用例验证

#### 3.1.2 自查报告模板
```plaintext
=== AI 自查报告 ===
修改时间：2024-01-15 14:30
修改文件：/data_crawl/scripts/cleaner.py
修改类型：bug修复

检查结果：
1. 语法检查：✅ 通过（无错误）
2. 依赖检查：✅ 通过（新增pandas==2.1.0，与现有numpy==1.24.3兼容）
3. 业务规则：✅ 通过（未涉及禁止范围，未包含美股相关逻辑）
4. 核心测试：✅ 通过（/tests/test_trade_executor.py 全部用例通过）

风险评估：低风险
建议：可以进入下一层验证
```

### 3.2 自动化测试（第二层）

#### 3.2.1 测试金字塔
```
        E2E测试 (10%)
       ┌─────────────┐
       │集成测试 (20%)│
     ┌─────────────────┐
     │  单元测试 (70%)  │
     └─────────────────┘
```

#### 3.2.2 测试要求
- **单元测试**：覆盖率 ≥ 80%，包含边界条件和异常情况
- **集成测试**：模块间交互测试，数据流验证
- **回归测试**：历史用例集，确保老功能不被破坏

#### 3.2.3 CI/CD 集成
```yaml
# .github/workflows/ci.yml
name: Code Quality Check
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Run Tests
        run: |
          pytest tests/ --cov=src/ --cov-report=xml
          pylint src/
          flake8 src/
```

### 3.3 人工审核（第三层）

#### 3.3.1 审核触发条件
- 涉及 PROTECTED.md 中的核心模块
- 变更影响范围超过单个函数
- 自动化测试出现新增失败用例
- 性能下降超过 10%

#### 3.3.2 变更申请单模板
```markdown
## 变更申请单

**申请时间**：2024-01-15
**申请人**：AI Assistant
**审核人**：JohnC

### 变更内容
修复A股日线数据缺失值处理逻辑

### 修改文件
- `/data_crawl/scripts/cleaner.py` (主要修改)
- `/tests/test_cleaner.py` (新增测试)

### 关联测试
- 新增：`test_clean_missing_value()`
- 修复：3个回归测试用例
- 覆盖率：从 75% 提升到 85%

### 潜在风险
可能影响依赖该函数的均线计算模块（已补充对应测试）

### 回滚方案
- 保留原函数作为 `clean_data_v1()`
- 提供快速回滚脚本
- 数据库变更提供回滚迁移

### 审核意见
- [ ] 同意修改
- [ ] 需要调整
- [ ] 拒绝修改

**审核人签名**：_________
**审核时间**：_________
```

---

## 4. 版本控制与回溯

### 4.1 分支管理策略

#### 4.1.1 分支结构
```
main (生产环境)
├── develop (开发环境)
├── feature/功能名称 (功能开发)
├── hotfix/修复名称 (紧急修复)
└── release/版本号 (发布准备)
```

#### 4.1.2 分支规则
- **main 分支**：仅存放经过验证的稳定版本，AI 不得直接修改
- **功能分支**：AI 每次修改需基于 main 新建分支
- **合并规则**：PR 必须通过自动化测试 + 人工审核

### 4.2 版本标签管理

#### 4.2.1 标签规范
```bash
# 功能版本
v2.1.0_feature_data_clean

# 修复版本  
v2.1.1_fix_missing_value

# 紧急修复
v2.1.2_hotfix_trade_bug
```

#### 4.2.2 快速回滚
```bash
# 回滚到指定版本
git reset --hard v2.1.0_feature_data_clean

# 数据库回滚
python scripts/rollback_db.py --version=v2.1.0
```

### 4.3 数据库变更管理

#### 4.3.1 迁移脚本要求
- 所有数据库变更必须提供迁移脚本
- 支持向前和向后兼容
- 提供升级和回滚脚本

#### 4.3.2 迁移脚本模板
```python
# migrations/001_add_volume_field.py
def upgrade():
    """添加成交量字段"""
    # 升级逻辑
    pass

def downgrade():
    """移除成交量字段"""
    # 回滚逻辑
    pass
```

---

## 5. AI 交互优化

### 5.1 上下文锚定

#### 5.1.1 任务确认机制
AI 每次修改前必须复述：
- 当前任务目标
- 可能影响的模块
- 预期修改范围

**示例**：
```
本次任务：优化 A 股分钟线数据爬取效率
可能影响的模块：
- /data_crawl/scripts/minute_crawl.py (主要修改)
- /common/utils/request.py (可能优化)
- /config/crawl_config.yaml (配置调整)

预期修改范围：单个模块内的函数优化
是否继续？
```

### 5.2 增量修改可视化

#### 5.2.1 Diff 格式展示
AI 提交修改时必须使用 diff 格式：

```diff
# /data_crawl/scripts/minute_crawl.py
-  sleep(3)  # 固定间隔3秒
+  sleep(config.get('api_interval', 3))  # 从配置文件读取间隔，默认3秒

# 修改原因：支持动态调整API调用间隔，避免硬编码
# 影响范围：仅影响该函数，不影响其他模块
```

### 5.3 错误复盘机制

#### 5.3.1 复盘流程
1. **问题记录**：详细记录错误现象和影响
2. **根因分析**：分析错误的根本原因
3. **规则更新**：更新项目开发规范
4. **预防措施**：AI 自验证逻辑增强

#### 5.3.2 错误案例库
```markdown
## 错误案例 #001
**时间**：2024-01-10
**问题**：修改数据清洗逻辑导致回测模块报错
**根因**：未考虑新增字段对历史数据兼容性
**预防措施**：数据库字段新增需兼容3个月内历史数据
**AI学习**：修改clean_data()后必须运行test_backtest_compatibility.py
```

#### 5.3.3 架构违背案例库

**案例 #002: DatabaseTableManager 临时补救错误** 🔥

**基本信息**：
- **时间**：2025-10-24 (Day 5 Web 层表创建)
- **场景**：使用 ConfigDrivenTableManager 创建表时遇到报错
- **问题**：尝试用独立 SQL 脚本绕过配置驱动架构

**错误过程**：
```python
# 步骤 1：ConfigDrivenTableManager 报错
mgr = DatabaseTableManager()
mgr.batch_create_tables('table_config.yaml')
# ❌ 错误: PostgreSQL ENUM type requires a name

# 步骤 2：AI 的错误选择（违背架构）
# 创建 create_web_tables.py，直接用 SQL 创建表
conn.execute("""
    CREATE TABLE strategies (
        id SERIAL PRIMARY KEY,
        name VARCHAR(100) NOT NULL,
        ...
    )
""")  # ❌ 绕过 ConfigDrivenTableManager

# 步骤 3：用户拒绝临时补救
# 用户: "严禁违背核心架构要求的临时补救"
```

**根本原因**：
1. **问题 #1**：PostgreSQL ENUM 缺少 `name` 参数
   ```python
   # db_manager/database_manager.py:118-120
   Column(SQLEnum('CREATE', 'ALTER', 'DROP'))  # ❌ 缺少 name
   ```

2. **问题 #2**：default_value 字段类型转换错误
   ```python
   # db_manager/database_manager.py:346
   default_value=col_def.get('default')  # ❌ 隐式类型推断
   ```

**正确的解决方案**：
```python
# 修复 #1: 添加 ENUM name 参数
Column(SQLEnum('CREATE', 'ALTER', 'DROP', name='operation_type_enum'))

# 修复 #2: 显式类型转换
default_val = col_def.get('default')
if default_val is not None:
    default_val = str(default_val)  # 显式转换

# 删除所有表，重新通过 ConfigDrivenTableManager 创建
mgr.batch_create_tables('table_config.yaml')  # ✅ 架构合规
```

**最终结果**：
- ✅ 所有 6 张表通过 ConfigDrivenTableManager 创建成功
- ✅ 100% 架构合规，无任何临时补救措施
- ✅ 删除违背架构的 `create_web_tables.py` 脚本

**关键学习**：
1. **遇到工具报错，修复工具而非绕过工具**
   - ❌ 绕过 = 技术债务积累
   - ✅ 修复 = 长期可维护性

2. **架构合规 = 100%，不允许 99%**
   - 即使只有 1% 的临时补救，也会破坏配置单一数据源
   - 用户的坚持是对项目长期负责

3. **短期痛苦 > 长期债务**
   - 修复 bug 需要 30 分钟（短期痛苦）
   - 临时补救后续维护成本 = 无穷大（长期债务）

**AI 行为改进**：
- 遇到配置驱动工具报错时，第一反应是"修复工具"而非"绕过工具"
- 如果用户拒绝临时补救，立即认识到这是对的，并感谢用户把关
- 架构原则不可妥协，即使在"时间紧迫"的情况下

**预防措施**：
- PostgreSQL 数据库操作前检查 ENUM 类型是否有 `name` 参数
- ORM 字段映射时使用显式类型转换
- 所有配置驱动工具的修改都记录在 `DATABASE_MANAGER_ISSUES.md` 中

---

## 6. 质量保障体系

### 6.1 代码质量门禁

#### 6.1.1 静态代码分析
- **工具集成**：SonarQube、CodeClimate、ESLint
- **质量指标**：
  - 代码复杂度 ≤ 10
  - 重复代码率 ≤ 3%
  - 测试覆盖率 ≥ 80%
  - 安全漏洞 = 0

#### 6.1.2 安全扫描
```yaml
# 安全扫描配置
security_scan:
  - dependency_audit: true  # 依赖漏洞扫描
  - secret_detection: true  # 敏感信息泄露检查
  - sql_injection: true     # SQL注入检测
  - xss_detection: true     # XSS漏洞检测
```

### 6.2 性能影响评估

#### 6.2.1 性能基准测试
- **响应时间**：修改前后对比，增加不超过 5%
- **内存使用**：监控内存泄漏和峰值使用
- **CPU 占用**：确保计算密集型操作效率
- **数据库查询**：查询性能影响评估

#### 6.2.2 性能回归检测
```python
# 性能测试示例
def test_performance_regression():
    """性能回归测试"""
    start_time = time.time()
    result = process_large_dataset()
    end_time = time.time()
    
    execution_time = end_time - start_time
    assert execution_time < MAX_EXECUTION_TIME, f"性能下降：{execution_time}s"
```

### 6.3 数据一致性保障

#### 6.3.1 事务完整性
- **事务边界**：明确定义跨模块操作的事务边界
- **失败回滚**：确保部分失败时能够完全回滚
- **数据一致性检查点**：关键操作前后的数据状态验证

#### 6.3.2 数据备份策略
```python
# 数据备份示例
def backup_before_modification():
    """修改前数据备份"""
    backup_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = f"backups/backup_{backup_timestamp}.sql"

    # 执行备份
    subprocess.run(f"mysqldump -u user -p database > {backup_path}")
    return backup_path
```

### 6.4 数据库 ORM 类型安全

#### 6.4.1 显式类型转换原则

**问题背景**：
Python/SQLAlchemy 的隐式类型推断不总是可靠，特别是在批量插入、JSONB 字段、默认值等场景下，容易出现类型推断错误。

**典型错误案例**：
```python
# ❌ 错误：依赖隐式类型推断
for col_def in columns:
    col_log = ColumnDefinitionLog(
        col_length=col_def.get('length'),      # 可能是 None
        default_value=col_def.get('default')   # 可能是字符串、数字、None
    )
    # PostgreSQL 可能将 default_value 推断为 NUMERIC 而非 VARCHAR
```

**正确做法**：
```python
# ✅ 正确：显式类型转换
for col_def in columns:
    # 显式处理 None 和类型转换
    col_length = col_def.get('length')
    # 对于可能存储在 VARCHAR 字段的值，显式转为字符串
    default_val = col_def.get('default')
    if default_val is not None:
        default_val = str(default_val)  # 显式转换为字符串

    col_log = ColumnDefinitionLog(
        col_length=col_length,
        default_value=default_val  # 类型确定，避免推断错误
    )
```

**显式类型转换的场景**：
1. **JSONB 字段**：确保字典/列表正确序列化
2. **默认值**：字符串、数字、布尔值混合时
3. **可选字段**：None 值的正确处理
4. **批量插入**：SQLAlchemy 批量操作时的类型推断

#### 6.4.2 PostgreSQL 特定要求

**ENUM 类型必须指定 name**：

```python
# ❌ 错误：缺少 name 参数
operation_type = Column(SQLEnum('CREATE', 'ALTER', 'DROP', 'VALIDATE'), nullable=False)
# PostgreSQL 报错: PostgreSQL ENUM type requires a name

# ✅ 正确：指定 name 参数
operation_type = Column(
    SQLEnum('CREATE', 'ALTER', 'DROP', 'VALIDATE', name='operation_type_enum'),
    nullable=False
)
```

**为什么 PostgreSQL 需要 name？**
- PostgreSQL 的 ENUM 是用户自定义类型（UDT），必须有名称
- MySQL 的 ENUM 是字段级别的约束，不需要名称
- 迁移到 PostgreSQL 时需要注意这个差异

**其他 PostgreSQL 特定类型**：
```python
from sqlalchemy import Column, Integer, String
from sqlalchemy.dialects.postgresql import JSONB, ARRAY, UUID

# JSONB 类型
parameters = Column(JSONB, nullable=True)

# ARRAY 类型
tags = Column(ARRAY(String), nullable=True)

# UUID 类型
id = Column(UUID(as_uuid=True), primary_key=True)
```

#### 6.4.3 ORM 字段映射最佳实践

**1. 明确字段默认值**：
```python
# ❌ 不明确
created_at = Column(DateTime)

# ✅ 明确默认值
created_at = Column(DateTime, default=datetime.utcnow, nullable=False)
```

**2. 处理可选字段**：
```python
# ❌ 混淆 None 和 空字符串
description = Column(String(255))

# ✅ 明确 nullable
description = Column(String(255), nullable=True)  # 允许 NULL
# 或
description = Column(String(255), nullable=False, default='')  # 不允许 NULL，默认空字符串
```

**3. JSONB 字段的正确使用**：
```python
from sqlalchemy.dialects.postgresql import JSONB
import json

# ✅ 正确：显式序列化
config_data = {"key": "value"}
obj = MyModel(
    config=config_data  # SQLAlchemy 自动序列化为 JSONB
)

# 读取时自动反序列化
config = obj.config  # Python dict
```

#### 6.4.4 类型安全检查清单

在编写 ORM 映射代码时，AI 必须检查：

- [ ] 所有 ENUM 类型都指定了 `name` 参数
- [ ] 默认值字段使用显式类型转换
- [ ] 可选字段明确声明 `nullable=True` 或 `nullable=False`
- [ ] JSONB/ARRAY 等 PostgreSQL 特定类型使用正确的 dialect import
- [ ] 批量插入前验证类型一致性
- [ ] None 值的处理逻辑清晰

**金标准**：
```
代码中不应该依赖数据库的隐式类型推断，所有类型都应该显式声明。
```

---

## 7. 监控与反馈

### 7.1 实时监控体系

#### 7.1.1 代码变更监控
- **变更追踪**：实时检测代码变更对系统的影响
- **异常告警**：异常行为自动告警机制
- **性能监控**：关键指标实时监控

#### 7.1.2 业务指标监控
```python
# 监控指标示例
monitoring_metrics = {
    "trading_volume": "交易量监控",
    "error_rate": "错误率监控", 
    "response_time": "响应时间监控",
    "data_quality": "数据质量监控"
}
```

### 7.2 反馈机制优化

#### 7.2.1 错误标注与归因
当发现 AI 修改问题时，需要明确告知：
- **具体错误点**：精确到文件和行号
- **错误根源**：分析错误的根本原因
- **正确逻辑**：提供正确的解决方案

#### 7.2.2 阶段性验证
将大需求拆解为小步骤：
1. **第一步**：完成核心功能，测试通过
2. **第二步**：添加扩展功能，验证兼容性
3. **第三步**：优化性能，确保无回归

### 7.3 知识库管理

#### 7.3.1 项目全景地图
维护 `PROJECT_MAP.md`：
```markdown
# 项目架构地图

## 核心模块
- `/core/` - 交易核心逻辑
  - `trade_executor.py` - 交易执行
  - `risk_manager.py` - 风险控制
  - `position_manager.py` - 仓位管理

## 数据模块  
- `/data_crawl/` - 数据采集
  - 依赖：`/common/utils/request.py`
  - 输出：`/db/stock_data/`

## 分析模块
- `/analysis/` - 策略分析
  - 依赖：`/data_crawl/stock_data.py`
  - 调用：`get_daily()` 方法
```

#### 7.3.2 历史变更知识库
建立 `ERROR_CASES.md`：
```markdown
# 错误案例库

## 案例 #001
**时间**：2024-01-10
**场景**：修改数据清洗逻辑导致回测模块报错
**根因**：未考虑新增字段对历史数据兼容性
**预防措施**：数据库字段新增需兼容3个月内历史数据
**AI学习**：修改clean_data()后必须运行test_backtest_compatibility.py
```

---

## 8. 快速参考

### 8.1 AI 修改前检查清单

```markdown
## ✅ AI 修改前检查清单

### 基础检查
- [ ] 确认修改范围不涉及 PROTECTED.md 中的文件
- [ ] 识别可能受影响的模块和依赖关系
- [ ] 评估修改的风险等级（低/中/高/极高）
- [ ] 准备相应的测试用例和验证方案

### 架构合规检查
- [ ] 确认遵循配置驱动架构（如有）
- [ ] 确认无临时补救措施
- [ ] 如遇工具报错，优先修复工具而非绕过
- [ ] 验证修改后配置文件仍是唯一数据源

### 技术检查
- [ ] 检查语法和代码规范
- [ ] 验证依赖兼容性
- [ ] 确认业务规则符合性
- [ ] 准备回滚方案

### 数据库 ORM 检查（如涉及）
- [ ] PostgreSQL ENUM 类型指定 name 参数
- [ ] 默认值字段使用显式类型转换
- [ ] 可选字段明确 nullable 声明
- [ ] JSONB/ARRAY 类型正确导入

### 流程检查
- [ ] 是否需要人工审核
- [ ] 是否需要创建变更申请单
- [ ] 是否需要数据库迁移脚本
- [ ] 是否需要性能测试
```

### 8.2 常用命令参考

```bash
# 代码质量检查
pylint src/
flake8 src/
pytest tests/ --cov=src/

# 版本控制
git checkout -b feature/new_feature
git add .
git commit -m "feat: 添加新功能"
git push origin feature/new_feature

# 数据库操作
python scripts/migrate.py --upgrade
python scripts/rollback.py --version=v2.1.0

# 性能测试
python scripts/performance_test.py
```

### 8.3 紧急处理流程

```markdown
## 🚨 紧急问题处理流程

### 1. 立即止损
- 停止相关服务
- 向最终审批人申请
- 申请通过后，回滚到上一稳定版本

### 2. 问题分析
- 收集错误日志
- 分析影响范围
- 确定根本原因

### 3. 修复验证
- 制定修复方案
- 充分测试验证
- 逐步恢复服务

### 4. 事后复盘
- 记录问题详情
- 更新预防措施
- 完善监控告警
```

## 总结

通过建立 "限制修改范围→分层验证拦截→版本控制兜底→交互优化预防" 的闭环机制，将 AI 的 "自由修改" 转化为 "可控变更"。

**核心要点**：
1. **事前约束**：明确保护范围，最小化变更影响
2. **过程验证**：多层验证机制，确保修改质量
3. **事后保障**：版本控制和快速回滚能力
4. **持续改进**：错误复盘和知识积累
5. **架构合规**：100% 遵循配置驱动架构，严禁临时补救

**架构合规的价值** 🏗️：
- **可追溯性**：配置文件是单一数据源，所有状态可查
- **可维护性**：新团队成员快速上手，无隐藏状态
- **一致性**：开发/测试/生产环境通过配置保证一致
- **自动化**：支持 CI/CD 一键重建

**关键原则** ⚖️：
> **短期痛苦（修复 bug）> 长期技术债务（临时补救）**

对于量化交易等对稳定性要求极高的系统，"慢迭代 + 强验证 + 架构合规" 远胜于 "快交付 + 常救火 + 临时补救"。

**Day 5 关键学习** 📚：
- 遇到工具报错时，修复工具而非绕过工具
- 架构合规 = 100%，不允许 99% 或临时补救
- PostgreSQL ENUM 必须指定 name，显式类型转换避免推断错误
- 用户坚持架构原则是对项目长期负责