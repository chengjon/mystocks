# MyStocks AIç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜MyStocks AIç³»ç»Ÿåœ¨ç”Ÿäº§ç¯å¢ƒçš„éƒ¨ç½²ã€è¿ç»´å’Œæ‰©å±•æ–¹æ³•ï¼Œä¸ºmystocks_niceåˆ†æ”¯æä¾›å®Œæ•´çš„éƒ¨ç½²å‚è€ƒã€‚

**ç›®æ ‡è¯»è€…**: DevOpså·¥ç¨‹å¸ˆã€è¿ç»´å›¢é˜Ÿã€ç³»ç»Ÿæ¶æ„å¸ˆã€ç”Ÿäº§ç¯å¢ƒç®¡ç†å‘˜  
**å®æ–½éš¾åº¦**: é«˜çº§  
**å‰ç½®è¦æ±‚**: Dockerã€Kubernetesã€CI/CDã€ç›‘æ§è¿ç»´ç»éªŒ

---

## ğŸ—ï¸ ç”Ÿäº§æ¶æ„æ¦‚è§ˆ

### ç³»ç»Ÿæ¶æ„å›¾

```yaml
# docker-compose.prod.yml - ç”Ÿäº§ç¯å¢ƒæ¶æ„
version: '3.8'

services:
  # AIæ ¸å¿ƒæœåŠ¡
  ai-strategy-engine:
    image: mystocks/ai-strategy:latest
    environment:
      - ENV=production
      - GPU_ENABLED=true
      - REDIS_URL=redis://redis:6379
    deploy:
      replicas: 3
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    depends_on:
      - redis
      - postgresql
      - tdengine
    networks:
      - ai-network

  # GPUåŠ é€ŸæœåŠ¡
  gpu-acceleration-service:
    image: mystocks/gpu-service:latest
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - RAPIDS_ENABLED=true
    deploy:
      replicas: 2
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    networks:
      - ai-network

  # Webå‰ç«¯æœåŠ¡ (mystocks_niceåˆ†æ”¯)
  web-frontend:
    image: mystocks/web-frontend:latest
    ports:
      - "80:80"
      - "443:443"
    environment:
      - API_BASE_URL=http://api-gateway:8080
    depends_on:
      - api-gateway
    networks:
      - ai-network

  # APIç½‘å…³
  api-gateway:
    image: mystocks/api-gateway:latest
    ports:
      - "8080:8080"
    environment:
      - STRATEGY_SERVICE_URL=http://ai-strategy-engine:8000
      - GPU_SERVICE_URL=http://gpu-acceleration-service:8001
    networks:
      - ai-network

  # æ•°æ®æœåŠ¡
  postgresql:
    image: postgres:15
    environment:
      - POSTGRES_DB=mystocks
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - ai-network

  tdengine:
    image: tdengine/tdengine:latest
    environment:
      - TAOS_FIRST_EP=tdengine
    volumes:
      - tdengine_data:/var/lib/taos
    networks:
      - ai-network

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    networks:
      - ai-network

  # ç›‘æ§æœåŠ¡
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - ai-network

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - ai-network

volumes:
  postgres_data:
  tdengine_data:
  redis_data:
  grafana_data:

networks:
  ai-network:
    driver: bridge
```

---

## ğŸš€ CI/CD æµæ°´çº¿

### GitHub Actions å·¥ä½œæµ

```yaml
# .github/workflows/deploy-production.yml
name: Deploy to Production

on:
  push:
    branches: [main, production]
    tags: ['v*']

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: mystocks

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-test.txt
      
      - name: Run tests
        run: |
          pytest tests/ --cov=src/ --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
      
      - name: Build and push
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  security-scan:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ needs.build.outputs.image-tag }}
          format: 'sarif'
          output: 'trivy-results.sarif'
      
      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

  deploy-staging:
    needs: [build, security-scan]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: staging
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Deploy to staging
        run: |
          echo "Deploying to staging environment..."
          # kubectl apply -f k8s/staging/
      
      - name: Run integration tests
        run: |
          echo "Running integration tests..."
          pytest tests/integration/ -v

  deploy-production:
    needs: [build, security-scan]
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/v')
    environment: production
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Deploy to production
        run: |
          echo "Deploying to production environment..."
          # kubectl apply -f k8s/production/
      
      - name: Verify deployment
        run: |
          echo "Verifying production deployment..."
          # kubectl rollout status deployment/ai-strategy-engine
      
      - name: Notify deployment
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#deployments'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}

  rollback:
    needs: deploy-production
    runs-on: ubuntu-latest
    if: failure()
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Rollback deployment
        run: |
          echo "Rolling back deployment..."
          # kubectl rollout undo deployment/ai-strategy-engine
```

---

## ğŸ”§ Kubernetes éƒ¨ç½²

### ç”Ÿäº§ç¯å¢ƒé…ç½®

```yaml
# k8s/production/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: mystocks-prod
  labels:
    name: mystocks-prod
    environment: production

---
# k8s/production/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: mystocks-config
  namespace: mystocks-prod
data:
  ENV: "production"
  LOG_LEVEL: "INFO"
  REDIS_URL: "redis://redis-service:6379"
  POSTGRES_URL: "postgresql://admin:password@postgres-service:5432/mystocks"
  TDENGINE_URL: "tdengine-service:6030"
  GPU_ENABLED: "true"
  MONITORING_ENABLED: "true"

---
# k8s/production/ai-strategy-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-strategy-engine
  namespace: mystocks-prod
  labels:
    app: ai-strategy-engine
    version: v1
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app: ai-strategy-engine
  template:
    metadata:
      labels:
        app: ai-strategy-engine
        version: v1
    spec:
      serviceAccountName: mystocks-sa
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      containers:
      - name: ai-strategy-engine
        image: ghcr.io/mystocks/ai-strategy:latest
        ports:
        - containerPort: 8000
          name: http
        - containerPort: 9090
          name: metrics
        env:
        - name: ENV
          valueFrom:
            configMapKeyRef:
              name: mystocks-config
              key: ENV
        - name: GPU_ENABLED
          valueFrom:
            configMapKeyRef:
              name: mystocks-config
              key: GPU_ENABLED
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
            nvidia.com/gpu: 1
          limits:
            memory: "4Gi"
            cpu: "2000m"
            nvidia.com/gpu: 1
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
      volumes:
      - name: config-volume
        configMap:
          name: mystocks-config
      nodeSelector:
        accelerator: nvidia-tesla-k80
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule

---
# k8s/production/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: ai-strategy-service
  namespace: mystocks-prod
  labels:
    app: ai-strategy-engine
spec:
  selector:
    app: ai-strategy-engine
  ports:
  - name: http
    port: 80
    targetPort: 8000
  - name: metrics
    port: 9090
    targetPort: 9090
  type: ClusterIP

---
# k8s/production/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ai-strategy-hpa
  namespace: mystocks-prod
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ai-strategy-engine
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60

---
# k8s/production/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: mystocks-ingress
  namespace: mystocks-prod
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/rate-limit: "100"
spec:
  tls:
  - hosts:
    - mystocks.yourcompany.com
    secretName: mystocks-tls
  rules:
  - host: mystocks.yourcompany.com
    http:
      paths:
      - path: /api/strategy
        pathType: Prefix
        backend:
          service:
            name: ai-strategy-service
            port:
              number: 80
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-frontend-service
            port:
              number: 80
```

---

## ğŸ“Š ç›‘æ§å’Œå‘Šè­¦é…ç½®

### Prometheus é…ç½®

```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'ai-strategy-engine'
    static_configs:
      - targets: ['ai-strategy-service:9090']
    metrics_path: '/metrics'
    scrape_interval: 5s

  - job_name: 'gpu-acceleration-service'
    static_configs:
      - targets: ['gpu-service:9091']
    metrics_path: '/metrics'
    scrape_interval: 5s

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-service:9121']

  - job_name: 'postgresql'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
```

### AlertManager é…ç½®

```yaml
# monitoring/alertmanager.yml
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@mystocks.com'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'
  routes:
  - match:
      severity: critical
    receiver: 'critical-alerts'
  - match:
      severity: warning
    receiver: 'warning-alerts'

receivers:
- name: 'web.hook'
  webhook_configs:
  - url: 'http://webhook-service:5000/alerts'

- name: 'critical-alerts'
  email_configs:
  - to: 'ops-team@mystocks.com'
    subject: 'ã€ä¸¥é‡ã€‘MyStocks AIç³»ç»Ÿå‘Šè­¦'
    body: |
      {{ range .Alerts }}
      å‘Šè­¦: {{ .Annotations.summary }}
      è¯¦æƒ…: {{ .Annotations.description }}
      æ—¶é—´: {{ .StartsAt }}
      {{ end }}
  slack_configs:
  - api_url: 'YOUR_SLACK_WEBHOOK_URL'
    channel: '#critical-alerts'
    title: 'MyStocks AIç³»ç»Ÿä¸¥é‡å‘Šè­¦'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

- name: 'warning-alerts'
  email_configs:
  - to: 'dev-team@mystocks.com'
    subject: 'ã€è­¦å‘Šã€‘MyStocks AIç³»ç»Ÿå‘Šè­¦'
```

### è‡ªå®šä¹‰å‘Šè­¦è§„åˆ™

```yaml
# monitoring/alert_rules.yml
groups:
- name: mystocks-ai-rules
  rules:
  - alert: AIStrategyEngineDown
    expr: up{job="ai-strategy-engine"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "AIç­–ç•¥å¼•æ“æœåŠ¡ä¸å¯ç”¨"
      description: "AIç­–ç•¥å¼•æ“æœåŠ¡å·²ç»å®•æœºè¶…è¿‡1åˆ†é’Ÿ"

  - alert: GPUUtilizationHigh
    expr: nvidia_gpu_utilization > 90
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "GPUä½¿ç”¨ç‡è¿‡é«˜"
      description: "GPUä½¿ç”¨ç‡å·²è¾¾åˆ° {{ $value }}%ï¼Œè¶…è¿‡90%é˜ˆå€¼"

  - alert: StrategyPerformanceDegraded
    expr: strategy_win_rate < 0.3
    for: 10m
    labels:
      severity: critical
    annotations:
      summary: "AIç­–ç•¥è¡¨ç°å¼‚å¸¸"
      description: "ç­–ç•¥èƒœç‡å·²é™è‡³ {{ $value }}ï¼ŒæŒç»­è¶…è¿‡10åˆ†é’Ÿ"

  - alert: HighMemoryUsage
    expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
      description: "ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡å·²è¾¾ {{ $value }}%ï¼Œè¶…è¿‡85%é˜ˆå€¼"

  - alert: PostgreSQLDown
    expr: up{job="postgresql"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "PostgreSQLæ•°æ®åº“ä¸å¯ç”¨"
      description: "PostgreSQLæ•°æ®åº“è¿æ¥å·²ä¸­æ–­è¶…è¿‡1åˆ†é’Ÿ"

  - alert: RedisDown
    expr: up{job="redis"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Redisç¼“å­˜æœåŠ¡ä¸å¯ç”¨"
      description: "Redisç¼“å­˜æœåŠ¡è¿æ¥å·²ä¸­æ–­è¶…è¿‡1åˆ†é’Ÿ"
```

---

## ğŸ›¡ï¸ å®‰å…¨é…ç½®

### RBAC é…ç½®

```yaml
# k8s/production/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: mystocks-sa
  namespace: mystocks-prod

---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: mystocks-prod
  name: mystocks-role
rules:
- apiGroups: [""]
  resources: ["configmaps", "secrets"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: mystocks-rolebinding
  namespace: mystocks-prod
subjects:
- kind: ServiceAccount
  name: mystocks-sa
  namespace: mystocks-prod
roleRef:
  kind: Role
  name: mystocks-role
  apiGroup: rbac.authorization.k8s.io
```

### ç½‘ç»œç­–ç•¥

```yaml
# k8s/production/network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  namespace: mystocks-prod
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: ai-strategy-policy
  namespace: mystocks-prod
spec:
  podSelector:
    matchLabels:
      app: ai-strategy-engine
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: api-gateway
    ports:
    - protocol: TCP
      port: 8000
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: redis
    ports:
    - protocol: TCP
      port: 6379
  - to:
    - podSelector:
        matchLabels:
          app: postgresql
    ports:
    - protocol: TCP
      port: 5432
```

### å¯†é’¥ç®¡ç†

```yaml
# k8s/production/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: mystocks-secrets
  namespace: mystocks-prod
type: Opaque
data:
  # å®é™…ä½¿ç”¨æ—¶åº”ä½¿ç”¨ kubectl create secret åŠ¨æ€ç”Ÿæˆ
  postgres-password: cGFzc3dvcmQxMjM= # base64ç¼–ç 
  redis-password: cmVkaXNwYXNzd29yZA== # base64ç¼–ç 
  jwt-secret: eW91cl9zdXBlcl9zZWNyZXQ= # base64ç¼–ç 
  openai-api-key: eW91cl9vcGVuYWlfa2V5 # base64ç¼–ç 

---
# ä½¿ç”¨External Secrets Operatoræˆ–Vaulté›†æˆ
apiVersion: external-secrets.io/v1beta1
kind: SecretStore
metadata:
  name: mystocks-secrets
  namespace: mystocks-prod
spec:
  provider:
    vault:
      server: "https://vault.yourcompany.com"
      path: "secret"
      version: "v2"
      auth:
        kubernetes:
          mountPath: "kubernetes"
          role: "mystocks-role"

---
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: mystocks-external-secrets
  namespace: mystocks-prod
spec:
  refreshInterval: 15s
  secretStoreRef:
    name: mystocks-secrets
    kind: SecretStore
  target:
    creationPolicy: Owner
  data:
  - secretKey: postgres-password
    remoteRef:
      key: database
      property: password
  - secretKey: redis-password
    remoteRef:
      key: cache
      property: password
  - secretKey: jwt-secret
    remoteRef:
      key: auth
      property: jwt-secret
```

---

## ğŸ”„ ç¾éš¾æ¢å¤è®¡åˆ’

### æ•°æ®å¤‡ä»½ç­–ç•¥

```bash
#!/bin/bash
# backup/backup-script.sh

set -e

BACKUP_DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup/mystocks/${BACKUP_DATE}"

echo "å¼€å§‹å¤‡ä»½ MyStocks æ•°æ® - ${BACKUP_DATE}"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p "${BACKUP_DIR}"

# 1. å¤‡ä»½ PostgreSQL
echo "å¤‡ä»½ PostgreSQL æ•°æ®åº“..."
kubectl exec -n mystocks-prod deployment/postgres -- pg_dump -U admin mystocks > "${BACKUP_DIR}/postgresql.sql"

# 2. å¤‡ä»½ TDengine
echo "å¤‡ä»½ TDengine æ•°æ®..."
kubectl exec -n mystocks-prod statefulset/tdengine -- taosdump -u root -p password -o /var/lib/taos/backup_${BACKUP_DATE}

# 3. å¤‡ä»½ Redis
echo "å¤‡ä»½ Redis æ•°æ®..."
kubectl exec -n mystocks-prod deployment/redis -- redis-cli --rdb /data/dump.rdb
kubectl cp mystocks-prod/$(kubectl get pods -n mystocks-prod -l app=redis -o jsonpath='{.items[0].metadata.name}'):/data/dump.rdb "${BACKUP_DIR}/redis.rdb"

# 4. å¤‡ä»½é…ç½®å’Œå¯†é’¥
echo "å¤‡ä»½é…ç½®..."
kubectl get configmaps -n mystocks-prod -o yaml > "${BACKUP_DIR}/configmaps.yaml"
kubectl get secrets -n mystocks-prod -o yaml > "${BACKUP_DIR}/secrets.yaml"

# 5. å¤‡ä»½æŒä¹…åŒ–å·
echo "å¤‡ä»½æŒä¹…åŒ–å·..."
for pvc in $(kubectl get pvc -n mystocks-prod -o jsonpath='{.items[*].metadata.name}'); do
    kubectl exec -n mystocks-prod deployment/backup-tool -- tar czf "/backup/${pvc}.tar.gz" -C /mnt/pvc "${pvc}"
    kubectl cp mystocks-prod/backup-pod:/backup/${pvc}.tar.gz "${BACKUP_DIR}/${pvc}.tar.gz"
done

# 6. å‹ç¼©å¹¶ä¸Šä¼ åˆ°å¯¹è±¡å­˜å‚¨
echo "ä¸Šä¼ åˆ°å¯¹è±¡å­˜å‚¨..."
tar czf "${BACKUP_DIR}.tar.gz" -C /backup/mystocks "${BACKUP_DATE}"
aws s3 cp "${BACKUP_DIR}.tar.gz" s3://mystocks-backups/database/

# 7. æ¸…ç†æœ¬åœ°å¤‡ä»½
echo "æ¸…ç†æœ¬åœ°å¤‡ä»½..."
rm -rf "${BACKUP_DIR}"
rm -f "${BACKUP_DIR}.tar.gz"

# 8. éªŒè¯å¤‡ä»½
echo "éªŒè¯å¤‡ä»½å®Œæ•´æ€§..."
BACKUP_SIZE=$(aws s3 ls s3://mystocks-backups/database/ --human-readable | tail -n 1 | awk '{print $3}')
echo "å¤‡ä»½å¤§å°: ${BACKUP_SIZE}"

echo "å¤‡ä»½å®Œæˆ - ${BACKUP_DATE}"
```

### æ¢å¤ç¨‹åº

```bash
#!/bin/bash
# disaster-recovery/restore-script.sh

BACKUP_FILE=$1
if [ -z "$BACKUP_FILE" ]; then
    echo "ä½¿ç”¨æ–¹æ³•: $0 <backup_file>"
    exit 1
fi

echo "å¼€å§‹æ¢å¤ MyStocks ç³»ç»Ÿ - ${BACKUP_FILE}"

# 1. ä¸‹è½½å¤‡ä»½æ–‡ä»¶
echo "ä¸‹è½½å¤‡ä»½æ–‡ä»¶..."
aws s3 cp s3://mystocks-backups/database/${BACKUP_FILE} ./

# 2. è§£å‹å¤‡ä»½æ–‡ä»¶
echo "è§£å‹å¤‡ä»½æ–‡ä»¶..."
tar xzf ${BACKUP_FILE}

# 3. åœæ­¢åº”ç”¨æœåŠ¡
echo "åœæ­¢åº”ç”¨æœåŠ¡..."
kubectl scale deployment ai-strategy-engine --replicas=0 -n mystocks-prod
kubectl scale deployment gpu-acceleration-service --replicas=0 -n mystocks-prod

# 4. æ¢å¤ PostgreSQL
echo "æ¢å¤ PostgreSQL æ•°æ®åº“..."
BACKUP_DIR=$(basename ${BACKUP_FILE} .tar.gz)
kubectl exec -i -n mystocks-prod deployment/postgres -- psql -U admin mystocks < "${BACKUP_DIR}/postgresql.sql"

# 5. æ¢å¤ TDengine
echo "æ¢å¤ TDengine æ•°æ®..."
kubectl exec -n mystocks-prod statefulset/tdengine -- rm -rf /var/lib/taos/data/*
kubectl exec -n mystocks-prod statefulset/tdengine -- taosdump -u root -p password -i /var/lib/taos/backup_*

# 6. æ¢å¤ Redis
echo "æ¢å¤ Redis æ•°æ®..."
kubectl cp "${BACKUP_DIR}/redis.rdb" mystocks-prod/$(kubectl get pods -n mystocks-prod -l app=redis -o jsonpath='{.items[0].metadata.name}'):/data/dump.rdb
kubectl exec -n mystocks-prod deployment/redis -- redis-cli --rdb /data/dump.rdb

# 7. æ¢å¤åº”ç”¨æœåŠ¡
echo "æ¢å¤åº”ç”¨æœåŠ¡..."
kubectl scale deployment ai-strategy-engine --replicas=3 -n mystocks-prod
kubectl scale deployment gpu-acceleration-service --replicas=2 -n mystocks-prod

# 8. éªŒè¯æ¢å¤
echo "éªŒè¯æ¢å¤çŠ¶æ€..."
sleep 30
kubectl get pods -n mystocks-prod
kubectl rollout status deployment/ai-strategy-engine -n mystocks-prod

echo "æ¢å¤å®Œæˆ"
```

---

## ğŸ“ˆ æ€§èƒ½è°ƒä¼˜

### GPU ä¼˜åŒ–é…ç½®

```python
# src/gpu/optimization/gpu_config.py
import cupy as cp
import cudf
from numba import cuda
import rmm

class GPUOptimizationManager:
    """GPUæ€§èƒ½ä¼˜åŒ–ç®¡ç†å™¨"""
    
    def __init__(self):
        self.gpu_id = 0
        self.setup_memory_pool()
        self.setup_kernel_cache()
    
    def setup_memory_pool(self):
        """è®¾ç½®GPUå†…å­˜æ± """
        # åˆå§‹åŒ–RMMå†…å­˜æ± 
        rmm.reinitialize(
            pool_allocator=True,
            managed_memory=True,
            initial_pool_size=1e9,  # 1GBåˆå§‹æ± å¤§å°
            max_pool_size=8e9,      # 8GBæœ€å¤§æ± å¤§å°
            devices=[0]
        )
        
        # é…ç½®CuPyå†…å­˜æ± 
        cp.cuda.runtime.setDevice(self.gpu_id)
        mempool = cp.get_default_memory_pool()
        mempool.set_limit(fraction=0.8)  # ä½¿ç”¨80% GPUå†…å­˜
    
    def setup_kernel_cache(self):
        """è®¾ç½®å†…æ ¸ç¼“å­˜"""
        # é¢„ç¼–è¯‘å¸¸ç”¨å†…æ ¸
        @cp.fuse
        def fast_ma(data, window):
            """å¿«é€Ÿç§»åŠ¨å¹³å‡"""
            cumsum = cp.cumsum(data, dtype=cp.float32)
            cumsum[window:] = cumsum[window:] - cumsum[:-window]
            return cumsum[window - 1:] / window
        
        # ç¼–è¯‘å¹¶ç¼“å­˜
        self.ma_kernel = fast_ma
        print("âœ… GPUå†…æ ¸ç¼“å­˜é¢„ç¼–è¯‘å®Œæˆ")
    
    def optimize_strategies(self, strategy_data):
        """ä¼˜åŒ–ç­–ç•¥è®¡ç®—"""
        # ä½¿ç”¨CuDFè¿›è¡ŒGPUåŠ é€Ÿæ•°æ®å¤„ç†
        gpu_df = cudf.from_pandas(strategy_data)
        
        # GPUåŠ é€ŸæŠ€æœ¯æŒ‡æ ‡è®¡ç®—
        gpu_df['ma_20'] = gpu_df['close'].rolling(20).mean()
        gpu_df['ma_50'] = gpu_df['close'].rolling(50).mean()
        gpu_df['rsi'] = self.calculate_gpu_rsi(gpu_df['close'])
        
        return gpu_df.to_pandas()
    
    def calculate_gpu_rsi(self, prices, period=14):
        """GPUåŠ é€ŸRSIè®¡ç®—"""
        prices_gpu = cp.asarray(prices.values)
        deltas = cp.diff(prices_gpu)
        
        gains = cp.where(deltas > 0, deltas, 0)
        losses = cp.where(deltas < 0, -deltas, 0)
        
        avg_gains = cp.convolve(gains, cp.ones(period), 'valid') / period
        avg_losses = cp.convolve(losses, cp.ones(period), 'valid') / period
        
        rs = avg_gains / (avg_losses + 1e-10)
        rsi = 100 - (100 / (1 + rs))
        
        return cp.asnumpy(rsi)
```

### æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–

```python
# src/database/connection_pool.py
import asyncpg
import asyncio
from sqlalchemy import create_engine, pool
from sqlalchemy.pool import QueuePool
import redis.asyncio as redis
from contextlib import asynccontextmanager

class DatabaseConnectionPool:
    """æ•°æ®åº“è¿æ¥æ± ç®¡ç†å™¨"""
    
    def __init__(self):
        self.postgres_pool = None
        self.redis_pool = None
        self.tdengine_pool = None
    
    async def initialize_pools(self):
        """åˆå§‹åŒ–è¿æ¥æ± """
        # PostgreSQLè¿æ¥æ± 
        self.postgres_pool = await asyncpg.create_pool(
            host='postgres-service',
            port=5432,
            user='admin',
            password='password',
            database='mystocks',
            min_size=5,
            max_size=20,
            command_timeout=60
        )
        
        # Redisè¿æ¥æ± 
        self.redis_pool = redis.ConnectionPool.from_url(
            'redis://redis-service:6379',
            max_connections=20,
            retry_on_timeout=True
        )
        
        print("âœ… æ•°æ®åº“è¿æ¥æ± åˆå§‹åŒ–å®Œæˆ")
    
    @asynccontextmanager
    async def get_postgres_connection(self):
        """è·å–PostgreSQLè¿æ¥"""
        async with self.postgres_pool.acquire() as connection:
            try:
                yield connection
            except Exception as e:
                print(f"PostgreSQLè¿æ¥é”™è¯¯: {e}")
                raise
    
    @asynccontextmanager
    async def get_redis_connection(self):
        """è·å–Redisè¿æ¥"""
        async with redis.Redis(connection_pool=self.redis_pool) as redis_client:
            try:
                yield redis_client
            except Exception as e:
                print(f"Redisè¿æ¥é”™è¯¯: {e}")
                raise

# ä½¿ç”¨ç¤ºä¾‹
async def example_usage():
    db_pool = DatabaseConnectionPool()
    await db_pool.initialize_pools()
    
    # ä½¿ç”¨PostgreSQL
    async with db_pool.get_postgres_connection() as conn:
        result = await conn.fetch("SELECT * FROM ai_strategies WHERE active = true")
        print(f"ç­–ç•¥æ•°é‡: {len(result)}")
    
    # ä½¿ç”¨Redisç¼“å­˜
    async with db_pool.get_redis_connection() as redis_client:
        await redis_client.set("key", "value", ex=3600)
        value = await redis_client.get("key")
        print(f"ç¼“å­˜å€¼: {value}")
```

---

## ğŸš€ è‡ªåŠ¨åŒ–è¿ç»´è„šæœ¬

### æ—¥å¸¸è¿ç»´è„šæœ¬

```bash
#!/bin/bash
# scripts/daily-maintenance.sh

set -e

LOG_FILE="/var/log/mystocks-maintenance.log"
DATE=$(date '+%Y-%m-%d %H:%M:%S')

log() {
    echo "[$DATE] $1" | tee -a "$LOG_FILE"
}

log "å¼€å§‹æ—¥å¸¸ç»´æŠ¤ä»»åŠ¡"

# 1. æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€
log "æ£€æŸ¥PodçŠ¶æ€..."
kubectl get pods -n mystocks-prod -o wide

log "æ£€æŸ¥NodeçŠ¶æ€..."
kubectl get nodes -o wide

log "æ£€æŸ¥PVCçŠ¶æ€..."
kubectl get pvc -n mystocks-prod

# 2. æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ
log "æ£€æŸ¥èµ„æºä½¿ç”¨..."
kubectl top nodes
kubectl top pods -n mystocks-prod

# 3. æ£€æŸ¥GPUçŠ¶æ€
log "æ£€æŸ¥GPUçŠ¶æ€..."
kubectl exec -n mystocks-prod deployment/ai-strategy-engine -- nvidia-smi

# 4. æ¸…ç†è¿‡æœŸæ—¥å¿—
log "æ¸…ç†è¿‡æœŸæ—¥å¿—..."
find /var/log -name "*.log" -mtime +7 -delete

# 5. å¤‡ä»½é‡è¦é…ç½®
log "å¤‡ä»½é…ç½®..."
kubectl get all -n mystocks-prod -o yaml > /backup/config/$(date +%Y%m%d)_mystocks-config.yaml

# 6. æ›´æ–°ç›‘æ§æŒ‡æ ‡
log "æ›´æ–°ç›‘æ§æŒ‡æ ‡..."
curl -X POST http://prometheus:9090/-/reload

# 7. æ£€æŸ¥å‘Šè­¦çŠ¶æ€
log "æ£€æŸ¥å‘Šè­¦çŠ¶æ€..."
curl -s http://alertmanager:9093/api/v1/alerts | jq '.data[].status'

# 8. æ€§èƒ½åŸºå‡†æµ‹è¯•
log "è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•..."
python /opt/mystocks/performance_benchmark.py

log "æ—¥å¸¸ç»´æŠ¤ä»»åŠ¡å®Œæˆ"
```

### è‡ªåŠ¨æ‰©ç¼©å®¹è„šæœ¬

```python
#!/usr/bin/env python3
# scripts/auto_scaling.py

import asyncio
import kubernetes_asyncio as k8s
import requests
import logging
from datetime import datetime

class AutoScalingManager:
    """è‡ªåŠ¨æ‰©ç¼©å®¹ç®¡ç†å™¨"""
    
    def __init__(self):
        self.namespace = "mystocks-prod"
        self.deployment_name = "ai-strategy-engine"
        self.min_replicas = 3
        self.max_replicas = 15
        
    async def initialize(self):
        """åˆå§‹åŒ–Kuberneteså®¢æˆ·ç«¯"""
        k8s.config.load_incluster_config()
        self.api = k8s.client.AppsV1Api()
        
    async def get_current_metrics(self):
        """è·å–å½“å‰ç³»ç»ŸæŒ‡æ ‡"""
        try:
            # ä»Prometheusè·å–CPUä½¿ç”¨ç‡
            cpu_query = 'avg(rate(container_cpu_usage_seconds_total{namespace="mystocks-prod"}[5m])) * 100'
            cpu_response = requests.get(
                'http://prometheus:9090/api/v1/query',
                params={'query': cpu_query}
            )
            cpu_usage = float(cpu_response.json()['data']['result'][0]['value'][1])
            
            # è·å–GPUä½¿ç”¨ç‡
            gpu_query = 'avg(nvidia_gpu_utilization)'
            gpu_response = requests.get(
                'http://prometheus:9090/api/v1/query',
                params={'query': gpu_query}
            )
            gpu_usage = float(gpu_response.json()['data']['result'][0]['value'][1])
            
            # è·å–å†…å­˜ä½¿ç”¨ç‡
            memory_query = 'avg(container_memory_working_set_bytes{namespace="mystocks-prod"}) / avg(container_spec_memory_limit_bytes{namespace="mystocks-prod"}) * 100'
            memory_response = requests.get(
                'http://prometheus:9090/api/v1/query',
                params={'query': memory_query}
            )
            memory_usage = float(memory_response.json()['data']['result'][0]['value'][1])
            
            return {
                'cpu_usage': cpu_usage,
                'gpu_usage': gpu_usage,
                'memory_usage': memory_usage
            }
        except Exception as e:
            logging.error(f"è·å–æŒ‡æ ‡å¤±è´¥: {e}")
            return None
    
    async def calculate_target_replicas(self, metrics):
        """è®¡ç®—ç›®æ ‡å‰¯æœ¬æ•°"""
        if not metrics:
            return None
        
        cpu_usage = metrics['cpu_usage']
        gpu_usage = metrics['gpu_usage']
        memory_usage = metrics['memory_usage']
        
        # åŸºäºèµ„æºä½¿ç”¨ç‡çš„æ‰©ç¼©å®¹ç­–ç•¥
        if cpu_usage > 80 or gpu_usage > 90 or memory_usage > 85:
            # é«˜è´Ÿè½½ - å¢åŠ å‰¯æœ¬
            target_replicas = min(self.max_replicas, int((cpu_usage + gpu_usage + memory_usage) / 30))
        elif cpu_usage < 30 and gpu_usage < 30 and memory_usage < 30:
            # ä½è´Ÿè½½ - å‡å°‘å‰¯æœ¬
            target_replicas = max(self.min_replicas, int((cpu_usage + gpu_usage + memory_usage) / 90))
        else:
            # ä¸­ç­‰è´Ÿè½½ - ä¿æŒç°çŠ¶
            return None
        
        return max(self.min_replicas, min(self.max_replicas, target_replicas))
    
    async def scale_deployment(self, replicas):
        """æ‰§è¡Œæ‰©ç¼©å®¹"""
        try:
            # è·å–å½“å‰éƒ¨ç½²
            deployment = await self.api.read_namespaced_deployment(
                name=self.deployment_name,
                namespace=self.namespace
            )
            
            current_replicas = deployment.spec.replicas
            
            if current_replicas == replicas:
                logging.info(f"å‰¯æœ¬æ•°æ— éœ€è°ƒæ•´ï¼Œå½“å‰: {current_replicas}, ç›®æ ‡: {replicas}")
                return False
            
            # æ›´æ–°å‰¯æœ¬æ•°
            deployment.spec.replicas = replicas
            
            await self.api.patch_namespaced_deployment(
                name=self.deployment_name,
                namespace=self.namespace,
                body=deployment
            )
            
            logging.info(f"æ‰©ç¼©å®¹å®Œæˆ: {current_replicas} -> {replicas}")
            return True
            
        except Exception as e:
            logging.error(f"æ‰©ç¼©å®¹å¤±è´¥: {e}")
            return False
    
    async def run_scaling_loop(self):
        """è¿è¡Œæ‰©ç¼©å®¹å¾ªç¯"""
        await self.initialize()
        
        while True:
            try:
                # è·å–å½“å‰æŒ‡æ ‡
                metrics = await self.get_current_metrics()
                
                if metrics:
                    # è®¡ç®—ç›®æ ‡å‰¯æœ¬æ•°
                    target_replicas = await self.calculate_target_replicas(metrics)
                    
                    if target_replicas:
                        # æ‰§è¡Œæ‰©ç¼©å®¹
                        await self.scale_deployment(target_replicas)
                
                # ç­‰å¾…60ç§’åé‡æ–°æ£€æŸ¥
                await asyncio.sleep(60)
                
            except Exception as e:
                logging.error(f"æ‰©ç¼©å®¹å¾ªç¯å¼‚å¸¸: {e}")
                await asyncio.sleep(60)

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    manager = AutoScalingManager()
    asyncio.run(manager.run_scaling_loop())
```

---

## ğŸ“ æ•…éšœæ’æŸ¥æŒ‡å—

### å¸¸è§é—®é¢˜è¯Šæ–­

```bash
#!/bin/bash
# scripts/troubleshoot.sh

echo "=== MyStocks AIç³»ç»Ÿæ•…éšœæ’æŸ¥ ==="

# 1. æ£€æŸ¥æ ¸å¿ƒæœåŠ¡çŠ¶æ€
echo "1. æ£€æŸ¥PodçŠ¶æ€..."
kubectl get pods -n mystocks-prod -o wide

# 2. æ£€æŸ¥äº‹ä»¶æ—¥å¿—
echo "2. æ£€æŸ¥äº‹ä»¶æ—¥å¿—..."
kubectl get events -n mystocks-prod --sort-by='.lastTimestamp'

# 3. æ£€æŸ¥èµ„æºä½¿ç”¨
echo "3. æ£€æŸ¥èµ„æºä½¿ç”¨..."
kubectl top nodes
kubectl top pods -n mystocks-prod

# 4. æ£€æŸ¥GPUçŠ¶æ€
echo "4. æ£€æŸ¥GPUçŠ¶æ€..."
kubectl exec -n mystocks-prod deployment/ai-strategy-engine -- nvidia-smi

# 5. æ£€æŸ¥ç½‘ç»œè¿æ¥
echo "5. æ£€æŸ¥æœåŠ¡è¿é€šæ€§..."
kubectl exec -n mystocks-prod deployment/ai-strategy-engine -- curl -f http://redis-service:6379/ping
kubectl exec -n mystocks-prod deployment/ai-strategy-engine -- nc -zv postgres-service 5432

# 6. æ£€æŸ¥æ—¥å¿—
echo "6. æ£€æŸ¥æœ€è¿‘çš„é”™è¯¯æ—¥å¿—..."
kubectl logs -n mystocks-prod deployment/ai-strategy-engine --tail=50 | grep ERROR

# 7. æ£€æŸ¥å­˜å‚¨
echo "7. æ£€æŸ¥å­˜å‚¨çŠ¶æ€..."
kubectl get pv,pvc -n mystocks-prod

# 8. æ£€æŸ¥ç½‘ç»œç­–ç•¥
echo "8. æ£€æŸ¥ç½‘ç»œç­–ç•¥..."
kubectl get networkpolicies -n mystocks-prod

# 9. æ£€æŸ¥PrometheusæŒ‡æ ‡
echo "9. æ£€æŸ¥PrometheusæŒ‡æ ‡..."
curl -s "http://prometheus:9090/api/v1/query?query=up" | jq '.data.result'

# 10. æ£€æŸ¥å‘Šè­¦çŠ¶æ€
echo "10. æ£€æŸ¥å‘Šè­¦çŠ¶æ€..."
curl -s "http://alertmanager:9093/api/v1/alerts" | jq '.data[].status'

echo "=== æ•…éšœæ’æŸ¥å®Œæˆ ==="
```

---

## ğŸ“š æœ€ä½³å®è·µæ€»ç»“

### éƒ¨ç½²æ£€æŸ¥æ¸…å•

- [ ] **ç¯å¢ƒå‡†å¤‡**
  - [ ] Kubernetesé›†ç¾¤è¿è¡Œæ­£å¸¸
  - [ ] NVIDIA GPUèŠ‚ç‚¹é…ç½®å®Œæˆ
  - [ ] å­˜å‚¨ç±»é…ç½®æ­£ç¡®
  - [ ] ç½‘ç»œç­–ç•¥è®¾ç½®å®Œæˆ

- [ ] **å®‰å…¨é…ç½®**
  - [ ] RBACæƒé™é…ç½®æ­£ç¡®
  - [ ] å¯†é’¥ç®¡ç†é…ç½®å®Œæˆ
  - [ ] ç½‘ç»œç­–ç•¥å¯ç”¨
  - [ ] é•œåƒç­¾åéªŒè¯

- [ ] **ç›‘æ§å‘Šè­¦**
  - [ ] Prometheusé…ç½®æ­£ç¡®
  - [ ] Grafanaä»ªè¡¨æ¿éƒ¨ç½²
  - [ ] AlertManagerè§„åˆ™é…ç½®
  - [ ] é€šçŸ¥æ¸ é“æµ‹è¯•

- [ ] **å¤‡ä»½æ¢å¤**
  - [ ] è‡ªåŠ¨å¤‡ä»½è„šæœ¬é…ç½®
  - [ ] æ¢å¤æµç¨‹æµ‹è¯•
  - [ ] ç¾éš¾æ¢å¤è®¡åˆ’æ–‡æ¡£

- [ ] **æ€§èƒ½ä¼˜åŒ–**
  - [ ] GPUå†…å­˜æ± é…ç½®
  - [ ] æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–
  - [ ] ç¼“å­˜ç­–ç•¥é…ç½®
  - [ ] è‡ªåŠ¨æ‰©ç¼©å®¹æµ‹è¯•

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æ›´æ–°æ—¶é—´**: 2025-11-16  
**ç»´æŠ¤è€…**: MyStockså¼€å‘å›¢é˜Ÿ