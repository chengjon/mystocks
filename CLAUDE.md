<!-- OPENSPEC:START -->
# OpenSpec Instructions

These instructions are for AI assistants working in this project.

Always open `@/openspec/AGENTS.md` when the request:
- Mentions planning or proposals (words like proposal, spec, change, plan)
- Introduces new capabilities, breaking changes, architecture shifts, or big performance/security work
- Sounds ambiguous and you need the authoritative spec before coding

Use `@/openspec/AGENTS.md` to learn:
- How to create and apply change proposals
- Spec format and conventions
- Project structure and guidelines

Keep this managed block so 'openspec update' can refresh the instructions.

<!-- OPENSPEC:END -->

# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

**Note**: This file works in conjunction with the project constitution (`.specify/memory/constitution.md`) and the highest guidance document (`é¡¹ç›®å¼€å‘è§„èŒƒä¸æŒ‡å¯¼æ–‡æ¡£.md`) to ensure consistent development practices.

## ğŸ—‚ï¸ é‡å¤§æ›´æ–° (2025-11-09): é¡¹ç›®ç›®å½•é‡ç»„å®Œæˆ

**ç›®å½•ç»“æ„ä¼˜åŒ–**: ä»42ä¸ªæ‚ä¹±çš„æ ¹ç›®å½•ç²¾ç®€åˆ°13ä¸ªç§‘å­¦ç»„ç»‡çš„ç›®å½•

**é‡ç»„æˆæœ**:
- âœ… æ‰€æœ‰æºä»£ç æ•´åˆåˆ° `src/` ç›®å½•
- âœ… æ‰€æœ‰æ–‡æ¡£æ•´åˆåˆ° `docs/` ç›®å½•
- âœ… æ‰€æœ‰è„šæœ¬æ•´åˆåˆ° `scripts/` ç›®å½•
- âœ… ç»Ÿä¸€å¯¼å…¥è·¯å¾„ä¸º `from src.*` æ ¼å¼
- âœ… åˆ›å»º `src/db_manager/` å…¼å®¹å±‚ç¡®ä¿å¹³æ»‘è¿‡æ¸¡
- âœ… Gitå†å²å®Œæ•´ä¿ç•™ (ä½¿ç”¨ `git mv` ç§»åŠ¨æ‰€æœ‰æ–‡ä»¶)
- âœ… ç›®å½•æ··ä¹±åº¦é™ä½ **69%**

**æ–°çš„å¯¼å…¥è·¯å¾„æ ‡å‡†**:
```python
# âœ… æ¨è: æ–°çš„æ ‡å‡†å¯¼å…¥è·¯å¾„
from src.core import ConfigDrivenTableManager, DataClassification
from src.adapters.akshare_adapter import AkshareDataSource
from src.data_access import TDengineDataAccess, PostgreSQLDataAccess
from src.db_manager import DatabaseTableManager  # å…¼å®¹å±‚
from src.monitoring import MonitoringDatabase, AlertManager
from src.interfaces import IDataSource

# âš ï¸ ä»ç„¶æœ‰æ•ˆ: æ—§çš„å¯¼å…¥è·¯å¾„ (é€šè¿‡å…¼å®¹å±‚)
from core import ConfigDrivenTableManager
from db_manager.database_manager import DatabaseTableManager

# âŒ å·²åºŸå¼ƒ: ç›´æ¥ä»æ ¹ç›®å½•å¯¼å…¥æ¨¡å—ç›®å½•
from adapters.akshare_adapter import AkshareDataSource
```

**è„šæœ¬è·¯å¾„æ›´æ–°**:
```bash
# âœ… æ–°è·¯å¾„
python scripts/runtime/system_demo.py
python scripts/tests/test_config_driven_table_manager.py
python scripts/database/check_tdengine_tables.py

# âŒ æ—§è·¯å¾„
python system_demo.py
python test_config_driven_table_manager.py
```

**è¯¦ç»†æŠ¥å‘Š**: å‚è§ [`REORGANIZATION_COMPLETION_REPORT.md`](./REORGANIZATION_COMPLETION_REPORT.md)

**æ ¸å¿ƒåŸåˆ™**: æ¸…æ™°çš„ç›®å½•ç»“æ„ + ç§‘å­¦çš„æ–‡ä»¶åˆ†ç±» + å®Œæ•´çš„Gitå†å²ä¿ç•™

---

## ğŸ“Š Current Development Status (2025-11-22)

### Development Progress Summary

| Phase | Description | Status |
|-------|-------------|--------|
| Phase 1-3 | Core System (ç›‘æ§/æŠ€æœ¯åˆ†æ/å¤šæ•°æ®æº) | âœ… å®Œæˆ |
| Phase 4 | GPU API System (å›æµ‹å¼•æ“/MLæœåŠ¡) | âœ… å®Œæˆ |
| Phase 5 | Backtest Engine (12ä¸ªç­–ç•¥) | âœ… å®Œæˆ |
| Phase 6 | Technical Debt Remediation | âœ… å®Œæˆ |
| Phase 6.4 | GPUåŠ é€Ÿå¼•æ“é›†æˆä¸æµ‹è¯• | âœ… å®Œæˆ (68.58xæ€§èƒ½æå‡) |

### GPUåŠ é€Ÿå¼•æ“å¼€å‘æˆæœ

**Phase 6.4 å®Œæˆæƒ…å†µ**:
- **é›†æˆæµ‹è¯•æˆåŠŸç‡**: 100% (ä»85.7%ä¼˜åŒ–åˆ°100%)
- **å¹³å‡æ€§èƒ½æå‡**: 68.58x
- **çŸ©é˜µè¿ç®—åŠ é€Ÿæ¯”**: 187.35x (æœ€å¤§306.62x)
- **å†…å­˜æ“ä½œåŠ é€Ÿæ¯”**: 82.53x (æœ€å¤§372.72x)
- **å³°å€¼æ€§èƒ½**: 662.52 GFLOPS
- **é•¿æœŸç¨³å®šæ€§**: 83.3%æˆåŠŸç‡ï¼Œ100%å¹¶å‘å®‰å…¨

**å…³é”®æŠ€æœ¯çªç ´**:
- **HALå±‚æ¶æ„**: 4å±‚æŠ½è±¡è®¾è®¡ï¼Œç­–ç•¥éš”ç¦»ï¼Œæ•…éšœå®¹ç¾
- **ç®—æ³•ä¼˜åŒ–**: Strassenç®—æ³•(O(n^2.807))ï¼Œåˆ†å—çŸ©é˜µä¹˜æ³•ï¼ŒCUDAæµå¹¶è¡Œ
- **å†…å­˜ç®¡ç†**: æ™ºèƒ½å†…å­˜æ± ï¼Œ100%å‘½ä¸­ç‡ï¼Œè‡ªåŠ¨æ¸…ç†æœºåˆ¶
- **æ ‡å‡†åŒ–æ¥å£**: GPU/CPUå›é€€æœºåˆ¶ï¼Œç”Ÿäº§çº§ç¨³å®šæ€§ä¿éšœ

**æ–‡æ¡£ä¸ç»éªŒ**: å®Œæ•´çš„å¼€å‘ç»éªŒå·²è®°å½•åœ¨ [`docs/api/GPUå¼€å‘ç»éªŒæ€»ç»“.md`](./docs/api/GPUå¼€å‘ç»éªŒæ€»ç»“.md)

### Technical Debt Status (æŠ€æœ¯å€ºåŠ¡ç°çŠ¶)

**ä»£ç è´¨é‡æŒ‡æ ‡** (Pylint Analysis):
- Errors: 215 (ä¸¥é‡é—®é¢˜ï¼Œéœ€ä¼˜å…ˆä¿®å¤)
- Warnings: 2,606 (æ½œåœ¨é—®é¢˜)
- Refactoring: 571 (éœ€è¦é‡æ„)
- Convention: 1,858 (ä»£ç é£æ ¼)

**æµ‹è¯•è¦†ç›–ç‡ç›®æ ‡**:
- å½“å‰è¦†ç›–ç‡: ~6% â†’ **ç›®æ ‡: 80%**
- å•å…ƒæµ‹è¯•: 459ä¸ª (éƒ¨åˆ†å¤±è´¥)
- data_accesså±‚: PostgreSQL 67%, TDengine 56%

**ä¿®å¤è®¡åˆ’**:
1. âœ… Phase 1: é…ç½® `.pylintrc` å’Œ `.pre-commit-config.yaml`
2. ğŸ”„ Phase 2: æå‡æµ‹è¯•è¦†ç›–ç‡ (è¿›è¡Œä¸­)
3. â³ Phase 3: é‡æ„é«˜å¤æ‚åº¦æ–¹æ³•

### Python ä»£ç è´¨é‡ä¿è¯å·¥å…· (2025-12-23 æ›´æ–°)

**ä¼˜åŒ–ç­–ç•¥**: Ruff ä¼˜å…ˆ + Black å…œåº• + Pylint æ·±åº¦å®¡æŸ¥

**ç»Ÿä¸€é…ç½®**: æ‰€æœ‰å·¥å…·è¡Œé•¿åº¦ 120 å­—ç¬¦

**å·¥å…·ç‰ˆæœ¬**:
- Ruff: 0.9.10 (æ—¥å¸¸å¼€å‘ - æ•ˆç‡ä¼˜å…ˆ)
- Black: 25.11.0 (æ ¼å¼åŒ–å…œåº•)
- Pylint: 4.0.3 (æ·±åº¦è´¨é‡åˆ†æ)
- MyPy: (åœ¨ dev ä¾èµ–ä¸­)
- Bandit: 1.7.5+ (å®‰å…¨æ‰«æ)
- Safety: 2.3.0+ (ä¾èµ–å®‰å…¨)

#### å››é˜¶æ®µè´¨é‡ä¿è¯æµç¨‹

**é˜¶æ®µ 1: æ—¥å¸¸å¼€å‘** (æ•ˆç‡ä¼˜å…ˆ)
- **å·¥å…·**: Ruff (ä¸€ç«™å¼æ ¼å¼åŒ– + Lint)
- **è§¦å‘æ—¶æœº**: æ¯æ¬¡ä¿å­˜æ–‡ä»¶å
- **å‘½ä»¤**: `ruff check --fix .`
- **ç‰¹ç‚¹**:
  - æµ‹è¯•ä¸“å±è§„åˆ™ (PT: pytest ä¸“å±è§„åˆ™)
  - å¿«é€Ÿå¤±è´¥: ä»…æ£€æŸ¥å½±å“æµ‹è¯•æ‰§è¡Œçš„é—®é¢˜
  - è‡ªåŠ¨ä¿®å¤: å¤§éƒ¨åˆ†é—®é¢˜å¯è‡ªåŠ¨ä¿®å¤

**é˜¶æ®µ 2: æäº¤å‰æ£€æŸ¥** (æ ¼å¼å…œåº• + æ ¸å¿ƒæ£€æŸ¥)
- **å·¥å…·**: Pre-commit Hooks (è‡ªåŠ¨è§¦å‘)
- **è§¦å‘æ—¶æœº**: æ¯æ¬¡ `git commit` æ—¶è‡ªåŠ¨è¿è¡Œ
- **æ‰§è¡Œé¡ºåº** (9 ä¸ªæ­¥éª¤):
  1. Ruff (Lint & Fix) - å¿«é€Ÿä¿®å¤é”™è¯¯å‹é—®é¢˜
  2. Black (Formatter) - ç»Ÿä¸€ä»£ç é£æ ¼ (1-2ç§’)
  3. Ruff (Check only) - äºŒæ¬¡æ ¡éªŒï¼Œç¡®ä¿æ— æ–°é—®é¢˜
  4. MyPy - ç±»å‹æ£€æŸ¥
  5. Bandit - å®‰å…¨æ‰«æ
  6. Safety - ä¾èµ–å®‰å…¨æ£€æŸ¥
  7-9. é€šç”¨æ–‡ä»¶æ£€æŸ¥ã€å¯†é’¥æ£€æµ‹ã€Python è¯­æ³•æ£€æŸ¥
- **å‘½ä»¤**: `pre-commit run --all-files`

**é˜¶æ®µ 3: å®šæœŸæ·±åº¦åˆ†æ** (Pylint æ ¸å¿ƒä»·å€¼)
- **å·¥å…·**: Pylint (æµ‹è¯•ä»£ç ä¸“ç”¨é…ç½®)
- **è§¦å‘æ—¶æœº**: æ¯å‘¨ / æ¯è¿­ä»£æœ«
- **å‘½ä»¤**: `pylint --rcfile=.pylint.test.rc tests/`
- **ç‰¹ç‚¹**:
  - æµ‹è¯•ä¸“ç”¨è§„åˆ™ (`.pylint.test.rc`)
  - ç¦ç”¨æ‰€æœ‰ï¼Œå¯ç”¨æ ¸å¿ƒè§„åˆ™
  - æ›´å®½æ¾çš„å¤æ‚åº¦é˜ˆå€¼ (max-args=15, max-locals=25)
  - pytest ä¸“å±è§„åˆ™ (PT001-PT025)
  - ç”Ÿæˆ HTML æŠ¥å‘Š

**é˜¶æ®µ 4: CI/CD é›†æˆ** (å¿«é€Ÿå¤±è´¥ + å®Œæ•´æ£€æŸ¥)
- **å·¥å…·é¡ºåº**: Ruff+Black â†’ MyPy+Bandit+Safety â†’ Pylint (ä»…è®°å½•)
- **ç­–ç•¥**:
  - Ruff/Black é—®é¢˜ç›´æ¥å¤±è´¥ (å¿«é€Ÿå¤±è´¥)
  - MyPy/Bandit/Safety é—®é¢˜å¿…é¡»ä¿®å¤ (æ ¸å¿ƒæ£€æŸ¥)
  - Pylint ä»…ç”ŸæˆæŠ¥å‘Šï¼Œä¸é˜»æ–­æ„å»º (è®°å½•åˆ†æ)

#### å…³é”®é…ç½®æ–‡ä»¶

| é…ç½®æ–‡ä»¶ | ç”¨é€” | ä½ç½® |
|----------|------|------|
| `pyproject.toml` | Ruff, Black, MyPy, Pylint (å¸¸è§„) | é¡¹ç›®æ ¹ç›®å½• |
| `.pylint.test.rc` | Pylint (æµ‹è¯•ä¸“ç”¨) | é¡¹ç›®æ ¹ç›®å½• |
| `.pre-commit-config.yaml` | Pre-commit hooks | é¡¹ç›®æ ¹ç›®å½• |
| `config/.security.yml` | å®‰å…¨é…ç½® | `config/` ç›®å½• |

#### å¿«é€Ÿå¼€å§‹

**é¦–æ¬¡è®¾ç½®**:
```bash
# å®‰è£…å¼€å‘ä¾èµ–
pip install -e ".[dev]"

# å®‰è£… pre-commit hooks
pre-commit install

# (å¯é€‰) å®‰è£… pylint-pytest æ’ä»¶
pip install pylint-pytest

# éªŒè¯å®‰è£…
ruff --version && black --version && pylint --version
```

**æ—¥å¸¸ä½¿ç”¨**:
```bash
# æ—¥å¸¸å¼€å‘: ä¸€é”®ä¿®å¤
ruff check --fix .

# æäº¤ä»£ç : è‡ªåŠ¨è¿è¡Œ 9 æ­¥æ£€æŸ¥
git add . && git commit -m "message"

# æ¯å‘¨åˆ†æ: ç”Ÿæˆè´¨é‡æŠ¥å‘Š
pylint --rcfile=.pylint.test.rc --output=report.html --output-format=html tests/
```

#### å·¥ä½œæµç¨‹å›¾

```
å¼€å‘ä»£ç  â†’ ruff check --fix . â†’ ä¿å­˜
    â†“
git add â†’ git commit â†’ pre-commit hooks è‡ªåŠ¨è¿è¡Œ
    â†“
    â”œâ”€ Ruff (fix) â†’ Black â†’ Ruff (check) â†’ MyPy â†’ Bandit â†’ Safety
    â””â”€ é€šç”¨æ–‡ä»¶æ£€æŸ¥ã€å¯†é’¥æ£€æµ‹ã€Pythonè¯­æ³•æ£€æŸ¥
    â†“
æäº¤æˆåŠŸ â†’ æ¨é€åˆ°è¿œç¨‹ â†’ CI/CD è¿è¡Œ
    â†“
æ¯å‘¨æœ« â†’ pylint --rcfile=.pylint.test.rc tests/ â†’ ç”ŸæˆæŠ¥å‘Š
```

#### è¯¦ç»†æ–‡æ¡£

å®Œæ•´çš„ Python ä»£ç è´¨é‡ä¿è¯å·¥ä½œæµç¨‹è¯·å‚é˜…:
- **å®Œæ•´å·¥ä½œæµç¨‹**: `docs/guides/PYTHON_QUALITY_ASSURANCE_WORKFLOW.md`
- **å¿«é€Ÿå‚è€ƒ**: `docs/guides/PYTHON_QUALITY_TOOLS_QUICK_REFERENCE.md`
- **å®æ–½æ€»ç»“**: `docs/guides/PYTHON_QUALITY_TOOLS_IMPLEMENTATION_SUMMARY.md`

#### æ ¸å¿ƒåŸåˆ™

1. **Ruff ä¼˜å…ˆ** - æ—¥å¸¸å¼€å‘å¿«é€Ÿä¿®å¤
2. **Black å…œåº•** - ç¡®ä¿æ ¼å¼ç»Ÿä¸€
3. **Pylint æ·±åº¦** - å®šæœŸè´¨é‡åˆ†æ
4. **å®‰å…¨å¿…ä¿** - Bandit + Safety ä¸å¯æ›¿ä»£
5. **ç»Ÿä¸€é…ç½®** - æ‰€æœ‰å·¥å…·è¡Œé•¿åº¦ 120

**ä¼˜åŒ–æˆæœ**:
- âœ… æ—¥å¸¸å¼€å‘æ•ˆç‡æå‡: Ruff ä¸€ç«™å¼å¤„ç†
- âœ… æäº¤å‰è‡ªåŠ¨åŒ–: Pre-commit 9 æ­¥æ£€æŸ¥ (1-2 åˆ†é’Ÿ)
- âœ… æ·±åº¦è´¨é‡åˆ†æ: Pylint æ¯å‘¨/æ¯è¿­ä»£æœ«
- âœ… CI/CD ä¼˜åŒ–: å¿«é€Ÿå¤±è´¥ + è®°å½•æŠ¥å‘Š

### Core Architecture (æ ¸å¿ƒæ¶æ„)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MyStocks Unified Manager                 â”‚
â”‚              (ç»Ÿä¸€æ•°æ®è®¿é—®å’Œè·¯ç”±å…¥å£ç‚¹)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Adapters   â”‚    â”‚    Core     â”‚    â”‚  Monitoring â”‚     â”‚
â”‚  â”‚  (7ä¸ª)      â”‚    â”‚  (åˆ†ç±»/è·¯ç”±) â”‚    â”‚  (ç›‘æ§/å‘Šè­¦) â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                  â”‚                  â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚              Data Access Layer                     â”‚     â”‚
â”‚  â”‚         (TDengineAccess / PostgreSQLAccess)        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                         â”‚                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚              Storage Layer                   â”‚           â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚           â”‚
â”‚  â”‚  â”‚    TDengine     â”‚  â”‚   PostgreSQL    â”‚   â”‚           â”‚
â”‚  â”‚  â”‚  (é«˜é¢‘æ—¶åºæ•°æ®)   â”‚  â”‚  (æ‰€æœ‰å…¶ä»–æ•°æ®)  â”‚   â”‚           â”‚
â”‚  â”‚  â”‚  Tick/åˆ†é’ŸKçº¿    â”‚  â”‚  æ—¥çº¿/å‚è€ƒ/äº¤æ˜“  â”‚   â”‚           â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Dependencies (ä¸»è¦ä¾èµ–)

**æ ¸å¿ƒæ¡†æ¶**:
- Python 3.12+ / FastAPI 0.114+ / Vue 3.4+
- pandas 2.0+ / numpy 1.24+ / pydantic 2.0+

**æ•°æ®åº“**:
- TDengine 3.3+ (é«˜é¢‘æ—¶åº) / PostgreSQL 17+ (é€šç”¨å­˜å‚¨)
- TimescaleDB 2.x (æ—¶åºæ‰©å±•)

**GPUåŠ é€Ÿ** (å¯é€‰):
- CUDA 12.x / cuDF 25.10+ / cuML 25.10+ / CuPy 13.6+

**GPUåŠ é€Ÿå¼•æ“å¼€å‘ç»éªŒ**: è¯¦ç»†çš„GPUå¼€å‘ç»éªŒã€é—®é¢˜è§£å†³æ–¹æ¡ˆå’Œæœ€ä½³å®è·µè¯·å‚è€ƒ [`docs/api/GPUå¼€å‘ç»éªŒæ€»ç»“.md`](./docs/api/GPUå¼€å‘ç»éªŒæ€»ç»“.md)

**æ•°æ®æº**:
- akshare / baostock / tushare / efinance

---

## âš¡ Week 3 Update (2025-10-19): Database Simplification

**Major Change**: System simplified from 4 databases to 2 (TDengine + PostgreSQL)

**Migration Completed**:
- âœ… MySQL data migrated to PostgreSQL (18 tables, 299 rows)
- âœ… Redis removed (configured db1 was empty)
- âœ… Architecture complexity reduced by 50%
- âœ… **TDengine retained**: Specialized for high-frequency time-series market data
- âœ… **PostgreSQL**: Handles all other data types with TimescaleDB extension

**New Configuration**: See `.env` for 2-database setup (TDengine + PostgreSQL).

**Philosophy**: Right Tool for Right Job, Simplicity > Unnecessary Complexity

---

## Project Overview

MyStocks is a professional quantitative trading data management system that uses a **dual-database architecture** optimized for different data characteristics. The system is built on adapter and factory patterns to provide unified data access layers with configuration-driven automation.

**Current Architecture** (Post-Week 3):
- **TDengine**: High-frequency time-series market data (tick/minute data) with extreme compression
- **PostgreSQL + TimescaleDB**: All other data types (daily bars, reference data, derived data, metadata)
- **GPUåŠ é€Ÿå¼•æ“**: é«˜æ€§èƒ½çŸ©é˜µè¿ç®—å’Œç®—æ³•åŠ é€Ÿï¼Œå®ç°68.58xå¹³å‡æ€§èƒ½æå‡
- **Optimized Operations**: Right database for right workload, reduced unnecessary complexity

## Common Development Commands

### Environment Setup
```bash
# Install dependencies (dual-database setup)
pip install pandas numpy pyyaml psycopg2-binary taospy akshare

# Create .env file with database configuration
# Required environment variables for 2-database architecture:
# TDengine (high-frequency time-series data):
# - TDENGINE_HOST, TDENGINE_PORT, TDENGINE_USER, TDENGINE_PASSWORD, TDENGINE_DATABASE
# PostgreSQL (all other data):
# - POSTGRESQL_HOST, POSTGRESQL_USER, POSTGRESQL_PASSWORD, POSTGRESQL_PORT, POSTGRESQL_DATABASE
# - MONITOR_DB_URL (uses PostgreSQL for monitoring database)

# Note: MySQL (pymysql) and Redis removed after Week 3 simplification

# JWT Authentication Configuration
# - JWT_SECRET_KEY (required for API authentication)
# Use the provided script to generate and set up JWT key:
# bash scripts/JWT_key_update.sh
```

### JWT å¯†é’¥é…ç½® (JWT_SECRET_KEY)

**é—®é¢˜æè¿°**: å¦‚æœå¯åŠ¨åç«¯æœåŠ¡æ—¶å‡ºç° `JWT_SECRET_KEY` é…ç½®é”™è¯¯ï¼Œéœ€è¦è®¾ç½® JWT å¯†é’¥ã€‚

**è§£å†³æ–¹æ¡ˆ - è‡ªåŠ¨åŒ–è„šæœ¬ (æ¨è)**:
```bash
# è¿è¡Œè‡ªåŠ¨åŒ–è„šæœ¬ï¼Œè‡ªåŠ¨ç”Ÿæˆå¹¶é…ç½® JWT_SECRET_KEY
bash scripts/JWT_key_update.sh
```

**è§£å†³æ–¹æ¡ˆ - æ‰‹åŠ¨é…ç½®**:
```bash
# æ–¹æ³•1: ä½¿ç”¨ Python ç”Ÿæˆå¯†é’¥
python3 -c "import secrets; print(secrets.token_urlsafe(32))"

# æ–¹æ³•2: ä½¿ç”¨ OpenSSL ç”Ÿæˆå¯†é’¥ (æ¨è)
openssl rand -hex 32

# ç„¶åå°†ç”Ÿæˆçš„å¯†é’¥æ·»åŠ åˆ° .env æ–‡ä»¶:
# echo "JWT_SECRET_KEY=<ç”Ÿæˆçš„å¯†é’¥>" >> .env
```

**ç›¸å…³æ–‡ä»¶**:
- é…ç½®è„šæœ¬: `scripts/JWT_key_update.sh` - è‡ªåŠ¨åŒ– JWT å¯†é’¥é…ç½®å’ŒæœåŠ¡é‡å¯
- é…ç½®æ¨¡æ¿: `.env.example` - åŒ…å«æ‰€æœ‰å¿…éœ€çš„ç¯å¢ƒå˜é‡
- é…ç½®æ–‡æ¡£: `docs/standards/LOCAL_ENV_SETUP.md` - ç¯å¢ƒé…ç½®å®Œæ•´æŒ‡å—
- å®‰å…¨æŒ‡å—: `docs/guides/PHASE0_CREDENTIAL_ROTATION_GUIDE.md` - å‡­è¯è½®æ¢æŒ‡å—

**åç«¯é…ç½®å®ç°** (`web/backend/app/core/config.py`):
```python
# JWT è®¤è¯é…ç½®å­—æ®µ
jwt_secret_key: str = Field(default="", env="JWT_SECRET_KEY")

# å‘åå…¼å®¹å±æ€§
@property
def secret_key(self) -> str:
    return self.jwt_secret_key
```

**æ³¨æ„**: Pydantic-Settings v2 ä¸­ï¼Œå­—æ®µå `jwt_secret_key` åœ¨ `case_sensitive=False` æ—¶ä¼šè‡ªåŠ¨æ˜ å°„åˆ° `JWT_SECRET_KEY` ç¯å¢ƒå˜é‡ã€‚

---

### System Initialization and Management
```bash
# Initialize the complete system
python -c "from unified_manager import MyStocksUnifiedManager; manager = MyStocksUnifiedManager(); manager.initialize_system()"

# Run system demonstration
python scripts/runtime/system_demo.py

# Validate database connections and table structures
python -c "from core import ConfigDrivenTableManager; mgr = ConfigDrivenTableManager(); mgr.validate_all_table_structures()"

# Run realtime market data saver
python scripts/runtime/run_realtime_market_saver.py

# Check database connections (TDengine + PostgreSQL)
python scripts/database/check_tdengine_tables.py
python scripts/database/verify_tdengine_deployment.py
```

### Testing
```bash
# Test unified manager functionality
python scripts/tests/test_config_driven_table_manager.py

# Test financial adapter
python scripts/tests/test_financial_adapter.py

# Test dual database architecture
python scripts/tests/test_dual_database_architecture.py

# Test realtime data functionality
python scripts/tests/test_save_realtime_data.py

# Test TDX adapter
python scripts/tests/test_tdx_mvp.py

# Test GPU acceleration engine (if available)
python test_gpu_integration.py
python test_performance_comparison.py
python test_long_term_stability.py
```

### Configuration Management
```bash
# View current table configuration
python -c "
import yaml
with open('table_config.yaml', 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)
print(f'Configuration version: {config.get(\"version\", \"unknown\")}')
print(f'Tables configured: {len(config.get(\"tables\", []))}')
"

# Create tables from configuration
python -c "from db_manager.database_manager import DatabaseTableManager; mgr = DatabaseTableManager(); mgr.batch_create_tables('table_config.yaml')"
```

## High-Level Architecture

### Mockæ•°æ®ä½¿ç”¨è§„åˆ™ (é‡è¦)

**æ ¸å¿ƒåŸåˆ™**: æ‰€æœ‰æ¨¡æ‹Ÿæ•°æ®å¿…é¡»é€šè¿‡ Mock æ•°æ®æ¨¡å—æä¾›ï¼Œ**ä¸¥ç¦åœ¨ä¸šåŠ¡ä»£ç ä¸­ç›´æ¥ç¡¬ç¼–ç æ•°æ®**ã€‚

è¯¦ç»†è§„åˆ™è¯·å‚é˜…: [`docs/guides/MOCK_DATA_USAGE_RULES.md`](./guides/MOCK_DATA_USAGE_RULES.md)

**å¿«é€Ÿå‚è€ƒ**:
```python
# âœ… æ­£ç¡®: é€šè¿‡å·¥å‚å‡½æ•°è·å–Mockæ•°æ®
from src.data_sources.factory import get_timeseries_source
source = get_timeseries_source(source_type="mock")
data = source.get_kline_data(symbol, start_time, end_time, interval)

# âŒ é”™è¯¯: ç›´æ¥ç¡¬ç¼–ç æ•°æ®
historical_data = [
    {"date": "2025-01-01", "close": 10.5},  # ä¸¥ç¦!
]
```

**ä¸»è¦Mockæ¨¡å—**:
- `src/data_sources/factory.py` - æ•°æ®æºå·¥å‚å…¥å£
- `src/data_sources/mock/timeseries_mock.py` - æ—¶åºæ•°æ®
- `src/data_sources/mock/relational_mock.py` - å…³ç³»æ•°æ®
- `src/data_sources/mock/business_mock.py` - ä¸šåŠ¡æ•°æ®
- `src/mock/` - é¡µé¢çº§Mockæ•°æ®

---

### Core Design Principles

1. **Dual-Database Data Storage** (Week 3+): Right database for right workload
   - **High-Frequency Market Data** (é«˜é¢‘æ—¶åºæ•°æ®): Tick/minute data â†’ **TDengine** (extreme compression, ultra-high write performance)
   - **Daily Market Data** (æ—¥çº¿æ•°æ®): Daily bars, historical data â†’ **PostgreSQL TimescaleDB** hypertables
   - **Reference Data** (å‚è€ƒæ•°æ®): Relatively static descriptive data â†’ **PostgreSQL** standard tables
   - **Derived Data** (è¡ç”Ÿæ•°æ®): Computed analytical results â†’ **PostgreSQL** standard tables
   - **Transaction Data** (äº¤æ˜“æ•°æ®): Orders, positions, portfolios â†’ **PostgreSQL** standard tables
   - **Meta Data** (å…ƒæ•°æ®): System configuration and metadata â†’ **PostgreSQL** standard tables

2. **Optimized Architecture** (Post-Week 3): 2-database strategy balances performance and simplicity
   - **TDengine database**: `market_data` (è¶…è¡¨: tick_data, minute_data)
   - **PostgreSQL database**: `mystocks` (æ‰€æœ‰å…¶ä»–è¡¨ + TimescaleDBæ··åˆè¡¨)
   - Unified access layer abstracts database differences
   - Monitoring database in PostgreSQL tracks all operations

3. **Configuration-Driven Management**: All table structures managed through YAML configuration
   - `table_config.yaml` defines complete table schemas
   - `ConfigDrivenTableManager` automates table creation and validation

4. **Complete Monitoring Integration**: Separate monitoring database tracks all operations
   - `MonitoringDatabase` logs all operations independent of business databases
   - `PerformanceMonitor` tracks query performance and alerts on slow operations
   - `DataQualityMonitor` ensures data completeness, freshness, and accuracy

### Key Components (é‡ç»„åçš„æ¨¡å—è·¯å¾„)

#### Core Management Layer (`src/core/`)
**ä½ç½®**: `src/core/` ç›®å½•
- `DataClassification`: 5å¤§æ•°æ®åˆ†ç±»æšä¸¾å®šä¹‰
- `DatabaseTarget`: æ”¯æŒçš„æ•°æ®åº“ç±»å‹ (**TDengine**, **PostgreSQL**)
- `DataStorageStrategy`: æ™ºèƒ½è·¯ç”±é€»è¾‘,è‡ªåŠ¨æ˜ å°„æ•°æ®ç±»å‹åˆ°æœ€ä¼˜æ•°æ®åº“
- `ConfigDrivenTableManager`: YAMLé…ç½®é©±åŠ¨çš„è¡¨ç®¡ç†å™¨

**å¯¼å…¥**:
```python
from src.core import ConfigDrivenTableManager, DataClassification
from src.core.data_storage_strategy import DataStorageStrategy
```

#### Unified Access Layer (`src/core/` - unified_manager)
**ä½ç½®**: `src/core/unified_manager.py` + æ ¹ç›®å½• `unified_manager.py` (å…¥å£ç‚¹)
- `MyStocksUnifiedManager`: æ‰€æœ‰æ•°æ®æ“ä½œçš„ç»Ÿä¸€å…¥å£ç‚¹
- `AutomatedMaintenanceManager`: å®šæ—¶ç»´æŠ¤å’Œå¥åº·æ£€æŸ¥
- è‡ªåŠ¨è·¯ç”±æ–¹æ³•: `save_data_by_classification()` å’Œ `load_data_by_classification()`

**å¯¼å…¥**:
```python
from unified_manager import MyStocksUnifiedManager  # é€šè¿‡æ ¹ç›®å½•å…¥å£ç‚¹
# æˆ–
from src.core.unified_manager import MyStocksUnifiedManager  # ç›´æ¥å¯¼å…¥
```

#### Database Access Layer (`src/data_access/`)
**ä½ç½®**: `src/data_access/` ç›®å½•
- `TDengineDataAccess`: é«˜é¢‘æ—¶åºæ•°æ®è®¿é—® (tick, åˆ†é’ŸKçº¿)
- `PostgreSQLDataAccess`: æ‰€æœ‰å…¶ä»–æ•°æ®è®¿é—® (æ—¥çº¿ã€æŒ‡æ ‡ã€å‚è€ƒæ•°æ®ã€å…ƒæ•°æ®)

**å¯¼å…¥**:
```python
from src.data_access import TDengineDataAccess, PostgreSQLDataAccess
```

#### Data Source Adapters (`src/adapters/`)
**ä½ç½®**: `src/adapters/` ç›®å½• (7ä¸ªæ ¸å¿ƒé€‚é…å™¨)
- ç»Ÿä¸€æ¥å£ `IDataSource` å®šä¹‰äº `src/interfaces/data_source.py`
- `AkshareDataSource`: Akshareä¸­å›½å¸‚åœºæ•°æ®
- `BaostockDataSource`: Baostockå†å²æ•°æ®
- `FinancialDataSource`: è´¢åŠ¡æŠ¥è¡¨å’ŒåŸºæœ¬é¢æ•°æ®
- `TdxDataSource`: é€šè¾¾ä¿¡ç›´è¿æ•°æ®æº
- `ByapiDataSource`: REST APIæ•°æ®æº
- `CustomerDataSource`: å®æ—¶è¡Œæƒ…æ•°æ®æº
- `TushareDataSource`: Tushareä¸“ä¸šæ•°æ®æº

**å¯¼å…¥**:
```python
from src.adapters.akshare_adapter import AkshareDataSource
from src.adapters.tdx_adapter import TdxDataSource
from src.interfaces import IDataSource
```

#### Database Infrastructure (`src/storage/database/` + å…¼å®¹å±‚ `src/db_manager/`)
**å®é™…ä½ç½®**: `src/storage/database/` ç›®å½•
**å…¼å®¹å±‚**: `src/db_manager/` (é‡å¯¼å‡º `src.storage.database` çš„æ‰€æœ‰ç±»)

- `DatabaseTableManager`: åŒæ•°æ®åº“è¿æ¥å’Œè¡¨ç®¡ç†
- `DatabaseConnectionManager`: æ•°æ®åº“è¿æ¥æ± ç®¡ç†
- æ”¯æŒ **TDengine** (WebSocket/Native) å’Œ **PostgreSQL** (TimescaleDBæ‰©å±•)
- ç¯å¢ƒå˜é‡é©±åŠ¨é…ç½®,ç¡®ä¿å®‰å…¨æ€§

**å¯¼å…¥** (ä¸¤ç§æ–¹å¼å‡å¯):
```python
# æ–¹å¼1: é€šè¿‡å…¼å®¹å±‚ (æ—§ä»£ç å¯ç»§ç»­ä½¿ç”¨)
from src.db_manager import DatabaseTableManager, DatabaseConnectionManager

# æ–¹å¼2: ç›´æ¥å¯¼å…¥ (æ¨è)
from src.storage.database import DatabaseTableManager, DatabaseConnectionManager
```

#### Monitoring and Quality (`src/monitoring/`)
**ä½ç½®**: `src/monitoring/` ç›®å½•
- `MonitoringDatabase`: ç‹¬ç«‹ç›‘æ§æ•°æ®åº“
- `DataQualityMonitor`: æ•°æ®å®Œæ•´æ€§ã€å‡†ç¡®æ€§ã€æ–°é²œåº¦æ£€æŸ¥
- `PerformanceMonitor`: æŸ¥è¯¢æ€§èƒ½è·Ÿè¸ªå’Œæ…¢æŸ¥è¯¢æ£€æµ‹
- `AlertManager`: å¤šæ¸ é“å‘Šè­¦ (é‚®ä»¶ã€Webhookã€æ—¥å¿—)

**å¯¼å…¥**:
```python
from src.monitoring import MonitoringDatabase, DataQualityMonitor
from src.monitoring import PerformanceMonitor, AlertManager
```

#### GPU Acceleration Engine (`src/gpu/`)
**ä½ç½®**: `src/gpu/` ç›®å½•
- **Hardware Abstraction Layer (HAL)**: `src/gpu/core/hardware_abstraction/`
  - `GPUResourceManager`: GPUèµ„æºç®¡ç†å™¨ï¼Œç­–ç•¥éš”ç¦»å’Œæ•…éšœå®¹ç¾
  - `StrategyGPUContext`: ç­–ç•¥GPUä¸Šä¸‹æ–‡ç®¡ç†
  - `MemoryPool`: æ™ºèƒ½å†…å­˜æ± ç®¡ç†ï¼Œ100%å‘½ä¸­ç‡
- **Kernel Layer**: `src/gpu/core/kernels/`
  - `MatrixKernelEngine`: çŸ©é˜µè¿ç®—å¼•æ“ï¼Œæ”¯æŒStrassenç®—æ³•å’Œåˆ†å—ä¼˜åŒ–
  - `TransformKernelEngine`: æ•°æ®å˜æ¢å¼•æ“ï¼Œæ”¯æŒFFTç­‰ç®—æ³•
  - `StandardizedKernelInterface`: æ ‡å‡†åŒ–å†…æ ¸æ¥å£ï¼Œæ”¯æŒGPU/CPUå›é€€
- **API System**: `src/gpu/api_system/`
  - `gpu_api_server`: GPUåŠ é€ŸAPIæœåŠ¡å™¨
  - é›†æˆæµ‹è¯•å’Œæ€§èƒ½ç›‘æ§

**æ ¸å¿ƒæˆå°±**:
- **68.58xå¹³å‡æ€§èƒ½æå‡**ï¼ŒçŸ©é˜µè¿ç®—æœ€é«˜187.35xåŠ é€Ÿæ¯”
- **662+ GFLOPSå³°å€¼æ€§èƒ½**ï¼Œ100%é›†æˆæµ‹è¯•é€šè¿‡ç‡
- **ç”Ÿäº§çº§ç¨³å®šæ€§**ï¼Œé•¿æœŸè¿è¡ŒéªŒè¯å’Œæ•…éšœå®¹ç¾æœºåˆ¶

**å¯¼å…¥**:
```python
from src.gpu.core.hardware_abstraction.resource_manager import GPUResourceManager
from src.gpu.core.kernels.matrix_kernels import MatrixKernelEngine
from src.gpu.core.kernels.standardized_interface import StandardizedKernelInterface
```

### Data Flow Architecture

1. **Data Ingestion**: External adapters â†’ Unified Manager â†’ Auto-routing
2. **Storage Strategy**: Classification determines optimal database automatically
3. **Access Pattern**: Unified interface regardless of underlying database
4. **Monitoring**: All operations logged to separate monitoring database
5. **Quality Assurance**: Automated data quality checks and alerts

### Database Specialization Strategy

- **TDengine**: Extreme compression (20:1 ratio), ultra-high write performance for high-frequency market data (tick/minute)
  - Native time-series database optimized for IoT and financial data
  - Automatic data retention policies
  - Superior performance for time-range queries on tick data

- **PostgreSQL + TimescaleDB**: Robust relational database with time-series optimization
  - ACID compliance for all transactional data
  - Complex JOIN operations on reference and derived data
  - TimescaleDB hypertables for daily market data
  - Full-text search and advanced indexing

## Important Implementation Notes

### Configuration Management
- All database connections configured via environment variables (never hardcode credentials)
- `table_config.yaml` contains complete table schemas with support for all database types
- Tables auto-created on system initialization via `ConfigDrivenTableManager`

### Data Operations
- Always use `MyStocksUnifiedManager` as the primary entry point
- Classification-based methods: `save_data_by_classification()`, `load_data_by_classification()`
- System automatically selects optimal database based on data classification

### Error Handling and Monitoring
- All operations automatically logged to monitoring database
- Performance metrics tracked and slow operations flagged
- Data quality checks run automatically with configurable thresholds

### Testing and Validation
- Use `system_demo.py` for comprehensive system testing
- Individual component tests available in `test_*.py` files
- Database validation available via `check_*_tables.py` scripts

### Dual-Database Support
- **TDengine** for high-frequency time-series data (tick, minute bars)
- **PostgreSQL** for all other data types (daily bars, reference, metadata)
- Unified access layer abstracts database differences
- Seamless connection management and automatic routing

This architecture enables efficient handling of quantitative trading data by using the right database for each workload, with comprehensive monitoring and configuration-driven automation.

## File Organization Rules

**Philosophy**: Maintain a clean, minimal root directory with logical categorization by functionality. Every file should have a clear, rule-based location.

**ä»£ç å¤§å°ä¼˜åŒ–è§„èŒƒ**: ä¸ºäº†ä¿è¯ä»£ç çš„å¯ç»´æŠ¤æ€§å’Œå¯è¯»æ€§ï¼Œå¼ºçƒˆå»ºè®®éµå¾ª[ã€Šä»£ç æ–‡ä»¶é•¿åº¦ä¼˜åŒ–è§„èŒƒã€‹](./CODE_SIZE_OPTIMIZATION_REPORT.md)ã€‚è¯¥è§„èŒƒè¦æ±‚ï¼š

1. **ä»£ç æ–‡ä»¶é•¿åº¦é™åˆ¶**: å•ä¸ªPythonæ–‡ä»¶åº”æ§åˆ¶åœ¨2000è¡Œä»¥å†…ï¼Œå¤§äºæ­¤é™åˆ¶çš„æ–‡ä»¶éœ€è¦è¿›è¡Œæ¨¡å—åŒ–æ‹†åˆ†
2. **æ¨¡å—åŒ–æ‹†åˆ†åŸåˆ™**: å°†å¤§æ–‡ä»¶æŒ‰ç…§åŠŸèƒ½æ‹†åˆ†ä¸ºå¤šä¸ªå°æ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶ä¸“æ³¨äºç‰¹å®šåŠŸèƒ½
3. **å‘åå…¼å®¹æ€§**: æ‹†åˆ†åçš„ä»£ç åº”ä¿æŒåŸæœ‰çš„å¯¼å…¥è·¯å¾„ä¸å˜ï¼Œç¡®ä¿ç°æœ‰ä»£ç å¯ä»¥æ­£å¸¸å·¥ä½œ
4. **æ’é™¤ç›®å½•**: tempç›®å½•åŠå…¶å­ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ä¸çº³å…¥é•¿åº¦ä¼˜åŒ–èŒƒå›´

éµå¾ªæ­¤è§„èŒƒæœ‰åŠ©äºæé«˜ä»£ç è´¨é‡ï¼Œé™ä½ç»´æŠ¤éš¾åº¦ï¼Œå¹¶æå‡å¼€å‘æ•ˆç‡ã€‚è¯¦ç»†å†…å®¹è¯·å‚é˜…[ã€Šä»£ç æ–‡ä»¶é•¿åº¦ä¼˜åŒ–è§„èŒƒã€‹](./CODE_SIZE_OPTIMIZATION_REPORT.md)ã€‚

### Root Directory Standards

**ONLY these 5 core files belong in root**:
- `README.md` - Project overview and main documentation
- `CLAUDE.md` - Claude Code integration guide (this file)
- `CHANGELOG.md` - Version history and changes
- `requirements.txt` - Python dependencies
- `.mcp.json` - MCP server configuration

**All other files MUST be organized into subdirectories**.

### Directory Structure and Rules

#### 1. **scripts/** - All Executable Scripts

Organized by functionality into 4 categories:

**scripts/tests/** - Test Files
- **Pattern**: Files prefixed with `test_`
- **Purpose**: Unit tests, integration tests, acceptance tests
- **Examples**: `test_config_driven_table_manager.py`, `test_financial_adapter.py`
- **Special files**: `test_requirements.txt`, `coverage.xml`

**scripts/runtime/** - Production Runtime Scripts
- **Pattern**: Files prefixed with `run_`, `save_`, `monitor_`, or `*_demo.py`
- **Purpose**: Production data collection, monitoring, demonstrations
- **Examples**: `run_realtime_market_saver.py`, `save_realtime_data.py`, `system_demo.py`

**scripts/database/** - Database Operations
- **Pattern**: Files prefixed with `check_`, `verify_`, `create_`
- **Purpose**: Database initialization, validation, management
- **Examples**: `check_tdengine_tables.py`, `verify_tdengine_deployment.py`

**scripts/dev/** - Development Tools
- **Pattern**: Development utilities not fitting other categories
- **Purpose**: Code validation, testing utilities, development aids
- **Examples**: `gpu_test_examples.py`, `validate_documentation_consistency.py`
- **Special files**: `git_commit_comments.txt`

#### 2. **docs/** - Documentation Files

**docs/guides/** - User and Developer Guides
- **Files**: `QUICKSTART.md`, `IFLOW.md`, tutorial documents
- **Purpose**: Getting started guides, workflow documentation

**docs/archived/** - Deprecated Documentation
- **Files**: `START_HERE.md`, `TASKMASTER_START_HERE.md` (kept for historical reference)
- **Purpose**: Preserve old documentation without cluttering active docs
- **Rule**: Add deprecation notice at top of file when archiving

**docs/architecture/** - Architecture Design Documents
- **Purpose**: System design, technical architecture documentation
- **Examples**: Database design docs, system architecture diagrams

**docs/api/** - API Documentation
- **Purpose**: API reference, endpoint documentation, SDK guides

#### 3. **config/** - Configuration Files

**All configuration files** (regardless of extension):
- **Extensions**: `.yaml`, `.yml`, `.ini`, `.toml`, `docker-compose.*.yml`
- **Examples**:
  - `mystocks_table_config.yaml` - Table structure definitions
  - `docker-compose.tdengine.yml` - Docker setup
  - `pytest.ini` - Test configuration
  - `.readthedocs.yaml` - Documentation build config

#### 4. **reports/** - Generated Reports and Analysis

**Pattern**: Files generated by analysis scripts, timestamped if recurring
- **Extensions**: `.json`, `.txt`, analysis outputs
- **Examples**:
  - `database_assessment_20251019_165817.json`
  - `query_patterns_analysis.txt`
  - `dump_result.txt`
  - `WENCAI_INTEGRATION_FILES.txt`

**Naming Convention**: Use ISO date format for timestamped files: `YYYYMMDD_HHMMSS`

### File Lifecycle Management

#### Pre-Classification (Proactive)

**When creating new files**, place them directly in the correct location:

1. **Determine file purpose**: Test? Runtime? Configuration? Documentation?
2. **Match against rules**: Use the directory structure above
3. **Create in correct location**: Never create in root unless it's one of the 5 core files

**Example Pre-Classification**:
```python
# Creating a new test file
# âœ… CORRECT: Create directly in scripts/tests/
with open('scripts/tests/test_new_feature.py', 'w') as f:
    f.write(test_code)

# âŒ INCORRECT: Creating in root
with open('test_new_feature.py', 'w') as f:
    f.write(test_code)
```

#### Post-Classification (Reactive)

**When organizing existing files**:

1. **Identify misplaced files**: Use `ls` or `find` to list root directory files
2. **Categorize by rules**: Match each file against the directory structure rules
3. **Plan the reorganization**: Create a categorization plan before execution
4. **Use git mv**: Preserve file history when moving tracked files
5. **Update references**: Update all import paths, documentation links
6. **Validate**: Test that moved files work correctly

**Post-Classification Workflow**:
```bash
# 1. List root directory files (exclude core 5)
ls -1 | grep -v -E '^(README\.md|CLAUDE\.md|CHANGELOG\.md|requirements\.txt|\.mcp\.json)$'

# 2. For each file, determine correct location using rules above

# 3. Move files (use git mv for tracked files)
git mv test_something.py scripts/tests/
git mv run_collector.py scripts/runtime/
git mv config.yaml config/
git mv analysis_report.txt reports/

# 4. Update references in affected files

# 5. Commit with descriptive message
git commit -m "refactor: organize files according to directory structure rules"
```

### Import Path Management for Scripts

**Critical Rule**: All scripts in nested directories must calculate project root correctly.

**Standard Pattern for scripts in `scripts/**/`**:
```python
import sys
import os
from pathlib import Path

# Calculate project root (3 levels up from script location)
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

# Now you can import from project root
from core import ConfigDrivenTableManager
from adapters.akshare_adapter import AkshareDataSource
from db_manager.database_manager import DatabaseTableManager
```

**Explanation**:
- Script in `scripts/tests/test_something.py`
- `__file__` â†’ `scripts/tests/test_something.py`
- `os.path.dirname(__file__)` â†’ `scripts/tests/`
- `os.path.dirname(os.path.dirname(__file__))` â†’ `scripts/`
- `os.path.dirname(os.path.dirname(os.path.dirname(__file__)))` â†’ project root `/opt/claude/mystocks_spec/`

### Git Best Practices

**Always use `git mv` for tracked files**:
```bash
# âœ… CORRECT: Preserves file history
git mv old_location/file.py new_location/file.py

# âŒ INCORRECT: Breaks file history
mv old_location/file.py new_location/file.py
git add new_location/file.py
```

**For untracked files**, regular `mv` is fine:
```bash
# For files not in git yet
mv untracked_file.log reports/
```

### Validation Checklist

After any file reorganization:

- [ ] Root directory contains only the 5 core files
- [ ] All scripts properly categorized in scripts/{tests,runtime,database,dev}
- [ ] All documentation in docs/{guides,archived,architecture,api}
- [ ] All configuration files in config/
- [ ] All reports in reports/
- [ ] All moved scripts have updated import paths (3-level dirname)
- [ ] All documentation links updated to new paths
- [ ] `git status` shows moves (not deletions + additions)
- [ ] All tests pass after reorganization
- [ ] `scripts/README.md` is up to date

### Common Mistakes to Avoid

1. **Creating files in root**: Always use subdirectories unless it's one of the 5 core files
2. **Wrong import paths**: Remember to use 3-level dirname for scripts in nested directories
3. **Using `mv` instead of `git mv`**: Always preserve git history
4. **Forgetting to update references**: Check all imports, documentation links
5. **Mixing purposes**: Don't put test files in runtime/, or config files in docs/

### Reference Documentation

For detailed directory contents and file inventory:
- **Complete documentation structure**: See `docs/DOCUMENTATION_STRUCTURE.md`
- **Script organization guide**: See `scripts/README.md`

## Task Master AI Instructions
**Import Task Master's development workflow commands and guidelines, treat as if import is in the main CLAUDE.md file.**
@./.taskmaster/CLAUDE.md
