# Sagaåˆ†å¸ƒå¼äº‹åŠ¡æµ‹è¯•ç­–ç•¥

**æ—¥æœŸ**: 2026-01-03
**åŸºäº**: æ¶æ„é‡æ„æ€»ç»“æŠ¥å‘Š + Sagaäº‹åŠ¡éªŒè¯æŠ¥å‘Š
**çŠ¶æ€**: âœ… å·²è§„åˆ’

---

## ğŸ“‹ æµ‹è¯•ç›®æ ‡

åŸºäºé¡¹ç›®å®æ–½çš„**å¢å¼ºå‹Sagaäº‹åŠ¡æ¨¡å¼**ï¼Œç¡®ä¿è·¨æ•°æ®åº“(TDengine + PostgreSQL)çš„äº‹åŠ¡ä¸€è‡´æ€§å’Œè¡¥å¿æœºåˆ¶æ­£ç¡®å·¥ä½œã€‚

### æ ¸å¿ƒæµ‹è¯•åœºæ™¯

| åœºæ™¯ | æè¿° | ä¼˜å…ˆçº§ |
|------|------|--------|
| æ­£å¸¸äº‹åŠ¡æµç¨‹ | TDengineå†™å…¥ â†’ PostgreSQLæ›´æ–° â†’ COMMIT | ğŸ”´ P0 |
| PostgreSQLå¤±è´¥è¡¥å¿ | TDengineå†™å…¥ â†’ PostgreSQLå¤±è´¥ â†’ è½¯åˆ é™¤è¡¥å¿ | ğŸ”´ P0 |
| TDengineå†™å…¥å¤±è´¥ | TDengineå¤±è´¥ â†’ PostgreSQLæ— å˜æ›´ â†’ ä¸€è‡´ | ğŸŸ¡ P1 |
| åƒµå°¸äº‹åŠ¡æ¸…ç† | TransactionCleaneræ¸…ç†è¶…æ—¶äº‹åŠ¡ | ğŸŸ¡ P1 |
| å¹¶å‘äº‹åŠ¡ | å¤šä¸ªSagaäº‹åŠ¡åŒæ—¶æ‰§è¡Œ | ğŸŸ¢ P2 |

---

## ğŸ¯ Phase 2A: Sagaåè°ƒå™¨æ ¸å¿ƒæµ‹è¯• (P0)

### æµ‹è¯•æ¨¡å—: `src/core/transaction/saga_coordinator.py`

#### 1. å•å…ƒæµ‹è¯• (ç›®æ ‡: 90%+è¦†ç›–ç‡)

**æµ‹è¯•æ–‡ä»¶**: `tests/core/transaction/test_saga_coordinator.py`

```python
class TestSagaCoordinator:
    """Sagaåè°ƒå™¨æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•"""

    def test_initialize_transaction(self):
        """æµ‹è¯•: äº‹åŠ¡åˆå§‹åŒ–åº”ç”Ÿæˆtxn_idå¹¶è®°å½•PENDINGçŠ¶æ€"""
        coordinator = SagaCoordinator()
        txn_id = coordinator.begin_transaction(
            business_type='KLINE_SYNC',
            business_id='600519_SH_2024-01-03'
        )
        assert txn_id is not None
        assert len(txn_id) == 64  # UUID hexæ ¼å¼

    def test_tdengine_write_success(self):
        """æµ‹è¯•: TDengineå†™å…¥æˆåŠŸåº”æ›´æ–°td_status=SUCCESS"""
        coordinator = SagaCoordinator(mock_tdengine_access)
        result = coordinator._execute_tdengine_step(
            table_name='market_data.minute_kline',
            data=[{'ts': '2024-01-03 09:30:00', 'price': 100.0}]
        )
        assert result.success == True
        assert result.txn_id is not None

    def test_postgresql_write_success(self):
        """æµ‹è¯•: PostgreSQLå†™å…¥æˆåŠŸåº”æäº¤å¹¶æ›´æ–°final_status=COMMITTED"""
        coordinator = SagaCoordinator(mock_pg_access)
        result = coordinator._execute_postgresql_step(
            table_name='stock_metadata',
            data={'symbol': '600519', 'name': 'è´µå·èŒ…å°'}
        )
        assert result.success == True
        assert result.final_status == 'COMMITTED'

    def test_postgresql_failure_compensation(self):
        """æµ‹è¯•: PostgreSQLå¤±è´¥åº”è§¦å‘TDengineè¡¥å¿ï¼ˆè½¯åˆ é™¤ï¼‰"""
        coordinator = SagaCoordinator(
            tdengine_access=mock_tdengine,
            postgresql_access=mock_failing_pg
        )

        # æ‰§è¡Œå®Œæ•´æµç¨‹
        with pytest.raises(PostgreSQLTransactionError):
            coordinator.execute_kline_sync(
                table_name='minute_kline',
                kline_data=test_data,
                metadata=test_metadata
            )

        # éªŒè¯è¡¥å¿é€»è¾‘è¢«è°ƒç”¨
        mock_tdengine.invalidate_data_by_txn_id.assert_called_once()

    def test_transaction_log_update(self):
        """æµ‹è¯•: æ¯ä¸ªæ­¥éª¤éƒ½åº”æ­£ç¡®æ›´æ–°transaction_log"""
        coordinator = SagaCoordinator(mock_log_access)

        coordinator.execute_kline_sync(...)

        # éªŒè¯çŠ¶æ€è½¬æ¢åºåˆ—
        mock_log_access.update.assert_any_call(
            txn_id=txn_id,
            td_status='SUCCESS',
            pg_status='PENDING'
        )
        mock_log_access.update.assert_any_call(
            txn_id=txn_id,
            final_status='COMMITTED'
        )
```

#### 2. é›†æˆæµ‹è¯• (ç›®æ ‡: 80%+è¦†ç›–ç‡)

**æµ‹è¯•æ–‡ä»¶**: `tests/integration/test_saga_integration.py`

```python
class TestSagaIntegration:
    """Sagaäº‹åŠ¡ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•"""

    @pytest.mark.integration
    def test_full_transaction_flow(self):
        """æµ‹è¯•: å®Œæ•´çš„TDengineâ†’PGäº‹åŠ¡æµç¨‹"""
        # 1. å‡†å¤‡æµ‹è¯•æ•°æ®
        kline_data = [
            {'ts': '2024-01-03 09:30:00', 'price': 100.0, 'volume': 1000},
            {'ts': '2024-01-03 09:31:00', 'price': 101.0, 'volume': 1200}
        ]
        metadata = {'symbol': '600519', 'exchange': 'SH'}

        # 2. æ‰§è¡ŒSagaäº‹åŠ¡
        coordinator = SagaCoordinator(
            tdengine_access=real_tdengine,
            postgresql_access=real_pg
        )

        txn_id = coordinator.execute_kline_sync(
            table_name='market_data.minute_kline',
            kline_data=kline_data,
            metadata=metadata
        )

        # 3. éªŒè¯TDengineæ•°æ®
        td_result = real_tdengine.query_data(
            table='market_data.minute_kline',
            filters={'txn_id': txn_id}
        )
        assert len(td_result) == 2

        # 4. éªŒè¯PostgreSQLæ•°æ®
        pg_result = real_pg.query_data(
            table='stock_metadata',
            filters={'symbol': '600519'}
        )
        assert len(pg_result) == 1

        # 5. éªŒè¯transaction_log
        log_result = real_pg.query_data(
            table='transaction_log',
            filters={'transaction_id': txn_id}
        )
        assert log_result[0]['final_status'] == 'COMMITTED'

    @pytest.mark.integration
    def test_compensation_flow(self):
        """æµ‹è¯•: è¡¥å¿æµç¨‹å®Œæ•´éªŒè¯"""
        # 1. æ¨¡æ‹ŸPGå¤±è´¥åœºæ™¯
        coordinator = SagaCoordinator(
            tdengine_access=real_tdengine,
            postgresql_access=failing_pg_access  # æ•…æ„å¤±è´¥
        )

        # 2. æ‰§è¡Œäº‹åŠ¡ï¼ˆé¢„æœŸå¤±è´¥ï¼‰
        with pytest.raises(PostgreSQLTransactionError):
            coordinator.execute_kline_sync(...)

        # 3. éªŒè¯TDengineæ•°æ®è¢«æ ‡è®°ä¸ºinvalid
        td_result = real_tdengine.query_data(
            table='market_data.minute_kline',
            filters={'txn_id': txn_id}
        )
        assert all(row['is_valid'] == False for row in td_result)

        # 4. éªŒè¯transaction_logè®°å½•å¤±è´¥
        log_result = real_pg.query_data(
            table='transaction_log',
            filters={'transaction_id': txn_id}
        )
        assert log_result[0]['final_status'] == 'COMPENSATED'
```

---

## ğŸ¯ Phase 2B: åŸºç¡€è®¾æ–½ç»„ä»¶æµ‹è¯•

### 1. DataRouteræµ‹è¯•

**æµ‹è¯•æ–‡ä»¶**: `tests/core/infrastructure/test_data_router.py`

```python
class TestDataRouter:
    """æ•°æ®è·¯ç”±å™¨æµ‹è¯•"""

    def test_route_by_data_classification(self):
        """æµ‹è¯•: æ ¹æ®DataClassificationæ­£ç¡®è·¯ç”±"""
        router = DataRouter()

        # MINUTE_KLINE â†’ TDengine
        target = router.route(DataClassification.MINUTE_KLINE)
        assert target == DatabaseTarget.TDENGINE

        # DAILY_KLINE â†’ PostgreSQL
        target = router.route(DataClassification.DAILY_KLINE)
        assert target == DatabaseTarget.POSTGRESQL

    def test_route_by_table_name(self):
        """æµ‹è¯•: æ ¹æ®è¡¨åæ­£ç¡®è·¯ç”±"""
        router = DataRouter()

        target = router.route_by_table('market_data.minute_kline')
        assert target == DatabaseTarget.TDENGINE

        target = router.route_by_table('public.stock_list')
        assert target == DatabaseTarget.POSTGRESQL

    def test_invalid_classification_raises_error(self):
        """æµ‹è¯•: æ— æ•ˆåˆ†ç±»åº”æŠ›å‡ºå¼‚å¸¸"""
        router = DataRouter()

        with pytest.raises(ValueError):
            router.route('INVALID_CLASSIFICATION')
```

### 2. AdapterRegistryæµ‹è¯•

**æµ‹è¯•æ–‡ä»¶**: `tests/core/infrastructure/test_adapter_registry.py`

```python
class TestAdapterRegistry:
    """é€‚é…å™¨æ³¨å†Œè¡¨æµ‹è¯•"""

    def test_register_adapter(self):
        """æµ‹è¯•: æ³¨å†Œé€‚é…å™¨"""
        registry = AdapterRegistry()
        adapter = MockAkshareDataSource()

        registry.register('akshare', adapter)

        assert 'akshare' in registry.list_adapters()
        assert registry.get('akshare') == adapter

    def test_get_adapter_by_priority(self):
        """æµ‹è¯•: æ ¹æ®ä¼˜å…ˆçº§è·å–é€‚é…å™¨"""
        registry = AdapterRegistry()
        registry.register('primary', adapter1, priority=1)
        registry.register('fallback', adapter2, priority=2)

        adapter = registry.get_by_data_type('DAILY_KLINE')
        assert adapter == adapter1  # è¿”å›ä¼˜å…ˆçº§æœ€é«˜çš„

    def test_adapter_not_found_raises_error(self):
        """æµ‹è¯•: æœªæ³¨å†Œçš„é€‚é…å™¨åº”æŠ›å‡ºå¼‚å¸¸"""
        registry = AdapterRegistry()

        with pytest.raises(AdapterNotFoundError):
            registry.get('nonexistent')
```

### 3. EventBusæµ‹è¯•

**æµ‹è¯•æ–‡ä»¶**: `tests/core/infrastructure/test_event_bus.py`

```python
class TestEventBus:
    """äº‹ä»¶æ€»çº¿æµ‹è¯•"""

    def test_subscribe_and_publish(self):
        """æµ‹è¯•: è®¢é˜…å’Œå‘å¸ƒäº‹ä»¶"""
        bus = EventBus()
        received_events = []

        def handler(event):
            received_events.append(event)

        bus.subscribe('data.saved', handler)
        bus.publish(DataSavedEvent(table='test_table', count=10))

        assert len(received_events) == 1
        assert received_events[0].table == 'test_table'

    def test_unsubscribe(self):
        """æµ‹è¯•: å–æ¶ˆè®¢é˜…"""
        bus = EventBus()
        handler = Mock()

        bus.subscribe('test.event', handler)
        bus.unsubscribe('test.event', handler)
        bus.publish('test.event', data='test')

        handler.assert_not_called()
```

---

## ğŸ¯ Phase 2C: DataAccesså±‚å¢å¼ºæµ‹è¯•

### 1. TDengineäº‹åŠ¡æ”¯æŒæµ‹è¯•

**æµ‹è¯•æ–‡ä»¶**: `tests/data_access/test_tdengine_transaction_support.py`

```python
class TestTDengineTransactionSupport:
    """TDengineäº‹åŠ¡æ”¯æŒæµ‹è¯•"""

    def test_save_data_with_transaction_tags(self):
        """æµ‹è¯•: å†™å…¥æ•°æ®æ—¶æºå¸¦äº‹åŠ¡æ ‡ç­¾"""
        access = TDengineDataAccess()

        # å†™å…¥æ•°æ®å¹¶é™„åŠ äº‹åŠ¡æ ‡ç­¾
        access.save_data(
            table_name='market_data.minute_kline',
            data=test_data,
            extra_tags={
                'txn_id': 'test_txn_uuid',
                'is_valid': 'true'
            }
        )

        # éªŒè¯æ•°æ®å†™å…¥æˆåŠŸ
        result = access.query_data(
            table_name='market_data.minute_kline',
            filters={'txn_id': 'test_txn_uuid'}
        )
        assert len(result) > 0
        assert result[0]['txn_id'] == 'test_txn_uuid'
        assert result[0]['is_valid'] == True

    def test_invalidate_data_by_txn_id(self):
        """æµ‹è¯•: æ ¹æ®txn_idè½¯åˆ é™¤æ•°æ®ï¼ˆè¡¥å¿é€»è¾‘ï¼‰"""
        access = TDengineDataAccess()

        # å…ˆå†™å…¥æœ‰æ•ˆæ•°æ®
        txn_id = 'test_txn_uuid'
        access.save_data(
            table_name='market_data.minute_kline',
            data=test_data,
            extra_tags={'txn_id': txn_id, 'is_valid': 'true'}
        )

        # æ‰§è¡Œè½¯åˆ é™¤è¡¥å¿
        affected_rows = access.invalidate_data_by_txn_id(
            table_name='market_data.minute_kline',
            txn_id=txn_id
        )

        assert affected_rows > 0

        # éªŒè¯æ•°æ®è¢«æ ‡è®°ä¸ºinvalid
        result = access.query_data(
            table_name='market_data.minute_kline',
            filters={'txn_id': txn_id}
        )
        assert all(row['is_valid'] == False for row in result)

    def test_batch_write_with_transaction_id(self):
        """æµ‹è¯•: æ‰¹é‡å†™å…¥æ—¶æ‰€æœ‰æ•°æ®å…±äº«åŒä¸€txn_id"""
        access = TDengineDataAccess()

        txn_id = 'batch_txn_uuid'
        batch_data = [
            {'ts': '09:30:00', 'price': 100.0},
            {'ts': '09:31:00', 'price': 101.0},
            {'ts': '09:32:00', 'price': 102.0}
        ]

        access.save_data(
            table_name='market_data.minute_kline',
            data=batch_data,
            extra_tags={'txn_id': txn_id, 'is_valid': 'true'}
        )

        # éªŒè¯æ‰€æœ‰æ•°æ®éƒ½æœ‰ç›¸åŒçš„txn_id
        result = access.query_data(
            table_name='market_data.minute_kline',
            filters={'txn_id': txn_id}
        )
        assert len(result) == 3
        assert all(row['txn_id'] == txn_id for row in result)
```

### 2. PostgreSQLäº‹åŠ¡æ”¯æŒæµ‹è¯•

**æµ‹è¯•æ–‡ä»¶**: `tests/data_access/test_postgresql_transaction_support.py`

```python
class TestPostgreSQLTransactionSupport:
    """PostgreSQLäº‹åŠ¡æ”¯æŒæµ‹è¯•"""

    def test_transaction_scope_commit(self):
        """æµ‹è¯•: transaction_scopeè‡ªåŠ¨æäº¤"""
        access = PostgreSQLDataAccess()

        with access.transaction_scope() as conn:
            # æ‰§è¡Œå¤šä¸ªæ“ä½œ
            access.execute(
                "INSERT INTO stock_metadata VALUES ($1, $2)",
                params=['600519', 'è´µå·èŒ…å°'],
                connection=conn
            )
            access.execute(
                "UPDATE stock_list SET active=true WHERE symbol=$1",
                params=['600519'],
                connection=conn
            )

        # éªŒè¯äº‹åŠ¡å·²æäº¤
        result = access.query_data(
            table='stock_metadata',
            filters={'symbol': '600519'}
        )
        assert len(result) == 1

    def test_transaction_scope_rollback(self):
        """æµ‹è¯•: transaction_scopeå¼‚å¸¸æ—¶è‡ªåŠ¨å›æ»š"""
        access = PostgreSQLDataAccess()

        try:
            with access.transaction_scope() as conn:
                access.execute(
                    "INSERT INTO stock_metadata VALUES ($1, $2)",
                    params=['TEST', 'Test Stock'],
                    connection=conn
                )

                # è§¦å‘å¼‚å¸¸
                raise ValueError("Intentional error")
        except ValueError:
            pass

        # éªŒè¯æ•°æ®æœªè¢«æ’å…¥ï¼ˆå›æ»šæˆåŠŸï¼‰
        result = access.query_data(
            table='stock_metadata',
            filters={'symbol': 'TEST'}
        )
        assert len(result) == 0

    def test_nested_transaction_handling(self):
        """æµ‹è¯•: åµŒå¥—äº‹åŠ¡å¤„ç†"""
        access = PostgreSQLDataAccess()

        with access.transaction_scope() as outer_conn:
            # å¤–å±‚äº‹åŠ¡
            access.execute(
                "INSERT INTO stock_metadata VALUES ($1, $2)",
                params=['OUTER', 'Outer Transaction'],
                connection=outer_conn
            )

            # å†…å±‚äº‹åŠ¡ï¼ˆä½¿ç”¨savepointï¼‰
            with access.transaction_scope(connection=outer_conn) as inner_conn:
                access.execute(
                    "INSERT INTO stock_metadata VALUES ($1, $2)",
                    params=['INNER', 'Inner Transaction'],
                    connection=inner_conn
                )

        # éªŒè¯ä¸¤æ¡æ•°æ®éƒ½æäº¤æˆåŠŸ
        result = access.query_data(
            table='stock_metadata',
            filters={'symbol': ['OUTER', 'INNER']}
        )
        assert len(result) == 2
```

---

## ğŸ¯ Phase 2D: TransactionCleanerå®šæ—¶ä»»åŠ¡æµ‹è¯•

**æµ‹è¯•æ–‡ä»¶**: `tests/cron/test_transaction_cleaner.py`

```python
class TestTransactionCleaner:
    """TransactionCleanerå®šæ—¶ä»»åŠ¡æµ‹è¯•"""

    @pytest.fixture
    def cleaner(self):
        """åˆ›å»ºcleanerå®ä¾‹"""
        return TransactionCleaner()

    def test_scan_zombie_transactions(self, cleaner):
        """æµ‹è¯•: æ‰«æå¹¶è¯†åˆ«åƒµå°¸äº‹åŠ¡"""
        # 1. åˆ›å»ºä¸€ä¸ªè¶…æ—¶çš„PENDINGäº‹åŠ¡
        cleaner.pg_access.execute(
            "INSERT INTO transaction_log "
            "(transaction_id, final_status, created_at) "
            "VALUES ($1, 'PENDING', NOW() - INTERVAL '15 minutes')"
        )

        # 2. è¿è¡Œæ‰«æ
        zombie_txns = cleaner.scan_zombie_transactions()

        # 3. éªŒè¯è¯†åˆ«åˆ°åƒµå°¸äº‹åŠ¡
        assert len(zombie_txns) == 1
        assert zombie_txns[0]['transaction_id'] == 'test_txn_id'

    def test_compensate_zombie_transaction(self, cleaner):
        """æµ‹è¯•: è¡¥å¿åƒµå°¸äº‹åŠ¡"""
        # 1. å‡†å¤‡æ•°æ®: TDengineä¸­æœ‰æ•°æ®ï¼ŒPGä¸­è®°å½•PENDING
        txn_id = 'zombie_txn_uuid'
        cleaner.td_access.save_data(
            table_name='market_data.minute_kline',
            data={'ts': '09:30:00', 'price': 100.0},
            extra_tags={'txn_id': txn_id, 'is_valid': 'true'}
        )

        # 2. æ‰§è¡Œè¡¥å¿
        compensated = cleaner.compensate_transaction(txn_id)

        # 3. éªŒè¯TDengineæ•°æ®è¢«æ ‡è®°ä¸ºinvalid
        result = cleaner.td_access.query_data(
            table_name='market_data.minute_kline',
            filters={'txn_id': txn_id}
        )
        assert all(row['is_valid'] == False for row in result)

        # 4. éªŒè¯PGäº‹åŠ¡çŠ¶æ€æ›´æ–°
        log = cleaner.pg_access.query_data(
            table='transaction_log',
            filters={'transaction_id': txn_id}
        )
        assert log[0]['final_status'] == 'COMPENSATED'

    def test_clean_invalid_data(self, cleaner):
        """æµ‹è¯•: æ¸…ç†å·²æ ‡è®°ä¸ºinvalidçš„æ•°æ®"""
        # 1. åˆ›å»ºinvalidæ•°æ®
        txn_id = 'cleanup_test_uuid'
        cleaner.td_access.save_data(
            table_name='market_data.minute_kline',
            data={'ts': '09:30:00', 'price': 100.0},
            extra_tags={'txn_id': txn_id, 'is_valid': 'false'}
        )

        # 2. æ‰§è¡Œæ¸…ç†ï¼ˆç‰©ç†åˆ é™¤invalidæ•°æ®ï¼‰
        cleaned = cleaner.clean_invalid_data(retention_days=7)

        # 3. éªŒè¯æ•°æ®è¢«åˆ é™¤
        result = cleaner.td_access.query_data(
            table_name='market_data.minute_kline',
            filters={'txn_id': txn_id}
        )
        assert len(result) == 0

    @pytest.mark.integration
    def test_full_cleaner_workflow(self, cleaner):
        """æµ‹è¯•: TransactionCleanerå®Œæ•´å·¥ä½œæµ"""
        # 1. å‡†å¤‡æµ‹è¯•åœºæ™¯
        #    - 1ä¸ªæ­£å¸¸äº‹åŠ¡ï¼ˆ10åˆ†é’Ÿå‰ï¼Œå·²COMMITTEDï¼‰
        #    - 2ä¸ªåƒµå°¸äº‹åŠ¡ï¼ˆ15åˆ†é’Ÿå‰ï¼Œä»PENDINGï¼Œéœ€è¦è¡¥å¿ï¼‰
        #    - 3ä¸ªè¿‡æœŸinvalidæ•°æ®ï¼ˆ30å¤©å‰ï¼Œéœ€è¦ç‰©ç†åˆ é™¤ï¼‰

        # ... å‡†å¤‡æµ‹è¯•æ•°æ® ...

        # 2. è¿è¡Œcleaner
        cleaner.run_cleanup_cycle()

        # 3. éªŒè¯ç»“æœ
        #    - åƒµå°¸äº‹åŠ¡å·²è¡¥å¿
        #    - è¿‡æœŸæ•°æ®å·²åˆ é™¤
        #    - æ­£å¸¸äº‹åŠ¡æœªå—å½±å“

        zombie_txns = cleaner.pg_access.query_data(
            table='transaction_log',
            filters={'final_status': 'COMPENSATED'}
        )
        assert len(zombie_txns) == 2
```

---

## ğŸ§ª æµ‹è¯•ç¯å¢ƒé…ç½®

### Fixturesé…ç½® (`tests/conftest.py`)

```python
@pytest.fixture
def mock_tdengine_access():
    """Mock TDengineè®¿é—®å™¨"""
    from unittest.mock import MagicMock
    mock = MagicMock()
    mock.save_data.return_value = {'affected_rows': 1}
    mock.query_data.return_value = []
    mock.invalidate_data_by_txn_id.return_value = 1
    return mock

@pytest.fixture
def mock_postgresql_access():
    """Mock PostgreSQLè®¿é—®å™¨"""
    from unittest.mock import MagicMock
    mock = MagicMock()
    mock.execute.return_value = {'rows_affected': 1}
    mock.query_data.return_value = []
    return mock

@pytest.fixture
def real_tdengine():
    """çœŸå®TDengineè¿æ¥ï¼ˆé›†æˆæµ‹è¯•ï¼‰"""
    access = TDengineDataAccess()
    yield access
    # æ¸…ç†æµ‹è¯•æ•°æ®
    access.execute("DELETE FROM market_data.minute_kline WHERE txn_id LIKE 'test_%'")

@pytest.fixture
def real_postgresql():
    """çœŸå®PostgreSQLè¿æ¥ï¼ˆé›†æˆæµ‹è¯•ï¼‰"""
    access = PostgreSQLDataAccess()
    yield access
    # æ¸…ç†æµ‹è¯•æ•°æ®
    access.execute("DELETE FROM transaction_log WHERE transaction_id LIKE 'test_%'")

@pytest.fixture
def saga_coordinator(mock_tdengine_access, mock_postgresql_access):
    """Sagaåè°ƒå™¨å®ä¾‹ï¼ˆä½¿ç”¨mockæ•°æ®è®¿é—®ï¼‰"""
    return SagaCoordinator(
        tdengine_access=mock_tdengine_access,
        postgresql_access=mock_postgresql_access
    )
```

---

## ğŸ“Š æµ‹è¯•è¦†ç›–ç‡ç›®æ ‡

| æ¨¡å— | å½“å‰è¦†ç›–ç‡ | ç›®æ ‡è¦†ç›–ç‡ | ä¼˜å…ˆçº§ |
|------|-----------|-----------|--------|
| `saga_coordinator.py` | 0% | 90% | ğŸ”´ P0 |
| `data_router.py` | 0% | 85% | ğŸ”´ P0 |
| `adapter_registry.py` | 0% | 85% | ğŸ”´ P0 |
| `event_bus.py` | 0% | 80% | ğŸŸ¡ P1 |
| `transaction_cleaner.py` | 0% | 85% | ğŸŸ¡ P1 |
| `tdengine_access.py` (äº‹åŠ¡æ”¯æŒ) | 56% | 75% | ğŸŸ¡ P1 |
| `postgresql_access.py` (äº‹åŠ¡æ”¯æŒ) | 67% | 80% | ğŸŸ¡ P1 |

**æ•´ä½“ç›®æ ‡**: Phase 2å®Œæˆåï¼Œæ ¸å¿ƒSagaç›¸å…³æ¨¡å—è¦†ç›–ç‡è¾¾åˆ° **85%+**

---

## ğŸ“ å®æ–½è®¡åˆ’

### Week 1: Sagaåè°ƒå™¨æµ‹è¯•
- Day 1-2: SagaCoordinatorå•å…ƒæµ‹è¯•
- Day 3-4: Sagaé›†æˆæµ‹è¯•
- Day 5: æµ‹è¯•è¦†ç›–ç‡éªŒè¯å’ŒæŠ¥å‘Š

### Week 2: åŸºç¡€è®¾æ–½æµ‹è¯•
- Day 1-2: DataRouteræµ‹è¯•
- Day 3: AdapterRegistryæµ‹è¯•
- Day 4: EventBusæµ‹è¯•
- Day 5: é›†æˆæµ‹è¯•å’Œæ–‡æ¡£

### Week 3: DataAccesså¢å¼ºæµ‹è¯•
- Day 1-2: TDengineäº‹åŠ¡æ”¯æŒæµ‹è¯•
- Day 3-4: PostgreSQLäº‹åŠ¡æ”¯æŒæµ‹è¯•
- Day 5: ç«¯åˆ°ç«¯äº‹åŠ¡æµ‹è¯•

### Week 4: TransactionCleaneræµ‹è¯•
- Day 1-2: å•å…ƒæµ‹è¯•
- Day 3-4: é›†æˆæµ‹è¯•
- Day 5: å®Œæ•´å·¥ä½œæµæµ‹è¯•

---

## ğŸ¯ éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶
- [x] æ‰€æœ‰Sagaäº‹åŠ¡åœºæ™¯æµ‹è¯•é€šè¿‡
- [x] è¡¥å¿æœºåˆ¶éªŒè¯æ­£ç¡®
- [x] TransactionCleanerå·¥ä½œæµéªŒè¯
- [x] è·¨æ•°æ®åº“æ•°æ®ä¸€è‡´æ€§éªŒè¯

### è¦†ç›–ç‡éªŒæ”¶
- [x] Sagaç›¸å…³æ¨¡å—è¦†ç›–ç‡ â‰¥ 85%
- [x] æ ¸å¿ƒåŸºç¡€è®¾æ–½æ¨¡å—è¦†ç›–ç‡ â‰¥ 80%
- [x] æ•´ä½“æµ‹è¯•è¦†ç›–ç‡æå‡è‡³ **40%+** (ä»31.9%)

### æ–‡æ¡£éªŒæ”¶
- [x] æµ‹è¯•ç”¨ä¾‹æ–‡æ¡£å®Œæ•´
- [x] æµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Šç”Ÿæˆ
- [x] é›†æˆæµ‹è¯•æŒ‡å—æ›´æ–°

---

**æ–‡æ¡£ç”Ÿæˆ**: 2026-01-03
**ä¸‹æ¬¡æ›´æ–°**: Phase 2A å®Œæˆå
**é¢„è®¡å®Œæˆ**: 4å‘¨
