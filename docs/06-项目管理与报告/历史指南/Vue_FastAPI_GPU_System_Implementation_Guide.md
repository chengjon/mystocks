# Vue + FastAPI æ¶æ„é€‚é…çš„ GPU ç³»ç»Ÿå®æ–½æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£ä¸ºåŸºäºVue.js + FastAPIæ¶æ„çš„MyStocksé¡¹ç›®æä¾›å®Œæ•´çš„GPUåŠ é€Ÿç³»ç»Ÿå®æ–½æŒ‡å¯¼ï¼Œç»“åˆmystocks_specé¡¹ç›®çš„RAPIDS GPUåŠ é€Ÿç³»ç»Ÿï¼Œé’ˆå¯¹Vue.jså‰ç«¯å’ŒFastAPIåç«¯çš„æ¶æ„ç‰¹ç‚¹è¿›è¡Œä¸“é—¨ä¼˜åŒ–ã€‚

**é€‚ç”¨æ¶æ„**: Vue.js (å‰ç«¯) + FastAPI (åç«¯)  
**å‚è€ƒé¡¹ç›®**: mystocks_spec (ä¸»åˆ†æ”¯), src/gpu/api_system/  
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¶é—´**: 2025-11-16

---

## ğŸ—ï¸ ç°æœ‰GPUç³»ç»Ÿæ¶æ„åˆ†æ

### 1.1 å½“å‰GPUç³»ç»Ÿæ¶æ„

åŸºäºç°æœ‰ä»£ç åˆ†æï¼ŒMyStocks GPUç³»ç»Ÿæ¶æ„å¦‚ä¸‹ï¼š

```
Vue.js + FastAPI GPU ç³»ç»Ÿæ¶æ„
â”œâ”€â”€ åç«¯ (FastAPI)
â”‚   â”œâ”€â”€ app/api/gpu_status.py        # GPUçŠ¶æ€APIè·¯ç”±
â”‚   â”œâ”€â”€ app/services/gpu_service.py  # GPUä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ app/models/gpu.py            # GPUæ•°æ®æ¨¡å‹
â”‚   â””â”€â”€ app/schemas/gpu.py           # GPUæ•°æ®éªŒè¯
â”œâ”€â”€ GPUåŠ é€Ÿæ¨¡å—
â”‚   â”œâ”€â”€ src/gpu/api_system/          # GPU APIç³»ç»Ÿ
â”‚   â”‚   â”œâ”€â”€ services/gpu_api_server.py  # GPU APIæœåŠ¡å™¨
â”‚   â”‚   â”œâ”€â”€ core/gpu_resource_manager.py  # GPUèµ„æºç®¡ç†å™¨
â”‚   â”‚   â”œâ”€â”€ acceleration/backtest_accelerator.py  # å›æµ‹åŠ é€Ÿå™¨
â”‚   â”‚   â”œâ”€â”€ acceleration/ml_accelerator.py      # æœºå™¨å­¦ä¹ åŠ é€Ÿå™¨
â”‚   â”‚   â””â”€â”€ utils/gpu_monitor.py              # GPUç›‘æ§å·¥å…·
â”‚   â”œâ”€â”€ gpu_ai_integration.py        # GPU AIé›†æˆç®¡ç†å™¨
â”‚   â””â”€â”€ gpu_ai_integration_report.json  # GPUé›†æˆæŠ¥å‘Š
â”œâ”€â”€ å‰ç«¯ (Vue.js)
â”‚   â”œâ”€â”€ src/views/GPUStatus.vue      # GPUçŠ¶æ€é¡µé¢
â”‚   â”œâ”€â”€ src/components/GPU/          # GPUç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ GPUStatusPanel.vue       # GPUçŠ¶æ€é¢æ¿
â”‚   â”‚   â”œâ”€â”€ GPUUsageChart.vue        # GPUä½¿ç”¨ç‡å›¾è¡¨
â”‚   â”‚   â””â”€â”€ AccelerationManager.vue  # åŠ é€Ÿç®¡ç†å™¨
â”‚   â””â”€â”€ src/stores/gpu.js            # GPUçŠ¶æ€ç®¡ç†
â””â”€â”€ é…ç½®æ–‡ä»¶
    â””â”€â”€ share/GPU_SYSTEM_GUIDE.md    # GPUç³»ç»Ÿå®æ–½æŒ‡å—
```

### 1.2 GPUç³»ç»Ÿæ ¸å¿ƒç»„ä»¶

ä»ç°æœ‰ä»£ç åˆ†æï¼ŒGPUç³»ç»ŸåŒ…å«ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶ï¼š

1. **GPUResourceManager**: è´Ÿè´£GPUèµ„æºç®¡ç†
2. **GPUAPIAccelerator**: æä¾›GPUåŠ é€ŸæœåŠ¡
3. **BacktestAccelerator**: GPUåŠ é€Ÿå›æµ‹å¼•æ“
4. **MLAccelerator**: GPUåŠ é€Ÿæœºå™¨å­¦ä¹ 
5. **ä¸‰çº§ç¼“å­˜ç³»ç»Ÿ**: L1/L2/L3ç¼“å­˜ï¼Œå‘½ä¸­ç‡>90%
6. **gRPCå¾®æœåŠ¡**: GPU APIæœåŠ¡

---

## ğŸš€ å®æ–½è·¯çº¿å›¾

### Phase 1: åç«¯FastAPI GPUæœåŠ¡ (Week 1)
**ç›®æ ‡**: å»ºç«‹ä¸ç°æœ‰GPUç³»ç»Ÿå…¼å®¹çš„FastAPIåç«¯æœåŠ¡

#### 1.1 GPUæœåŠ¡æ¶æ„è®¾è®¡
```python
# backend/app/services/gpu_service.py
from typing import Dict, Any, List, Optional
from datetime import datetime
import logging
import asyncio
import subprocess
import json

class GPUService:
    """GPUæœåŠ¡ç±»"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.gpu_manager = None
        self.accelerator = None
        self.cache_manager = None
        self.is_initialized = False
    
    async def initialize(self):
        """åˆå§‹åŒ–GPUæœåŠ¡"""
        try:
            # å¯¼å…¥GPUç®¡ç†å™¨
            from gpu_ai_integration import GPUAIIntegrationManager
            self.gpu_manager = GPUAIIntegrationManager()
            
            # åˆå§‹åŒ–åŠ é€Ÿå™¨
            self.accelerator = self.gpu_manager.get_accelerator()
            
            # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
            self.cache_manager = self.gpu_manager.get_cache_manager()
            
            self.is_initialized = True
            self.logger.info("âœ… GPUæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
            
        except ImportError as e:
            self.logger.warning(f"âš ï¸ GPUåŠ é€Ÿæœªå¯ç”¨: {e}")
            self.is_initialized = False
        except Exception as e:
            self.logger.error(f"âŒ GPUæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            self.is_initialized = False
    
    async def get_gpu_status(self) -> Dict[str, Any]:
        """è·å–GPUçŠ¶æ€"""
        if not self.is_initialized:
            return {
                "gpu_available": False,
                "error": "GPUæœåŠ¡æœªåˆå§‹åŒ–æˆ–ä¸å¯ç”¨"
            }
        
        try:
            status = self.gpu_manager.get_gpu_status()
            
            # æ·»åŠ é¢å¤–çš„ç›‘æ§æŒ‡æ ‡
            extended_status = {
                **status,
                "timestamp": datetime.now().isoformat(),
                "service_status": "healthy" if status.get("gpu_available", False) else "unhealthy",
                "acceleration_enabled": True,
                "cache_hit_rate": status.get("cache_hit_rate", 0.0),
                "active_tasks": status.get("active_tasks", 0)
            }
            
            return extended_status
        except Exception as e:
            self.logger.error(f"è·å–GPUçŠ¶æ€å¤±è´¥: {e}")
            return {
                "gpu_available": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def get_gpu_detailed_info(self) -> Dict[str, Any]:
        """è·å–GPUè¯¦ç»†ä¿¡æ¯"""
        if not self.is_initialized:
            return {"error": "GPUæœåŠ¡æœªåˆå§‹åŒ–"}
        
        try:
            # ä»ç³»ç»Ÿè·å–GPUè¯¦ç»†ä¿¡æ¯
            gpu_info = self.gpu_manager.get_gpu_detailed_info()
            
            # è·å–RAPIDSç‰ˆæœ¬ä¿¡æ¯
            rapids_info = self._get_rapids_info()
            
            # è·å–ç¼“å­˜çŠ¶æ€
            cache_info = self._get_cache_info()
            
            return {
                "gpu_info": gpu_info,
                "rapids_info": rapids_info,
                "cache_info": cache_info,
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            self.logger.error(f"è·å–GPUè¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _get_rapids_info(self) -> Dict[str, str]:
        """è·å–RAPIDSåº“ä¿¡æ¯"""
        try:
            import cudf
            import cuml
            import cupy as cp
            
            return {
                "cudf_version": cudf.__version__,
                "cuml_version": cuml.__version__,
                "cupy_version": cp.__version__,
                "rapids_available": True
            }
        except ImportError:
            return {
                "rapids_available": False,
                "error": "RAPIDSåº“æœªå®‰è£…"
            }
    
    def _get_cache_info(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ä¿¡æ¯"""
        if self.cache_manager:
            try:
                return self.cache_manager.get_cache_status()
            except Exception as e:
                self.logger.error(f"è·å–ç¼“å­˜ä¿¡æ¯å¤±è´¥: {e}")
                return {"error": str(e)}
        else:
            return {"cache_enabled": False}
    
    async def accelerate_backtest(self, strategy_data: Dict[str, Any]) -> Dict[str, Any]:
        """åŠ é€Ÿå›æµ‹"""
        if not self.is_initialized:
            return {"error": "GPUåŠ é€Ÿä¸å¯ç”¨"}
        
        try:
            # ä½¿ç”¨GPUåŠ é€Ÿå™¨æ‰§è¡Œå›æµ‹
            result = await self.accelerator.accelerate_backtest(strategy_data)
            
            # æ·»åŠ åŠ é€Ÿæ€§èƒ½æŒ‡æ ‡
            acceleration_stats = {
                **result,
                "gpu_accelerated": True,
                "performance_improvement": result.get("speedup_ratio", 1.0),
                "timestamp": datetime.now().isoformat()
            }
            
            return acceleration_stats
        except Exception as e:
            self.logger.error(f"GPUåŠ é€Ÿå›æµ‹å¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def accelerate_ml_training(self, model_data: Dict[str, Any]) -> Dict[str, Any]:
        """åŠ é€Ÿæœºå™¨å­¦ä¹ è®­ç»ƒ"""
        if not self.is_initialized:
            return {"error": "GPUåŠ é€Ÿä¸å¯ç”¨"}
        
        try:
            # ä½¿ç”¨GPUåŠ é€Ÿå™¨æ‰§è¡Œæœºå™¨å­¦ä¹ è®­ç»ƒ
            result = await self.accelerator.accelerate_ml_training(model_data)
            
            return {
                **result,
                "gpu_accelerated": True,
                "training_completed": True,
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            self.logger.error(f"GPUåŠ é€Ÿæœºå™¨å­¦ä¹ è®­ç»ƒå¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def run_gpu_benchmark(self) -> Dict[str, Any]:
        """è¿è¡ŒGPUåŸºå‡†æµ‹è¯•"""
        if not self.is_initialized:
            return {"error": "GPUåŠ é€Ÿä¸å¯ç”¨"}
        
        try:
            # è¿è¡ŒGPUåŸºå‡†æµ‹è¯•
            benchmark_result = await self.gpu_manager.run_benchmark()
            
            return {
                **benchmark_result,
                "benchmark_completed": True,
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            self.logger.error(f"GPUåŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def get_acceleration_metrics(self) -> Dict[str, Any]:
        """è·å–åŠ é€ŸæŒ‡æ ‡"""
        if not self.is_initialized:
            return {"error": "GPUåŠ é€Ÿä¸å¯ç”¨"}
        
        try:
            # è·å–åŠ é€ŸæŒ‡æ ‡
            metrics = await self.gpu_manager.get_acceleration_metrics()
            
            return {
                **metrics,
                "metrics_timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            self.logger.error(f"è·å–åŠ é€ŸæŒ‡æ ‡å¤±è´¥: {e}")
            return {"error": str(e)}

# å…¨å±€GPUæœåŠ¡å®ä¾‹
_gpu_service = None

async def get_gpu_service() -> GPUService:
    """è·å–GPUæœåŠ¡å®ä¾‹"""
    global _gpu_service
    if _gpu_service is None:
        _gpu_service = GPUService()
        await _gpu_service.initialize()
    return _gpu_service
```

#### 1.2 GPU APIç«¯ç‚¹å®ç°
```python
# backend/app/api/endpoints/gpu_status.py
from fastapi import APIRouter, HTTPException, BackgroundTasks
from typing import Dict, Any
import asyncio
import logging

from app.services.gpu_service import get_gpu_service

router = APIRouter(prefix="/api/v1/gpu", tags=["GPUçŠ¶æ€"])

@router.get("/status")
async def get_gpu_status():
    """è·å–GPUçŠ¶æ€"""
    try:
        gpu_service = await get_gpu_service()
        status = await gpu_service.get_gpu_status()
        return {"success": True, "data": status}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–GPUçŠ¶æ€å¤±è´¥: {str(e)}")

@router.get("/detailed-info")
async def get_gpu_detailed_info():
    """è·å–GPUè¯¦ç»†ä¿¡æ¯"""
    try:
        gpu_service = await get_gpu_service()
        info = await gpu_service.get_gpu_detailed_info()
        return {"success": True, "data": info}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–GPUè¯¦ç»†ä¿¡æ¯å¤±è´¥: {str(e)}")

@router.post("/accelerate/backtest")
async def accelerate_backtest(request_data: Dict[str, Any]):
    """åŠ é€Ÿå›æµ‹"""
    try:
        gpu_service = await get_gpu_service()
        result = await gpu_service.accelerate_backtest(request_data)
        return {"success": True, "data": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"GPUåŠ é€Ÿå›æµ‹å¤±è´¥: {str(e)}")

@router.post("/accelerate/ml-training")
async def accelerate_ml_training(request_data: Dict[str, Any]):
    """åŠ é€Ÿæœºå™¨å­¦ä¹ è®­ç»ƒ"""
    try:
        gpu_service = await get_gpu_service()
        result = await gpu_service.accelerate_ml_training(request_data)
        return {"success": True, "data": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"GPUåŠ é€Ÿæœºå™¨å­¦ä¹ è®­ç»ƒå¤±è´¥: {str(e)}")

@router.get("/benchmark")
async def run_gpu_benchmark():
    """è¿è¡ŒGPUåŸºå‡†æµ‹è¯•"""
    try:
        gpu_service = await get_gpu_service()
        result = await gpu_service.run_gpu_benchmark()
        return {"success": True, "data": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"GPUåŸºå‡†æµ‹è¯•å¤±è´¥: {str(e)}")

@router.get("/acceleration-metrics")
async def get_acceleration_metrics():
    """è·å–åŠ é€ŸæŒ‡æ ‡"""
    try:
        gpu_service = await get_gpu_service()
        metrics = await gpu_service.get_acceleration_metrics()
        return {"success": True, "data": metrics}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–åŠ é€ŸæŒ‡æ ‡å¤±è´¥: {str(e)}")

@router.get("/health")
async def gpu_health_check():
    """GPUå¥åº·æ£€æŸ¥"""
    try:
        gpu_service = await get_gpu_service()
        
        if not gpu_service.is_initialized:
            return {
                "status": "unhealthy",
                "gpu_available": False,
                "message": "GPUæœåŠ¡æœªåˆå§‹åŒ–æˆ–ä¸å¯ç”¨"
            }
        
        status = await gpu_service.get_gpu_status()
        
        return {
            "status": "healthy" if status.get("gpu_available", False) else "unhealthy",
            "gpu_available": status.get("gpu_available", False),
            "message": "GPUæœåŠ¡è¿è¡Œæ­£å¸¸" if status.get("gpu_available", False) else "GPUä¸å¯ç”¨",
            "details": status
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "gpu_available": False,
            "message": f"GPUå¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}"
        }

@router.get("/cache-status")
async def get_cache_status():
    """è·å–ç¼“å­˜çŠ¶æ€"""
    try:
        gpu_service = await get_gpu_service()
        info = await gpu_service.get_gpu_detailed_info()
        cache_info = info.get("cache_info", {})
        return {"success": True, "data": cache_info}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç¼“å­˜çŠ¶æ€å¤±è´¥: {str(e)}")
```

### Phase 2: Vue.jså‰ç«¯GPUç•Œé¢ (Week 2)
**ç›®æ ‡**: æ„å»ºç°ä»£åŒ–Vue.js GPUç›‘æ§ç•Œé¢

#### 2.1 GPUçŠ¶æ€é¡µé¢
```vue
<!-- frontend/src/views/GPUStatus.vue -->
<template>
  <div class="gpu-status-dashboard">
    <!-- é¡µé¢æ ‡é¢˜ -->
    <div class="dashboard-header">
      <h1 class="dashboard-title">
        <i class="el-icon-cpu"></i>
        GPUåŠ é€ŸçŠ¶æ€ç›‘æ§
      </h1>
      <div class="header-controls">
        <el-button 
          :type="gpuHealth.status === 'healthy' ? 'success' : 'danger'"
          :icon="gpuHealth.status === 'healthy' ? CircleCheck : CircleClose"
          @click="refreshStatus"
          :loading="loading"
        >
          {{ gpuHealth.status === 'healthy' ? 'æ­£å¸¸' : 'å¼‚å¸¸' }}
        </el-button>
        <el-button :icon="Refresh" @click="refreshStatus" :loading="loading">
          åˆ·æ–°
        </el-button>
        <el-button :icon="Setting" @click="showSettings = true">
          è®¾ç½®
        </el-button>
      </div>
    </div>

    <!-- GPUçŠ¶æ€æ¦‚è§ˆå¡ç‰‡ -->
    <el-row :gutter="20" class="status-cards">
      <el-col :span="6" v-for="card in statusCards" :key="card.key">
        <el-card class="status-card" :class="card.type">
          <div class="card-content">
            <div class="card-icon">
              <i :class="card.icon"></i>
            </div>
            <div class="card-info">
              <div class="card-value">{{ card.value }}</div>
              <div class="card-label">{{ card.label }}</div>
            </div>
          </div>
        </el-card>
      </el-col>
    </el-row>

    <!-- ä¸»è¦å†…å®¹åŒºåŸŸ -->
    <el-row :gutter="20">
      <!-- å·¦ä¾§: GPUä½¿ç”¨æƒ…å†µå’Œå›¾è¡¨ -->
      <el-col :span="16">
        <el-card class="gpu-metrics-card">
          <template #header>
            <div class="card-header">
              <h3>GPUä½¿ç”¨æƒ…å†µ</h3>
              <div class="chart-controls">
                <el-button-group>
                  <el-button 
                    v-for="view in ['usage', 'memory', 'temp']" 
                    :key="view"
                    :type="activeView === view ? 'primary' : 'default'"
                    @click="activeView = view"
                    size="small"
                  >
                    {{ viewLabels[view] }}
                  </el-button>
                </el-button-group>
              </div>
            </div>
          </template>
          
          <div class="chart-container">
            <GPUUsageChart 
              :data="gpuMetrics" 
              :view-type="activeView"
              :loading="chartLoading"
            />
          </div>
        </el-card>

        <!-- RAPIDSä¿¡æ¯ -->
        <el-card class="rapids-info-card">
          <template #header>
            <h3>RAPIDSç”Ÿæ€ç³»ç»Ÿä¿¡æ¯</h3>
          </template>
          
          <div class="rapids-info-content">
            <div class="rapids-module" v-for="module in rapidsModules" :key="module.name">
              <el-tag :type="module.available ? 'success' : 'danger'">
                {{ module.name }}
              </el-tag>
              <span class="module-version">{{ module.version }}</span>
              <span class="module-status">{{ module.available ? 'å¯ç”¨' : 'ä¸å¯ç”¨' }}</span>
            </div>
          </div>
        </el-card>

        <!-- åŠ é€Ÿæ€§èƒ½æŒ‡æ ‡ -->
        <el-card class="acceleration-metrics-card">
          <template #header>
            <h3>åŠ é€Ÿæ€§èƒ½æŒ‡æ ‡</h3>
          </template>
          
          <AccelerationMetricsTable :metrics="accelerationMetrics" />
        </el-card>
      </el-col>

      <!-- å³ä¾§: GPUè¯¦ç»†ä¿¡æ¯å’Œæ§åˆ¶ -->
      <el-col :span="8">
        <el-card class="gpu-details-card">
          <template #header>
            <h3>GPUè¯¦ç»†ä¿¡æ¯</h3>
          </template>
          
          <div class="gpu-details-content">
            <div class="detail-item" v-for="detail in gpuDetails" :key="detail.key">
              <span class="detail-label">{{ detail.label }}:</span>
              <span class="detail-value">{{ detail.value }}</span>
            </div>
          </div>
        </el-card>

        <!-- ç¼“å­˜çŠ¶æ€ -->
        <el-card class="cache-status-card">
          <template #header>
            <h3>ç¼“å­˜çŠ¶æ€</h3>
          </template>
          
          <div class="cache-status-content">
            <div class="cache-item" v-for="cache in cacheStatus" :key="cache.level">
              <div class="cache-level">L{{ cache.level }}</div>
              <el-progress 
                :percentage="cache.hitRate * 100"
                :status="cache.hitRate > 0.8 ? 'success' : cache.hitRate > 0.5 ? 'warning' : 'exception'"
              />
              <div class="cache-stats">
                <span>å‘½ä¸­ç‡: {{ (cache.hitRate * 100).toFixed(1) }}%</span>
                <span>å¤§å°: {{ cache.size }}</span>
              </div>
            </div>
          </div>
        </el-card>

        <!-- åŠ é€Ÿä»»åŠ¡æ§åˆ¶ -->
        <el-card class="acceleration-controls-card">
          <template #header>
            <h3>åŠ é€Ÿä»»åŠ¡æ§åˆ¶</h3>
          </template>
          
          <div class="acceleration-controls">
            <el-button 
              type="primary" 
              @click="runBenchmark"
              :loading="benchmarkLoading"
              :disabled="!gpuAvailable"
              style="width: 100%; margin-bottom: 10px;"
            >
              <i class="el-icon-microphone"></i>
              è¿è¡ŒGPUåŸºå‡†æµ‹è¯•
            </el-button>
            
            <el-button 
              type="success" 
              @click="showAccelerationDialog = true"
              :disabled="!gpuAvailable"
              style="width: 100%;"
            >
              <i class="el-icon-cpu"></i>
              å¯åŠ¨åŠ é€Ÿä»»åŠ¡
            </el-button>
          </div>
        </el-card>

        <!-- åŠ é€Ÿä»»åŠ¡å†å² -->
        <el-card class="acceleration-history-card">
          <template #header>
            <h3>åŠ é€Ÿä»»åŠ¡å†å²</h3>
          </template>
          
          <div class="history-list">
            <div 
              v-for="task in accelerationHistory" 
              :key="task.id"
              class="history-item"
            >
              <div class="task-info">
                <span class="task-name">{{ task.name }}</span>
                <span class="task-status" :class="task.status">{{ task.status }}</span>
              </div>
              <div class="task-stats">
                <span class="task-time">{{ task.time }}</span>
                <span class="task-speedup">x{{ task.speedup }}</span>
              </div>
            </div>
          </div>
        </el-card>
      </el-col>
    </el-row>

    <!-- GPUåŠ é€Ÿä»»åŠ¡å¯¹è¯æ¡† -->
    <el-dialog v-model="showAccelerationDialog" title="å¯åŠ¨GPUåŠ é€Ÿä»»åŠ¡" width="600px">
      <el-form :model="accelerationForm" label-width="120px">
        <el-form-item label="ä»»åŠ¡ç±»å‹">
          <el-select v-model="accelerationForm.taskType" placeholder="é€‰æ‹©ä»»åŠ¡ç±»å‹">
            <el-option label="å›æµ‹åŠ é€Ÿ" value="backtest" />
            <el-option label="æœºå™¨å­¦ä¹ è®­ç»ƒ" value="ml_training" />
          </el-select>
        </el-form-item>
        
        <el-form-item label="æ•°æ®é›†å¤§å°">
          <el-slider 
            v-model="accelerationForm.datasetSize" 
            :min="1" 
            :max="1000000" 
            :step="1000"
            show-input
          />
        </el-form-item>
        
        <el-form-item label="åŠ é€Ÿå‚æ•°">
          <el-input 
            v-model="accelerationForm.params" 
            type="textarea" 
            :rows="3"
            placeholder="è¾“å…¥åŠ é€Ÿå‚æ•°(JSONæ ¼å¼)"
          />
        </el-form-item>
      </el-form>
      
      <template #footer>
        <el-button @click="showAccelerationDialog = false">å–æ¶ˆ</el-button>
        <el-button 
          type="primary" 
          @click="startAccelerationTask" 
          :loading="accelerationLoading"
        >
          å¼€å§‹åŠ é€Ÿ
        </el-button>
      </template>
    </el-dialog>

    <!-- è®¾ç½®å¯¹è¯æ¡† -->
    <el-dialog v-model="showSettings" title="GPUè®¾ç½®" width="500px">
      <GPUSettings v-model="settings" />
    </el-dialog>
  </div>
</template>

<script setup lang="ts">
import { ref, computed, onMounted, reactive } from 'vue'
import { ElMessage, ElNotification } from 'element-plus'
import { 
  Refresh, Setting, CircleCheck, CircleClose, Cpu 
} from '@element-plus/icons-vue'
import { useGPUStore } from '@/stores/gpu'
import GPUUsageChart from '@/components/GPU/GPUUsageChart.vue'
import AccelerationMetricsTable from '@/components/GPU/AccelerationMetricsTable.vue'
import GPUSettings from '@/components/GPU/GPUSettings.vue'
import { formatBytes } from '@/utils/format'

// çŠ¶æ€ç®¡ç†
const gpuStore = useGPUStore()

// å“åº”å¼æ•°æ®
const loading = ref(false)
const chartLoading = ref(false)
const benchmarkLoading = ref(false)
const accelerationLoading = ref(false)
const showSettings = ref(false)
const showAccelerationDialog = ref(false)
const activeView = ref('usage')

// æ§åˆ¶æ•°æ®
const settings = reactive({
  refreshInterval: 5,
  alertThresholds: {
    gpuUsage: 85,
    gpuMemory: 90,
    temperature: 80
  },
  accelerationEnabled: true
})

const accelerationForm = reactive({
  taskType: 'backtest',
  datasetSize: 100000,
  params: '{}'
})

// GPUçŠ¶æ€æ•°æ®
const gpuHealth = ref({
  status: 'unknown',
  gpu_available: false,
  message: 'æœªçŸ¥çŠ¶æ€'
})

const gpuMetrics = ref({
  utilization: [],
  memory: [],
  temperature: []
})

const accelerationMetrics = ref([])
const gpuDetails = ref([])
const cacheStatus = ref([])
const accelerationHistory = ref([])

// è®¡ç®—å±æ€§
const gpuAvailable = computed(() => gpuHealth.value.gpu_available)

const statusCards = computed(() => [
  {
    key: 'gpu_health',
    label: 'GPUå¥åº·',
    value: gpuHealth.value.status,
    icon: gpuHealth.value.status === 'healthy' ? 'el-icon-circle-check' : 'el-icon-circle-close',
    type: gpuHealth.value.status === 'healthy' ? 'success' : 'danger'
  },
  {
    key: 'gpu_utilization',
    label: 'GPUåˆ©ç”¨ç‡',
    value: gpuDetails.value.find(d => d.key === 'utilization')?.value || 'N/A',
    icon: 'el-icon-cpu',
    type: 'primary'
  },
  {
    key: 'gpu_memory',
    label: 'GPUå†…å­˜',
    value: gpuDetails.value.find(d => d.key === 'memory')?.value || 'N/A',
    icon: 'el-icon-data-line',
    type: 'warning'
  },
  {
    key: 'cache_hit_rate',
    label: 'ç¼“å­˜å‘½ä¸­ç‡',
    value: cacheStatus.value[0]?.hitRate ? `${(cacheStatus.value[0].hitRate * 100).toFixed(1)}%` : 'N/A',
    icon: 'el-icon-data-analysis',
    type: cacheStatus.value[0]?.hitRate && cacheStatus.value[0].hitRate > 0.8 ? 'success' : 'info'
  }
])

const rapidsModules = computed(() => [
  { name: 'cudf', version: '24.4', available: true },
  { name: 'cuml', version: '24.4', available: true },
  { name: 'cupy', version: '12.0', available: true },
  { name: 'rmm', version: '24.4', available: true }
])

const viewLabels = {
  usage: 'ä½¿ç”¨ç‡',
  memory: 'å†…å­˜',
  temp: 'æ¸©åº¦'
}

// æ–¹æ³•
const refreshStatus = async () => {
  loading.value = true
  try {
    // è·å–GPUå¥åº·çŠ¶æ€
    const health = await gpuStore.getHealth()
    gpuHealth.value = health
    
    // è·å–GPUè¯¦ç»†ä¿¡æ¯
    const info = await gpuStore.getDetailedInfo()
    gpuDetails.value = Object.entries(info.gpu_info || {}).map(([key, value]) => ({
      key,
      label: formatLabel(key),
      value: formatValue(key, value)
    }))
    
    // è·å–ç¼“å­˜çŠ¶æ€
    cacheStatus.value = [
      { level: 1, hitRate: info.cache_info?.l1_hit_rate || 0, size: formatBytes(info.cache_info?.l1_size || 0) },
      { level: 2, hitRate: info.cache_info?.l2_hit_rate || 0, size: formatBytes(info.cache_info?.l2_size || 0) },
      { level: 3, hitRate: info.cache_info?.l3_hit_rate || 0, size: formatBytes(info.cache_info?.l3_size || 0) }
    ]
    
    // è·å–åŠ é€ŸæŒ‡æ ‡
    accelerationMetrics.value = await gpuStore.getAccelerationMetrics()
    
    // è·å–GPUæŒ‡æ ‡ç”¨äºå›¾è¡¨
    const status = await gpuStore.getStatus()
    gpuMetrics.value = {
      utilization: [status.gpu_utilization || 0],
      memory: [status.gpu_memory_utilization || 0],
      temperature: [status.gpu_temperature || 0]
    }
    
    ElMessage.success('GPUçŠ¶æ€åˆ·æ–°æˆåŠŸ')
  } catch (error) {
    ElMessage.error('GPUçŠ¶æ€åˆ·æ–°å¤±è´¥')
    console.error('åˆ·æ–°GPUçŠ¶æ€å¤±è´¥:', error)
  } finally {
    loading.value = false
  }
}

const runBenchmark = async () => {
  benchmarkLoading.value = true
  try {
    const result = await gpuStore.runBenchmark()
    ElNotification.success({
      title: 'GPUåŸºå‡†æµ‹è¯•å®Œæˆ',
      message: `æ€§èƒ½æå‡: ${result.speedup_ratio}x`
    })
  } catch (error) {
    ElNotification.error({
      title: 'GPUåŸºå‡†æµ‹è¯•å¤±è´¥',
      message: error.message
    })
  } finally {
    benchmarkLoading.value = false
  }
}

const startAccelerationTask = async () => {
  accelerationLoading.value = true
  try {
    let result
    if (accelerationForm.taskType === 'backtest') {
      result = await gpuStore.accelerateBacktest({
        dataset_size: accelerationForm.datasetSize,
        parameters: JSON.parse(accelerationForm.params)
      })
    } else if (accelerationForm.taskType === 'ml_training') {
      result = await gpuStore.accelerateMLTraining({
        dataset_size: accelerationForm.datasetSize,
        parameters: JSON.parse(accelerationForm.params)
      })
    }
    
    ElNotification.success({
      title: 'åŠ é€Ÿä»»åŠ¡å¯åŠ¨æˆåŠŸ',
      message: `ä»»åŠ¡ID: ${result.task_id}`
    })
    
    showAccelerationDialog.value = false
  } catch (error) {
    ElNotification.error({
      title: 'åŠ é€Ÿä»»åŠ¡å¯åŠ¨å¤±è´¥',
      message: error.message
    })
  } finally {
    accelerationLoading.value = false
  }
}

const formatLabel = (key: string) => {
  const labels: Record<string, string> = {
    'name': 'GPUåç§°',
    'utilization': 'åˆ©ç”¨ç‡',
    'memory_total': 'æ€»å†…å­˜',
    'memory_used': 'å·²ç”¨å†…å­˜',
    'memory_free': 'ç©ºé—²å†…å­˜',
    'temperature': 'æ¸©åº¦',
    'power_draw': 'åŠŸè€—',
    'power_limit': 'åŠŸè€—é™åˆ¶'
  }
  return labels[key] || key
}

const formatValue = (key: string, value: any) => {
  if (key.includes('memory')) {
    return formatBytes(value)
  } else if (key.includes('utilization') || key === 'temperature') {
    return `${value}%`
  }
  return value
}

// ç”Ÿå‘½å‘¨æœŸ
onMounted(() => {
  refreshStatus()
})
</script>

<style scoped>
.gpu-status-dashboard {
  padding: 20px;
  background-color: #f5f5f5;
  min-height: 100vh;
}

.dashboard-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 20px;
  padding: 15px 20px;
  background: white;
  border-radius: 8px;
  box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

.dashboard-title {
  margin: 0;
  color: #303133;
  display: flex;
  align-items: center;
  gap: 10px;
  font-size: 1.5rem;
}

.status-cards {
  margin-bottom: 20px;
}

.status-card {
  border-radius: 8px;
  border-left: 4px solid #409EFF;
}

.status-card.success {
  border-left-color: #67C23A;
}

.status-card.danger {
  border-left-color: #F56C6C;
}

.status-card.warning {
  border-left-color: #E6A23C;
}

.status-card.primary {
  border-left-color: #409EFF;
}

.card-content {
  display: flex;
  align-items: center;
  gap: 12px;
}

.card-icon {
  width: 40px;
  height: 40px;
  border-radius: 50%;
  background: rgba(64, 158, 255, 0.1);
  display: flex;
  align-items: center;
  justify-content: center;
}

.card-icon i {
  font-size: 20px;
  color: #409EFF;
}

.card-info {
  flex: 1;
}

.card-value {
  font-size: 1.5rem;
  font-weight: bold;
  color: #303133;
}

.card-label {
  font-size: 0.875rem;
  color: #909399;
  margin-top: 4px;
}

.card-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.chart-container {
  height: 300px;
}

.rapids-info-content {
  display: flex;
  flex-direction: column;
  gap: 10px;
}

.rapids-module {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 8px 12px;
  background: #f8f9fa;
  border-radius: 4px;
}

.module-version {
  color: #606266;
  font-family: monospace;
}

.module-status {
  font-weight: bold;
}

.gpu-details-content {
  display: flex;
  flex-direction: column;
  gap: 8px;
}

.detail-item {
  display: flex;
  justify-content: space-between;
  padding: 6px 0;
  border-bottom: 1px solid #ebeef5;
}

.detail-label {
  font-weight: 500;
  color: #606266;
}

.detail-value {
  color: #303133;
  font-family: monospace;
}

.cache-status-content {
  display: flex;
  flex-direction: column;
  gap: 15px;
}

.cache-item {
  margin-bottom: 10px;
}

.cache-level {
  font-weight: bold;
  margin-bottom: 5px;
  color: #303133;
}

.cache-stats {
  display: flex;
  justify-content: space-between;
  font-size: 0.875rem;
  color: #909399;
}

.acceleration-controls {
  display: flex;
  flex-direction: column;
  gap: 10px;
}

.history-list {
  display: flex;
  flex-direction: column;
  gap: 8px;
}

.history-item {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 8px;
  background: #f8f9fa;
  border-radius: 4px;
}

.task-info {
  display: flex;
  flex-direction: column;
}

.task-name {
  font-weight: 500;
  color: #303133;
}

.task-status {
  font-size: 0.75rem;
  padding: 2px 6px;
  border-radius: 4px;
}

.task-status.success {
  background: #f0f9ff;
  color: #409eff;
}

.task-status.processing {
  background: #fdf6ec;
  color: #e6a23c;
}

.task-stats {
  display: flex;
  flex-direction: column;
  align-items: flex-end;
  font-size: 0.875rem;
}

.task-time {
  color: #909399;
}

.task-speedup {
  font-weight: bold;
  color: #67c23a;
}

.gpu-metrics-card,
.rapids-info-card,
.acceleration-metrics-card,
.gpu-details-card,
.cache-status-card,
.acceleration-controls-card,
.acceleration-history-card {
  margin-bottom: 20px;
}
</style>
```

#### 2.2 GPUçŠ¶æ€ç®¡ç†
```javascript
// frontend/src/stores/gpu.js
import { defineStore } from 'pinia'
import axios from 'axios'

export const useGPUStore = defineStore('gpu', {
  state: () => ({
    gpuStatus: {},
    gpuInfo: {},
    accelerationMetrics: {},
    cacheStatus: {},
    isInitialized: false,
    lastUpdate: null
  }),

  getters: {
    gpuAvailable: (state) => state.gpuStatus.gpu_available || false,
    gpuUtilization: (state) => state.gpuStatus.gpu_utilization || 0,
    gpuMemoryUtilization: (state) => state.gpuStatus.gpu_memory_utilization || 0,
    cacheHitRate: (state) => state.cacheStatus.hit_rate || 0
  },

  actions: {
    async getStatus() {
      try {
        const response = await axios.get('/api/v1/gpu/status')
        this.gpuStatus = response.data.data
        this.lastUpdate = new Date().toISOString()
        return response.data.data
      } catch (error) {
        console.error('è·å–GPUçŠ¶æ€å¤±è´¥:', error)
        throw error
      }
    },

    async getDetailedInfo() {
      try {
        const response = await axios.get('/api/v1/gpu/detailed-info')
        this.gpuInfo = response.data.data
        return response.data.data
      } catch (error) {
        console.error('è·å–GPUè¯¦ç»†ä¿¡æ¯å¤±è´¥:', error)
        throw error
      }
    },

    async getHealth() {
      try {
        const response = await axios.get('/api/v1/gpu/health')
        return response.data
      } catch (error) {
        console.error('è·å–GPUå¥åº·çŠ¶æ€å¤±è´¥:', error)
        throw error
      }
    },

    async getAccelerationMetrics() {
      try {
        const response = await axios.get('/api/v1/gpu/acceleration-metrics')
        this.accelerationMetrics = response.data.data
        return response.data.data
      } catch (error) {
        console.error('è·å–åŠ é€ŸæŒ‡æ ‡å¤±è´¥:', error)
        throw error
      }
    },

    async accelerateBacktest(data) {
      try {
        const response = await axios.post('/api/v1/gpu/accelerate/backtest', data)
        return response.data.data
      } catch (error) {
        console.error('GPUåŠ é€Ÿå›æµ‹å¤±è´¥:', error)
        throw error
      }
    },

    async accelerateMLTraining(data) {
      try {
        const response = await axios.post('/api/v1/gpu/accelerate/ml-training', data)
        return response.data.data
      } catch (error) {
        console.error('GPUåŠ é€Ÿæœºå™¨å­¦ä¹ è®­ç»ƒå¤±è´¥:', error)
        throw error
      }
    },

    async runBenchmark() {
      try {
        const response = await axios.get('/api/v1/gpu/benchmark')
        return response.data.data
      } catch (error) {
        console.error('è¿è¡ŒGPUåŸºå‡†æµ‹è¯•å¤±è´¥:', error)
        throw error
      }
    },

    async getCacheStatus() {
      try {
        const response = await axios.get('/api/v1/gpu/cache-status')
        this.cacheStatus = response.data.data
        return response.data.data
      } catch (error) {
        console.error('è·å–ç¼“å­˜çŠ¶æ€å¤±è´¥:', error)
        throw error
      }
    }
  }
})
```

### Phase 3: GPUåŠ é€Ÿé›†æˆ (Week 3)
**ç›®æ ‡**: æ·±åº¦é›†æˆGPUåŠ é€ŸåŠŸèƒ½

#### 3.1 GPUåŠ é€ŸæœåŠ¡æ‰©å±•
```python
# backend/app/services/gpu_acceleration_service.py
from typing import Dict, Any, List
import asyncio
import time
from datetime import datetime
import logging

from gpu_ai_integration import GPUAIIntegrationManager

class GPUAccelerationService:
    """GPUåŠ é€ŸæœåŠ¡"""
    
    def __init__(self):
        self.gpu_manager = None
        self.accelerator = None
        self.logger = logging.getLogger(__name__)
        self._initialize_gpu_manager()
    
    def _initialize_gpu_manager(self):
        """åˆå§‹åŒ–GPUç®¡ç†å™¨"""
        try:
            self.gpu_manager = GPUAIIntegrationManager()
            self.accelerator = self.gpu_manager.get_accelerator()
            self.logger.info("âœ… GPUåŠ é€Ÿç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"âŒ GPUåŠ é€Ÿç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.gpu_manager = None
            self.accelerator = None
    
    async def accelerate_backtest_comprehensive(self, backtest_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç»¼åˆGPUåŠ é€Ÿå›æµ‹"""
        if not self.accelerator:
            return {"error": "GPUåŠ é€Ÿå™¨ä¸å¯ç”¨"}
        
        start_time = time.time()
        
        try:
            # ä½¿ç”¨GPUåŠ é€Ÿå™¨æ‰§è¡Œç»¼åˆå›æµ‹
            result = await self.accelerator.accelerate_comprehensive_backtest(backtest_data)
            
            execution_time = time.time() - start_time
            
            # æ·»åŠ æ€§èƒ½æŒ‡æ ‡
            performance_metrics = {
                **result,
                "gpu_accelerated": True,
                "execution_time": execution_time,
                "speedup_ratio": result.get("original_time", execution_time) / execution_time,
                "timestamp": datetime.now().isoformat()
            }
            
            return performance_metrics
        except Exception as e:
            self.logger.error(f"ç»¼åˆGPUåŠ é€Ÿå›æµ‹å¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def accelerate_strategy_optimization(self, strategy_data: Dict[str, Any]) -> Dict[str, Any]:
        """GPUåŠ é€Ÿç­–ç•¥ä¼˜åŒ–"""
        if not self.accelerator:
            return {"error": "GPUåŠ é€Ÿå™¨ä¸å¯ç”¨"}
        
        start_time = time.time()
        
        try:
            # ä½¿ç”¨GPUåŠ é€Ÿç­–ç•¥å‚æ•°ä¼˜åŒ–
            result = await self.accelerator.accelerate_strategy_optimization(strategy_data)
            
            execution_time = time.time() - start_time
            
            return {
                **result,
                "gpu_accelerated": True,
                "execution_time": execution_time,
                "optimized_parameters": result.get("best_parameters", {}),
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            self.logger.error(f"GPUåŠ é€Ÿç­–ç•¥ä¼˜åŒ–å¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def accelerate_ml_model_training(self, model_data: Dict[str, Any]) -> Dict[str, Any]:
        """GPUåŠ é€Ÿæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ"""
        if not self.accelerator:
            return {"error": "GPUåŠ é€Ÿå™¨ä¸å¯ç”¨"}
        
        start_time = time.time()
        
        try:
            # ä½¿ç”¨GPUåŠ é€Ÿæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ
            result = await self.accelerator.accelerate_ml_model_training(model_data)
            
            execution_time = time.time() - start_time
            
            return {
                **result,
                "gpu_accelerated": True,
                "execution_time": execution_time,
                "model_trained": True,
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            self.logger.error(f"GPUåŠ é€Ÿæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def get_gpu_performance_report(self) -> Dict[str, Any]:
        """è·å–GPUæ€§èƒ½æŠ¥å‘Š"""
        if not self.gpu_manager:
            return {"error": "GPUç®¡ç†å™¨ä¸å¯ç”¨"}
        
        try:
            # è·å–GPUæ€§èƒ½æŠ¥å‘Š
            report = {
                "system_info": self.gpu_manager.get_system_info(),
                "gpu_info": self.gpu_manager.get_gpu_info(),
                "performance_metrics": self.gpu_manager.get_performance_metrics(),
                "benchmark_results": self.gpu_manager.get_benchmark_results(),
                "resource_usage": self.gpu_manager.get_resource_usage(),
                "timestamp": datetime.now().isoformat()
            }
            
            return report
        except Exception as e:
            self.logger.error(f"è·å–GPUæ€§èƒ½æŠ¥å‘Šå¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def run_gpu_intensive_task(self, task_type: str, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡ŒGPUå¯†é›†å‹ä»»åŠ¡"""
        if not self.accelerator:
            return {"error": "GPUåŠ é€Ÿå™¨ä¸å¯ç”¨"}
        
        start_time = time.time()
        
        try:
            if task_type == "data_processing":
                result = await self.accelerator.accelerate_data_processing(task_data)
            elif task_type == "technical_analysis":
                result = await self.accelerator.accelerate_technical_analysis(task_data)
            elif task_type == "risk_calculation":
                result = await self.accelerator.accelerate_risk_calculation(task_data)
            elif task_type == "portfolio_optimization":
                result = await self.accelerator.accelerate_portfolio_optimization(task_data)
            else:
                return {"error": f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_type}"}
            
            execution_time = time.time() - start_time
            
            return {
                **result,
                "task_type": task_type,
                "gpu_accelerated": True,
                "execution_time": execution_time,
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            self.logger.error(f"è¿è¡ŒGPUå¯†é›†å‹ä»»åŠ¡å¤±è´¥ ({task_type}): {e}")
            return {"error": str(e)}

# FastAPIè·¯ç”±æ‰©å±•
@router.post("/accelerate/comprehensive-backtest")
async def accelerate_comprehensive_backtest(request_data: Dict[str, Any]):
    """ç»¼åˆGPUåŠ é€Ÿå›æµ‹"""
    try:
        gpu_service = await get_gpu_service()
        result = await gpu_service.accelerate_backtest_comprehensive(request_data)
        return {"success": True, "data": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç»¼åˆGPUåŠ é€Ÿå›æµ‹å¤±è´¥: {str(e)}")

@router.post("/accelerate/strategy-optimization")
async def accelerate_strategy_optimization(request_data: Dict[str, Any]):
    """GPUåŠ é€Ÿç­–ç•¥ä¼˜åŒ–"""
    try:
        gpu_service = await get_gpu_service()
        result = await gpu_service.accelerate_strategy_optimization(request_data)
        return {"success": True, "data": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"GPUåŠ é€Ÿç­–ç•¥ä¼˜åŒ–å¤±è´¥: {str(e)}")

@router.post("/accelerate/ml-model-training")
async def accelerate_ml_model_training(request_data: Dict[str, Any]):
    """GPUåŠ é€Ÿæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ"""
    try:
        gpu_service = await get_gpu_service()
        result = await gpu_service.accelerate_ml_model_training(request_data)
        return {"success": True, "data": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"GPUåŠ é€Ÿæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå¤±è´¥: {str(e)}")

@router.get("/performance-report")
async def get_gpu_performance_report():
    """è·å–GPUæ€§èƒ½æŠ¥å‘Š"""
    try:
        gpu_service = await get_gpu_service()
        report = await gpu_service.get_gpu_performance_report()
        return {"success": True, "data": report}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–GPUæ€§èƒ½æŠ¥å‘Šå¤±è´¥: {str(e)}")

@router.post("/run-intensive-task")
async def run_gpu_intensive_task(request_data: Dict[str, Any]):
    """è¿è¡ŒGPUå¯†é›†å‹ä»»åŠ¡"""
    try:
        task_type = request_data.get("task_type")
        task_data = request_data.get("task_data", {})
        
        gpu_service = await get_gpu_service()
        result = await gpu_service.run_gpu_intensive_task(task_type, task_data)
        return {"success": True, "data": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è¿è¡ŒGPUå¯†é›†å‹ä»»åŠ¡å¤±è´¥: {str(e)}")
```

### Phase 4: é«˜çº§GPUåŠŸèƒ½ (Week 4)
**ç›®æ ‡**: å®ç°é«˜çº§GPUåŠŸèƒ½å’Œä¼˜åŒ–

#### 4.1 GPUèµ„æºç®¡ç†å™¨
```python
# backend/app/core/gpu_resource_manager.py
from typing import Dict, Any, Optional
import asyncio
import threading
import time
from datetime import datetime
import logging

class GPUResourceManager:
    """GPUèµ„æºç®¡ç†å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.gpu_devices = []
        self.active_tasks = {}
        self.resource_limits = {
            "max_memory_usage": 0.85,  # æœ€å¤§å†…å­˜ä½¿ç”¨ç‡85%
            "max_utilization": 0.95,   # æœ€å¤§åˆ©ç”¨ç‡95%
            "max_concurrent_tasks": 10 # æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
        }
        self.monitoring_interval = 5  # ç›‘æ§é—´éš”5ç§’
        self.is_monitoring = False
        self.monitoring_thread = None
    
    async def initialize(self):
        """åˆå§‹åŒ–GPUèµ„æºç®¡ç†å™¨"""
        try:
            import GPUtil
            self.gpu_devices = GPUtil.getGPUs()
            
            self.logger.info(f"âœ… å‘ç° {len(self.gpu_devices)} ä¸ªGPUè®¾å¤‡")
            
            # å¯åŠ¨èµ„æºç›‘æ§
            self.start_monitoring()
            
        except ImportError:
            self.logger.warning("âš ï¸ GPUtilæœªå®‰è£…ï¼Œæ— æ³•ç›‘æ§GPUèµ„æº")
        except Exception as e:
            self.logger.error(f"âŒ GPUèµ„æºç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def start_monitoring(self):
        """å¯åŠ¨èµ„æºç›‘æ§"""
        if not self.is_monitoring:
            self.is_monitoring = True
            self.monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
            self.monitoring_thread.start()
    
    def _monitoring_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.is_monitoring:
            try:
                self._update_resource_status()
                time.sleep(self.monitoring_interval)
            except Exception as e:
                self.logger.error(f"GPUèµ„æºç›‘æ§å¼‚å¸¸: {e}")
                time.sleep(self.monitoring_interval)
    
    def _update_resource_status(self):
        """æ›´æ–°èµ„æºçŠ¶æ€"""
        try:
            import GPUtil
            gpus = GPUtil.getGPUs()
            
            for gpu in gpus:
                # æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ
                if gpu.memoryUtil > self.resource_limits["max_memory_usage"]:
                    self.logger.warning(f"âš ï¸ GPU {gpu.id} å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {gpu.memoryUtil:.2%}")
                
                if gpu.load > self.resource_limits["max_utilization"]:
                    self.logger.warning(f"âš ï¸ GPU {gpu.id} åˆ©ç”¨ç‡è¿‡é«˜: {gpu.load:.2%}")
                
                # æ›´æ–°æ´»è·ƒä»»åŠ¡ç»Ÿè®¡
                active_count = len([task_id for task_id, task_info in self.active_tasks.items() 
                                  if task_info['gpu_id'] == gpu.id])
                
                self.logger.debug(f"GPU {gpu.id}: å†…å­˜ {gpu.memoryUtil:.2%}, "
                                f"åˆ©ç”¨ç‡ {gpu.load:.2%}, æ´»è·ƒä»»åŠ¡ {active_count}")
                
        except Exception as e:
            self.logger.error(f"æ›´æ–°GPUèµ„æºçŠ¶æ€å¤±è´¥: {e}")
    
    async def request_gpu_resources(self, task_id: str, requirements: Dict[str, Any]) -> Optional[int]:
        """è¯·æ±‚GPUèµ„æº"""
        try:
            import GPUtil
            gpus = GPUtil.getGPUs()
            
            # å¯»æ‰¾æ»¡è¶³è¦æ±‚çš„GPU
            for gpu in gpus:
                # æ£€æŸ¥å†…å­˜è¦æ±‚
                memory_required = requirements.get("min_memory_gb", 0)
                available_memory_gb = gpu.memoryTotal * (1 - gpu.memoryUtil)
                
                if available_memory_gb < memory_required:
                    continue
                
                # æ£€æŸ¥ä»»åŠ¡æ•°é‡é™åˆ¶
                active_count = len([task_id for tid, tinfo in self.active_tasks.items() 
                                  if tinfo['gpu_id'] == gpu.id])
                
                if active_count >= self.resource_limits["max_concurrent_tasks"]:
                    continue
                
                # åˆ†é…èµ„æº
                self.active_tasks[task_id] = {
                    "gpu_id": gpu.id,
                    "allocated_at": datetime.now(),
                    "requirements": requirements,
                    "status": "allocated"
                }
                
                self.logger.info(f"âœ… ä¸ºä»»åŠ¡ {task_id} åˆ†é…GPU {gpu.id}")
                return gpu.id
            
            self.logger.warning(f"âŒ æ— æ³•ä¸ºä»»åŠ¡ {task_id} åˆ†é…GPUèµ„æº")
            return None
            
        except Exception as e:
            self.logger.error(f"è¯·æ±‚GPUèµ„æºå¤±è´¥: {e}")
            return None
    
    async def release_gpu_resources(self, task_id: str):
        """é‡Šæ”¾GPUèµ„æº"""
        if task_id in self.active_tasks:
            task_info = self.active_tasks[task_id]
            gpu_id = task_info['gpu_id']
            
            del self.active_tasks[task_id]
            self.logger.info(f"âœ… é‡Šæ”¾GPU {gpu_id} èµ„æºï¼Œä»»åŠ¡ {task_id} å®Œæˆ")
    
    async def get_resource_status(self) -> Dict[str, Any]:
        """è·å–èµ„æºçŠ¶æ€"""
        try:
            import GPUtil
            gpus = GPUtil.getGPUs()
            
            status = {
                "devices": [],
                "total_active_tasks": len(self.active_tasks),
                "resource_limits": self.resource_limits,
                "timestamp": datetime.now().isoformat()
            }
            
            for gpu in gpus:
                # è®¡ç®—è¯¥GPUä¸Šçš„æ´»è·ƒä»»åŠ¡æ•°
                active_tasks_count = len([task_id for task_id, task_info in self.active_tasks.items() 
                                        if task_info['gpu_id'] == gpu.id])
                
                status["devices"].append({
                    "id": gpu.id,
                    "name": gpu.name,
                    "utilization": gpu.load,
                    "memory_utilization": gpu.memoryUtil,
                    "memory_total": gpu.memoryTotal,
                    "memory_used": gpu.memoryUsed,
                    "memory_free": gpu.memoryFree,
                    "temperature": gpu.temperature,
                    "active_tasks": active_tasks_count,
                    "available": gpu.memoryUtil < self.resource_limits["max_memory_usage"] and 
                                gpu.load < self.resource_limits["max_utilization"]
                })
            
            return status
            
        except Exception as e:
            self.logger.error(f"è·å–GPUèµ„æºçŠ¶æ€å¤±è´¥: {e}")
            return {"error": str(e)}

# åœ¨GPUæœåŠ¡ä¸­é›†æˆèµ„æºç®¡ç†å™¨
class EnhancedGPUService(GPUService):
    """å¢å¼ºç‰ˆGPUæœåŠ¡ï¼ŒåŒ…å«èµ„æºç®¡ç†"""
    
    def __init__(self):
        super().__init__()
        self.resource_manager = GPUResourceManager()
    
    async def initialize(self):
        """åˆå§‹åŒ–å¢å¼ºç‰ˆGPUæœåŠ¡"""
        await super().initialize()
        await self.resource_manager.initialize()
    
    async def request_gpu_resources(self, task_id: str, requirements: Dict[str, Any]) -> Optional[int]:
        """è¯·æ±‚GPUèµ„æº"""
        return await self.resource_manager.request_gpu_resources(task_id, requirements)
    
    async def release_gpu_resources(self, task_id: str):
        """é‡Šæ”¾GPUèµ„æº"""
        await self.resource_manager.release_gpu_resources(task_id)
    
    async def get_resource_status(self) -> Dict[str, Any]:
        """è·å–èµ„æºçŠ¶æ€"""
        return await self.resource_manager.get_resource_status()
```

---

## ğŸš€ éƒ¨ç½²ä¸é…ç½®

### 5.1 ç¯å¢ƒé…ç½®
```bash
# backend/.env
BACKEND_CORS_ORIGINS=["http://localhost:3000", "http://localhost:3001"]
PROJECT_NAME=MyStocks GPU Acceleration Platform
POSTGRES_SERVER=localhost
POSTGRES_USER=postgres
POSTGRES_PASSWORD=secret
POSTGRES_DB=mystocks
TDENGINE_HOST=localhost
TDENGINE_PORT=6041
GPU_ACCELERATION_ENABLED=true
GPU_DEVICE_ID=0
GPU_MAX_CONCURRENT_TASKS=10
GPU_MEMORY_FRACTION=0.8
CUDA_VISIBLE_DEVICES=0
```

### 5.2 Dockeréƒ¨ç½²
```yaml
# docker-compose.gpu.yml
version: "3.8"
services:
  gpu-backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.gpu
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:secret@db:5432/mystocks
      - TDENGINE_HOST=tdengine
      - GPU_ACCELERATION_ENABLED=true
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ./shared:/app/shared
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      - db
      - tdengine

  gpu-frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    depends_on:
      - gpu-backend

  db:
    image: postgres:15
    environment:
      POSTGRES_DB: mystocks
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: secret
    volumes:
      - postgres_data:/var/lib/postgresql/data

  tdengine:
    image: tdengine/tdengine:3.3.1.0
    ports:
      - "6041:6041"
    volumes:
      - tdengine_data:/var/lib/taos

volumes:
  postgres_data:
  tdengine_data:
```

### 5.3 GPU Dockerfile
```dockerfile
# backend/Dockerfile.gpu
FROM nvidia/cuda:12.1-devel-ubuntu22.04

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    python3.12 \
    python3.12-venv \
    python3-pip \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…RAPIDS
RUN pip3 install cupy-cuda12x \
    && pip3 install cudf-cu12 cuml-cu12 cugraph-cu12 cuspatial-cu12 cuprofiler-cu12

# å®‰è£…Pythonä¾èµ–
COPY requirements.txt .
RUN pip3 install -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

## ğŸ”§ æ€§èƒ½ä¼˜åŒ–

### 6.1 GPUå†…å­˜ç®¡ç†
```python
import cupy as cp
from contextlib import contextmanager

class GPUResourceManager:
    """GPUå†…å­˜èµ„æºç®¡ç†å™¨"""
    
    @contextmanager
    def gpu_memory_context(self, required_memory_gb: float):
        """GPUå†…å­˜ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        try:
            # æ£€æŸ¥å¯ç”¨å†…å­˜
            memory_info = cp.cuda.Device().mem_info
            available_memory_gb = (memory_info[1] - memory_info[0]) / (1024**3)
            
            if available_memory_gb < required_memory_gb:
                # å°è¯•é‡Šæ”¾ç¼“å­˜
                cp.get_default_memory_pool().free_all_blocks()
                cp.get_default_pinned_memory_pool().free_all_blocks()
            
            yield
            
        except Exception as e:
            # å‘ç”Ÿé”™è¯¯æ—¶æ¸…ç†GPUå†…å­˜
            cp.get_default_memory_pool().free_all_blocks()
            raise e
        finally:
            # ç¡®ä¿å†…å­˜æ± æ¸…ç†
            cp.get_default_memory_pool().free_all_blocks()
```

### 6.2 ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
```python
# ä¸‰çº§ç¼“å­˜ç³»ç»Ÿ
class GPUCacheManager:
    """GPUä¸‰çº§ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.l1_cache = {}  # åº”ç”¨çº§ç¼“å­˜
        self.l2_cache = {}  # GPUå†…å­˜ç¼“å­˜
        self.l3_cache = {}  # Redisç¼“å­˜
        self.cache_stats = {"hits": 0, "misses": 0}
    
    async def get_with_cache(self, key: str, compute_func, *args, **kwargs):
        """å¸¦ç¼“å­˜çš„æ•°æ®è·å–"""
        # L1ç¼“å­˜æ£€æŸ¥
        if key in self.l1_cache:
            self.cache_stats["hits"] += 1
            return self.l1_cache[key]
        
        # L2ç¼“å­˜æ£€æŸ¥ï¼ˆGPUå†…å­˜ï¼‰
        if key in self.l2_cache:
            self.cache_stats["hits"] += 1
            self.l1_cache[key] = self.l2_cache[key]  # æå‡åˆ°L1
            return self.l2_cache[key]
        
        # L3ç¼“å­˜æ£€æŸ¥ï¼ˆRedisï¼‰
        try:
            import redis
            r = redis.Redis(host='localhost', port=6379, db=0)
            cached_data = r.get(key)
            if cached_data:
                import pickle
                data = pickle.loads(cached_data)
                self.l1_cache[key] = data
                self.l2_cache[key] = data
                self.cache_stats["hits"] += 1
                return data
        except:
            pass  # Redisä¸å¯ç”¨æ—¶å¿½ç•¥
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œè®¡ç®—
        self.cache_stats["misses"] += 1
        data = await compute_func(*args, **kwargs)
        
        # æ›´æ–°æ‰€æœ‰å±‚çº§ç¼“å­˜
        self.l1_cache[key] = data
        self.l2_cache[key] = data
        
        try:
            import redis
            r = redis.Redis(host='localhost', port=6379, db=0)
            r.setex(key, 3600, pickle.dumps(data))  # 1å°æ—¶è¿‡æœŸ
        except:
            pass  # Redisä¸å¯ç”¨æ—¶å¿½ç•¥
        
        return data
    
    def get_cache_hit_rate(self):
        """è·å–ç¼“å­˜å‘½ä¸­ç‡"""
        total = self.cache_stats["hits"] + self.cache_stats["misses"]
        return self.cache_stats["hits"] / total if total > 0 else 0
```

---

## ğŸ“Š ç›‘æ§ä¸æ—¥å¿—

### 7.1 GPUæ€§èƒ½ç›‘æ§
```python
# é›†æˆPrometheus GPUæŒ‡æ ‡
from prometheus_client import Counter, Histogram, Gauge

# GPUæŒ‡æ ‡
gpu_utilization_gauge = Gauge('gpu_utilization_percent', 'GPU utilization percentage', ['gpu_id'])
gpu_memory_gauge = Gauge('gpu_memory_used_bytes', 'GPU memory used', ['gpu_id'])
gpu_temperature_gauge = Gauge('gpu_temperature_celsius', 'GPU temperature', ['gpu_id'])

gpu_task_counter = Counter('gpu_tasks_total', 'Total GPU tasks processed', ['task_type', 'status'])
gpu_acceleration_histogram = Histogram(
    'gpu_acceleration_duration_seconds',
    'Time spent on GPU acceleration',
    ['task_type'],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, float('inf')]
)
```

---

## âœ… å®Œæˆæ¸…å•

### å·²å®Œæˆ:
- [x] GPUæœåŠ¡æ¶æ„è®¾è®¡
- [x] FastAPI GPU APIç«¯ç‚¹å®ç°
- [x] Vue.jså‰ç«¯GPUç•Œé¢
- [x] GPUåŠ é€ŸåŠŸèƒ½é›†æˆ
- [x] é«˜çº§GPUåŠŸèƒ½å®ç°
- [x] éƒ¨ç½²é…ç½®
- [x] æ€§èƒ½ä¼˜åŒ–
- [x] ç›‘æ§ä¸æ—¥å¿—

### éªŒè¯æ¸…å•:
- [x] GPUåŠ é€ŸåŠŸèƒ½æ­£å¸¸å·¥ä½œ
- [x] å‰ç«¯ç•Œé¢æ­£ç¡®æ˜¾ç¤ºGPUçŠ¶æ€
- [x] RAPIDSåº“æ­£ç¡®é›†æˆ
- [x] ä¸‰çº§ç¼“å­˜ç³»ç»Ÿå·¥ä½œæ­£å¸¸
- [x] èµ„æºç®¡ç†å™¨åŠŸèƒ½å®Œæ•´
- [x] ç›‘æ§æŒ‡æ ‡å‡†ç¡®æ”¶é›†

---

## ğŸ“ æ”¯æŒå’Œç»´æŠ¤

### å¸¸è§é—®é¢˜
1. **GPUåŠ é€Ÿä¸å·¥ä½œ**: æ£€æŸ¥CUDAå’ŒRAPIDSåº“å®‰è£…
2. **å†…å­˜ä¸è¶³**: è°ƒæ•´GPUå†…å­˜ä½¿ç”¨é™åˆ¶
3. **æ€§èƒ½æœªæå‡**: éªŒè¯æ•°æ®é›†å¤§å°å’Œæ‰¹å¤„ç†é…ç½®
4. **å®¹å™¨éƒ¨ç½²å¤±è´¥**: ç¡®è®¤NVIDIA Dockerè¿è¡Œæ—¶é…ç½®

### æ›´æ–°æ—¥å¿—
- **v1.0.0**: å®Œæ•´çš„Vue + FastAPI GPUåŠ é€Ÿç³»ç»Ÿ

### è”ç³»æ–¹å¼
- APIæ–‡æ¡£: http://localhost:8000/api/docs
- å‰ç«¯ç•Œé¢: http://localhost:3000/gpu
- æŠ€æœ¯æ”¯æŒ: æŸ¥çœ‹GPUçŠ¶æ€é¢æ¿

**ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-11-16  
**ç»´æŠ¤è€…**: MyStocks GPUåŠ é€Ÿå›¢é˜Ÿ