# MyStocks æ•°æ®æºç®¡ç†ä¸æ•°æ®åº“æ¶æ„è¯´æ˜

**ç‰ˆæœ¬**: 2.2.0 (Dual-Database Architecture)
**æ›´æ–°æ—¥æœŸ**: 2025-10-25
**ä½œè€…**: MyStocks é¡¹ç›®ç»„

---

## ç›®å½•

1. [æ¶æ„æ¦‚è§ˆ](#æ¶æ„æ¦‚è§ˆ)
2. [æ•°æ®æºç®¡ç†ä½“ç³»](#æ•°æ®æºç®¡ç†ä½“ç³»)
3. [Adapterå·¥ä½œé€»è¾‘](#adapterå·¥ä½œé€»è¾‘)
4. [æ•°æ®æµè½¬æœºåˆ¶](#æ•°æ®æµè½¬æœºåˆ¶)
5. [æ•°æ®åº“ç®¡ç†ç³»ç»Ÿ](#æ•°æ®åº“ç®¡ç†ç³»ç»Ÿ)
6. [å®Œæ•´æ•°æ®æµç¨‹ç¤ºä¾‹](#å®Œæ•´æ•°æ®æµç¨‹ç¤ºä¾‹)

---

## æ¶æ„æ¦‚è§ˆ

MyStocks ç³»ç»Ÿé‡‡ç”¨**åˆ†å±‚æ¶æ„**å’Œ**é€‚é…å™¨æ¨¡å¼**ï¼Œå®ç°äº†ä»æ•°æ®è·å–åˆ°å­˜å‚¨çš„å®Œæ•´è‡ªåŠ¨åŒ–æµç¨‹ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        å¤–éƒ¨æ•°æ®æºå±‚                              â”‚
â”‚  (AkShare, Baostock, TDX, efinance, easyquotation, Tushare...)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       é€‚é…å™¨å±‚ (Adapters)                        â”‚
â”‚  ç»Ÿä¸€æ¥å£: IDataSource (8ä¸ªæ ‡å‡†æ–¹æ³•)                             â”‚
â”‚  - akshare_adapter.py     - tdx_adapter.py                      â”‚
â”‚  - financial_adapter.py   - baostock_adapter.py                 â”‚
â”‚  - customer_adapter.py    - byapi_adapter.py                    â”‚
â”‚  - tushare_adapter.py     - akshare_proxy_adapter.py            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å·¥å‚å±‚ (Factory Pattern)                      â”‚
â”‚  - DataSourceFactory: åˆ›å»ºå’Œæ³¨å†Œé€‚é…å™¨                          â”‚
â”‚  - DataSourceManager: ç®¡ç†å¤šæ•°æ®æºï¼Œä¼˜å…ˆçº§åˆ‡æ¢                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ç»Ÿä¸€ç®¡ç†å±‚ (Unified Manager)                    â”‚
â”‚  - MyStocksUnifiedManager: æ ¸å¿ƒæ•°æ®ç®¡ç†å…¥å£                     â”‚
â”‚  - è‡ªåŠ¨è·¯ç”±: 23ç§æ•°æ®åˆ†ç±» â†’ 2ä¸ªæ•°æ®åº“ (TDengine/PostgreSQL)    â”‚
â”‚  - æ•…éšœæ¢å¤é˜Ÿåˆ— + ç›‘æ§é›†æˆ                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ•°æ®è®¿é—®å±‚ (Data Access)                      â”‚
â”‚  - TDengineDataAccess: é«˜é¢‘æ—¶åºæ•°æ® (tick/minute)               â”‚
â”‚  - PostgreSQLDataAccess: æ‰€æœ‰å…¶ä»–æ•°æ® (daily bars/metadata)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               ç‰©ç†æ•°æ®åº“å±‚ (Dual-Database Architecture)          â”‚
â”‚  TDengine (é«˜é¢‘æ—¶åº) | PostgreSQL+TimescaleDB (å…¶ä»–æ‰€æœ‰æ•°æ®)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æ•°æ®æºç®¡ç†ä½“ç³»

### 1. ç»Ÿä¸€æ¥å£å®šä¹‰ (IDataSource)

æ‰€æœ‰æ•°æ®æºé€‚é…å™¨å¿…é¡»å®ç° `IDataSource` æ¥å£ï¼Œç¡®ä¿ç»Ÿä¸€çš„è°ƒç”¨æ–¹å¼ï¼š

**æ¥å£ä½ç½®**: `interfaces/data_source.py`

**æ ¸å¿ƒæ–¹æ³•**ï¼ˆ8ä¸ªæ ‡å‡†æ¥å£ï¼‰:

```python
class IDataSource(abc.ABC):
    """ç»Ÿä¸€æ•°æ®æ¥å£ï¼šå®šä¹‰æ‰€æœ‰æ•°æ®æºå¿…é¡»å®ç°çš„æ–¹æ³•"""

    @abc.abstractmethod
    def get_stock_daily(self, symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
        """è·å–è‚¡ç¥¨æ—¥çº¿æ•°æ®"""
        pass

    @abc.abstractmethod
    def get_index_daily(self, symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
        """è·å–æŒ‡æ•°æ—¥çº¿æ•°æ®"""
        pass

    @abc.abstractmethod
    def get_stock_basic(self, symbol: str) -> Dict:
        """è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        pass

    @abc.abstractmethod
    def get_index_components(self, symbol: str) -> List[str]:
        """è·å–æŒ‡æ•°æˆåˆ†è‚¡"""
        pass

    @abc.abstractmethod
    def get_real_time_data(self, symbol: str) -> Union[Dict, str]:
        """è·å–å®æ—¶æ•°æ®"""
        pass

    @abc.abstractmethod
    def get_market_calendar(self, start_date: str, end_date: str) -> Union[pd.DataFrame, str]:
        """è·å–äº¤æ˜“æ—¥å†"""
        pass

    @abc.abstractmethod
    def get_financial_data(self, symbol: str, period: str = "annual") -> Union[pd.DataFrame, str]:
        """è·å–è´¢åŠ¡æ•°æ®"""
        pass

    @abc.abstractmethod
    def get_news_data(self, symbol: Optional[str] = None, limit: int = 10) -> Union[List[Dict], str]:
        """è·å–æ–°é—»æ•°æ®"""
        pass
```

### 2. å·¥å‚æ¨¡å¼ç®¡ç† (DataSourceFactory)

**å·¥å‚ä½ç½®**: `factory/data_source_factory.py`

**æ ¸å¿ƒåŠŸèƒ½**:
- æ³¨å†Œå’Œç®¡ç†æ‰€æœ‰å¯ç”¨çš„æ•°æ®æºé€‚é…å™¨
- åŠ¨æ€åˆ›å»ºæ•°æ®æºå®ä¾‹
- å®¹é”™æœºåˆ¶ï¼šå¯¼å…¥å¤±è´¥è‡ªåŠ¨è·³è¿‡

**å·¥å‚æ–¹æ³•**:

```python
class DataSourceFactory:
    """æ•°æ®æºå·¥å‚ï¼šè´Ÿè´£åˆ›å»ºå…·ä½“çš„æ•°æ®æºå¯¹è±¡"""

    @classmethod
    def create_source(cls, source_type: str) -> IDataSource:
        """æ ¹æ®ç±»å‹åˆ›å»ºæ•°æ®æº

        Args:
            source_type: æ•°æ®æºç±»å‹åç§°ï¼Œå¦‚ 'akshare' æˆ– 'tdx'

        Returns:
            IDataSource: å®ç°äº†IDataSourceæ¥å£çš„å¯¹è±¡
        """
        source_type = source_type.lower()
        if source_type not in cls._source_types:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æºç±»å‹: {source_type}")

        return cls._source_types[source_type]()

    @classmethod
    def get_available_sources(cls) -> List[str]:
        """è·å–æ‰€æœ‰å¯ç”¨çš„æ•°æ®æºç±»å‹"""
        return list(cls._source_types.keys())
```

**ä½¿ç”¨ç¤ºä¾‹**:

```python
# åˆ›å»ºAkshareæ•°æ®æº
from factory.data_source_factory import DataSourceFactory

akshare_ds = DataSourceFactory.create_source('akshare')
data = akshare_ds.get_stock_daily("000001", "2024-01-01", "2024-12-31")
```

### 3. æ•°æ®æºç®¡ç†å™¨ (DataSourceManager)

**ç®¡ç†å™¨ä½ç½®**: `adapters/data_source_manager.py`

**æ ¸å¿ƒåŠŸèƒ½**:
1. **ç»Ÿä¸€ç®¡ç†å¤šä¸ªæ•°æ®æº**: æ³¨å†Œã€è·å–ã€åˆ—å‡ºæ‰€æœ‰æ•°æ®æº
2. **ä¼˜å…ˆçº§å’Œæ•…éšœè½¬ç§»**: æŒ‰é…ç½®ä¼˜å…ˆçº§å°è¯•å¤šä¸ªæ•°æ®æº
3. **æ•°æ®éªŒè¯å’Œè´¨é‡æ£€æŸ¥**: è‡ªåŠ¨éªŒè¯è¿”å›æ•°æ®çš„å®Œæ•´æ€§
4. **ç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–**: æ”¯æŒç»“æœç¼“å­˜ï¼ˆæœªæ¥å®ç°ï¼‰

**ä¼˜å…ˆçº§é…ç½®**:

```python
# æ•°æ®æºä¼˜å…ˆçº§é…ç½®
_priority_config = {
    'real_time': ['tdx', 'akshare'],      # å®æ—¶è¡Œæƒ…ä¼˜å…ˆçº§
    'daily': ['tdx', 'akshare'],          # æ—¥çº¿æ•°æ®ä¼˜å…ˆçº§
    'financial': ['akshare', 'tdx'],      # è´¢åŠ¡æ•°æ®ä¼˜å…ˆçº§
}
```

**æ ¸å¿ƒæ–¹æ³•**:

```python
class DataSourceManager:
    def register_source(self, name: str, source: IDataSource):
        """æ³¨å†Œæ•°æ®æºé€‚é…å™¨"""
        self._sources[name] = source

    def get_real_time_data(self, symbol: str, source: Optional[str] = None) -> Union[Dict, str]:
        """è·å–å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆæ”¯æŒè‡ªåŠ¨æ•…éšœè½¬ç§»ï¼‰"""
        if source:
            # ä½¿ç”¨æŒ‡å®šæ•°æ®æº
            return self._sources[source].get_real_time_data(symbol)

        # æŒ‰ä¼˜å…ˆçº§å°è¯•å¤šä¸ªæ•°æ®æº
        for source_name in self._priority_config['real_time']:
            data_source = self._sources.get(source_name)
            if data_source:
                result = data_source.get_real_time_data(symbol)
                if isinstance(result, dict):
                    return result

        return "æ‰€æœ‰æ•°æ®æºå‡è·å–å¤±è´¥"
```

**ä½¿ç”¨ç¤ºä¾‹**:

```python
# åˆ›å»ºç®¡ç†å™¨å¹¶æ³¨å†Œå¤šä¸ªæ•°æ®æº
manager = DataSourceManager()
manager.register_source('tdx', TdxDataSource())
manager.register_source('akshare', AkshareDataSource())

# è‡ªåŠ¨æ•…éšœè½¬ç§»ï¼šä¼˜å…ˆTDXï¼Œå¤±è´¥åˆ™ç”¨AkShare
quote = manager.get_real_time_data('600519')  # ä¼˜å…ˆä½¿ç”¨TDX
df = manager.get_stock_daily('600519', '2024-01-01', '2024-12-31', source='akshare')  # æŒ‡å®šAkShare
```

---

## Adapterå·¥ä½œé€»è¾‘

### 1. é€‚é…å™¨å®ç°ç»“æ„

æ¯ä¸ªé€‚é…å™¨éƒ½éµå¾ªç›¸åŒçš„å®ç°æ¨¡å¼ï¼š

**æ–‡ä»¶ä½ç½®**: `adapters/*_adapter.py`

**æ ¸å¿ƒç»„ä»¶**:

```python
class AkshareDataSource(IDataSource):
    """Akshareæ•°æ®æºå®ç°"""

    def __init__(self, api_timeout: int = 10, max_retries: int = 3):
        """åˆå§‹åŒ–é…ç½®"""
        self.api_timeout = api_timeout
        self.max_retries = max_retries

    def _retry_api_call(self, func):
        """APIè°ƒç”¨é‡è¯•è£…é¥°å™¨"""
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(1, self.max_retries + 1):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt < self.max_retries:
                        time.sleep(RETRY_DELAY * attempt)
            raise last_exception
        return wrapper

    def get_stock_daily(self, symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
        """è·å–è‚¡ç¥¨æ—¥çº¿æ•°æ®-Akshareå®ç°"""
        # 1. è‚¡ç¥¨ä»£ç æ ¼å¼åŒ–
        stock_code = format_stock_code_for_source(symbol, 'akshare')

        # 2. æ—¥æœŸæ ¼å¼åŒ–
        start_date = normalize_date(start_date)
        end_date = normalize_date(end_date)

        # 3. è°ƒç”¨Akshare API
        df = ak.stock_zh_a_hist(
            symbol=stock_code,
            period="daily",
            start_date=start_date_fmt,
            end_date=end_date_fmt,
            adjust="qfq",
            timeout=self.api_timeout
        )

        # 4. åˆ—åæ˜ å°„å’Œæ ‡å‡†åŒ–
        df = ColumnMapper.map_columns(df, 'akshare', 'standard')

        return df
```

### 2. é€‚é…å™¨ç‰¹æ€§å¯¹æ¯”

| é€‚é…å™¨ | æ•°æ®æº | å®æ—¶æ•°æ® | å†å²æ•°æ® | è´¢åŠ¡æ•°æ® | å…è´¹ | ç¨³å®šæ€§ | v2.1æ ¸å¿ƒ |
|--------|--------|----------|----------|----------|------|--------|----------|
| **tdx_adapter** â­ | pytdx | âœ… | âœ… | âŒ | âœ… | æé«˜ | âœ… |
| **byapi_adapter** â­ | biyingapi.com | âœ… | âœ… | âœ… | âœ… | é«˜ | âœ… |
| financial_adapter | efinance + easyquotation | âœ… | âœ… | âœ… | âœ… | é«˜ | âŒ |
| akshare_adapter | akshare | âœ… | âœ… | âœ… | âœ… | é«˜ | âŒ |
| baostock_adapter | baostock | âŒ | âœ… | âœ… | âœ… | ä¸­ | âŒ |
| customer_adapter | efinance + easyquotation | âœ… | âŒ | âŒ | âœ… | é«˜ | âŒ |
| tushare_adapter | tushare | âœ… | âœ… | âœ… | éƒ¨åˆ† | é«˜ | âŒ |

### 3. æ ¸å¿ƒé€‚é…å™¨è¯¦è§£

#### TDX Adapter (é€šè¾¾ä¿¡é€‚é…å™¨) â­

**ç‰¹ç‚¹**:
- ç›´è¿é€šè¾¾ä¿¡æœåŠ¡å™¨ï¼Œæ— APIé™æµ
- æ”¯æŒå¤šå‘¨æœŸKçº¿ (1m/5m/15m/30m/1h/1d)
- æ™ºèƒ½æœåŠ¡å™¨åˆ‡æ¢å’Œé‡è¯•
- å®æ—¶è¡Œæƒ…å»¶è¿Ÿä½ï¼ˆæ¯«ç§’çº§ï¼‰

**æ ¸å¿ƒæ–¹æ³•**:
```python
class TdxDataSource(IDataSource):
    def __init__(self):
        self.api = TdxHq_API()  # è¿æ¥é€šè¾¾ä¿¡è¡Œæƒ…æœåŠ¡å™¨
        self._connect_to_best_server()

    def get_real_time_data(self, symbol: str) -> Dict:
        """è·å–å®æ—¶è¡Œæƒ…ï¼ˆç›´è¿TDXæœåŠ¡å™¨ï¼‰"""
        # è§£æå¸‚åœºå’Œä»£ç 
        market, code = self._parse_symbol(symbol)

        # è°ƒç”¨pytdx API
        quotes = self.api.get_security_quotes([(market, code)])

        return self._format_quote(quotes[0])
```

#### Financial Adapter (è´¢åŠ¡ç»¼åˆé€‚é…å™¨)

**ç‰¹ç‚¹**:
- åŒæ•°æ®æºä¿éšœï¼šefinanceï¼ˆä¸»ï¼‰+ easyquotationï¼ˆå¤‡ï¼‰
- è‡ªåŠ¨åˆ‡æ¢æ•°æ®æº
- å®Œå–„é”™è¯¯å¤„ç†

**æ ¸å¿ƒæ–¹æ³•**:
```python
class FinancialDataSource(IDataSource):
    def __init__(self):
        self.primary_source = 'efinance'
        self.backup_source = 'easyquotation'

    def get_real_time_data(self, symbol: str) -> Dict:
        """è·å–å®æ—¶è¡Œæƒ…ï¼ˆåŒæºä¿éšœï¼‰"""
        try:
            # ä¼˜å…ˆä½¿ç”¨efinance
            return self._get_from_efinance(symbol)
        except Exception as e:
            logger.warning(f"efinanceå¤±è´¥: {e}ï¼Œåˆ‡æ¢åˆ°easyquotation")
            # å¤‡ç”¨easyquotation
            return self._get_from_easyquotation(symbol)
```

### 4. å·¥å…·å‡½æ•°æ”¯æŒ

é€‚é…å™¨ä¾èµ–çš„å·¥å…·å‡½æ•°ï¼ˆä½äº `utils/` ç›®å½•ï¼‰ï¼š

#### æ—¥æœŸå¤„ç† (date_utils.py)
```python
def normalize_date(date_str: str) -> str:
    """æ ‡å‡†åŒ–æ—¥æœŸæ ¼å¼ä¸º YYYY-MM-DD"""
    # æ”¯æŒå¤šç§è¾“å…¥æ ¼å¼ï¼š20240101, 2024/01/01, 2024-01-01
    pass
```

#### ä»£ç æ ¼å¼åŒ– (symbol_utils.py)
```python
def format_stock_code_for_source(symbol: str, source: str) -> str:
    """
    æ ¹æ®æ•°æ®æºæ ¼å¼åŒ–è‚¡ç¥¨ä»£ç 

    Examples:
        format_stock_code_for_source('000001', 'akshare')  # â†’ '000001'
        format_stock_code_for_source('000001', 'tushare')  # â†’ '000001.SZ'
        format_stock_code_for_source('000001', 'tdx')      # â†’ ('0', '000001')
    """
    pass
```

#### åˆ—åæ˜ å°„ (column_mapper.py)
```python
class ColumnMapper:
    """ç»Ÿä¸€åˆ—åæ˜ å°„ï¼šå„æ•°æ®æº â†” æ ‡å‡†æ ¼å¼"""

    @staticmethod
    def map_columns(df: pd.DataFrame, from_source: str, to_source: str) -> pd.DataFrame:
        """
        åˆ—åæ˜ å°„

        Examples:
            # Akshare â†’ æ ‡å‡†æ ¼å¼
            df = ColumnMapper.map_columns(df, 'akshare', 'standard')
            # æ—¥æœŸ, å¼€ç›˜, æ”¶ç›˜ â†’ date, open, close
        """
        pass
```

---

## æ•°æ®æµè½¬æœºåˆ¶

### 1. 5å±‚æ•°æ®åˆ†ç±»ä½“ç³»

**æ ¸å¿ƒæšä¸¾**: `core.py` ä¸­çš„ `DataClassification`

ç³»ç»Ÿå°†æ‰€æœ‰é‡‘èæ•°æ®åˆ†ä¸º5å¤§ç±»åˆ«ï¼Œæ¯ç±»æœ‰ä¸åŒçš„å­˜å‚¨ç­–ç•¥ï¼š

```python
class DataClassification(Enum):
    """æ•°æ®åˆ†ç±»ä½“ç³» - åŸºäºåŒæ•°æ®åº“æ¶æ„çš„5å¤§åˆ†ç±»"""

    # ç¬¬1ç±»ï¼šå¸‚åœºæ•°æ®ï¼ˆMarket Dataï¼‰- æ—¶é—´åºåˆ—ä»·æ ¼æ•°æ®
    TICK_DATA = "tick_data"                    # Tickæ•°æ® â†’ TDengine
    MINUTE_KLINE = "minute_kline"              # åˆ†é’ŸKçº¿ â†’ TDengine
    DAILY_KLINE = "daily_kline"                # æ—¥çº¿æ•°æ® â†’ PostgreSQL+TimescaleDB
    REALTIME_QUOTES = "realtime_quotes"        # å®æ—¶è¡Œæƒ…å¿«ç…§ â†’ PostgreSQL
    DEPTH_DATA = "depth_data"                  # æ·±åº¦æ•°æ® â†’ TDengine

    # ç¬¬2ç±»ï¼šå‚è€ƒæ•°æ®ï¼ˆReference Dataï¼‰- ç›¸å¯¹é™æ€çš„æè¿°æ€§æ•°æ®
    SYMBOLS_INFO = "symbols_info"              # æ ‡çš„åˆ—è¡¨ â†’ PostgreSQL
    CONTRACT_INFO = "contract_info"            # åˆçº¦ä¿¡æ¯ â†’ PostgreSQL
    CONSTITUENT_INFO = "constituent_info"      # æˆåˆ†è‚¡ä¿¡æ¯ â†’ PostgreSQL
    TRADE_CALENDAR = "trade_calendar"          # äº¤æ˜“æ—¥å† â†’ PostgreSQL

    # ç¬¬3ç±»ï¼šè¡ç”Ÿæ•°æ®ï¼ˆDerived Dataï¼‰- é€šè¿‡åŸå§‹æ•°æ®è®¡ç®—å¾—å‡º
    TECHNICAL_INDICATORS = "technical_indicators"  # æŠ€æœ¯æŒ‡æ ‡ â†’ PostgreSQL+TimescaleDB
    QUANTITATIVE_FACTORS = "quantitative_factors"  # é‡åŒ–å› å­ â†’ PostgreSQL+TimescaleDB
    MODEL_OUTPUTS = "model_outputs"            # æ¨¡å‹è¾“å‡º â†’ PostgreSQL+TimescaleDB
    TRADING_SIGNALS = "trading_signals"        # äº¤æ˜“ä¿¡å· â†’ PostgreSQL+TimescaleDB

    # ç¬¬4ç±»ï¼šäº¤æ˜“æ•°æ®ï¼ˆTransaction Dataï¼‰- ç­–ç•¥æ‰§è¡Œå’Œè´¦æˆ·æ´»åŠ¨
    ORDER_RECORDS = "order_records"            # è®¢å•è®°å½• â†’ PostgreSQL
    TRANSACTION_RECORDS = "transaction_records" # æˆäº¤è®°å½• â†’ PostgreSQL
    POSITION_RECORDS = "position_records"      # æŒä»“è®°å½• â†’ PostgreSQL
    ACCOUNT_FUNDS = "account_funds"            # è´¦æˆ·èµ„é‡‘ â†’ PostgreSQL
    REALTIME_POSITIONS = "realtime_positions"  # å®æ—¶æŒä»“ â†’ PostgreSQL
    REALTIME_ACCOUNT = "realtime_account"      # å®æ—¶è´¦æˆ· â†’ PostgreSQL

    # ç¬¬5ç±»ï¼šå…ƒæ•°æ®ï¼ˆMeta Dataï¼‰- å…³äºæ•°æ®çš„æ•°æ®å’Œç³»ç»Ÿé…ç½®
    DATA_SOURCE_STATUS = "data_source_status"  # æ•°æ®æºçŠ¶æ€ â†’ PostgreSQL
    TASK_SCHEDULES = "task_schedules"          # ä»»åŠ¡è°ƒåº¦ â†’ PostgreSQL
    STRATEGY_PARAMETERS = "strategy_parameters" # ç­–ç•¥å‚æ•° â†’ PostgreSQL
    SYSTEM_CONFIG = "system_config"            # ç³»ç»Ÿé…ç½® â†’ PostgreSQL
```

### 2. æ•°æ®å­˜å‚¨ç­–ç•¥ (DataStorageStrategy)

**æ ¸å¿ƒç±»**: `core.py` ä¸­çš„ `DataStorageStrategy`

**è‡ªåŠ¨è·¯ç”±æ˜ å°„**:

```python
class DataStorageStrategy:
    """æ•°æ®å­˜å‚¨ç­–ç•¥æ˜ å°„ - å®ç°è‡ªåŠ¨è·¯ç”±ï¼ˆåŒæ•°æ®åº“æ¶æ„ï¼‰"""

    # æ•°æ®åˆ†ç±»åˆ°æ•°æ®åº“çš„æ˜ å°„å…³ç³»ï¼ˆ34é¡¹åˆ†ç±» â†’ 2ä¸ªæ•°æ®åº“ï¼‰
    CLASSIFICATION_TO_DATABASE = {
        # é«˜é¢‘æ—¶åºæ•°æ® (5é¡¹) â†’ TDengine
        DataClassification.TICK_DATA: DatabaseTarget.TDENGINE,
        DataClassification.MINUTE_KLINE: DatabaseTarget.TDENGINE,
        DataClassification.DEPTH_DATA: DatabaseTarget.TDENGINE,

        # æ‰€æœ‰å…¶ä»–æ•°æ® (20é¡¹) â†’ PostgreSQL
        DataClassification.DAILY_KLINE: DatabaseTarget.POSTGRESQL,
        DataClassification.REALTIME_QUOTES: DatabaseTarget.POSTGRESQL,
        DataClassification.TECHNICAL_INDICATORS: DatabaseTarget.POSTGRESQL,
        DataClassification.QUANTITATIVE_FACTORS: DatabaseTarget.POSTGRESQL,
        DataClassification.MODEL_OUTPUTS: DatabaseTarget.POSTGRESQL,
        DataClassification.TRADING_SIGNALS: DatabaseTarget.POSTGRESQL,
        DataClassification.ORDER_RECORDS: DatabaseTarget.POSTGRESQL,
        DataClassification.TRANSACTION_RECORDS: DatabaseTarget.POSTGRESQL,
        DataClassification.POSITION_RECORDS: DatabaseTarget.POSTGRESQL,
        DataClassification.ACCOUNT_FUNDS: DatabaseTarget.POSTGRESQL,
        DataClassification.REALTIME_POSITIONS: DatabaseTarget.POSTGRESQL,
        DataClassification.REALTIME_ACCOUNT: DatabaseTarget.POSTGRESQL,
        DataClassification.SYMBOLS_INFO: DatabaseTarget.POSTGRESQL,
        DataClassification.CONTRACT_INFO: DatabaseTarget.POSTGRESQL,
        DataClassification.CONSTITUENT_INFO: DatabaseTarget.POSTGRESQL,
        DataClassification.TRADE_CALENDAR: DatabaseTarget.POSTGRESQL,
        DataClassification.DATA_SOURCE_STATUS: DatabaseTarget.POSTGRESQL,
        DataClassification.TASK_SCHEDULES: DatabaseTarget.POSTGRESQL,
        DataClassification.STRATEGY_PARAMETERS: DatabaseTarget.POSTGRESQL,
        DataClassification.SYSTEM_CONFIG: DatabaseTarget.POSTGRESQL,
        # ... (å…¶ä»–PostgreSQLåˆ†ç±»)
    }

    @classmethod
    def get_target_database(cls, classification: DataClassification) -> DatabaseTarget:
        """æ ¹æ®æ•°æ®åˆ†ç±»è·å–ç›®æ ‡æ•°æ®åº“ï¼ˆé»˜è®¤PostgreSQLï¼‰"""
        return cls.CLASSIFICATION_TO_DATABASE.get(classification, DatabaseTarget.POSTGRESQL)
```

**æ•°æ®åº“é€‰æ‹©ä¾æ®**ï¼ˆåŒæ•°æ®åº“æ¶æ„ï¼‰:

| æ•°æ®åº“ | é€‚ç”¨åœºæ™¯ | æ•°æ®åˆ†ç±»æ•° | æ ¸å¿ƒä¼˜åŠ¿ |
|--------|---------|-----------|---------|
| **TDengine** | Tickæ•°æ®ã€åˆ†é’Ÿçº¿ã€æ·±åº¦æ•°æ® | 5é¡¹ | æè‡´å‹ç¼©(20:1)ã€é«˜å†™å…¥æ€§èƒ½(ç™¾ä¸‡æ¡/ç§’)ã€åŸç”Ÿæ—¶åºä¼˜åŒ– |
| **PostgreSQL** | æ—¥çº¿æ•°æ®ã€æŠ€æœ¯æŒ‡æ ‡ã€å‚è€ƒæ•°æ®ã€å…ƒæ•°æ® | 29é¡¹ | TimescaleDBæ—¶åºä¼˜åŒ–ã€å¤æ‚æŸ¥è¯¢ã€ACIDä¿è¯ã€æˆç†Ÿç”Ÿæ€ |

### 3. ç»Ÿä¸€ç®¡ç†å™¨ (MyStocksUnifiedManager)

**æ ¸å¿ƒç±»**: `unified_manager.py` ä¸­çš„ `MyStocksUnifiedManager`

**æ ¸å¿ƒåŠŸèƒ½**:
1. **è‡ªåŠ¨è·¯ç”±**: æ ¹æ®æ•°æ®åˆ†ç±»è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ•°æ®åº“
2. **ç»Ÿä¸€æ¥å£**: 2è¡Œä»£ç å®Œæˆä¿å­˜/åŠ è½½æ“ä½œ
3. **æ•…éšœæ¢å¤**: æ•°æ®åº“ä¸å¯ç”¨æ—¶è‡ªåŠ¨æ’é˜Ÿï¼Œæ•°æ®ä¸ä¸¢å¤±
4. **ç›‘æ§é›†æˆ**: æ‰€æœ‰æ“ä½œè‡ªåŠ¨è®°å½•åˆ°ç›‘æ§æ•°æ®åº“

**æ ¸å¿ƒæ–¹æ³•**:

```python
class MyStocksUnifiedManager:
    def __init__(self, enable_monitoring: bool = True):
        """åˆå§‹åŒ–ç»Ÿä¸€ç®¡ç†å™¨ï¼ˆåŒæ•°æ®åº“æ¶æ„ï¼‰"""
        # åˆå§‹åŒ–2ä¸ªæ•°æ®è®¿é—®å±‚
        self.tdengine = TDengineDataAccess()
        self.postgresql = PostgreSQLDataAccess()

        # åˆå§‹åŒ–æ•…éšœæ¢å¤é˜Ÿåˆ—
        self.recovery_queue = FailureRecoveryQueue()

        # åˆå§‹åŒ–ç›‘æ§ç»„ä»¶ï¼ˆä½¿ç”¨PostgreSQLï¼‰
        if enable_monitoring:
            self.monitoring_db = get_monitoring_database()
            self.performance_monitor = get_performance_monitor()
            self.quality_monitor = get_quality_monitor()

    def save_data_by_classification(
        self,
        classification: DataClassification,
        data: pd.DataFrame,
        table_name: str,
        **kwargs
    ) -> bool:
        """
        æŒ‰åˆ†ç±»ä¿å­˜æ•°æ® (æ ¸å¿ƒæ–¹æ³• #1)

        æ ¹æ®æ•°æ®åˆ†ç±»è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ•°æ®åº“å¹¶ä¿å­˜æ•°æ®ã€‚
        æ”¯æŒåŒæ•°æ®åº“æ¶æ„ï¼šTDengineï¼ˆé«˜é¢‘æ—¶åºï¼‰å’Œ PostgreSQLï¼ˆå…¶ä»–æ‰€æœ‰æ•°æ®ï¼‰
        """
        # 1. è·å–ç›®æ ‡æ•°æ®åº“
        target_db = DataStorageStrategy.get_target_database(classification)

        # 2. è·¯ç”±åˆ°å¯¹åº”çš„æ•°æ®è®¿é—®å±‚ï¼ˆä»…2ä¸ªé€‰é¡¹ï¼‰
        if target_db == DatabaseTarget.TDENGINE:
            rows = self.tdengine.insert_dataframe(table_name, data, **kwargs)
        elif target_db == DatabaseTarget.POSTGRESQL:
            rows = self.postgresql.insert_dataframe(table_name, data)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®åº“ç±»å‹: {target_db}")

        # 3. è®°å½•ç›‘æ§æ•°æ®
        if self.enable_monitoring:
            self.monitoring_db.log_operation(...)

        return True

    def load_data_by_classification(
        self,
        classification: DataClassification,
        table_name: str,
        filters: Optional[Dict] = None,
        **kwargs
    ) -> pd.DataFrame:
        """
        æŒ‰åˆ†ç±»åŠ è½½æ•°æ® (æ ¸å¿ƒæ–¹æ³• #2)

        ä»åŒæ•°æ®åº“æ¶æ„ä¸­åŠ è½½æ•°æ®ã€‚
        """
        # 1. è·å–ç›®æ ‡æ•°æ®åº“
        target_db = DataStorageStrategy.get_target_database(classification)

        # 2. ä»å¯¹åº”çš„æ•°æ®è®¿é—®å±‚è¯»å–
        if target_db == DatabaseTarget.TDENGINE:
            return self.tdengine.query_dataframe(table_name, filters, **kwargs)
        elif target_db == DatabaseTarget.POSTGRESQL:
            return self.postgresql.query_dataframe(table_name, filters)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®åº“ç±»å‹: {target_db}")
```

### 4. æ•°æ®æµè½¬å®Œæ•´è·¯å¾„

```
Step 1: ç”¨æˆ·ä»£ç è°ƒç”¨
â”œâ”€ from factory.data_source_factory import DataSourceFactory
â”œâ”€ akshare_ds = DataSourceFactory.create_source('akshare')
â””â”€ df = akshare_ds.get_stock_daily("600519", "2024-01-01", "2024-12-31")
         â†“
Step 2: é€‚é…å™¨å¤„ç†
â”œâ”€ 1. ä»£ç æ ¼å¼åŒ–: format_stock_code_for_source('600519', 'akshare')
â”œâ”€ 2. æ—¥æœŸæ ¼å¼åŒ–: normalize_date('2024-01-01')
â”œâ”€ 3. APIè°ƒç”¨: ak.stock_zh_a_hist(...)
â”œâ”€ 4. åˆ—åæ˜ å°„: ColumnMapper.map_columns(df, 'akshare', 'standard')
â””â”€ 5. è¿”å›æ ‡å‡†DataFrame
         â†“
Step 3: ä¿å­˜åˆ°æ•°æ®åº“
â”œâ”€ from unified_manager import MyStocksUnifiedManager
â”œâ”€ from core import DataClassification
â”œâ”€ manager = MyStocksUnifiedManager()
â””â”€ manager.save_data_by_classification(
      DataClassification.DAILY_KLINE,  # æ•°æ®åˆ†ç±»
      df,                                # æ•°æ®
      table_name='stock_daily_600519'    # è¡¨å
   )
         â†“
Step 4: è‡ªåŠ¨è·¯ç”±
â”œâ”€ DataStorageStrategy.get_target_database(DAILY_KLINE) â†’ PostgreSQL
â”œâ”€ manager.postgresql.insert_dataframe('stock_daily_600519', df)
â””â”€ è®°å½•ç›‘æ§æ—¥å¿—
         â†“
Step 5: æ•°æ®æŒä¹…åŒ–
â””â”€ PostgreSQLæ•°æ®åº“: mystocks.stock_daily_600519 è¡¨
```

---

## æ•°æ®åº“ç®¡ç†ç³»ç»Ÿ

### 1. æ•°æ®åº“ç±»å‹å’Œç”¨é€”

**Week 3 ç®€åŒ–æ›´æ–°** (2025-10-19):
- âœ… ç³»ç»Ÿä»4æ•°æ®åº“ç®€åŒ–ä¸º2æ•°æ®åº“ï¼ˆTDengine + PostgreSQLï¼‰
- âœ… MySQLæ•°æ®å·²è¿ç§»åˆ°PostgreSQLï¼ˆ18è¡¨ï¼Œ299è¡Œï¼‰
- âœ… Rediså·²ç§»é™¤ï¼ˆé…ç½®çš„db1ä¸ºç©ºï¼‰
- âœ… æ¶æ„å¤æ‚åº¦é™ä½50%
- âœ… **TDengineä¿ç•™**ï¼šä¸“é—¨å¤„ç†é«˜é¢‘æ—¶åºæ•°æ®ï¼ˆtick/minute dataï¼‰
- âœ… **PostgreSQLæ‰©å±•**ï¼šå¤„ç†æ‰€æœ‰å…¶ä»–æ•°æ®ç±»å‹ï¼ˆå«TimescaleDBï¼‰

**å½“å‰æ¶æ„**:

| æ•°æ®åº“ | çŠ¶æ€ | ç”¨é€” | æ•°æ®åˆ†ç±»æ•° | æ•°æ®ç¤ºä¾‹ |
|--------|-----|------|-----------|---------|
| **TDengine** | âœ… æ´»è·ƒ | é«˜é¢‘æ—¶åºæ•°æ® | 3é¡¹ | tick_data, minute_kline, depth_data |
| **PostgreSQL** | âœ… æ´»è·ƒ | æ‰€æœ‰å…¶ä»–æ•°æ® | 20é¡¹ | æ—¥çº¿ã€æŒ‡æ ‡ã€å‚è€ƒæ•°æ®ã€å…ƒæ•°æ® |
| MySQL | âŒ å·²åºŸå¼ƒ | - | 0é¡¹ | å·²è¿ç§»è‡³PostgreSQL |
| Redis | âŒ å·²åºŸå¼ƒ | - | 0é¡¹ | é…ç½®çš„db1ä¸ºç©º |

**æ•°æ®è·¯ç”±åˆ†å¸ƒ**ï¼ˆå…±23é¡¹æ•°æ®åˆ†ç±»ï¼‰:
- **TDengine** (3é¡¹): TICK_DATA, MINUTE_KLINE, DEPTH_DATA
- **PostgreSQL** (20é¡¹): å…¶ä»–æ‰€æœ‰æ•°æ®åˆ†ç±»

**æ–°é…ç½®**ï¼ˆè§ `.env` æ–‡ä»¶ï¼‰:
```bash
# åŒæ•°æ®åº“é…ç½®
# TDengine (é«˜é¢‘æ—¶åºæ•°æ®)
TDENGINE_HOST=192.168.123.104
TDENGINE_PORT=6030
TDENGINE_USER=root
TDENGINE_PASSWORD=taosdata
TDENGINE_DATABASE=market_data

# PostgreSQL (å…¶ä»–æ‰€æœ‰æ•°æ®)
POSTGRESQL_HOST=localhost
POSTGRESQL_USER=mystocks_user
POSTGRESQL_PASSWORD=xxxxx
POSTGRESQL_PORT=5432
POSTGRESQL_DATABASE=mystocks

# ç›‘æ§æ•°æ®åº“ï¼ˆä½¿ç”¨PostgreSQLï¼‰
MONITOR_DB_URL=postgresql://mystocks_user:xxxxx@localhost:5432/mystocks
```

### 2. æ•°æ®åº“è¡¨ç®¡ç†å™¨ (DatabaseTableManager)

**æ ¸å¿ƒç±»**: `db_manager/database_manager.py` ä¸­çš„ `DatabaseTableManager`

**ä¸»è¦åŠŸèƒ½**:
1. **åŒæ•°æ®åº“è¿æ¥ç®¡ç†**: ç»Ÿä¸€ç®¡ç†TDengineå’ŒPostgreSQLè¿æ¥æ± 
2. **è¡¨ç»“æ„ç®¡ç†**: åˆ›å»ºã€ä¿®æ”¹ã€åˆ é™¤è¡¨
3. **å…ƒæ•°æ®è®°å½•**: æ‰€æœ‰DDLæ“ä½œè®°å½•åˆ°ç›‘æ§æ•°æ®åº“
4. **ç»“æ„éªŒè¯**: å®šæœŸéªŒè¯è¡¨ç»“æ„å®Œæ•´æ€§

**æ ¸å¿ƒæ–¹æ³•**:

```python
class DatabaseTableManager:
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨ï¼ˆåŒæ•°æ®åº“æ¶æ„ï¼‰"""
        # ç›‘æ§æ•°æ®åº“è¿æ¥ï¼ˆä½¿ç”¨PostgreSQLï¼‰
        self.monitor_engine = create_engine(MONITOR_DB_URL)

        # ä»ç¯å¢ƒå˜é‡åŠ è½½åŒæ•°æ®åº“é…ç½®
        self.db_configs = {
            DatabaseType.TDENGINE: {
                'host': os.getenv('TDENGINE_HOST'),
                'user': os.getenv('TDENGINE_USER', 'root'),
                'password': os.getenv('TDENGINE_PASSWORD'),
                'port': int(os.getenv('TDENGINE_PORT', '6030'))
            },
            DatabaseType.POSTGRESQL: {
                'host': os.getenv('POSTGRESQL_HOST'),
                'user': os.getenv('POSTGRESQL_USER'),
                'password': os.getenv('POSTGRESQL_PASSWORD'),
                'port': int(os.getenv('POSTGRESQL_PORT', '5432'))
            }
        }

    def get_connection(self, db_type: DatabaseType, db_name: str, **kwargs):
        """è·å–æ•°æ®åº“è¿æ¥ï¼ˆæ”¯æŒTDengineå’ŒPostgreSQLï¼‰"""
        # éªŒè¯å¿…è¦å‚æ•°
        config = self.db_configs[db_type].copy()
        config.update(kwargs)

        # åˆ›å»ºè¿æ¥
        if db_type == DatabaseType.TDENGINE:
            import taos
            return taos.connect(
                host=config['host'],
                user=config['user'],
                password=config['password'],
                port=config['port'],
                database=db_name
            )
        elif db_type == DatabaseType.POSTGRESQL:
            return psycopg2.connect(
                host=config['host'],
                user=config['user'],
                password=config['password'],
                port=config['port'],
                database=db_name
            )

    def create_table(self, db_type: DatabaseType, db_name: str,
                    table_name: str, columns: List[Dict], **kwargs) -> bool:
        """åˆ›å»ºè¡¨"""
        # 1. ç”ŸæˆDDL
        ddl = self._generate_ddl(db_type, table_name, columns, **kwargs)

        # 2. æ‰§è¡ŒDDL
        conn = self.get_connection(db_type, db_name)
        cursor = conn.cursor()
        cursor.execute(ddl)
        conn.commit()

        # 3. è®°å½•åˆ°ç›‘æ§æ•°æ®åº“
        self._log_table_creation(table_name, db_type, db_name, ddl, 'success')

        return True
```

### 3. é…ç½®é©±åŠ¨ç®¡ç† (ConfigDrivenTableManager)

**æ ¸å¿ƒç±»**: `core.py` ä¸­çš„ `ConfigDrivenTableManager`

**æ ¸å¿ƒç†å¿µ**: æ‰€æœ‰è¡¨ç»“æ„é€šè¿‡YAMLé…ç½®æ–‡ä»¶ç®¡ç†ï¼Œé¿å…æ‰‹å·¥SQL

**é…ç½®æ–‡ä»¶**: `table_config.yaml`

**é…ç½®ç¤ºä¾‹**:

```yaml
version: "2.0.0"
description: "MyStocksé‡åŒ–äº¤æ˜“ç³»ç»Ÿè¡¨é…ç½®"

tables:
  - name: stock_daily_kline
    database_type: PostgreSQL
    database_name: mystocks
    description: è‚¡ç¥¨æ—¥çº¿æ•°æ®è¡¨
    columns:
      - name: id
        type: SERIAL
        primary_key: true
      - name: symbol
        type: VARCHAR(20)
        nullable: false
        comment: è‚¡ç¥¨ä»£ç 
      - name: trade_date
        type: DATE
        nullable: false
        comment: äº¤æ˜“æ—¥æœŸ
      - name: open
        type: DECIMAL(10,2)
        comment: å¼€ç›˜ä»·
      - name: high
        type: DECIMAL(10,2)
        comment: æœ€é«˜ä»·
      - name: low
        type: DECIMAL(10,2)
        comment: æœ€ä½ä»·
      - name: close
        type: DECIMAL(10,2)
        comment: æ”¶ç›˜ä»·
      - name: volume
        type: BIGINT
        comment: æˆäº¤é‡
    indexes:
      - columns: [symbol, trade_date]
        unique: true
```

**ä½¿ç”¨æ–¹æ³•**:

```python
from core import ConfigDrivenTableManager

# 1. åˆå§‹åŒ–ç®¡ç†å™¨ï¼ˆè‡ªåŠ¨åŠ è½½é…ç½®ï¼‰
manager = ConfigDrivenTableManager(config_file='table_config.yaml')

# 2. æ‰¹é‡åˆ›å»ºæ‰€æœ‰è¡¨
manager.batch_create_tables()

# 3. éªŒè¯è¡¨ç»“æ„
manager.validate_all_table_structures()

# 4. æŸ¥çœ‹é…ç½®æ‘˜è¦
manager.print_configuration_summary()
```

### 4. ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ

**ç›‘æ§æ•°æ®åº“ç»“æ„**:

```sql
-- è¡¨åˆ›å»ºæ—¥å¿—
CREATE TABLE table_creation_log (
    id SERIAL PRIMARY KEY,
    table_name VARCHAR(255) NOT NULL,
    database_type VARCHAR(20) NOT NULL,
    database_name VARCHAR(255) NOT NULL,
    creation_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    status VARCHAR(10) NOT NULL,
    ddl_command TEXT NOT NULL,
    error_message TEXT
);

-- è¡¨æ“ä½œæ—¥å¿—
CREATE TABLE table_operation_log (
    id SERIAL PRIMARY KEY,
    table_name VARCHAR(255) NOT NULL,
    database_type VARCHAR(20) NOT NULL,
    operation_type ENUM('CREATE', 'ALTER', 'DROP', 'VALIDATE'),
    operation_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    operation_status ENUM('success', 'failed', 'processing'),
    operation_details JSON,
    error_message TEXT
);

-- è¡¨éªŒè¯æ—¥å¿—
CREATE TABLE table_validation_log (
    id SERIAL PRIMARY KEY,
    table_name VARCHAR(255) NOT NULL,
    validation_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    validation_status VARCHAR(10) NOT NULL,
    validation_details JSON,
    issues_found TEXT
);
```

---

## å®Œæ•´æ•°æ®æµç¨‹ç¤ºä¾‹

### ç¤ºä¾‹1: è·å–å¹¶ä¿å­˜è‚¡ç¥¨æ—¥çº¿æ•°æ®

```python
# ========================================
# Step 1: å¯¼å…¥å¿…è¦çš„æ¨¡å—
# ========================================
from factory.data_source_factory import DataSourceFactory
from unified_manager import MyStocksUnifiedManager
from core import DataClassification

# ========================================
# Step 2: åˆ›å»ºæ•°æ®æºï¼ˆä½¿ç”¨å·¥å‚æ¨¡å¼ï¼‰
# ========================================
# æ–¹å¼A: ç›´æ¥åˆ›å»ºå•ä¸ªæ•°æ®æº
akshare_ds = DataSourceFactory.create_source('akshare')

# æ–¹å¼B: ä½¿ç”¨æ•°æ®æºç®¡ç†å™¨ï¼ˆæ”¯æŒæ•…éšœè½¬ç§»ï¼‰
from adapters.data_source_manager import get_default_manager
ds_manager = get_default_manager()  # è‡ªåŠ¨æ³¨å†ŒTDXå’ŒAkShare

# ========================================
# Step 3: è·å–æ•°æ®
# ========================================
# ä½¿ç”¨å•ä¸€æ•°æ®æº
df_daily = akshare_ds.get_stock_daily(
    symbol='600519',           # è´µå·èŒ…å°
    start_date='2024-01-01',
    end_date='2024-12-31'
)

# æˆ–ä½¿ç”¨ç®¡ç†å™¨ï¼ˆè‡ªåŠ¨æ•…éšœè½¬ç§»ï¼‰
df_daily = ds_manager.get_stock_daily(
    symbol='600519',
    start_date='2024-01-01',
    end_date='2024-12-31'
)  # ä¼˜å…ˆTDXï¼Œå¤±è´¥è‡ªåŠ¨åˆ‡æ¢AkShare

print(f"è·å–æ•°æ®æˆåŠŸ: {len(df_daily)}æ¡è®°å½•")
print(df_daily.head())
# è¾“å‡º:
#         date    open   high    low  close     volume
# 0  2024-01-02  1658.0  1688.8  1650.2  1678.5  15234567
# 1  2024-01-03  1679.0  1695.0  1672.0  1690.0  12456789
# ...

# ========================================
# Step 4: ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆè‡ªåŠ¨è·¯ç”±ï¼‰
# ========================================
manager = MyStocksUnifiedManager()

# ä¿å­˜æ—¥çº¿æ•°æ® â†’ è‡ªåŠ¨è·¯ç”±åˆ°PostgreSQL
success = manager.save_data_by_classification(
    classification=DataClassification.DAILY_KLINE,  # æ•°æ®åˆ†ç±»
    data=df_daily,                                   # æ•°æ®
    table_name='stock_daily_600519'                  # è¡¨å
)

# ç³»ç»Ÿè¾“å‡º:
# ğŸ“ è·¯ç”±: daily_kline â†’ POSTGRESQL
# âœ… PostgreSQLä¿å­˜æˆåŠŸ: 365è¡Œ

# ========================================
# Step 5: ä»æ•°æ®åº“åŠ è½½æ•°æ®
# ========================================
# åŠ è½½2024å¹´3æœˆçš„æ•°æ®
df_loaded = manager.load_data_by_classification(
    classification=DataClassification.DAILY_KLINE,
    table_name='stock_daily_600519',
    filters={
        'trade_date': ('>=', '2024-03-01'),
        'trade_date': ('<=', '2024-03-31')
    }
)

print(f"åŠ è½½æ•°æ®æˆåŠŸ: {len(df_loaded)}æ¡è®°å½•")
```

### ç¤ºä¾‹2: è·å–å®æ—¶è¡Œæƒ…å¹¶ä¿å­˜

```python
from adapters.data_source_manager import get_default_manager
from unified_manager import MyStocksUnifiedManager
from core import DataClassification
import pandas as pd

# 1. åˆ›å»ºæ•°æ®æºç®¡ç†å™¨
ds_manager = get_default_manager()

# 2. è·å–å®æ—¶è¡Œæƒ…ï¼ˆä¼˜å…ˆTDXï¼Œæ¯«ç§’çº§å»¶è¿Ÿï¼‰
quote = ds_manager.get_real_time_data('600519', source='tdx')

print(f"è‚¡ç¥¨åç§°: {quote['name']}")
print(f"æœ€æ–°ä»·: {quote['price']:.2f}")
print(f"æ¶¨è·Œå¹…: {quote['pct_change']:.2f}%")
print(f"æˆäº¤é‡: {quote['volume']:,}æ‰‹")

# è¾“å‡º:
# è‚¡ç¥¨åç§°: è´µå·èŒ…å°
# æœ€æ–°ä»·: 1678.50
# æ¶¨è·Œå¹…: +2.35%
# æˆäº¤é‡: 15,234,567æ‰‹

# 3. è½¬æ¢ä¸ºDataFrame
quote_df = pd.DataFrame([quote])

# 4. ä¿å­˜åˆ°æ•°æ®åº“ â†’ è‡ªåŠ¨è·¯ç”±åˆ°PostgreSQL
manager = MyStocksUnifiedManager()
manager.save_data_by_classification(
    classification=DataClassification.REALTIME_QUOTES,
    data=quote_df,
    table_name='realtime_quotes'
)

# ç³»ç»Ÿè¾“å‡º:
# ğŸ“ è·¯ç”±: realtime_quotes â†’ POSTGRESQL
# âœ… PostgreSQLä¿å­˜æˆåŠŸ: 1è¡Œ
```

### ç¤ºä¾‹3: æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨æ•°æ®

```python
from adapters.data_source_manager import get_default_manager
from unified_manager import MyStocksUnifiedManager
from core import DataClassification
import pandas as pd

# 1. åˆå§‹åŒ–
ds_manager = get_default_manager()
manager = MyStocksUnifiedManager()

# 2. è‚¡ç¥¨åˆ—è¡¨
stock_list = ['600519', '000858', '600036', '601318']  # èŒ…å°ã€äº”ç²®æ¶²ã€æ‹›è¡Œã€å¹³å®‰

# 3. æ‰¹é‡è·å–æ—¥çº¿æ•°æ®
all_data = []
for symbol in stock_list:
    print(f"æ­£åœ¨è·å– {symbol} çš„æ•°æ®...")

    df = ds_manager.get_stock_daily(
        symbol=symbol,
        start_date='2024-01-01',
        end_date='2024-12-31'
    )

    if not df.empty:
        df['symbol'] = symbol  # æ·»åŠ è‚¡ç¥¨ä»£ç åˆ—
        all_data.append(df)
        print(f"  âœ… æˆåŠŸ: {len(df)}æ¡è®°å½•")
    else:
        print(f"  âŒ å¤±è´¥æˆ–æ— æ•°æ®")

# 4. åˆå¹¶æ‰€æœ‰æ•°æ®
combined_df = pd.concat(all_data, ignore_index=True)
print(f"\nåˆå¹¶å®Œæˆ: æ€»è®¡{len(combined_df)}æ¡è®°å½•")

# 5. æ‰¹é‡ä¿å­˜åˆ°æ•°æ®åº“
success = manager.save_data_by_classification(
    classification=DataClassification.DAILY_KLINE,
    data=combined_df,
    table_name='stock_daily_multi'
)

# ç³»ç»Ÿè¾“å‡º:
# ğŸ“ è·¯ç”±: daily_kline â†’ POSTGRESQL
# âœ… PostgreSQLä¿å­˜æˆåŠŸ: 1460è¡Œ
```

### ç¤ºä¾‹4: ä½¿ç”¨é…ç½®é©±åŠ¨ç®¡ç†å™¨åˆ›å»ºè¡¨

```python
from core import ConfigDrivenTableManager

# 1. åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
manager = ConfigDrivenTableManager(config_file='table_config.yaml')

# 2. æŸ¥çœ‹é…ç½®æ‘˜è¦
manager.print_configuration_summary()

# è¾“å‡º:
# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘           MyStocks è¡¨é…ç½®æ‘˜è¦                                 â•‘
# â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
# â•‘ é…ç½®ç‰ˆæœ¬: 2.0.0                                              â•‘
# â•‘ é…ç½®æ–‡ä»¶: table_config.yaml                                  â•‘
# â•‘ è¡¨æ•°é‡: 18                                                   â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# è¡¨å                    æ•°æ®åº“ç±»å‹      æ•°æ®åº“å          åˆ—æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# stock_daily_kline       PostgreSQL      mystocks          8
# stock_minute_kline      PostgreSQL      mystocks          9
# realtime_quotes         PostgreSQL      mystocks          15
# ...

# 3. æ‰¹é‡åˆ›å»ºæ‰€æœ‰è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
print("\nå¼€å§‹æ‰¹é‡åˆ›å»ºè¡¨...")
manager.batch_create_tables()

# è¾“å‡º:
# æ­£åœ¨åˆ›å»ºè¡¨ stock_daily_kline (PostgreSQL)...
#   âœ… è¡¨åˆ›å»ºæˆåŠŸ
# æ­£åœ¨åˆ›å»ºè¡¨ stock_minute_kline (PostgreSQL)...
#   âœ… è¡¨åˆ›å»ºæˆåŠŸ
# ...
# æ‰¹é‡åˆ›å»ºå®Œæˆ: æˆåŠŸ 18, å¤±è´¥ 0

# 4. éªŒè¯æ‰€æœ‰è¡¨ç»“æ„
print("\nå¼€å§‹éªŒè¯è¡¨ç»“æ„...")
manager.validate_all_table_structures()

# è¾“å‡º:
# éªŒè¯è¡¨ stock_daily_kline...
#   âœ… ç»“æ„æ­£ç¡®
# éªŒè¯è¡¨ stock_minute_kline...
#   âœ… ç»“æ„æ­£ç¡®
# ...
# éªŒè¯å®Œæˆ: é€šè¿‡ 18, å¤±è´¥ 0
```

---

## æ€»ç»“

MyStocksç³»ç»Ÿé€šè¿‡**åˆ†å±‚æ¶æ„**å’Œ**é…ç½®é©±åŠ¨**çš„è®¾è®¡ç†å¿µï¼Œå®ç°äº†ä»æ•°æ®è·å–åˆ°å­˜å‚¨çš„å®Œæ•´è‡ªåŠ¨åŒ–æµç¨‹ï¼š

### æ ¸å¿ƒä¼˜åŠ¿

1. **ç»Ÿä¸€æ¥å£**: IDataSourceæ¥å£ä¿è¯æ‰€æœ‰æ•°æ®æºçš„ä¸€è‡´æ€§
2. **æ™ºèƒ½è·¯ç”±**: 23ç§æ•°æ®åˆ†ç±»è‡ªåŠ¨è·¯ç”±åˆ°æœ€ä¼˜æ•°æ®åº“ï¼ˆTDengineæˆ–PostgreSQLï¼‰
3. **æ•…éšœè½¬ç§»**: DataSourceManageræ”¯æŒå¤šæ•°æ®æºä¼˜å…ˆçº§å’Œè‡ªåŠ¨åˆ‡æ¢
4. **é…ç½®é©±åŠ¨**: YAMLé…ç½®ç®¡ç†æ‰€æœ‰è¡¨ç»“æ„ï¼Œé¿å…æ‰‹å·¥SQL
5. **ç›‘æ§å®Œæ•´**: æ‰€æœ‰æ“ä½œè®°å½•åˆ°ç›‘æ§æ•°æ®åº“ï¼ˆPostgreSQLï¼‰ï¼Œæ€§èƒ½å’Œè´¨é‡å¯è¿½æº¯
6. **ä¼˜åŒ–æ¶æ„**: Week 3æ›´æ–°ç®€åŒ–ä¸ºåŒæ•°æ®åº“æ¶æ„ï¼Œé™ä½50%å¤æ‚åº¦
7. **ä¸“ä¸šä¼˜åŒ–**: TDengineå¤„ç†é«˜é¢‘æ—¶åºæ•°æ®ï¼ˆæè‡´å‹ç¼©ï¼‰ï¼ŒPostgreSQLå¤„ç†å…¶ä»–æ‰€æœ‰æ•°æ®

### æ•°æ®åº“ç‰¹æ€§å¯¹æ¯”

| ç‰¹æ€§ | TDengine | PostgreSQL |
|------|---------|------------|
| **æ•°æ®åˆ†ç±»** | 3é¡¹é«˜é¢‘æ—¶åºæ•°æ® | 20é¡¹å…¶ä»–æ‰€æœ‰æ•°æ® |
| **å‹ç¼©ç‡** | 20:1ï¼ˆæè‡´å‹ç¼©ï¼‰ | 5:1ï¼ˆTimescaleDBï¼‰ |
| **å†™å…¥æ€§èƒ½** | ç™¾ä¸‡æ¡/ç§’ | åä¸‡æ¡/ç§’ |
| **æŸ¥è¯¢ä¼˜åŒ–** | æ—¶åºèŒƒå›´æŸ¥è¯¢ | å¤æ‚JOINã€èšåˆ |
| **æ•°æ®ä¿ç•™** | è‡ªåŠ¨è¿‡æœŸç­–ç•¥ | æ‰‹åŠ¨/è‡ªåŠ¨åˆ†åŒº |
| **ä½¿ç”¨åœºæ™¯** | tick/minuteæ•°æ® | daily bars/æŒ‡æ ‡/å…ƒæ•°æ® |

### å¿«é€Ÿä¸Šæ‰‹

```python
# 3è¡Œä»£ç å®Œæˆæ•°æ®è·å–å’Œä¿å­˜ï¼ˆè‡ªåŠ¨è·¯ç”±åˆ°æœ€ä¼˜æ•°æ®åº“ï¼‰
from adapters.data_source_manager import get_default_manager
from unified_manager import MyStocksUnifiedManager
from core import DataClassification

# è·å–æ•°æ®
ds_manager = get_default_manager()
df = ds_manager.get_stock_daily('600519', '2024-01-01', '2024-12-31')

# ä¿å­˜æ•°æ®ï¼ˆè‡ªåŠ¨è·¯ç”±åˆ°PostgreSQLï¼Œå› ä¸ºæ˜¯æ—¥çº¿æ•°æ®ï¼‰
manager = MyStocksUnifiedManager()
manager.save_data_by_classification(DataClassification.DAILY_KLINE, df, 'stock_daily_600519')
# ğŸ“ è·¯ç”±: daily_kline â†’ POSTGRESQL
# âœ… PostgreSQLä¿å­˜æˆåŠŸ: 365è¡Œ
```

---

**æ–‡æ¡£ç»´æŠ¤**: å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»é¡¹ç›®ç»„ã€‚
**å‚è€ƒæ–‡æ¡£**: `CLAUDE.md`, `README.md`, `adapters/README.md`
