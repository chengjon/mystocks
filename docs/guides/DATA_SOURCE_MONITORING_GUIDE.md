# æ•°æ®æºç›‘æ§ç³»ç»Ÿé›†æˆæŒ‡å—

> **ç‰ˆæœ¬**: v2.0
> **åˆ›å»ºæ—¥æœŸ**: 2026-01-02
> **ç›¸å…³ç»„ä»¶**: DataSourceManagerV2, Prometheus, Grafana

---

## ğŸ“Š æ¦‚è¿°

æ•°æ®æºç›‘æ§ç³»ç»Ÿä¸ºMyStocksçš„æ•°æ®æºç®¡ç†V2æä¾›äº†å®Œæ•´çš„å¯è§‚æµ‹æ€§ï¼ŒåŒ…æ‹¬ï¼š

- **å®æ—¶æŒ‡æ ‡**: æ•°æ®æºå¯ç”¨æ€§ã€å“åº”æ—¶é—´ã€æˆåŠŸç‡
- **å¥åº·ç›‘æ§**: è¿ç»­å¤±è´¥æ¬¡æ•°ã€è´¨é‡è¯„åˆ†ã€å¥åº·çŠ¶æ€
- **è°ƒç”¨ç»Ÿè®¡**: æ€»è°ƒç”¨æ¬¡æ•°ã€è®°å½•æ•°åˆ†å¸ƒã€é”™è¯¯ç‡
- **å¯è§†åŒ–ä»ªè¡¨æ¿**: Grafanaä»ªè¡¨æ¿å±•ç¤ºæ‰€æœ‰å…³é”®æŒ‡æ ‡

---

## ğŸ¯ æ ¸å¿ƒç»„ä»¶

### 1. Prometheus Metrics Exporter

**æ–‡ä»¶**: `src/monitoring/data_source_metrics.py`

**åŠŸèƒ½**:
- å®šä¹‰10ç§PrometheusæŒ‡æ ‡ç±»å‹ï¼ˆGauge, Counter, Histogram, Infoï¼‰
- æä¾›ä¾¿æ·çš„æ›´æ–°æ¥å£
- è‡ªåŠ¨æš´éœ²`/metrics`ç«¯ç‚¹ç»™PrometheusæŠ“å–

**æŒ‡æ ‡åˆ—è¡¨**:

| æŒ‡æ ‡åç§° | ç±»å‹ | æ ‡ç­¾ | è¯´æ˜ |
|---------|------|------|------|
| `data_source_up` | Gauge | endpoint_name, source_name, data_category | æ•°æ®æºå¯ç”¨æ€§ï¼ˆ1=å¯ç”¨ï¼Œ0=ä¸å¯ç”¨ï¼‰ |
| `data_source_response_time_seconds` | Histogram | endpoint_name, source_name | å“åº”æ—¶é—´åˆ†å¸ƒï¼ˆp50/p95/p99ï¼‰ |
| `data_source_calls_total` | Counter | endpoint_name, source_name, status | è°ƒç”¨æ€»æ¬¡æ•°ï¼ˆæŒ‰æˆåŠŸ/å¤±è´¥åˆ†ç±»ï¼‰ |
| `data_source_record_count` | Histogram | endpoint_name, source_name | è¿”å›è®°å½•æ•°åˆ†å¸ƒ |
| `data_source_success_rate` | Gauge | endpoint_name, source_name | æˆåŠŸç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰ |
| `data_source_health_status` | Gauge | endpoint_name, source_name | å¥åº·çŠ¶æ€ï¼ˆ3=å¥åº·ï¼Œ2=é™çº§ï¼Œ1=å¤±è´¥ï¼Œ0=æœªçŸ¥ï¼‰ |
| `data_source_quality_score` | Gauge | endpoint_name, source_name | è´¨é‡è¯„åˆ†ï¼ˆ0-10ï¼‰ |
| `data_source_consecutive_failures` | Gauge | endpoint_name, source_name | è¿ç»­å¤±è´¥æ¬¡æ•° |
| `data_source_total_calls` | Gauge | endpoint_name, source_name | æ€»è°ƒç”¨æ¬¡æ•° |
| `data_source_info` | Info | endpoint_name, source_name | æ•°æ®æºå…ƒæ•°æ® |

### 2. Grafana Dashboard

**æ–‡ä»¶**: `monitoring-stack/grafana-dashboards/data_source_monitoring.json`

**åŒ…å«12ä¸ªé¢æ¿**:
1. æ•°æ®æºå¯ç”¨æ€§çŠ¶æ€ï¼ˆStatï¼‰
2. æ•°æ®æºè°ƒç”¨é€Ÿç‡QPSï¼ˆTime Seriesï¼‰
3. æ•°æ®æºå¥åº·çŠ¶æ€ï¼ˆStatï¼‰
4. æ•°æ®æºå“åº”æ—¶é—´åˆ†å¸ƒï¼ˆTime Series - P50/P95/P99ï¼‰
5. æ•°æ®æºæˆåŠŸç‡è¶‹åŠ¿ï¼ˆTime Seriesï¼‰
6. æ•°æ®æºè´¨é‡è¯„åˆ†ï¼ˆStatï¼‰
7. è¿ç»­å¤±è´¥æ¬¡æ•°ï¼ˆStatï¼‰
8. æ€»è°ƒç”¨æ¬¡æ•°ï¼ˆStatï¼‰
9. æ•°æ®æºåˆ†å¸ƒæŒ‰æ¥æºï¼ˆPie Chartï¼‰
10. æ•°æ®æºåˆ†å¸ƒæŒ‰åˆ†ç±»ï¼ˆDonut Chartï¼‰
11. æ•°æ®æºè°ƒç”¨ç»Ÿè®¡è¡¨ï¼ˆTableï¼‰
12. æ•°æ®æºè¿”å›è®°å½•æ•°çƒ­åŠ›å›¾ï¼ˆHeatmapï¼‰

### 3. Metrics Server Startup Script

**æ–‡ä»¶**: `scripts/runtime/start_metrics_server.py`

**åŠŸèƒ½**:
- å¯åŠ¨Prometheus metrics HTTPæœåŠ¡å™¨ï¼ˆç«¯å£8001ï¼‰
- ä»PostgreSQLæ³¨å†Œè¡¨åŠ è½½æ‰€æœ‰æ•°æ®æº
- åˆå§‹åŒ–æ‰€æœ‰æ•°æ®æºçš„metrics
- æŒç»­æš´éœ²`/metrics`ç«¯ç‚¹

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Step 1: å¯åŠ¨MetricsæœåŠ¡å™¨

**æ–¹æ³•1: ç›´æ¥è¿è¡Œ**
```bash
cd /opt/claude/mystocks_spec
python scripts/runtime/start_metrics_server.py
```

**æ–¹æ³•2: åå°è¿è¡Œ**
```bash
nohup python scripts/runtime/start_metrics_server.py > logs/metrics_server.log 2>&1 &
```

**æ–¹æ³•3: ä½¿ç”¨PM2ç®¡ç†ï¼ˆæ¨èï¼‰**
```bash
pm2 start scripts/runtime/start_metrics_server.py --name mystocks-metrics
pm2 save
```

**éªŒè¯å¯åŠ¨**:
```bash
# æ£€æŸ¥ç«¯å£
lsof -i :8001

# æŸ¥çœ‹metrics
curl http://localhost:8001/metrics

# é¢„æœŸè¾“å‡º
# HELP data_source_up æ•°æ®æºæ˜¯å¦å¯ç”¨ï¼ˆ1=å¯ç”¨ï¼Œ0=ä¸å¯ç”¨ï¼‰
# TYPE data_source_up gauge
data_source_up{data_category="DAILY_KLINE",endpoint_name="akshare.stock_zh_a_hist",source_name="akshare"} 1.0
...
```

### Step 2: ç¡®è®¤Prometheuså·²é…ç½®æŠ“å–

**æ£€æŸ¥é…ç½®æ–‡ä»¶**: `monitoring-stack/config/prometheus.yml`

**å·²åŒ…å«çš„æŠ“å–ä»»åŠ¡**:
```yaml
- job_name: 'mystocks-data-sources'
  static_configs:
    - targets:
        - 'host.docker.internal:8001'  # æ•°æ®æºæŒ‡æ ‡æœåŠ¡å™¨ç«¯å£
      labels:
        service: 'mystocks-data-sources'
        component: 'data-source-manager'

  metrics_path: '/metrics'
  scrape_interval: 30s
```

**é‡å¯Prometheusï¼ˆå¦‚éœ€è¦ï¼‰**:
```bash
cd /opt/claude/mystocks_spec/monitoring-stack
docker-compose restart prometheus
```

**éªŒè¯æŠ“å–**:
1. è®¿é—® Prometheus: http://192.168.123.104:9090
2. è¿›å…¥ "Status" â†’ "Targets"
3. æŸ¥æ‰¾ `mystocks-data-sources` ä»»åŠ¡
4. ç¡®è®¤çŠ¶æ€ä¸º "UP"

### Step 3: å¯¼å…¥Grafanaä»ªè¡¨æ¿

**æ–¹æ³•1: é€šè¿‡UIå¯¼å…¥**
1. è®¿é—® Grafana: http://192.168.123.104:3000
2. ç™»å½•ï¼ˆadmin / mystocks2025ï¼‰
3. ç‚¹å‡» "+" â†’ "Import"
4. ä¸Šä¼ JSONæ–‡ä»¶: `monitoring-stack/grafana-dashboards/data_source_monitoring.json`
5. ç‚¹å‡» "Import"

**æ–¹æ³•2: è‡ªåŠ¨ provisioningï¼ˆæ¨èï¼‰**

é…ç½®æ–‡ä»¶å·²å­˜åœ¨äº `monitoring-stack/provisioning/dashboards/`ï¼ŒGrafanaä¼šè‡ªåŠ¨åŠ è½½ã€‚

**éªŒè¯å¯¼å…¥**:
1. è®¿é—® Grafana: http://192.168.123.104:3000
2. ç‚¹å‡» "Dashboards" â†’ "Manage"
3. æŸ¥æ‰¾ "MyStocks æ•°æ®æºç›‘æ§ä»ªè¡¨æ¿"
4. æ‰“å¼€ä»ªè¡¨æ¿æŸ¥çœ‹æŒ‡æ ‡

### Step 4: åœ¨ä»£ç ä¸­ä½¿ç”¨metrics

**ç¤ºä¾‹1: è®°å½•æ•°æ®æºè°ƒç”¨**
```python
from src.monitoring.data_source_metrics import update_call_metrics
import time

# è°ƒç”¨æ•°æ®æº
start_time = time.time()
try:
    data = fetch_data_from_api("akshare", "stock_zh_a_hist", symbol="000001")
    response_time = time.time() - start_time

    # è®°å½•æˆåŠŸè°ƒç”¨
    update_call_metrics(
        endpoint_name="akshare.stock_zh_a_hist",
        source_name="akshare",
        data_category="DAILY_KLINE",
        success=True,
        response_time=response_time,
        record_count=len(data)
    )
except Exception as e:
    response_time = time.time() - start_time

    # è®°å½•å¤±è´¥è°ƒç”¨
    update_call_metrics(
        endpoint_name="akshare.stock_zh_a_hist",
        source_name="akshare",
        data_category="DAILY_KLINE",
        success=False,
        response_time=response_time,
        error_msg=str(e)
    )
```

**ç¤ºä¾‹2: æ›´æ–°å¥åº·çŠ¶æ€**
```python
from src.monitoring.data_source_metrics import update_health_metrics

# å¥åº·æ£€æŸ¥åæ›´æ–°çŠ¶æ€
def perform_health_check(endpoint_name):
    result = check_api_health(endpoint_name)

    update_health_metrics(
        endpoint_name=endpoint_name,
        source_name="akshare",
        data_category="DAILY_KLINE",
        health_status=result['health_status'],  # healthy/degraded/failed/unknown
        quality_score=result['quality_score'],  # 0-10
        success_rate=result['success_rate'],    # 0-100
        consecutive_failures=result['consecutive_failures'],
        total_calls=result['total_calls']
    )
```

**ç¤ºä¾‹3: æ‰¹é‡æ›´æ–°ï¼ˆä»æ³¨å†Œè¡¨ï¼‰**
```python
from src.monitoring.data_source_metrics import update_all_from_registry
from src.core.data_source_manager_v2 import DataSourceManagerV2

manager = DataSourceManagerV2()

# è·å–æ‰€æœ‰æ•°æ®æº
registry_dict = manager.registry

# æ‰¹é‡æ›´æ–°æ‰€æœ‰metrics
update_all_from_registry(registry_dict)
```

---

## ğŸ“‹ ç›‘æ§æŒ‡æ ‡è¯´æ˜

### å…³é”®æŒ‡æ ‡è§£è¯»

#### 1. æ•°æ®æºå¯ç”¨æ€§ (`data_source_up`)

**å€¼**:
- `1` - æ•°æ®æºå¯ç”¨
- `0` - æ•°æ®æºä¸å¯ç”¨

**ç›‘æ§**: åº”è¯¥å§‹ç»ˆä¸º1ï¼Œå¦‚æœä¸º0è¯´æ˜æ•°æ®æºå‡ºç°é—®é¢˜

**å‘Šè­¦å»ºè®®**: è¿ç»­3æ¬¡æŠ“å–ä¸º0æ—¶è§¦å‘å‘Šè­¦

#### 2. å“åº”æ—¶é—´åˆ†å¸ƒ (`data_source_response_time_seconds`)

**å…³é”®åˆ†ä½æ•°**:
- P50 (ä¸­ä½æ•°): 50%çš„è°ƒç”¨åœ¨è¿™ä¸ªæ—¶é—´å†…å®Œæˆ
- P95: 95%çš„è°ƒç”¨åœ¨è¿™ä¸ªæ—¶é—´å†…å®Œæˆ
- P99: 99%çš„è°ƒç”¨åœ¨è¿™ä¸ªæ—¶é—´å†…å®Œæˆ

**æ­£å¸¸èŒƒå›´**:
- Mockæ•°æ®: < 0.1ç§’
- æœ¬åœ°æ•°æ®åº“: < 0.5ç§’
- å¤–éƒ¨API: 1-5ç§’ï¼ˆå–å†³äºç½‘ç»œå’Œæ•°æ®é‡ï¼‰

**å‘Šè­¦å»ºè®®**: P95 > 10ç§’æ—¶è§¦å‘å‘Šè­¦

#### 3. æˆåŠŸç‡ (`data_source_success_rate`)

**å€¼**: 0-100%

**æ­£å¸¸èŒƒå›´**: > 95%

**å‘Šè­¦å»ºè®®**:
- è­¦å‘Š: < 95%
- ä¸¥é‡: < 80%

#### 4. è¿ç»­å¤±è´¥æ¬¡æ•° (`data_source_consecutive_failures`)

**å€¼**: éè´Ÿæ•´æ•°

**å‘Šè­¦å»ºè®®**:
- è­¦å‘Š: >= 3
- ä¸¥é‡: >= 5

#### 5. å¥åº·çŠ¶æ€ (`data_source_health_status`)

**å€¼æ˜ å°„**:
- `3` = healthyï¼ˆå¥åº·ï¼‰
- `2` = degradedï¼ˆé™çº§ï¼‰
- `1` = failedï¼ˆå¤±è´¥ï¼‰
- `0` = unknownï¼ˆæœªçŸ¥ï¼‰

**å‘Šè­¦å»ºè®®**: çŠ¶æ€ä¸º1ï¼ˆfailedï¼‰æ—¶ç«‹å³å‘Šè­¦

#### 6. è´¨é‡è¯„åˆ† (`data_source_quality_score`)

**å€¼**: 0-10

**è¯„åˆ†æ ‡å‡†**:
- `9-10`: ä¼˜ç§€ï¼ˆå¿«é€Ÿã€ç¨³å®šã€æ•°æ®å®Œæ•´ï¼‰
- `7-8`: è‰¯å¥½
- `5-6`: ä¸€èˆ¬
- `0-4`: å·®ï¼ˆéœ€è¦ä¼˜åŒ–æˆ–æ›¿æ¢ï¼‰

---

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜1: MetricsæœåŠ¡å™¨æ— æ³•å¯åŠ¨

**ç—‡çŠ¶**: `Address already in use`

**è§£å†³**:
```bash
# æŸ¥æ‰¾å ç”¨ç«¯å£çš„è¿›ç¨‹
lsof -i :8001

# æ€æ­»è¿›ç¨‹
kill -9 <PID>

# æˆ–ä½¿ç”¨å…¶ä»–ç«¯å£
METRICS_PORT=8002 python scripts/runtime/start_metrics_server.py
```

### é—®é¢˜2: Prometheusæ— æ³•æŠ“å–metrics

**ç—‡çŠ¶**: Prometheus Targetsé¡µé¢æ˜¾ç¤º `mystocks-data-sources` ä¸º `DOWN`

**æ’æŸ¥æ­¥éª¤**:

1. **ç¡®è®¤metricsæœåŠ¡å™¨æ­£åœ¨è¿è¡Œ**
   ```bash
   curl http://localhost:8001/metrics
   ```

2. **ä»Prometheuså®¹å™¨å†…éƒ¨æµ‹è¯•**
   ```bash
   docker exec -it mystocks-prometheus sh
   wget -O- http://host.docker.internal:8001/metrics
   ```

3. **æ£€æŸ¥Dockerç½‘ç»œé…ç½®**
   - Linux Docker: éœ€è¦ä½¿ç”¨ `192.168.123.104:8001` è€Œä¸æ˜¯ `host.docker.internal:8001`
   - ä¿®æ”¹ `monitoring-stack/config/prometheus.yml`

4. **æŸ¥çœ‹Prometheusæ—¥å¿—**
   ```bash
   docker logs mystocks-prometheus -f
   ```

### é—®é¢˜3: Grafanaä»ªè¡¨æ¿æ²¡æœ‰æ•°æ®

**ç—‡çŠ¶**: ä»ªè¡¨æ¿å¯¼å…¥æˆåŠŸä½†æ‰€æœ‰é¢æ¿æ˜¾ç¤º "No data"

**æ’æŸ¥æ­¥éª¤**:

1. **ç¡®è®¤Prometheusæœ‰æ•°æ®**
   - è®¿é—® http://192.168.123.104:9090
   - æ‰§è¡ŒæŸ¥è¯¢: `up{job="mystocks-data-sources"}`
   - åº”è¯¥çœ‹åˆ°æ•°æ®

2. **æ£€æŸ¥Grafanaæ•°æ®æºé…ç½®**
   - Configuration â†’ Data Sources â†’ Prometheus
   - ç¡®è®¤URLæ­£ç¡®: `http://prometheus:9090`
   - ç‚¹å‡» "Test" åº”è¯¥æ˜¾ç¤º "Data source is working"

3. **æ£€æŸ¥ä»ªè¡¨æ¿æ—¶é—´èŒƒå›´**
   - ç¡®ä¿é€‰æ‹©äº†æ­£ç¡®çš„æ—¶é—´èŒƒå›´ï¼ˆå¦‚ "Last 1 hour"ï¼‰
   - ç‚¹å‡»ä»ªè¡¨æ¿å³ä¸Šè§’çš„åˆ·æ–°æŒ‰é’®

---

## ğŸ“ˆ æœ€ä½³å®è·µ

### 1. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

**ä½¿ç”¨PM2ç®¡ç†metricsæœåŠ¡å™¨**
```bash
pm2 start scripts/runtime/start_metrics_server.py \
  --name mystocks-metrics \
  --max-memory-restart 200M \
  --restart-delay 5000

pm2 save
pm2 startup
```

**é…ç½®è‡ªåŠ¨é‡å¯**
```bash
# ç›‘æ§metricsæœåŠ¡å™¨
pm2 monit

# æŸ¥çœ‹æ—¥å¿—
pm2 logs mystocks-metrics
```

### 2. ä¸DataSourceManagerV2é›†æˆ

**DataSourceManagerV2å·²å†…ç½®ç›‘æ§é›†æˆ**:

```python
from src.core.data_source_manager_v2 import DataSourceManagerV2

manager = DataSourceManagerV2()

# æ¯æ¬¡è°ƒç”¨ä¼šè‡ªåŠ¨è®°å½•metrics
data = manager.get_stock_daily(symbol="000001")

# è‡ªåŠ¨æ›´æ–°:
# - data_source_calls_total
# - data_source_response_time_seconds
# - data_source_record_count
# - data_source_up
```

**æ‰‹åŠ¨å¥åº·æ£€æŸ¥**:
```python
# æ£€æŸ¥æ‰€æœ‰æ•°æ®æº
health = manager.health_check()

# æŸ¥çœ‹ç»“æœ
print(f"æ€»è®¡: {health['total']}")
print(f"å¥åº·: {health['healthy']}")
print(f"å¼‚å¸¸: {health['unhealthy']}")
```

### 3. å®šæœŸæ›´æ–°å¥åº·çŠ¶æ€

**åˆ›å»ºå®šæ—¶ä»»åŠ¡**:
```bash
# æ·»åŠ åˆ°crontab
crontab -e

# æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
*/5 * * * * cd /opt/claude/mystocks_spec && python -c "
from src.core.data_source_manager_v2 import DataSourceManagerV2
from src.monitoring.data_source_metrics import update_all_from_registry

manager = DataSourceManagerV2()
health = manager.health_check()
print(f'å¥åº·æ£€æŸ¥å®Œæˆ: {health[\"healthy\"]}/{health[\"total\"]} å¥åº·')
"
```

---

## ğŸ“ è¿›é˜¶ä½¿ç”¨

### è‡ªå®šä¹‰Grafanaä»ªè¡¨æ¿

**åˆ›å»ºæ–°é¢æ¿**:
1. æ‰“å¼€ä»ªè¡¨æ¿ç¼–è¾‘æ¨¡å¼
2. æ·»åŠ æ–°æŸ¥è¯¢
3. ä½¿ç”¨PromQLæŸ¥è¯¢æŒ‡æ ‡

**å¸¸ç”¨PromQLæŸ¥è¯¢**:

```promql
# æŸ¥çœ‹æ‰€æœ‰æ•°æ®æºçš„å¯ç”¨æ€§
data_source_up

# æŸ¥çœ‹å“åº”æ—¶é—´çš„P95
histogram_quantile(0.95, rate(data_source_response_time_seconds_bucket[5m]))

# æŸ¥çœ‹æˆåŠŸç‡
data_source_success_rate > 95

# æŸ¥çœ‹è°ƒç”¨é€Ÿç‡
rate(data_source_calls_total[5m])

# æŸ¥çœ‹é”™è¯¯ç‡
rate(data_source_calls_total{status="failure"}[5m]) / rate(data_source_calls_total[5m])
```

### é…ç½®å‘Šè­¦

**åœ¨Prometheusä¸­é…ç½®å‘Šè­¦è§„åˆ™**:

æ–‡ä»¶: `monitoring-stack/config/rules/data_source_alerts.yml`

```yaml
groups:
  - name: data_source_alerts
    interval: 30s
    rules:
      # æ•°æ®æºä¸å¯ç”¨å‘Šè­¦
      - alert: DataSourceDown
        expr: data_source_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "æ•°æ®æº {{ $labels.endpoint_name }} ä¸å¯ç”¨"
          description: "æ•°æ®æº {{ $labels.endpoint_name }} å·²ç»è¿ç»­1åˆ†é’Ÿä¸å¯ç”¨"

      # æˆåŠŸç‡ä½å‘Šè­¦
      - alert: LowSuccessRate
        expr: data_source_success_rate < 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "æ•°æ®æº {{ $labels.endpoint_name }} æˆåŠŸç‡ä½"
          description: "æˆåŠŸç‡ {{ $value }}% ä½äº80%"

      # å“åº”æ—¶é—´é•¿å‘Šè­¦
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(data_source_response_time_seconds_bucket[5m])) > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "æ•°æ®æº {{ $labels.endpoint_name }} å“åº”æ…¢"
          description: "P95å“åº”æ—¶é—´ {{ $value }}ç§’ è¶…è¿‡10ç§’"
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **æ•°æ®æºç®¡ç†V2è®¾è®¡æ–‡æ¡£**: `docs/architecture/DATA_SOURCE_MANAGEMENT_V2.md`
- **å®æ–½æŠ¥å‘Š**: `docs/reports/DATA_SOURCE_V2_IMPLEMENTATION_REPORT.md`
- **Prometheusé…ç½®**: `monitoring-stack/config/prometheus.yml`
- **Grafanaä»ªè¡¨æ¿**: `monitoring-stack/grafana-dashboards/data_source_monitoring.json`

---

## ğŸ”— å¿«é€Ÿé“¾æ¥

- **Prometheus**: http://192.168.123.104:9090
- **Grafana**: http://192.168.123.104:3000
- **Metricsç«¯ç‚¹**: http://192.168.123.104:8001/metricsï¼ˆæœåŠ¡å™¨å¯åŠ¨åï¼‰

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-01-02
**ç»´æŠ¤è€…**: Main CLI
