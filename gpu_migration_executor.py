#!/usr/bin/env python3
"""
Phase 6.2.4 GPUè¿ç§»æ‰§è¡Œå™¨
æ‰§è¡ŒGPUå€ºåŠ¡æ–‡ä»¶çš„è¿ç§»ï¼Œå°†ç›´æ¥GPUè°ƒç”¨æ›¿æ¢ä¸ºHALå’Œå†…æ ¸æ¥å£
"""

import os
import re
from pathlib import Path
from typing import List, Dict, Any, Tuple
from datetime import datetime
from dataclasses import dataclass, field


@dataclass
class MigrationResult:
    """è¿ç§»ç»“æœ"""

    success: bool
    file_path: str
    original_lines: int
    modified_lines: int
    changes_made: List[str] = field(default_factory=list)
    errors: List[str] = field(default_factory=list)
    backup_path: str = ""


class GPUMigrationExecutor:
    """GPUè¿ç§»æ‰§è¡Œå™¨"""

    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root) if project_root else Path(".")
        self.migration_results: List[MigrationResult] = []
        self.backup_dir = self.project_root / "gpu_migration_backups"

    def execute_migration(self, target_files: List[str] = None) -> Dict[str, Any]:
        """æ‰§è¡ŒGPUè¿ç§»"""
        print("ğŸš€ å¼€å§‹GPUè¿ç§»æ‰§è¡Œ...")

        # åˆ›å»ºå¤‡ä»½ç›®å½•
        self._create_backup_directory()

        # ç¡®å®šç›®æ ‡æ–‡ä»¶
        if target_files is None:
            target_files = self._get_high_priority_files()

        print(f"ğŸ“‹ ç›®æ ‡æ–‡ä»¶æ•°é‡: {len(target_files)}")

        # æ‰§è¡Œè¿ç§»
        results = []
        for file_path in target_files:
            result = self._migrate_file(file_path)
            results.append(result)

            if result.success:
                print(
                    f"   âœ… {os.path.basename(file_path)}: {len(result.changes_made)}å¤„ä¿®æ”¹"
                )
            else:
                print(
                    f"   âŒ {os.path.basename(file_path)}: {', '.join(result.errors)}"
                )

        self.migration_results = results

        # ç”Ÿæˆè¿ç§»æŠ¥å‘Š
        report = self._generate_migration_report(results)

        return report

    def _create_backup_directory(self):
        """åˆ›å»ºå¤‡ä»½ç›®å½•"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.backup_dir = self.project_root / f"gpu_migration_backups_{timestamp}"
        self.backup_dir.mkdir(exist_ok=True)
        print(f"ğŸ“ å¤‡ä»½ç›®å½•: {self.backup_dir}")

    def _get_high_priority_files(self) -> List[str]:
        """è·å–é«˜ä¼˜å…ˆçº§æ–‡ä»¶"""
        # åŸºäºåˆ†æç»“æœï¼Œé€‰æ‹©å…³é”®åŸºç¡€è®¾æ–½æ–‡ä»¶
        key_files = [
            "src/gpu/api_system/utils/gpu_acceleration_engine.py",
            "src/gpu/api_system/utils/resource_scheduler.py",
            "src/gpu/api_system/services/resource_manager.py",
            "src/gpu/api_system/services/realtime_service.py",
            "src/gpu/api_system/utils/gpu_utils.py",
        ]

        # è¿‡æ»¤å­˜åœ¨çš„æ–‡ä»¶
        existing_files = []
        for file_path in key_files:
            if os.path.exists(file_path):
                existing_files.append(file_path)
            else:
                print(f"   âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

        return existing_files

    def _migrate_file(self, file_path: str) -> MigrationResult:
        """è¿ç§»å•ä¸ªæ–‡ä»¶"""
        print(f"   ğŸ”§ è¿ç§»: {os.path.basename(file_path)}")

        try:
            # è¯»å–åŸæ–‡ä»¶
            with open(file_path, "r", encoding="utf-8") as f:
                original_content = f.read()

            # åˆ›å»ºå¤‡ä»½
            backup_path = self._create_backup(file_path, original_content)

            # æ‰§è¡Œè¿ç§»è½¬æ¢
            migrated_content, changes, errors = self._perform_migration(
                file_path, original_content
            )

            # å†™å…¥è¿ç§»åçš„æ–‡ä»¶
            if changes or errors:  # æœ‰å˜æ›´æ‰å†™å…¥
                with open(file_path, "w", encoding="utf-8") as f:
                    f.write(migrated_content)

            return MigrationResult(
                success=len(errors) == 0,
                file_path=file_path,
                original_lines=len(original_content.split("\n")),
                modified_lines=len(migrated_content.split("\n")),
                changes_made=changes,
                errors=errors,
                backup_path=backup_path,
            )

        except Exception as e:
            return MigrationResult(
                success=False,
                file_path=file_path,
                original_lines=0,
                modified_lines=0,
                errors=[f"Migration failed: {str(e)}"],
            )

    def _create_backup(self, file_path: str, content: str) -> str:
        """åˆ›å»ºæ–‡ä»¶å¤‡ä»½"""
        relative_path = Path(file_path).relative_to(self.project_root)
        backup_path = self.backup_dir / relative_path

        # åˆ›å»ºç›®å½•ç»“æ„
        backup_path.parent.mkdir(parents=True, exist_ok=True)

        # å†™å…¥å¤‡ä»½
        with open(backup_path, "w", encoding="utf-8") as f:
            f.write(content)

        return str(backup_path)

    def _perform_migration(
        self, file_path: str, content: str
    ) -> Tuple[str, List[str], List[str]]:
        """æ‰§è¡Œè¿ç§»è½¬æ¢"""
        migrated_content = content
        changes = []
        errors = []

        # è¿ç§»è§„åˆ™
        migration_rules = [
            # 1. å¯¼å…¥æ›¿æ¢è§„åˆ™
            self._migrate_imports,
            # 2. GPUåˆ†é…è§„åˆ™
            self._migrate_gpu_allocation,
            # 3. çŸ©é˜µè¿ç®—è§„åˆ™
            self._migrate_matrix_operations,
            # 4. å†…å­˜ç®¡ç†è§„åˆ™
            self._migrate_memory_management,
            # 5. è®¾å¤‡ç®¡ç†è§„åˆ™
            self._migrate_device_management,
        ]

        for rule_func in migration_rules:
            try:
                new_content, rule_changes, rule_errors = rule_func(
                    file_path, migrated_content
                )
                migrated_content = new_content
                changes.extend(rule_changes)
                errors.extend(rule_errors)
            except Exception as e:
                errors.append(f"Rule {rule_func.__name__} failed: {str(e)}")

        return migrated_content, changes, errors

    def _migrate_imports(
        self, file_path: str, content: str
    ) -> Tuple[str, List[str], List[str]]:
        """è¿ç§»å¯¼å…¥è¯­å¥"""
        migrated_content = content
        changes = []
        errors = []

        # å¯¼å…¥æ›¿æ¢è§„åˆ™
        import_replacements = [
            # CuPyå¯¼å…¥
            (
                r"import\s+cupy\s+as\s+cp",
                "from src.gpu.core.hardware_abstraction import get_gpu_resource_manager",
                "Replace CuPy import with HAL manager",
            ),
            (
                r"from\s+cupy\s+import\s+(\w+)",
                "from src.gpu.core.kernels import get_kernel_executor",
                "Replace CuPy import with kernel executor",
            ),
            # PyTorchå¯¼å…¥
            (
                r"import\s+torch",
                "from src.gpu.core.hardware_abstraction import get_gpu_resource_manager",
                "Replace PyTorch import with HAL manager",
            ),
            # CUDAç›´æ¥å¯¼å…¥
            (
                r"import\s+cuda",
                "from src.gpu.core.hardware_abstraction import get_gpu_resource_manager",
                "Replace CUDA import with HAL manager",
            ),
        ]

        for pattern, replacement, description in import_replacements:
            if re.search(pattern, migrated_content):
                # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰HALå¯¼å…¥
                hal_pattern = r"from\s+src\.gpu\.core\.hardware_abstraction\s+import"
                if re.search(hal_pattern, migrated_content):
                    continue

                # åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ å¯¼å…¥
                lines = migrated_content.split("\n")
                import_line = "from src.gpu.core.hardware_abstraction import get_gpu_resource_manager"

                # æ‰¾åˆ°æœ€åä¸€ä¸ªimportè¯­å¥åæ’å…¥
                insert_index = 0
                for i, line in enumerate(lines):
                    if line.strip().startswith(("import ", "from ")):
                        insert_index = i + 1

                lines.insert(insert_index, import_line)
                migrated_content = "\n".join(lines)
                changes.append(description)

        return migrated_content, changes, errors

    def _migrate_gpu_allocation(
        self, file_path: str, content: str
    ) -> Tuple[str, List[str], List[str]]:
        """è¿ç§»GPUåˆ†é…"""
        migrated_content = content
        changes = []
        errors = []

        # GPUåˆ†é…æ›¿æ¢è§„åˆ™
        allocation_replacements = [
            # CuPyæ•°ç»„åˆ›å»º
            (
                r"cp\.array\(([^)]+)\)",
                r"await gpu_manager.allocate_array(\1)",
                "Replace CuPy array creation with HAL allocation",
            ),
            # PyTorchå¼ é‡åˆ›å»º
            (
                r"torch\.tensor\(([^)]+),\s*device\s*=\s*['\"]cuda",
                r"await gpu_manager.allocate_tensor(\1)",
                "Replace PyTorch tensor creation with HAL allocation",
            ),
            # CUDAè®¾å¤‡é€‰æ‹©
            (
                r"cp\.cuda\.Device\((\d+)\)\.use\(\)",
                r"await gpu_manager.set_device(\1)",
                "Replace CUDA device selection with HAL device management",
            ),
        ]

        for pattern, replacement, description in allocation_replacements:
            old_content = migrated_content
            migrated_content = re.sub(pattern, replacement, migrated_content)

            if old_content != migrated_content:
                changes.append(description)

        return migrated_content, changes, errors

    def _migrate_matrix_operations(
        self, file_path: str, content: str
    ) -> Tuple[str, List[str], List[str]]:
        """è¿ç§»çŸ©é˜µè¿ç®—"""
        migrated_content = content
        changes = []
        errors = []

        # çŸ©é˜µè¿ç®—æ›¿æ¢è§„åˆ™
        matrix_replacements = [
            # çŸ©é˜µä¹˜æ³•
            (
                r"(\w+)\s*@\s*(\w+)",
                r"await kernel_executor.execute_matrix_operation(\1, \2, matrix_config)",
                "Replace direct matrix multiplication with kernel executor",
            ),
            # çŸ©é˜µè½¬ç½®
            (
                r"(\w+)\.T",
                r"await kernel_executor.execute_transform_operation(\1, transpose_config)",
                "Replace direct matrix transpose with kernel executor",
            ),
            # çŸ©é˜µæ±‚é€†
            (
                r"cp\.linalg\.inv\(([^)]+)\)",
                r"await kernel_executor.execute_matrix_operation(\1, None, inverse_config)",
                "Replace direct matrix inverse with kernel executor",
            ),
        ]

        for pattern, replacement, description in matrix_replacements:
            old_content = migrated_content
            migrated_content = re.sub(pattern, replacement, migrated_content)

            if old_content != migrated_content:
                changes.append(description)

        return migrated_content, changes, errors

    def _migrate_memory_management(
        self, file_path: str, content: str
    ) -> Tuple[str, List[str], List[str]]:
        """è¿ç§»å†…å­˜ç®¡ç†"""
        migrated_content = content
        changes = []
        errors = []

        # å†…å­˜ç®¡ç†æ›¿æ¢è§„åˆ™
        memory_replacements = [
            # æ‰‹åŠ¨å†…å­˜åˆ é™¤
            (
                r"del\s+(gpu_\w+)",
                r"await gpu_manager.deallocate_array(\1)",
                "Replace manual memory deletion with HAL deallocation",
            ),
            # CUDAå†…å­˜ç¼“å­˜æ¸…ç†
            (
                r"cp\.cuda\.empty_cache\(\)",
                r"await gpu_manager.clear_cache()",
                "Replace CUDA cache clearing with HAL cache management",
            ),
            # CUDAåŒæ­¥
            (
                r"cp\.cuda\.Stream\.null\.synchronize\(\)",
                r"await gpu_manager.synchronize()",
                "Replace CUDA synchronization with HAL synchronization",
            ),
        ]

        for pattern, replacement, description in memory_replacements:
            old_content = migrated_content
            migrated_content = re.sub(pattern, replacement, migrated_content)

            if old_content != migrated_content:
                changes.append(description)

        return migrated_content, changes, errors

    def _migrate_device_management(
        self, file_path: str, content: str
    ) -> Tuple[str, List[str], List[str]]:
        """è¿ç§»è®¾å¤‡ç®¡ç†"""
        migrated_content = content
        changes = []
        errors = []

        # è®¾å¤‡ç®¡ç†æ›¿æ¢è§„åˆ™
        device_replacements = [
            # è®¾å¤‡æ£€æŸ¥
            (
                r"cp\.cuda\.is_available\(\)",
                r"await gpu_manager.is_gpu_available()",
                "Replace CUDA availability check with HAL check",
            ),
            # è®¾å¤‡æ•°é‡
            (
                r"len\(cp\.cuda\.get_devices\(\))",
                r"await gpu_manager.get_device_count()",
                "Replace CUDA device count with HAL device count",
            ),
            # å½“å‰è®¾å¤‡
            (
                r"cp\.cuda\.get_device_id\(\)",
                r"await gpu_manager.get_current_device_id()",
                "Replace CUDA device ID with HAL device ID",
            ),
        ]

        for pattern, replacement, description in device_replacements:
            old_content = migrated_content
            migrated_content = re.sub(pattern, replacement, migrated_content)

            if old_content != migrated_content:
                changes.append(description)

        return migrated_content, changes, errors

    def _generate_migration_report(
        self, results: List[MigrationResult]
    ) -> Dict[str, Any]:
        """ç”Ÿæˆè¿ç§»æŠ¥å‘Š"""
        total_files = len(results)
        successful_files = sum(1 for r in results if r.success)
        failed_files = total_files - successful_files

        total_changes = sum(len(r.changes_made) for r in results)
        total_errors = sum(len(r.errors) for r in results)

        # æ–‡ä»¶å¤§å°å˜åŒ–ç»Ÿè®¡
        total_original_lines = sum(r.original_lines for r in results)
        total_modified_lines = sum(r.modified_lines for r in results)

        return {
            "summary": {
                "total_files": total_files,
                "successful_files": successful_files,
                "failed_files": failed_files,
                "success_rate": (successful_files / total_files * 100)
                if total_files > 0
                else 0,
                "total_changes": total_changes,
                "total_errors": total_errors,
            },
            "statistics": {
                "total_original_lines": total_original_lines,
                "total_modified_lines": total_modified_lines,
                "line_change_rate": (
                    (total_modified_lines - total_original_lines)
                    / total_original_lines
                    * 100
                )
                if total_original_lines > 0
                else 0,
            },
            "files": [
                {
                    "path": r.file_path,
                    "name": os.path.basename(r.file_path),
                    "success": r.success,
                    "changes_count": len(r.changes_made),
                    "errors_count": len(r.errors),
                    "backup_path": r.backup_path,
                }
                for r in results
            ],
        }

    def print_migration_summary(self, report: Dict[str, Any]):
        """æ‰“å°è¿ç§»æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“Š GPUè¿ç§»æ‰§è¡Œæ‘˜è¦")
        print("=" * 60)

        summary = report["summary"]
        stats = report["statistics"]

        # åŸºæœ¬ç»Ÿè®¡
        print(f"ğŸ“ æ€»æ–‡ä»¶æ•°: {summary['total_files']}")
        print(f"âœ… æˆåŠŸè¿ç§»: {summary['successful_files']}")
        print(f"âŒ å¤±è´¥è¿ç§»: {summary['failed_files']}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print(f"ğŸ”§ æ€»ä¿®æ”¹æ•°: {summary['total_changes']}")
        print(f"âš ï¸ æ€»é”™è¯¯æ•°: {summary['total_errors']}")

        # ä»£ç è¡Œæ•°å˜åŒ–
        print("\nğŸ“ ä»£ç è¡Œæ•°å˜åŒ–:")
        print(f"   åŸå§‹æ€»è¡Œæ•°: {stats['total_original_lines']:,}")
        print(f"   è¿ç§»åè¡Œæ•°: {stats['total_modified_lines']:,}")
        print(f"   å˜åŒ–ç‡: {stats['line_change_rate']:+.1f}%")

        # è¯¦ç»†æ–‡ä»¶ç»“æœ
        print("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
        for file_info in report["files"]:
            status = "âœ…" if file_info["success"] else "âŒ"
            print(f"   {status} {file_info['name']}")
            print(
                f"      ä¿®æ”¹: {file_info['changes_count']} | é”™è¯¯: {file_info['errors_count']}"
            )

        print("\n" + "=" * 60)

        if summary["total_errors"] == 0:
            print("ğŸ‰ è¿ç§»æˆåŠŸå®Œæˆï¼æ‰€æœ‰æ–‡ä»¶éƒ½å·²æˆåŠŸè¿ç§»ã€‚")
        else:
            print("âš ï¸ è¿ç§»è¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯ï¼Œè¯·æ£€æŸ¥å¤±è´¥æ–‡ä»¶ã€‚")


def main():
    """ä¸»å‡½æ•°"""
    executor = GPUMigrationExecutor()

    print("ğŸš€ å¼€å§‹Phase 6.2.4 GPUè¿ç§»æ‰§è¡Œ...")

    # æ‰§è¡Œè¿ç§»
    report = executor.execute_migration()

    # ä¿å­˜è¿ç§»æŠ¥å‘Š
    report_path = "gpu_migration_report.json"
    try:
        import json

        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"âœ… è¿ç§»æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

    # æ‰“å°æ‘˜è¦
    executor.print_migration_summary(report)

    return report


if __name__ == "__main__":
    main()
