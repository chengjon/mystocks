#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Redisçƒ­æ•°æ®å›ºåŒ–å’Œå¼ºåˆ¶æ›´æ–°æ‰©å±•æ¨¡å—
è§£å†³Redis 5åˆ†é’Ÿè¿‡æœŸæ•°æ®çš„æŒä¹…åŒ–å’Œå¼ºåˆ¶åˆ·æ–°é—®é¢˜

åŠŸèƒ½ç‰¹æ€§ï¼š
1. è‡ªåŠ¨å›ºåŒ–Redisçƒ­æ•°æ®åˆ°æ°¸ä¹…å­˜å‚¨
2. æ”¯æŒå¼ºåˆ¶æ›´æ–°ï¼ˆè·³è¿‡ç¼“å­˜ï¼‰
3. æ•°æ®å¤‡ä»½å’Œæ¢å¤æœºåˆ¶
4. çµæ´»çš„å›ºåŒ–ç­–ç•¥é…ç½®

ä½œè€…: MyStocksé¡¹ç›®ç»„
æ—¥æœŸ: 2025-09-21
"""

import os
import sys
import logging
import pandas as pd
from datetime import datetime
from typing import Optional, Dict, Any
from enum import Enum

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core import DataClassification
from unified_manager import MyStocksUnifiedManager


class FixationStrategy(Enum):
    """æ•°æ®å›ºåŒ–ç­–ç•¥"""

    IMMEDIATE = "immediate"  # ç«‹å³å›ºåŒ–
    SCHEDULED = "scheduled"  # å®šæ—¶å›ºåŒ–
    BEFORE_EXPIRE = "before_expire"  # è¿‡æœŸå‰å›ºåŒ–
    ON_DEMAND = "on_demand"  # æŒ‰éœ€å›ºåŒ–


class RedisDataFixationManager:
    """Redisçƒ­æ•°æ®å›ºåŒ–ç®¡ç†å™¨"""

    def __init__(self, unified_manager: MyStocksUnifiedManager = None):
        """
        åˆå§‹åŒ–Redisæ•°æ®å›ºåŒ–ç®¡ç†å™¨

        Args:
            unified_manager: ç»Ÿä¸€ç®¡ç†å™¨å®ä¾‹
        """
        self.unified_manager = unified_manager or MyStocksUnifiedManager()
        self.logger = logging.getLogger("RedisFixation")

        # å›ºåŒ–é…ç½®
        self.config = {
            "fixation_strategy": FixationStrategy.BEFORE_EXPIRE,
            "fixation_interval_seconds": 300,  # 5åˆ†é’Ÿå›ºåŒ–ä¸€æ¬¡ï¼ˆä¸Redisè¿‡æœŸæ—¶é—´åŒæ­¥ï¼‰
            "backup_to_tick_data": True,  # å¤‡ä»½åˆ°TDengine Tickæ•°æ®
            "backup_to_daily_kline": False,  # å¤‡ä»½åˆ°PostgreSQLæ—¥çº¿æ•°æ®
            "max_retry_attempts": 3,
            "enable_compression": True,
            "retention_days": 30,
        }

        self.logger.info("Redisçƒ­æ•°æ®å›ºåŒ–ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def force_update_realtime_data(
        self, market_symbol: str = "hs", bypass_cache: bool = True
    ) -> Dict[str, Any]:
        """
        å¼ºåˆ¶æ›´æ–°å®æ—¶æ•°æ®ï¼ˆä¸è¯»ç¼“å­˜ï¼‰

        Args:
            market_symbol: å¸‚åœºä»£ç  ('hs', 'sh', 'sz')
            bypass_cache: æ˜¯å¦è·³è¿‡Redisç¼“å­˜

        Returns:
            Dict: æ“ä½œç»“æœå’Œæ•°æ®ç»Ÿè®¡
        """
        self.logger.info(
            f"ğŸ”„ å¼ºåˆ¶æ›´æ–°å®æ—¶æ•°æ®å¼€å§‹ - å¸‚åœº: {market_symbol}, è·³è¿‡ç¼“å­˜: {bypass_cache}"
        )

        try:
            # 1. æ¸…é™¤Redisç¼“å­˜ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if bypass_cache:
                cache_cleared = self._clear_redis_cache(market_symbol)
                self.logger.info(
                    f"ğŸ—‘ï¸ Redisç¼“å­˜æ¸…é™¤: {'æˆåŠŸ' if cache_cleared else 'å¤±è´¥'}"
                )

            # 2. å¼ºåˆ¶ä»æ•°æ®æºè·å–æœ€æ–°æ•°æ®
            from adapters.customer_adapter import CustomerDataSource

            customer_ds = CustomerDataSource()

            fresh_data = customer_ds.get_real_time_data(market_symbol)

            if fresh_data is None or fresh_data.empty:
                self.logger.error("âŒ æœªèƒ½è·å–åˆ°æ–°çš„å®æ—¶æ•°æ®")
                return {"success": False, "error": "æ•°æ®è·å–å¤±è´¥"}

            # 3. æ·»åŠ å¼ºåˆ¶æ›´æ–°æ ‡è®°
            fresh_data["force_update_time"] = datetime.now()
            fresh_data["update_source"] = "force_update"

            # 4. ä¿å­˜åˆ°Redisï¼ˆä¼šè¦†ç›–ç°æœ‰æ•°æ®ï¼‰
            success = self.unified_manager.save_data_by_classification(
                fresh_data, DataClassification.REALTIME_POSITIONS
            )

            result = {
                "success": success,
                "update_time": datetime.now(),
                "data_count": len(fresh_data),
                "market_symbol": market_symbol,
                "bypass_cache": bypass_cache,
                "data_columns": list(fresh_data.columns),
            }

            if success:
                self.logger.info(f"âœ… å¼ºåˆ¶æ›´æ–°æˆåŠŸ: {len(fresh_data)} æ¡è®°å½•")
                # ç«‹å³å›ºåŒ–æ–°æ•°æ®
                self.fixate_redis_data_immediate(fresh_data)
            else:
                self.logger.error("âŒ å¼ºåˆ¶æ›´æ–°å¤±è´¥")

            return result

        except Exception as e:
            self.logger.error(f"âŒ å¼ºåˆ¶æ›´æ–°å¼‚å¸¸: {e}")
            return {"success": False, "error": str(e)}

    def _clear_redis_cache(self, market_symbol: str) -> bool:
        """
        æ¸…é™¤Redisç¼“å­˜

        Args:
            market_symbol: å¸‚åœºä»£ç 

        Returns:
            bool: æ¸…é™¤æ˜¯å¦æˆåŠŸ
        """
        try:
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„Redis keyå‘½åè§„åˆ™æ¥æ¸…é™¤
            # ç¤ºä¾‹å®ç°ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰

            # è·å–Redisè¿æ¥ï¼ˆé€šè¿‡unified_manageræˆ–ç›´æ¥è¿æ¥ï¼‰
            # redis_client = self.unified_manager.get_redis_connection()
            # cache_keys = redis_client.keys(f"realtime_positions:*{market_symbol}*")
            # if cache_keys:
            #     redis_client.delete(*cache_keys)
            #     self.logger.info(f"æ¸…é™¤äº† {len(cache_keys)} ä¸ªRedisç¼“å­˜é”®")
            #     return True

            self.logger.info("Redisç¼“å­˜æ¸…é™¤ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰")
            return True

        except Exception as e:
            self.logger.error(f"æ¸…é™¤Redisç¼“å­˜å¤±è´¥: {e}")
            return False

    def fixate_redis_data_immediate(self, data: pd.DataFrame) -> Dict[str, bool]:
        """
        ç«‹å³å›ºåŒ–Redisæ•°æ®åˆ°æ°¸ä¹…å­˜å‚¨

        Args:
            data: è¦å›ºåŒ–çš„æ•°æ®

        Returns:
            Dict[str, bool]: å›ºåŒ–ç»“æœ
        """
        self.logger.info(f"ğŸ’¾ å¼€å§‹ç«‹å³å›ºåŒ–Redisæ•°æ®: {len(data)} æ¡è®°å½•")

        fixation_results = {}

        try:
            # æ·»åŠ å›ºåŒ–å…ƒæ•°æ®
            data_to_fixate = data.copy()
            data_to_fixate["fixation_time"] = datetime.now()
            data_to_fixate["fixation_strategy"] = "immediate"
            data_to_fixate["data_source"] = "redis_fixation"

            # æ–¹æ¡ˆ1: å›ºåŒ–åˆ°TDengine Tickæ•°æ®ï¼ˆæ¨èï¼‰
            if self.config["backup_to_tick_data"]:
                try:
                    tick_success = self.unified_manager.save_data_by_classification(
                        data_to_fixate, DataClassification.TICK_DATA
                    )
                    fixation_results["tick_data"] = tick_success

                    if tick_success:
                        self.logger.info("âœ… æ•°æ®å›ºåŒ–åˆ°TDengineæˆåŠŸ")
                    else:
                        self.logger.error("âŒ æ•°æ®å›ºåŒ–åˆ°TDengineå¤±è´¥")

                except Exception as e:
                    self.logger.error(f"TDengineå›ºåŒ–å¼‚å¸¸: {e}")
                    fixation_results["tick_data"] = False

            # æ–¹æ¡ˆ2: å›ºåŒ–åˆ°PostgreSQLæ—¥çº¿æ•°æ®ï¼ˆå¯é€‰ï¼‰
            if self.config["backup_to_daily_kline"]:
                try:
                    # å°†å®æ—¶æ•°æ®èšåˆä¸ºæ—¥çº¿æ ¼å¼
                    daily_data = self._aggregate_to_daily_format(data_to_fixate)

                    if daily_data is not None and not daily_data.empty:
                        daily_success = (
                            self.unified_manager.save_data_by_classification(
                                daily_data, DataClassification.DAILY_KLINE
                            )
                        )
                        fixation_results["daily_kline"] = daily_success

                        if daily_success:
                            self.logger.info("âœ… æ•°æ®å›ºåŒ–åˆ°PostgreSQLæˆåŠŸ")
                        else:
                            self.logger.error("âŒ æ•°æ®å›ºåŒ–åˆ°PostgreSQLå¤±è´¥")

                except Exception as e:
                    self.logger.error(f"PostgreSQLå›ºåŒ–å¼‚å¸¸: {e}")
                    fixation_results["daily_kline"] = False

            # è®°å½•å›ºåŒ–ç»Ÿè®¡
            success_count = sum(1 for result in fixation_results.values() if result)
            total_count = len(fixation_results)

            self.logger.info(f"ğŸ’¾ æ•°æ®å›ºåŒ–å®Œæˆ: {success_count}/{total_count} æˆåŠŸ")

            return fixation_results

        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®å›ºåŒ–å¼‚å¸¸: {e}")
            return {"error": False}

    def _aggregate_to_daily_format(
        self, realtime_data: pd.DataFrame
    ) -> Optional[pd.DataFrame]:
        """
        å°†å®æ—¶æ•°æ®èšåˆä¸ºæ—¥çº¿æ ¼å¼

        Args:
            realtime_data: å®æ—¶æ•°æ®

        Returns:
            Optional[pd.DataFrame]: èšåˆåçš„æ—¥çº¿æ•°æ®
        """
        try:
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æ•°æ®ç»“æ„æ¥å®ç°èšåˆé€»è¾‘
            # ç¤ºä¾‹èšåˆï¼ˆæŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„ï¼‰

            if "symbol" not in realtime_data.columns:
                # å°è¯•å…¶ä»–å¯èƒ½çš„è‚¡ç¥¨ä»£ç åˆ—å
                symbol_columns = ["è‚¡ç¥¨ä»£ç ", "code", "ts_code"]
                symbol_col = None
                for col in symbol_columns:
                    if col in realtime_data.columns:
                        symbol_col = col
                        break

                if symbol_col:
                    realtime_data["symbol"] = realtime_data[symbol_col]
                else:
                    self.logger.warning("âš ï¸ æ— æ³•æ‰¾åˆ°è‚¡ç¥¨ä»£ç åˆ—ï¼Œè·³è¿‡æ—¥çº¿èšåˆ")
                    return None

            # ç®€å•èšåˆç¤ºä¾‹ï¼ˆå®é™…å®ç°éœ€è¦æ›´å¤æ‚çš„OHLCVé€»è¾‘ï¼‰
            daily_data = (
                realtime_data.groupby("symbol")
                .agg(
                    {
                        "price": ["first", "max", "min", "last"],  # OHLC
                        "volume": "sum",
                        "amount": "sum",
                    }
                )
                .reset_index()
            )

            # é‡å‘½ååˆ—
            daily_data.columns = [
                "symbol",
                "open",
                "high",
                "low",
                "close",
                "volume",
                "amount",
            ]
            daily_data["trade_date"] = datetime.now().date()

            self.logger.info(f"ğŸ“Š å®æ—¶æ•°æ®èšåˆä¸ºæ—¥çº¿: {len(daily_data)} åªè‚¡ç¥¨")
            return daily_data

        except Exception as e:
            self.logger.error(f"æ—¥çº¿æ•°æ®èšåˆå¤±è´¥: {e}")
            return None

    def start_scheduled_fixation(self, interval_seconds: int = None):
        """
        å¯åŠ¨å®šæ—¶å›ºåŒ–ä»»åŠ¡

        Args:
            interval_seconds: å›ºåŒ–é—´éš”ï¼ˆç§’ï¼‰
        """
        interval = interval_seconds or self.config["fixation_interval_seconds"]

        self.logger.info(f"ğŸ•’ å¯åŠ¨å®šæ—¶å›ºåŒ–ä»»åŠ¡ï¼Œé—´éš”: {interval} ç§’")

        # è¿™é‡Œå¯ä»¥é›†æˆåˆ°ç³»ç»Ÿçš„å®šæ—¶ä»»åŠ¡ä¸­
        # æˆ–è€…ä½¿ç”¨å•ç‹¬çš„å®šæ—¶å™¨çº¿ç¨‹
        pass

    def get_fixation_statistics(self) -> Dict[str, Any]:
        """
        è·å–å›ºåŒ–ç»Ÿè®¡ä¿¡æ¯

        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            stats = {
                "last_fixation_time": "unknown",
                "total_fixations": 0,
                "success_rate": 0.0,
                "average_data_size": 0,
                "storage_targets": [],
            }

            if self.config["backup_to_tick_data"]:
                stats["storage_targets"].append("TDengine (Tickæ•°æ®)")

            if self.config["backup_to_daily_kline"]:
                stats["storage_targets"].append("PostgreSQL (æ—¥çº¿æ•°æ®)")

            return stats

        except Exception as e:
            self.logger.error(f"è·å–å›ºåŒ–ç»Ÿè®¡å¤±è´¥: {e}")
            return {}


def main():
    """æ¼”ç¤ºRedisçƒ­æ•°æ®å›ºåŒ–å’Œå¼ºåˆ¶æ›´æ–°åŠŸèƒ½"""

    print("=" * 70)
    print("ğŸ”„ Redisçƒ­æ•°æ®å›ºåŒ–å’Œå¼ºåˆ¶æ›´æ–°æ¼”ç¤º")
    print("=" * 70)

    # åˆ›å»ºå›ºåŒ–ç®¡ç†å™¨
    fixation_manager = RedisDataFixationManager()

    # æ¼”ç¤º1: å¼ºåˆ¶æ›´æ–°å®æ—¶æ•°æ®
    print("\n1ï¸âƒ£ å¼ºåˆ¶æ›´æ–°å®æ—¶æ•°æ®ï¼ˆè·³è¿‡ç¼“å­˜ï¼‰")
    update_result = fixation_manager.force_update_realtime_data(
        market_symbol="hs", bypass_cache=True
    )

    print(f"æ›´æ–°ç»“æœ: {update_result}")

    # æ¼”ç¤º2: è·å–å›ºåŒ–ç»Ÿè®¡
    print("\n2ï¸âƒ£ å›ºåŒ–ç»Ÿè®¡ä¿¡æ¯")
    stats = fixation_manager.get_fixation_statistics()
    print(f"ç»Ÿè®¡ä¿¡æ¯: {stats}")

    print("\n" + "=" * 70)
    print("âœ… æ¼”ç¤ºå®Œæˆ")


if __name__ == "__main__":
    main()
