"""
åå‘å·¥ç¨‹å¥‘çº¦ç”Ÿæˆå™¨

ä»è¿è¡Œä¸­çš„æœåŠ¡è‡ªåŠ¨ç”ŸæˆAPIå¥‘çº¦ï¼Œæ”¯æŒSwagger/OpenAPIæ–‡æ¡£å’ŒHTTPæ¥å£æ‰«æã€‚
"""

import asyncio
import json
import re
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from enum import Enum
from urllib.parse import urljoin, urlparse

import httpx


class ScannerType(Enum):
    """æ‰«æå™¨ç±»å‹æšä¸¾"""

    SWAGGER_UI = "swagger_ui"
    OPENAPI_JSON = "openapi_json"
    OPENAPI_YAML = "openapi_yaml"
    MANUAL_SCAN = "manual_scan"
    REVERSE_ENGINEER = "reverse_engineer"


@dataclass
class Endpoint:
    """ç«¯ç‚¹å®šä¹‰"""

    path: str
    method: str
    summary: str = ""
    description: str = ""
    parameters: List[Dict[str, Any]] = field(default_factory=list)
    request_body: Dict[str, Any] = field(default_factory=dict)
    responses: List[Dict[str, Any]] = field(default_factory=list)
    security: List[Dict[str, Any]] = field(default_factory=list)
    tags: List[str] = field(default_factory=list)
    deprecated: bool = False
    consumes: List[str] = field(default_factory=list)
    produces: List[str] = field(default_factory=list)


@dataclass
class ScanResult:
    """æ‰«æç»“æœ"""

    scanner_type: ScannerType
    base_url: str
    endpoints: List[Endpoint]
    metadata: Dict[str, Any] = field(default_factory=dict)
    discovered_at: datetime = field(default_factory=datetime.now)
    scan_duration: float = 0.0
    errors: List[str] = field(default_factory=list)


class WebScraper:
    """ç½‘é¡µçˆ¬å–å™¨"""

    def __init__(self, timeout: int = 30):
        self.timeout = timeout
        self.session = httpx.AsyncClient(timeout=timeout, verify=False)

    async def __aenter__(self):
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.session.aclose()

    async def fetch_page(self, url: str) -> str:
        """è·å–ç½‘é¡µå†…å®¹"""
        try:
            response = await self.session.get(url)
            response.raise_for_status()
            return response.text
        except httpx.HTTPError as e:
            raise Exception(f"è·å–ç½‘é¡µå¤±è´¥: {e}")

    async def fetch_json(self, url: str) -> Dict[str, Any]:
        """è·å–JSONæ•°æ®"""
        try:
            response = await self.session.get(url)
            response.raise_for_status()
            return response.json()
        except httpx.HTTPError as e:
            raise Exception(f"è·å–JSONæ•°æ®å¤±è´¥: {e}")

    async def discover_endpoints(self, base_url: str) -> List[str]:
        """å‘ç°ç«¯ç‚¹"""
        discovered = []

        # å¸¸è§ç«¯ç‚¹å‘ç°
        common_paths = [
            "/api",
            "/v1/api",
            "/v2/api",
            "/rest",
            "/swagger.json",
            "/swagger.yaml",
            "/openapi.json",
            "/openapi.yaml",
            "/docs",
            "/redoc",
            "/api-docs",
            "/api/v1",
            "/api/v2",
        ]

        for path in common_paths:
            url = urljoin(base_url, path)
            try:
                response = await self.session.get(url, follow_redirects=True)
                if response.status_code < 400:
                    discovered.append(path)
                    print(f"  âœ“ å‘ç°ç«¯ç‚¹: {path}")
                else:
                    print(f"  âœ— ç«¯ç‚¹ä¸å¯ç”¨: {path} (HTTP {response.status_code})")
            except Exception as e:
                print(f"  âœ— ç«¯ç‚¹è®¿é—®å¤±è´¥: {path} - {e}")

        return discovered


class SwaggerUIParser:
    """Swagger UIè§£æå™¨"""

    def __init__(self):
        self.patterns = {
            "swagger_json": re.compile(
                r'window\.__REDUX_STATE__\s*=\s*({[^}]*"swagger":\s*{[^}]*}[^}]*})',
                re.DOTALL,
            ),
            "openapi_json": re.compile(
                r'window\.__INITIAL_REDUX_STATE__\s*=\s*({[^}]*"openapi":\s*{[^}]*}[^}]*})',
                re.DOTALL,
            ),
            "spec_url": re.compile(r'url:\s*["\']([^"\']+)["\'],\s*spec:', re.DOTALL),
        }

    async def parse(self, base_url: str) -> Dict[str, Any]:
        """è§£æSwagger UI"""
        # è·å–æ–‡æ¡£é¡µé¢
        web_scraper = WebScraper()
        async with web_scraper:
            content = await web_scraper.fetch_page(base_url)

            # å°è¯•ä»é¡µé¢æå–JSON
            swagger_json_match = self.patterns["swagger_json"].search(content)
            if swagger_json_match:
                try:
                    return json.loads(swagger_json_match.group(1))
                except json.JSONDecodeError:
                    pass

            openapi_json_match = self.patterns["openapi_json"].search(content)
            if openapi_json_match:
                try:
                    return json.loads(openapi_json_match.group(1))
                except json.JSONDecodeError:
                    pass

            # å°è¯•ç›´æ¥è®¿é—®openapi.json
            try:
                openapi_url = urljoin(base_url, "/openapi.json")
                return await web_scraper.fetch_json(openapi_url)
            except Exception:
                pass

            # å°è¯•ç›´æ¥è®¿é—®swagger.json
            try:
                swagger_url = urljoin(base_url, "/swagger.json")
                return await web_scraper.fetch_json(swagger_url)
            except Exception:
                pass

            raise Exception("æ— æ³•ä»Swagger UIè·å–APIè§„èŒƒ")


class OpenAPIScraper:
    """OpenAPIçˆ¬å–å™¨"""

    async def scrape_from_url(self, url: str) -> Dict[str, Any]:
        """ä»URLçˆ¬å–OpenAPIè§„èŒƒ"""
        web_scraper = WebScraper()
        async with web_scraper:
            return await web_scraper.fetch_json(url)

    async def discover_openapi_docs(self, base_url: str) -> Optional[str]:
        """å‘ç°OpenAPIæ–‡æ¡£ä½ç½®"""
        possible_paths = [
            "/openapi.json",
            "/swagger.json",
            "/api/openapi.json",
            "/api/swagger.json",
            "/v1/openapi.json",
            "/v2/openapi.json",
            "/docs/swagger.json",
            "/docs/openapi.json",
        ]

        web_scraper = WebScraper()
        async with web_scraper:
            for path in possible_paths:
                try:
                    full_url = urljoin(base_url, path)
                    response = await web_scraper.session.get(full_url)
                    if response.status_code == 200:
                        content_type = response.headers.get("content-type", "").lower()
                        if "json" in content_type:
                            print(f"  âœ“ å‘ç°OpenAPIæ–‡æ¡£: {path}")
                            return full_url
                except Exception:
                    continue

        return None


class HTTPScanner:
    """HTTPæ‰«æå™¨"""

    def __init__(self, timeout: int = 10, max_concurrent: int = 10):
        self.timeout = timeout
        self.max_concurrent = max_concurrent

    async def scan_endpoints(
        self, base_url: str, paths: List[str]
    ) -> List[Dict[str, Any]]:
        """æ‰«æç«¯ç‚¹"""
        discovered_endpoints = []

        semaphore = asyncio.Semaphore(self.max_concurrent)

        async def scan_endpoint(path: str) -> Optional[Dict[str, Any]]:
            async with semaphore:
                url = urljoin(base_url, path)
                try:
                    # å°è¯•HTTPæ–¹æ³•
                    methods = [
                        "GET",
                        "POST",
                        "PUT",
                        "DELETE",
                        "PATCH",
                        "HEAD",
                        "OPTIONS",
                    ]
                    for method in methods:
                        try:
                            response = await self._send_request(method, url)
                            if response.status_code < 500:
                                return {
                                    "path": path,
                                    "method": method,
                                    "status_code": response.status_code,
                                    "content_type": response.headers.get(
                                        "content-type", ""
                                    ),
                                    "content_length": response.headers.get(
                                        "content-length", "0"
                                    ),
                                }
                        except Exception:
                            continue
                    return None
                except Exception:
                    return None

        tasks = [scan_endpoint(path) for path in paths]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        for result in results:
            if isinstance(result, dict) and result:
                discovered_endpoints.append(result)

        return discovered_endpoints

    async def _send_request(self, method: str, url: str) -> httpx.Response:
        """å‘é€HTTPè¯·æ±‚"""
        client = httpx.AsyncClient(timeout=self.timeout, verify=False)
        try:
            response = await client.request(method, url)
            return response
        finally:
            await client.aclose()


class ReverseContractGenerator:
    """åå‘å·¥ç¨‹å¥‘çº¦ç”Ÿæˆå™¨"""

    def __init__(self, timeout: int = 30, max_concurrent: int = 10):
        self.timeout = timeout
        self.max_concurrent = max_concurrent
        self.web_scraper = WebScraper(timeout)
        self.swagger_parser = SwaggerUIParser()
        self.openapi_scraper = OpenAPIScraper()
        self.http_scanner = HTTPScanner(timeout, max_concurrent)

    async def generate_contract(
        self, url: str, scanner_type: ScannerType = ScannerType.AUTO_DETECT
    ) -> ScanResult:
        """ç”Ÿæˆå¥‘çº¦"""
        start_time = time.time()
        base_url = self._normalize_url(url)

        scan_result = ScanResult(
            scanner_type=scanner_type, base_url=base_url, endpoints=[]
        )

        try:
            if scanner_type == ScannerType.SWAGGER_UI:
                await self._scan_from_swagger_ui(scan_result)
            elif scanner_type == ScannerType.OPENAPI_JSON:
                await self._scan_from_openapi_json(scan_result)
            elif scanner_type == ScannerType.MANUAL_SCAN:
                await self._manual_scan(scan_result)
            elif scanner_type == ScannerType.REVERSE_ENGINEER:
                await self._reverse_engineer(scan_result)
            else:
                # è‡ªåŠ¨æ£€æµ‹
                await self._auto_scan(scan_result)

            scan_result.scan_duration = time.time() - start_time

            print("\nğŸ“Š æ‰«æç»“æœ:")
            print(f"  æ‰«æå™¨: {scan_result.scanner_type.value}")
            print(f"  åŸºç¡€URL: {scan_result.base_url}")
            print(f"  ç«¯ç‚¹æ•°é‡: {len(scan_result.endpoints)}")
            print(f"  è€—æ—¶: {scan_result.scan_duration:.2f}ç§’")

            return scan_result

        except Exception as e:
            scan_result.scan_duration = time.time() - start_time
            scan_result.errors.append(str(e))
            print(f"âŒ æ‰«æå¤±è´¥: {e}")
            raise

    async def _auto_scan(self, scan_result: ScanResult):
        """è‡ªåŠ¨æ‰«æ"""
        print("ğŸ” å¼€å§‹è‡ªåŠ¨æ‰«æ...")

        # é¦–å…ˆå°è¯•ä»Swagger UIè§£æ
        try:
            spec = await self.swagger_parser.parse(scan_result.base_url)
            await self._parse_openapi_spec(spec, scan_result)
            scan_result.scanner_type = ScannerType.SWAGGER_UI
            return
        except Exception:
            pass

        # å°è¯•ç›´æ¥è·å–OpenAPI JSON
        try:
            openapi_url = await self.openapi_scraper.discover_openapi_docs(
                scan_result.base_url
            )
            if openapi_url:
                spec = await self.openapi_scraper.scrape_from_url(openapi_url)
                await self._parse_openapi_spec(spec, scan_result)
                scan_result.scanner_type = ScannerType.OPENAPI_JSON
                return
        except Exception:
            pass

        # å¦‚æœä»¥ä¸Šéƒ½å¤±è´¥ï¼Œä½¿ç”¨æ‰‹åŠ¨æ‰«æ
        await self._manual_scan(scan_result)
        scan_result.scanner_type = ScannerType.MANUAL_SCAN

    async def _scan_from_swagger_ui(self, scan_result: ScanResult):
        """ä»Swagger UIæ‰«æ"""
        print("ğŸ“– ä»Swagger UIè§£æ...")
        spec = await self.swagger_parser.parse(scan_result.base_url)
        await self._parse_openapi_spec(spec, scan_result)

    async def _scan_from_openapi_json(self, scan_result: ScanResult):
        """ä»OpenAPI JSONæ‰«æ"""
        print("ğŸ“„ ä»OpenAPI JSONè§£æ...")
        spec = await self.openapi_scraper.scrape_from_url(scan_result.base_url)
        await self._parse_openapi_spec(spec, scan_result)

    async def _manual_scan(self, scan_result: ScanResult):
        """æ‰‹åŠ¨æ‰«æ"""
        print("ğŸ”§ å¼€å§‹æ‰‹åŠ¨æ‰«æ...")

        web_scraper = WebScraper()
        async with web_scraper:
            # å‘ç°ç«¯ç‚¹
            discovered_paths = await web_scraper.discover_endpoints(
                scan_result.base_url
            )
            print(f"  å‘ç° {len(discovered_paths)} ä¸ªå¯èƒ½çš„ç«¯ç‚¹")

            # æ‰«æç«¯ç‚¹
            discovered_endpoints = await self.http_scanner.scan_endpoints(
                scan_result.base_url, discovered_paths
            )

            # è½¬æ¢ä¸ºç«¯ç‚¹å¯¹è±¡
            for endpoint_info in discovered_endpoints:
                endpoint = Endpoint(
                    path=endpoint_info["path"],
                    method=endpoint_info["method"],
                    responses=[
                        {
                            "status_code": endpoint_info["status_code"],
                            "description": "Successful response",
                        }
                    ],
                )
                scan_result.endpoints.append(endpoint)

    async def _reverse_engineer(self, scan_result: ScanResult):
        """åå‘å·¥ç¨‹æ‰«æ"""
        print("âš™ï¸ å¼€å§‹åå‘å·¥ç¨‹æ‰«æ...")

        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„åå‘å·¥ç¨‹é€»è¾‘
        # ä¾‹å¦‚é€šè¿‡åˆ†æç½‘é¡µå†…å®¹æ¥æ¨æ–­APIç«¯ç‚¹
        await self._manual_scan(scan_result)

    async def _parse_openapi_spec(self, spec: Dict[str, Any], scan_result: ScanResult):
        """è§£æOpenAPIè§„èŒƒ"""
        if not spec or "paths" not in spec:
            raise Exception("æ— æ•ˆçš„OpenAPIè§„èŒƒ")

        paths = spec["paths"]
        metadata = spec.get("info", {})
        scan_result.metadata = metadata

        for path, path_data in paths.items():
            for method, method_data in path_data.items():
                if method.upper() not in [
                    "GET",
                    "POST",
                    "PUT",
                    "DELETE",
                    "PATCH",
                    "HEAD",
                    "OPTIONS",
                ]:
                    continue

                # åˆ›å»ºç«¯ç‚¹
                endpoint = Endpoint(
                    path=path,
                    method=method.upper(),
                    summary=method_data.get("summary", ""),
                    description=method_data.get("description", ""),
                    tags=method_data.get("tags", []),
                    deprecated=method_data.get("deprecated", False),
                )

                # è§£æå‚æ•°
                if "parameters" in method_data:
                    for param in method_data["parameters"]:
                        endpoint.parameters.append(param)

                # è§£æè¯·æ±‚ä½“
                if "requestBody" in method_data:
                    endpoint.request_body = method_data["requestBody"]

                # è§£æå“åº”
                if "responses" in method_data:
                    for status_code, response_data in method_data["responses"].items():
                        endpoint.responses.append(
                            {
                                "status_code": int(status_code),
                                "description": response_data.get("description", ""),
                                "content": response_data.get("content", {}),
                            }
                        )

                # è§£æå®‰å…¨è¦æ±‚
                if "security" in method_data:
                    endpoint.security = method_data["security"]

                scan_result.endpoints.append(endpoint)

    def _normalize_url(self, url: str) -> str:
        """æ ‡å‡†åŒ–URL"""
        if not url.startswith(("http://", "https://")):
            url = "http://" + url

        parsed = urlparse(url)
        return f"{parsed.scheme}://{parsed.netloc}"

    def export_contract(
        self,
        scan_result: ScanResult,
        format: str = "openapi",
        output_path: Optional[str] = None,
    ):
        """å¯¼å‡ºå¥‘çº¦"""
        if format.lower() == "openapi":
            contract = self._convert_to_openapi(scan_result)
        elif format.lower() == "swagger":
            contract = self._convert_to_swagger(scan_result)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}")

        if output_path:
            with open(output_path, "w", encoding="utf-8") as f:
                if format.lower() in ["openapi", "swagger"]:
                    json.dump(contract, f, indent=2, ensure_ascii=False)
                else:
                    raise ValueError(f"ä¸æ”¯æŒå¯¼å‡ºæ ¼å¼: {format}")

        print(f"âœ“ å¥‘çº¦å·²å¯¼å‡º: {output_path}")
        return contract

    def _convert_to_openapi(self, scan_result: ScanResult) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºOpenAPIæ ¼å¼"""
        contract = {
            "openapi": "3.0.0",
            "info": scan_result.metadata,
            "servers": [
                {
                    "url": scan_result.base_url,
                    "description": "Generated from reverse engineering",
                }
            ],
            "paths": {},
        }

        for endpoint in scan_result.endpoints:
            if endpoint.path not in contract["paths"]:
                contract["paths"][endpoint.path] = {}

            method_spec = {
                "summary": endpoint.summary,
                "description": endpoint.description,
                "tags": endpoint.tags,
                "deprecated": endpoint.deprecated,
            }

            # æ·»åŠ å‚æ•°
            if endpoint.parameters:
                method_spec["parameters"] = endpoint.parameters

            # æ·»åŠ è¯·æ±‚ä½“
            if endpoint.request_body:
                method_spec["requestBody"] = endpoint.request_body

            # æ·»åŠ å“åº”
            if endpoint.responses:
                method_spec["responses"] = {}
                for response in endpoint.responses:
                    method_spec["responses"][str(response["status_code"])] = {
                        "description": response["description"],
                        "content": response.get("content", {}),
                    }

            # æ·»åŠ å®‰å…¨è¦æ±‚
            if endpoint.security:
                method_spec["security"] = endpoint.security

            contract["paths"][endpoint.path][endpoint.method.lower()] = method_spec

        return contract

    def _convert_to_swagger(self, scan_result: ScanResult) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºSwagger 2.0æ ¼å¼"""
        contract = self._convert_to_openapi(scan_result)
        # è¿™é‡Œå¯ä»¥æ·»åŠ Swaggerç‰¹å®šçš„è½¬æ¢é€»è¾‘
        return contract

    def analyze_api_coverage(self, scan_result: ScanResult) -> Dict[str, Any]:
        """åˆ†æAPIè¦†ç›–ç‡"""
        coverage = {
            "total_endpoints": len(scan_result.endpoints),
            "by_method": {},
            "by_status_code": {},
            "by_path_pattern": {},
            "security_endpoints": 0,
            "deprecated_endpoints": 0,
        }

        for endpoint in scan_result.endpoints:
            # æŒ‰æ–¹æ³•ç»Ÿè®¡
            method = endpoint.method
            coverage["by_method"][method] = coverage["by_method"].get(method, 0) + 1

            # æŒ‰çŠ¶æ€ç ç»Ÿè®¡
            if endpoint.responses:
                for response in endpoint.responses:
                    status = response["status_code"]
                    coverage["by_status_code"][status] = (
                        coverage["by_status_code"].get(status, 0) + 1
                    )

            # æŒ‰è·¯å¾„æ¨¡å¼ç»Ÿè®¡
            path_pattern = self._extract_path_pattern(endpoint.path)
            coverage["by_path_pattern"][path_pattern] = (
                coverage["by_path_pattern"].get(path_pattern, 0) + 1
            )

            # å®‰å…¨ç«¯ç‚¹
            if endpoint.security:
                coverage["security_endpoints"] += 1

            # å·²åºŸå¼ƒç«¯ç‚¹
            if endpoint.deprecated:
                coverage["deprecated_endpoints"] += 1

        return coverage

    def _extract_path_pattern(self, path: str) -> str:
        """æå–è·¯å¾„æ¨¡å¼"""
        # å°†è·¯å¾„å‚æ•°æ›¿æ¢ä¸ºå ä½ç¬¦
        pattern = re.sub(r"\{[^}]+\}", "{param}", path)
        return pattern


# ä½¿ç”¨ç¤ºä¾‹
async def demo_reverse_contract_generator():
    """æ¼”ç¤ºåå‘å·¥ç¨‹å¥‘çº¦ç”Ÿæˆå™¨"""
    print("ğŸš€ æ¼”ç¤ºåå‘å·¥ç¨‹å¥‘çº¦ç”Ÿæˆå™¨")

    # åˆ›å»ºç”Ÿæˆå™¨
    generator = ReverseContractGenerator(timeout=15, max_concurrent=5)

    # æ¼”ç¤ºURLï¼ˆæ›¿æ¢ä¸ºå®é™…çš„ç›®æ ‡APIï¼‰
    test_urls = [
        "https://httpbin.org",
        "https://jsonplaceholder.typicode.com",
        "http://localhost:8000",  # å¦‚æœæœ¬åœ°æœ‰è¿è¡Œçš„æœåŠ¡
    ]

    for url in test_urls:
        print(f"\nğŸ”— æµ‹è¯•URL: {url}")
        try:
            # ç”Ÿæˆå¥‘çº¦
            scan_result = await generator.generate_contract(
                url, ScannerType.AUTO_DETECT
            )

            # åˆ†æè¦†ç›–ç‡
            coverage = generator.analyze_api_coverage(scan_result)
            print("\nğŸ“Š APIè¦†ç›–ç‡åˆ†æ:")
            print(f"  æ€»ç«¯ç‚¹æ•°: {coverage['total_endpoints']}")
            print(f"  æŒ‰æ–¹æ³•åˆ†å¸ƒ: {coverage['by_method']}")
            print(f"  å®‰å…¨ç«¯ç‚¹: {coverage['security_endpoints']}")
            print(f"  å·²åºŸå¼ƒç«¯ç‚¹: {coverage['deprecated_endpoints']}")

            # å¯¼å‡ºå¥‘çº¦
            contract = generator.export_contract(
                scan_result,
                format="openapi",
                output_path=f"reverse_contract_{url.replace('://', '_')}.json",
            )

            print("âœ… åå‘å·¥ç¨‹æ¼”ç¤ºå®Œæˆ")
            break

        except Exception as e:
            print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
            continue


if __name__ == "__main__":
    asyncio.run(demo_reverse_contract_generator())
