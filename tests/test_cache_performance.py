#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¼“å­˜æ€§èƒ½å¯¹æ¯”æµ‹è¯•

å¯¹æ¯”åœºæ™¯:
1. æ— ç¼“å­˜ DataManager vs å¸¦ç¼“å­˜ CachedDataManager
2. é‡å¤æŸ¥è¯¢æ€§èƒ½æå‡
3. å†…å­˜ä½¿ç”¨å¯¹æ¯”
4. ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡

åˆ›å»ºæ—¥æœŸ: 2025-10-25
ç‰ˆæœ¬: 1.0.0 (P3)
"""

import sys
import os
import time
import pandas as pd
import psutil
from datetime import datetime

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from core.data_manager import DataManager
from core.cached_data_manager import CachedDataManager
from core.data_classification import DataClassification


def get_memory_usage_mb():
    """è·å–å½“å‰è¿›ç¨‹å†…å­˜ä½¿ç”¨ï¼ˆMBï¼‰"""
    process = psutil.Process()
    return process.memory_info().rss / 1024 / 1024


def test_basic_cache_functionality():
    """æµ‹è¯•1: åŸºç¡€ç¼“å­˜åŠŸèƒ½"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•1: åŸºç¡€ç¼“å­˜åŠŸèƒ½")
    print("=" * 70)

    # åˆ›å»ºå¸¦ç¼“å­˜çš„ DataManager
    dm = CachedDataManager(
        enable_cache=True,
        cache_size=100,
        default_ttl=60
    )

    print("âœ… CachedDataManager åˆå§‹åŒ–æˆåŠŸ")
    print(f"   ç¼“å­˜å¤§å°: 100")
    print(f"   é»˜è®¤TTL: 60ç§’")

    # æŸ¥çœ‹åˆå§‹ç¼“å­˜ç»Ÿè®¡
    stats = dm.get_cache_stats()
    print(f"\nåˆå§‹ç¼“å­˜ç»Ÿè®¡:")
    for cache_name, cache_stats in stats.items():
        if cache_name != 'caching_enabled':
            print(f"   {cache_name}:")
            print(f"     - å¤§å°: {cache_stats.get('size', 0)}/{cache_stats.get('max_size', 0)}")
            print(f"     - å‘½ä¸­ç‡: {cache_stats.get('hit_rate', 0)}")

    return dm


def test_query_performance_comparison():
    """æµ‹è¯•2: æŸ¥è¯¢æ€§èƒ½å¯¹æ¯”"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•2: æŸ¥è¯¢æ€§èƒ½å¯¹æ¯”ï¼ˆæ¨¡æ‹Ÿé‡å¤æŸ¥è¯¢ï¼‰")
    print("=" * 70)

    # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰
    test_data = pd.DataFrame({
        'symbol': ['600000.SH'] * 1000,
        'price': list(range(1000)),
        'volume': list(range(1000, 2000)),
        'date': [datetime.now()] * 1000
    })

    print(f"\næ¨¡æ‹ŸæŸ¥è¯¢æ•°æ®: {len(test_data)} è¡Œ")

    # æµ‹è¯•åœºæ™¯ï¼šé‡å¤æŸ¥è¯¢10æ¬¡
    iterations = 10

    # åˆ›å»ºå®ä¾‹
    dm_no_cache = DataManager(enable_monitoring=False)
    dm_cached = CachedDataManager(enable_cache=True, default_ttl=300)

    print(f"\næ‰§è¡Œ {iterations} æ¬¡é‡å¤æŸ¥è¯¢...")

    # åœºæ™¯1: æ— ç¼“å­˜ï¼ˆæ¨¡æ‹Ÿï¼‰
    start_time = time.time()
    for i in range(iterations):
        # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢å»¶è¿Ÿ
        time.sleep(0.001)  # 1msæ¨¡æ‹ŸæŸ¥è¯¢æ—¶é—´
        result = test_data.copy()  # æ¨¡æ‹Ÿä»æ•°æ®åº“è¿”å›

    no_cache_time = (time.time() - start_time) * 1000

    # åœºæ™¯2: å¸¦ç¼“å­˜
    cache_key = 'test_query_key'
    dm_cached._cache_manager.set('query_cache', cache_key, test_data)

    start_time = time.time()
    for i in range(iterations):
        # ä»ç¼“å­˜è·å–ï¼ˆæå¿«ï¼‰
        result = dm_cached._cache_manager.get('query_cache', cache_key)

    cached_time = (time.time() - start_time) * 1000

    # è®¡ç®—æ€§èƒ½æå‡
    speedup = no_cache_time / cached_time if cached_time > 0 else float('inf')

    print(f"\næ€§èƒ½å¯¹æ¯”ç»“æœ:")
    print(f"   æ— ç¼“å­˜æ€»æ—¶é—´: {no_cache_time:.2f}ms")
    print(f"   å¸¦ç¼“å­˜æ€»æ—¶é—´: {cached_time:.2f}ms")
    print(f"   æ€§èƒ½æå‡: {speedup:.1f}x")
    print(f"   æ—¶é—´èŠ‚çœ: {no_cache_time - cached_time:.2f}ms ({(1 - cached_time/no_cache_time)*100:.1f}%)")

    return {
        'no_cache_time': no_cache_time,
        'cached_time': cached_time,
        'speedup': speedup
    }


def test_cache_hit_rate():
    """æµ‹è¯•3: ç¼“å­˜å‘½ä¸­ç‡"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•3: ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡")
    print("=" * 70)

    dm = CachedDataManager(enable_cache=True, cache_size=50, default_ttl=300)

    # æ¨¡æ‹Ÿ50ä¸ªä¸åŒçš„æŸ¥è¯¢ï¼ˆå¡«æ»¡ç¼“å­˜ï¼‰
    print("\næ¨¡æ‹Ÿ50ä¸ªä¸åŒæŸ¥è¯¢ï¼ˆå¡«æ»¡ç¼“å­˜ï¼‰...")
    for i in range(50):
        key = f"query_{i}"
        data = pd.DataFrame({'value': [i]})
        dm._cache_manager.set('query_cache', key, data)

    # æ¨¡æ‹Ÿ100æ¬¡æŸ¥è¯¢ï¼š50%å‘½ä¸­ï¼Œ50%æœªå‘½ä¸­
    print("æ¨¡æ‹Ÿ100æ¬¡æ··åˆæŸ¥è¯¢ï¼ˆ50%å‘½ä¸­ï¼Œ50%æœªå‘½ä¸­ï¼‰...")
    hits = 0
    misses = 0

    for i in range(100):
        if i % 2 == 0:
            # å‘½ä¸­ï¼šæŸ¥è¯¢å·²ç¼“å­˜çš„æ•°æ®
            key = f"query_{i % 50}"
            result = dm._cache_manager.get('query_cache', key)
            if result is not None:
                hits += 1
        else:
            # æœªå‘½ä¸­ï¼šæŸ¥è¯¢æ–°æ•°æ®
            key = f"query_new_{i}"
            result = dm._cache_manager.get('query_cache', key)
            if result is None:
                misses += 1

    hit_rate = (hits / (hits + misses) * 100) if (hits + misses) > 0 else 0

    print(f"\nç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡:")
    print(f"   æ€»æŸ¥è¯¢æ•°: {hits + misses}")
    print(f"   ç¼“å­˜å‘½ä¸­: {hits}")
    print(f"   ç¼“å­˜æœªå‘½ä¸­: {misses}")
    print(f"   å‘½ä¸­ç‡: {hit_rate:.1f}%")

    # è·å–å®˜æ–¹ç»Ÿè®¡
    stats = dm.get_cache_stats()
    if 'query_cache' in stats:
        print(f"\nå®˜æ–¹ç¼“å­˜ç»Ÿè®¡:")
        cache_stats = stats['query_cache']
        print(f"   å‘½ä¸­: {cache_stats.get('hits', 0)}")
        print(f"   æœªå‘½ä¸­: {cache_stats.get('misses', 0)}")
        print(f"   å‘½ä¸­ç‡: {cache_stats.get('hit_rate', 0)}")
        print(f"   å½“å‰å¤§å°: {cache_stats.get('size', 0)}/{cache_stats.get('max_size', 0)}")

    return hit_rate


def test_memory_usage():
    """æµ‹è¯•4: å†…å­˜ä½¿ç”¨å¯¹æ¯”"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•4: å†…å­˜ä½¿ç”¨å¯¹æ¯”")
    print("=" * 70)

    # åˆå§‹å†…å­˜
    initial_memory = get_memory_usage_mb()
    print(f"\nåˆå§‹å†…å­˜: {initial_memory:.2f}MB")

    # åˆ›å»ºå¸¦ç¼“å­˜çš„ DataManager
    dm = CachedDataManager(enable_cache=True, cache_size=1000, default_ttl=300)

    # ç¼“å­˜1000ä¸ªå°æ•°æ®é›†
    print("\nç¼“å­˜1000ä¸ªå°æ•°æ®é›†ï¼ˆæ¯ä¸ª10è¡Œï¼‰...")
    for i in range(1000):
        key = f"data_{i}"
        data = pd.DataFrame({
            'id': list(range(10)),
            'value': list(range(i, i+10))
        })
        dm._cache_manager.set('query_cache', key, data)

    # ç¼“å­˜åå†…å­˜
    after_cache_memory = get_memory_usage_mb()
    memory_increase = after_cache_memory - initial_memory

    print(f"\nå†…å­˜ä½¿ç”¨ç»Ÿè®¡:")
    print(f"   ç¼“å­˜å‰: {initial_memory:.2f}MB")
    print(f"   ç¼“å­˜å: {after_cache_memory:.2f}MB")
    print(f"   å¢åŠ : {memory_increase:.2f}MB")
    print(f"   å¹³å‡æ¯æ¡ç›®: {memory_increase/1000*1024:.2f}KB")

    # æ¸…é™¤ç¼“å­˜
    dm.clear_cache()

    # æ¸…é™¤åå†…å­˜
    after_clear_memory = get_memory_usage_mb()

    print(f"\næ¸…é™¤ç¼“å­˜å:")
    print(f"   å†…å­˜: {after_clear_memory:.2f}MB")
    print(f"   é‡Šæ”¾: {after_cache_memory - after_clear_memory:.2f}MB")

    return memory_increase


def test_lru_eviction():
    """æµ‹è¯•5: LRUæ·˜æ±°æœºåˆ¶"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•5: LRUæ·˜æ±°æœºåˆ¶")
    print("=" * 70)

    # åˆ›å»ºå°ç¼“å­˜ï¼ˆæœ€å¤š10ä¸ªæ¡ç›®ï¼‰
    dm = CachedDataManager(enable_cache=True, cache_size=10, default_ttl=300)

    print(f"\nç¼“å­˜å¤§å°é™åˆ¶: 10æ¡ç›®")

    # æ’å…¥15ä¸ªæ¡ç›®ï¼ˆè¶…è¿‡é™åˆ¶ï¼‰
    print("æ’å…¥15ä¸ªæ¡ç›®...")
    for i in range(15):
        key = f"item_{i}"
        data = pd.DataFrame({'value': [i]})
        dm._cache_manager.set('query_cache', key, data)

    # æ£€æŸ¥æœ€æ—©çš„5ä¸ªæ¡ç›®æ˜¯å¦è¢«æ·˜æ±°
    print("\næ£€æŸ¥LRUæ·˜æ±°:")
    evicted_count = 0
    kept_count = 0

    for i in range(15):
        key = f"item_{i}"
        result = dm._cache_manager.get('query_cache', key)
        if result is None:
            evicted_count += 1
            if i < 5:  # å‰5ä¸ªåº”è¯¥è¢«æ·˜æ±°
                print(f"   âœ… {key}: å·²æ·˜æ±°ï¼ˆç¬¦åˆé¢„æœŸï¼‰")
        else:
            kept_count += 1
            if i >= 5:  # å10ä¸ªåº”è¯¥ä¿ç•™
                print(f"   âœ… {key}: å·²ä¿ç•™ï¼ˆç¬¦åˆé¢„æœŸï¼‰")

    stats = dm.get_cache_stats()
    if 'query_cache' in stats:
        cache_stats = stats['query_cache']
        print(f"\næ·˜æ±°ç»Ÿè®¡:")
        print(f"   æ·˜æ±°æ•°é‡: {cache_stats.get('evictions', 0)}")
        print(f"   å½“å‰å¤§å°: {cache_stats.get('size', 0)}")

    return evicted_count


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("\n" + "=" * 70)
    print("ç¼“å­˜æ€§èƒ½ç»¼åˆæµ‹è¯•")
    print("=" * 70)
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    results = {}

    try:
        # æµ‹è¯•1: åŸºç¡€åŠŸèƒ½
        test_basic_cache_functionality()

        # æµ‹è¯•2: æ€§èƒ½å¯¹æ¯”
        perf_results = test_query_performance_comparison()
        results['performance'] = perf_results

        # æµ‹è¯•3: å‘½ä¸­ç‡
        hit_rate = test_cache_hit_rate()
        results['hit_rate'] = hit_rate

        # æµ‹è¯•4: å†…å­˜ä½¿ç”¨
        memory_increase = test_memory_usage()
        results['memory'] = memory_increase

        # æµ‹è¯•5: LRUæ·˜æ±°
        evicted_count = test_lru_eviction()
        results['evictions'] = evicted_count

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()

    # è¾“å‡ºæ€»ç»“
    print("\n" + "=" * 70)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 70)

    if 'performance' in results:
        perf = results['performance']
        print(f"\nğŸ“Š æ€§èƒ½æå‡: {perf['speedup']:.1f}x")
        print(f"   æ— ç¼“å­˜: {perf['no_cache_time']:.2f}ms")
        print(f"   æœ‰ç¼“å­˜: {perf['cached_time']:.2f}ms")

    if 'hit_rate' in results:
        print(f"\nğŸ¯ ç¼“å­˜å‘½ä¸­ç‡: {results['hit_rate']:.1f}%")

    if 'memory' in results:
        print(f"\nğŸ’¾ å†…å­˜å¼€é”€: {results['memory']:.2f}MB (1000æ¡ç›®)")

    if 'evictions' in results:
        print(f"\nğŸ”„ LRUæ·˜æ±°: {results['evictions']}ä¸ªæ¡ç›®è¢«æ·˜æ±°")

    print(f"\nâœ… æ‰€æœ‰ç¼“å­˜æµ‹è¯•å®Œæˆï¼")

    return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
