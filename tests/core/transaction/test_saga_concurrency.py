#!/usr/bin/env python3
"""
Saga äº‹åŠ¡å¹¶å‘å‹åŠ›æµ‹è¯•

éªŒè¯é‡ç‚¹:
1. å¤šä¸ªå¹¶å‘ Saga äº‹åŠ¡çš„æ‰§è¡Œç¨³å®šæ€§ã€‚
2. æ•°æ®åº“è¿æ¥æ± åœ¨é«˜å¹¶å‘ä¸‹çš„è¡¨ç°ã€‚
3. éªŒè¯å¹¶å‘å›æ»šæ—¶çš„è¡¥å¿é€»è¾‘æ˜¯å¦æ­£ç¡®ï¼ˆæ˜¯å¦å­˜åœ¨ Race Conditionï¼‰ã€‚
"""

import os
import random
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta

import pandas as pd
import pytest

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))))

from src.core import DataClassification
from src.core.data_manager import DataManager

# å¹¶å‘æ•°é…ç½®
CONCURRENCY_LEVEL = 20  # å¹¶å‘çº¿ç¨‹æ•°
TOTAL_TRANSACTIONS = 50  # æ€»äº‹åŠ¡æ•°


class TestSagaConcurrency:

    @pytest.fixture(scope="class")
    def shared_dm(self):
        """Class-level DataManager to share connection pool"""
        return DataManager(enable_monitoring=True)

    def generate_kline_data(self, symbol, index):
        """ç”Ÿæˆæ¨¡æ‹Ÿ K çº¿æ•°æ®"""
        now = datetime.now()
        data = [
            {
                "ts": now + timedelta(minutes=index),
                "open": 10.0 + index * 0.1,
                "high": 11.0 + index * 0.1,
                "low": 9.0 + index * 0.1,
                "close": 10.5 + index * 0.1,
                "volume": 1000 + index,
                "amount": 10000.0 + index * 10,
                "symbol": symbol,
                "frequency": "1m",
            }
        ]
        return pd.DataFrame(data)

    def run_single_transaction(self, dm, txn_index):
        """æ‰§è¡Œå•ä¸ª Saga äº‹åŠ¡"""
        coordinator = dm.saga_coordinator

        # éšæœºå†³å®šæ˜¯æˆåŠŸè¿˜æ˜¯å¤±è´¥ (80% æˆåŠŸç‡)
        should_succeed = random.random() < 0.8
        symbol = f"CONC_TEST_{txn_index % 5}"  # 5ä¸ª Symbol è½®è¯¢ï¼Œåˆ¶é€ å†²çª

        kline_df = self.generate_kline_data(symbol, txn_index)
        business_id = f"{symbol}_CONC_{txn_index}_{int(time.time())}"

        def metadata_func(session):
            # æ¨¡æ‹Ÿ PG æ“ä½œå»¶è¿Ÿ
            time.sleep(random.uniform(0.01, 0.05))
            if not should_succeed:
                raise Exception(f"Simulated Failure for {business_id}")

        try:
            result = coordinator.execute_kline_sync(
                business_id=business_id,
                kline_data=kline_df,
                classification=DataClassification.MINUTE_KLINE,
                table_name="market_data.minute_kline",
                metadata_update_func=metadata_func,
            )
            return {"id": txn_index, "symbol": symbol, "expected": should_succeed, "actual": result, "error": None}
        except Exception as e:
            return {"id": txn_index, "symbol": symbol, "expected": should_succeed, "actual": False, "error": str(e)}

    def test_concurrent_saga_execution(self, shared_dm):
        """æ‰§è¡Œå¹¶å‘æµ‹è¯•"""
        print(f"\nğŸš€ å¼€å§‹ Saga å¹¶å‘å‹åŠ›æµ‹è¯• (Threads={CONCURRENCY_LEVEL}, Total={TOTAL_TRANSACTIONS})")

        start_time = time.time()
        results = []

        with ThreadPoolExecutor(max_workers=CONCURRENCY_LEVEL) as executor:
            future_to_txn = {
                executor.submit(self.run_single_transaction, shared_dm, i): i for i in range(TOTAL_TRANSACTIONS)
            }

            for future in as_completed(future_to_txn):
                try:
                    res = future.result()
                    results.append(res)
                except Exception as e:
                    print(f"  âŒ Thread Error: {e}")

        duration = time.time() - start_time
        print(f"  â±ï¸  è€—æ—¶: {duration:.2f}s (TPS: {TOTAL_TRANSACTIONS/duration:.2f})")

        # åˆ†æç»“æœ
        success_count = sum(1 for r in results if r["actual"])
        fail_count = sum(1 for r in results if not r["actual"])
        mismatch_count = sum(
            1 for r in results if r["expected"] != r["actual"]
        )  # æ³¨æ„ï¼šSaga å†…éƒ¨æ¶ˆåŒ–äº†å¼‚å¸¸è¿”å› Falseï¼Œæ‰€ä»¥ expected False åº”å¯¹åº” actual False

        print(f"  ğŸ“Š ç»Ÿè®¡: æˆåŠŸ={success_count}, å¤±è´¥(å›æ»š)={fail_count}, å¼‚å¸¸={mismatch_count}")

        # éªŒè¯é€»è¾‘ä¸€è‡´æ€§
        # å¦‚æœ expected=True ä½† actual=Falseï¼Œå¯èƒ½æ˜¯å¶ç„¶çš„æ•°æ®åº“é”™è¯¯ï¼ˆå¦‚é”è¶…æ—¶ï¼‰ï¼Œè¿™åœ¨é«˜å¹¶å‘ä¸‹æ˜¯å…è®¸çš„ï¼Œä½†ä¸èƒ½æœ‰æ•°æ®ä¸ä¸€è‡´
        # å…³é”®æ˜¯éªŒè¯ TDengine ä¸­ failed çš„äº‹åŠ¡æ˜¯å¦çœŸçš„è¢«æ ‡è®°ä¸ºæ— æ•ˆ

        failed_txns = [r for r in results if not r["actual"]]
        if failed_txns:
            print("  ğŸ” æŠ½æ ·éªŒè¯å›æ»šä¸€è‡´æ€§...")
            conn = shared_dm._tdengine.db_manager.get_connection(shared_dm._tdengine.db_type, "market_data")

            # éšæœºæŠ½æŸ¥ 3 ä¸ªå¤±è´¥äº‹åŠ¡
            sample_size = min(3, len(failed_txns))
            for i in range(sample_size):
                sample = failed_txns[i]
                symbol = sample["symbol"]
                # æŸ¥è¯¢è¯¥ Symbol æœ€è¿‘çš„æ— æ•ˆè®°å½•
                sql = f"SELECT count(*) FROM market_data.minute_kline WHERE symbol='{symbol}' AND is_valid=false"
                try:
                    df = pd.read_sql(sql, conn)
                    invalid_count = df.iloc[0, 0]
                    print(f"     - Symbol {symbol}: å‘ç° {invalid_count} æ¡æ— æ•ˆè®°å½• (é¢„æœŸè‡³å°‘åŒ…å«æœ¬æ¬¡å¤±è´¥)")
                    assert invalid_count > 0
                except Exception as e:
                    pytest.fail(f"éªŒè¯å¤±è´¥: {e}")

        assert len(results) == TOTAL_TRANSACTIONS
        print("  âœ… å¹¶å‘æµ‹è¯•é€šè¿‡")


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
