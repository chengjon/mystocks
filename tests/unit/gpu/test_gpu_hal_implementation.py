#!/usr/bin/env python3
"""
GPUç¡¬ä»¶æŠ½è±¡å±‚ï¼ˆHALï¼‰å®ç°æµ‹è¯•
éªŒè¯æ ¸å¿ƒç»„ä»¶çš„åŠŸèƒ½å’Œé›†æˆ
"""

import asyncio
import logging
import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

import numpy as np

# å¯¼å…¥HALç»„ä»¶
from src.gpu.core.hardware_abstraction import (
    DeviceHealthMonitor,
    GPUResourceManager,
    PerformanceProfile,
    PerformanceThreshold,
    RealTimeGPUPath,
    StrategyPriority,
)
from src.gpu.core.hardware_abstraction.memory_pool import MemoryPoolConfig

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


class HALImplementationTest:
    """HALå®ç°æµ‹è¯•ç±»"""

    def __init__(self):
        self.resource_manager = None
        self.realtime_path = None
        self.health_monitor = None
        self.test_results = {}

    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("=" * 60)
        logger.info("Starting GPU HAL Implementation Tests")
        logger.info("=" * 60)

        tests = [
            ("GPUèµ„æºç®¡ç†å™¨åˆå§‹åŒ–", self.test_resource_manager_init),
            ("ç­–ç•¥ä¸Šä¸‹æ–‡åˆ†é…", self.test_strategy_context_allocation),
            ("å†…å­˜æ± ç®¡ç†", self.test_memory_pool_management),
            ("å®æ—¶è·¯å¾„é¢„çƒ­", self.test_realtime_path_prewarming),
            ("å¥åº·ç›‘æ§", self.test_health_monitoring),
            ("æ€§èƒ½é˜ˆå€¼æ£€æŸ¥", self.test_performance_thresholds),
            ("é›†æˆæµ‹è¯•", self.test_integration),
        ]

        passed_tests = 0
        total_tests = len(tests)

        for test_name, test_func in tests:
            logger.info("\n--- Running Test: %(test_name)s ---")
            try:
                start_time = time.time()
                result = await test_func()
                duration = (time.time() - start_time) * 1000

                if result:
                    logger.info("âœ… %(test_name)s PASSED ({duration:.1f}ms)")
                    passed_tests += 1
                    self.test_results[test_name] = {
                        "status": "PASSED",
                        "duration_ms": duration,
                    }
                else:
                    logger.error("âŒ %(test_name)s FAILED")
                    self.test_results[test_name] = {
                        "status": "FAILED",
                        "duration_ms": duration,
                    }

            except Exception as e:
                logger.error("âŒ %(test_name)s ERROR: %(e)s")
                self.test_results[test_name] = {"status": "ERROR", "error": str(e)}

        # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
        logger.info("\n" + "=" * 60)
        logger.info("Test Results Summary")
        logger.info("=" * 60)
        logger.info("Total Tests: %(total_tests)s")
        logger.info("Passed: %(passed_tests)s")
        logger.info("Failed: {total_tests - passed_tests}")
        logger.info("Success Rate: {passed_tests / total_tests * 100:.1f}%")

        return passed_tests == total_tests

    async def test_resource_manager_init(self):
        """æµ‹è¯•GPUèµ„æºç®¡ç†å™¨åˆå§‹åŒ–"""
        self.resource_manager = GPUResourceManager()
        success = await self.resource_manager.initialize()

        if success:
            devices = self.resource_manager.get_available_devices()
            logger.info("Detected {len(devices)} GPU devices")
            for device in devices:
                logger.info("  Device {device.device_id}: {device.name} ({device.memory_total}MB)")
        else:
            logger.error("Failed to initialize GPU ResourceManager")

        return success

    async def test_strategy_context_allocation(self):
        """æµ‹è¯•ç­–ç•¥ä¸Šä¸‹æ–‡åˆ†é…"""
        if not self.resource_manager:
            return False

        # åˆ›å»ºåˆ†é…è¯·æ±‚
        from src.gpu.core.hardware_abstraction.interfaces import AllocationRequest

        request = AllocationRequest(
            strategy_id="test_strategy_001",
            priority=StrategyPriority.HIGH,
            required_memory=512,  # 512MB
            performance_profile=PerformanceProfile(max_memory_usage=0.8, latency_target_ms=1.0),
        )

        # åˆ†é…ç­–ç•¥ä¸Šä¸‹æ–‡
        context = await self.resource_manager.allocate_context(request)

        if context:
            logger.info("Allocated context for strategy {context.get_strategy_id()}")
            logger.info("Device ID: {context.get_device_id()}")

            # æµ‹è¯•æ€§èƒ½æŒ‡æ ‡
            metrics = context.get_performance_metrics()
            logger.info("Strategy metrics: %(metrics)s")

            # æ¸…ç†
            success = await self.resource_manager.release_context("test_strategy_001")
            return success
        else:
            logger.error("Failed to allocate strategy context")
            return False

    async def test_memory_pool_management(self):
        """æµ‹è¯•å†…å­˜æ± ç®¡ç†"""
        config = MemoryPoolConfig(
            pool_size_mb=1024,  # 1GB
            device_id=0,
            strategy_id="test_memory_strategy",
        )

        from src.gpu.core.hardware_abstraction.memory_pool import MemoryPool

        memory_pool = MemoryPool(config)

        # æµ‹è¯•å†…å­˜åˆ†é…
        ptr1 = memory_pool.allocate(1024 * 1024, "test_memory_strategy")  # 1MB
        ptr2 = memory_pool.allocate(512 * 1024, "test_memory_strategy")  # 512KB

        if ptr1 and ptr2:
            logger.info("Memory allocation successful")

            # è·å–ä½¿ç”¨ç»Ÿè®¡
            stats = memory_pool.get_usage_statistics()
            logger.info("Memory usage: {stats['usage']['utilization']:.2%}")

            # æµ‹è¯•å†…å­˜é‡Šæ”¾
            success1 = memory_pool.deallocate(ptr1, "test_memory_strategy")
            success2 = memory_pool.deallocate(ptr2, "test_memory_strategy")

            if success1 and success2:
                logger.info("Memory deallocation successful")
                memory_pool.cleanup()
                return True

        return False

    async def test_realtime_path_prewarming(self):
        """æµ‹è¯•å®æ—¶è·¯å¾„é¢„çƒ­"""
        self.realtime_path = RealTimeGPUPath()

        # æ¨¡æ‹Ÿç­–ç•¥ä¸Šä¸‹æ–‡
        mock_contexts = []
        for i in range(2):
            # è¿™é‡Œéœ€è¦åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„ç­–ç•¥ä¸Šä¸‹æ–‡
            # ç”±äºæˆ‘ä»¬æ²¡æœ‰å®Œæ•´çš„å®ç°ï¼Œä½¿ç”¨ä¸€ä¸ªç®€å•çš„æ¨¡æ‹Ÿ
            class MockStrategyContext:
                def get_strategy_id(self):
                    return f"mock_strategy_{i}"

                def get_device_id(self):
                    return 0

            mock_contexts.append(MockStrategyContext())

        # æµ‹è¯•æ ¸å‡½æ•°ç¼–è¯‘
        kernel_results = await self.realtime_path.compile_common_kernels(["matrix_multiply", "feature_transform"])

        if kernel_results.get("matrix_multiply", False):
            logger.info("Kernel compilation successful")

            # æµ‹è¯•å†…å­˜æ± åˆ†é…
            memory_success = await self.realtime_path.allocate_and_lock_memory_pools(512)
            if memory_success:
                logger.info("Memory pool allocation successful")

                # æµ‹è¯•è¡Œæƒ…æ•°æ®åŠ è½½
                market_data = np.random.random((1000, 10)).astype(np.float32)
                data_success = await self.realtime_path.load_market_data_to_gpu(market_data)

                if data_success:
                    logger.info("Market data loading successful")

                    # è·å–é¢„çƒ­çŠ¶æ€
                    status = self.realtime_path.get_prewarm_status()
                    logger.info("Prewarm status: %(status)s")

                    return True

        return False

    async def test_health_monitoring(self):
        """æµ‹è¯•å¥åº·ç›‘æ§"""
        if not self.resource_manager:
            return False

        self.health_monitor = DeviceHealthMonitor(
            self.resource_manager,
            thresholds=PerformanceThreshold(memory_threshold=0.8, compute_threshold=0.85),
        )

        # è·å–åˆå§‹è®¾å¤‡å¥åº·çŠ¶æ€
        summary = self.health_monitor.get_device_health_summary()
        logger.info("Health monitor status: {summary['monitoring_active']}")
        logger.info("Monitored devices: {summary['monitored_devices']}")

        # æ£€æŸ¥æ€§èƒ½é˜ˆå€¼
        if self.resource_manager.get_available_devices():
            device_id = self.resource_manager.get_available_devices()[0].device_id
            issues = self.health_monitor.check_performance_thresholds(device_id)
            logger.info("Performance issues: %(issues)s")

            return True

        return False

    async def test_performance_thresholds(self):
        """æµ‹è¯•æ€§èƒ½é˜ˆå€¼æ£€æŸ¥"""
        if not self.resource_manager or not self.health_monitor:
            return False

        # æ›´æ–°è®¾å¤‡æŒ‡æ ‡
        await self.resource_manager.update_device_metrics()

        # è·å–èµ„æºä½¿ç”¨æ‘˜è¦
        summary = self.resource_manager.get_resource_usage_summary()
        logger.info("Resource usage summary: %(summary)s")

        return True

    async def test_integration(self):
        """é›†æˆæµ‹è¯•"""
        try:
            # åˆ›å»ºå®Œæ•´çš„HALç»„ä»¶é›†æˆ
            if not self.resource_manager:
                return False

            # åˆ†é…å¤šä¸ªç­–ç•¥ä¸Šä¸‹æ–‡
            strategies = []
            for i in range(3):
                from src.gpu.core.hardware_abstraction.interfaces import (
                    AllocationRequest,
                )

                request = AllocationRequest(
                    strategy_id=f"integration_test_strategy_{i}",
                    priority=StrategyPriority.MEDIUM if i < 2 else StrategyPriority.LOW,
                    required_memory=256,
                )

                context = await self.resource_manager.allocate_context(request)
                if context:
                    strategies.append(context)

            if len(strategies) == 3:
                logger.info("Successfully allocated 3 strategy contexts")

                # æµ‹è¯•èµ„æºç®¡ç†æ‘˜è¦
                summary = self.resource_manager.get_resource_usage_summary()
                logger.info("Active strategies: {summary['active_strategies']}")

                # æ¸…ç†æ‰€æœ‰ç­–ç•¥
                for context in strategies:
                    await self.resource_manager.release_context(context.get_strategy_id())

                logger.info("Successfully cleaned up all strategies")
                return True

        except Exception as e:
            logger.error("Integration test error: %(e)s")
            return False

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.health_monitor:
            await self.health_monitor.stop_monitoring()

        if self.realtime_path:
            self.realtime_path.clear_prewarm()

        logger.info("HAL test cleanup completed")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    test = HALImplementationTest()

    try:
        success = await test.run_all_tests()

        if success:
            print("\nğŸ‰ All HAL implementation tests PASSED!")
            sys.exit(0)
        else:
            print("\nâŒ Some HAL implementation tests FAILED!")
            sys.exit(1)

    except KeyboardInterrupt:
        print("\nâš ï¸ Tests interrupted by user")
        sys.exit(1)

    except Exception as e:
        print(f"\nğŸ’¥ Unexpected error: {e}")
        sys.exit(1)

    finally:
        await test.cleanup()


if __name__ == "__main__":
    asyncio.run(main())
