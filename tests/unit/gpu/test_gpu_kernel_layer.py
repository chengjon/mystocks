#!/usr/bin/env python3
"""
Phase 6.2.3 è®¡ç®—å†…æ ¸å±‚æµ‹è¯•
éªŒè¯æ ‡å‡†åŒ–å†…æ ¸æ¥å£ã€çŸ©é˜µå†…æ ¸ã€å˜æ¢å†…æ ¸å’Œæ¨ç†å†…æ ¸çš„åŠŸèƒ½
"""

import asyncio
import logging
import sys
from pathlib import Path

import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


async def test_kernel_registry():
    """æµ‹è¯•å†…æ ¸æ³¨å†Œä¸­å¿ƒ"""
    print("ğŸ”§ æµ‹è¯•å†…æ ¸æ³¨å†Œä¸­å¿ƒ...")

    try:
        from src.gpu.core.kernels.kernel_registry import get_kernel_registry

        registry = get_kernel_registry()

        # è·å–æ³¨å†Œä¸­å¿ƒç»Ÿè®¡
        stats = registry.get_registry_stats()
        print(f"   æ³¨å†Œä¸­å¿ƒç»Ÿè®¡: {stats}")

        # åˆ—å‡ºæ‰€æœ‰å†…æ ¸
        kernels = registry.list_kernels()
        print(f"   å·²æ³¨å†Œå†…æ ¸æ•°é‡: {len(kernels)}")

        for name, metadata in kernels.items():
            print(f"   - {name}: {metadata.status.value}, æ”¯æŒ {len(metadata.supported_operations)} ä¸ªæ“ä½œ")

        # æµ‹è¯•æŸ¥æ‰¾å†…æ ¸
        matrix_kernels = registry.find_kernels_for_operation("matrix")
        print(f"   çŸ©é˜µå†…æ ¸: {matrix_kernels}")

        transform_kernels = registry.find_kernels_for_operation("transform")
        print(f"   å˜æ¢å†…æ ¸: {transform_kernels}")

        # æµ‹è¯•æœ€ä½³å†…æ ¸é€‰æ‹©
        best_matrix = registry.get_best_kernel_for_operation("matrix", "multiply", (1000, 1000))
        print(f"   æœ€ä½³çŸ©é˜µå†…æ ¸: {best_matrix}")

        return True, "å†…æ ¸æ³¨å†Œä¸­å¿ƒæµ‹è¯•é€šè¿‡"

    except Exception as e:
        return False, f"å†…æ ¸æ³¨å†Œä¸­å¿ƒæµ‹è¯•å¤±è´¥: {e}"


async def test_matrix_kernels():
    """æµ‹è¯•çŸ©é˜µå†…æ ¸"""
    print("ğŸ§® æµ‹è¯•çŸ©é˜µå†…æ ¸...")

    try:
        from src.gpu.core.kernels.matrix_kernels import MatrixKernelEngine
        from src.gpu.core.kernels.standardized_interface import (
            MatrixOperationConfig,
            MatrixOperationType,
        )

        # åˆ›å»ºçŸ©é˜µå†…æ ¸å¼•æ“
        kernel = MatrixKernelEngine()

        # åˆå§‹åŒ–
        success = await kernel.initialize()
        print(f"   çŸ©é˜µå†…æ ¸åˆå§‹åŒ–: {'æˆåŠŸ' if success else 'å¤±è´¥'}")

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        left_matrix = np.random.random((100, 100)).astype(np.float32)
        right_matrix = np.random.random((100, 100)).astype(np.float32)

        # æµ‹è¯•çŸ©é˜µä¹˜æ³•
        config = MatrixOperationConfig(operation_type=MatrixOperationType.MULTIPLY)
        result = await kernel.execute_matrix_operation(left_matrix, right_matrix, config)

        if result.success:
            print(f"   çŸ©é˜µä¹˜æ³•æˆåŠŸ: æ‰§è¡Œæ—¶é—´ {result.execution_time_ms:.2f}ms")
            print(f"   ç»“æœå½¢çŠ¶: {result.result_data.shape if result.result_data is not None else 'None'}")
            print(f"   å†…å­˜ä½¿ç”¨: {result.memory_used_bytes / 1024:.2f}KB")
        else:
            print(f"   çŸ©é˜µä¹˜æ³•å¤±è´¥: {result.error_message}")

        # æµ‹è¯•è½¬ç½®æ“ä½œ
        config_transpose = MatrixOperationConfig(operation_type=MatrixOperationType.TRANSPOSE)
        result_transpose = await kernel.execute_matrix_operation(left_matrix, config=config_transpose)

        if result_transpose.success:
            print(f"   çŸ©é˜µè½¬ç½®æˆåŠŸ: æ‰§è¡Œæ—¶é—´ {result_transpose.execution_time_ms:.2f}ms")

        # æµ‹è¯•æ‰¹é‡æ‰§è¡Œ
        operations = [
            (
                "multiply",
                left_matrix,
                right_matrix,
                MatrixOperationConfig(operation_type=MatrixOperationType.MULTIPLY),
            ),
            (
                "transpose",
                left_matrix,
                None,
                MatrixOperationConfig(operation_type=MatrixOperationType.TRANSPOSE),
            ),
        ]

        batch_results = await kernel.batch_execute(operations)
        print(f"   æ‰¹é‡æ‰§è¡Œ: {len(batch_results)} ä¸ªæ“ä½œï¼ŒæˆåŠŸ {sum(1 for r in batch_results if r.success)} ä¸ª")

        # è·å–æ€§èƒ½ç»Ÿè®¡
        stats = kernel.get_performance_stats()
        print(f"   æ€§èƒ½ç»Ÿè®¡: {stats}")

        return result.success, f"çŸ©é˜µå†…æ ¸æµ‹è¯•: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}"

    except Exception as e:
        return False, f"çŸ©é˜µå†…æ ¸æµ‹è¯•å¤±è´¥: {e}"


async def test_transform_kernels():
    """æµ‹è¯•å˜æ¢å†…æ ¸"""
    print("ğŸ”„ æµ‹è¯•å˜æ¢å†…æ ¸...")

    try:
        from src.gpu.core.kernels.standardized_interface import (
            TransformConfig,
            TransformOperationType,
        )
        from src.gpu.core.kernels.transform_kernels import TransformKernelEngine

        # åˆ›å»ºå˜æ¢å†…æ ¸å¼•æ“
        kernel = TransformKernelEngine()

        # åˆå§‹åŒ–
        success = await kernel.initialize()
        print(f"   å˜æ¢å†…æ ¸åˆå§‹åŒ–: {'æˆåŠŸ' if success else 'å¤±è´¥'}")

        # åˆ›å»ºæµ‹è¯•æ•°æ® (æ¨¡æ‹Ÿè‚¡ä»·åºåˆ—)
        price_data = np.random.random(1000).astype(np.float32) * 100 + 50

        # æµ‹è¯•æ ‡å‡†åŒ–
        config_normalize = TransformConfig(operation_type=TransformOperationType.NORMALIZE)
        result = await kernel.execute_transform_operation(price_data, config_normalize)

        if result.success:
            print(f"   æ•°æ®æ ‡å‡†åŒ–æˆåŠŸ: æ‰§è¡Œæ—¶é—´ {result.execution_time_ms:.2f}ms")
            if result.result_data is not None:
                normalized_data = result.result_data
                print(f"   æ ‡å‡†åŒ–åæ•°æ®èŒƒå›´: [{normalized_data.min():.4f}, {normalized_data.max():.4f}]")
        else:
            print(f"   æ•°æ®æ ‡å‡†åŒ–å¤±è´¥: {result.error_message}")

        # æµ‹è¯•æ»šåŠ¨å¹³å‡
        config_ma = TransformConfig(operation_type=TransformOperationType.ROLLING_MEAN, window_size=20)
        result_ma = await kernel.execute_transform_operation(price_data, config_ma)

        if result_ma.success:
            print(f"   æ»šåŠ¨å¹³å‡æˆåŠŸ: æ‰§è¡Œæ—¶é—´ {result_ma.execution_time_ms:.2f}ms")
            if result_ma.result_data is not None:
                ma_data = result_ma.result_data
                print(f"   æ»šåŠ¨å¹³å‡æ•°æ®é•¿åº¦: {len(ma_data)}")

        # æµ‹è¯•æ”¶ç›Šç‡è®¡ç®—
        config_return = TransformConfig(operation_type=TransformOperationType.RETURN)
        result_return = await kernel.execute_transform_operation(price_data, config_return)

        if result_return.success:
            print(f"   æ”¶ç›Šç‡è®¡ç®—æˆåŠŸ: æ‰§è¡Œæ—¶é—´ {result_return.execution_time_ms:.2f}ms")

        # è·å–æ”¯æŒçš„å˜æ¢æ“ä½œ
        supported_ops = kernel.get_supported_operations()
        print(f"   æ”¯æŒçš„å˜æ¢æ“ä½œ: {supported_ops}")

        return result.success, f"å˜æ¢å†…æ ¸æµ‹è¯•: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}"

    except Exception as e:
        return False, f"å˜æ¢å†…æ ¸æµ‹è¯•å¤±è´¥: {e}"


async def test_inference_kernels():
    """æµ‹è¯•æ¨ç†å†…æ ¸"""
    print("ğŸ¤– æµ‹è¯•æ¨ç†å†…æ ¸...")

    try:
        from src.gpu.core.kernels.inference_kernels import InferenceKernelEngine
        from src.gpu.core.kernels.standardized_interface import (
            InferenceConfig,
            InferenceOperationType,
        )

        # åˆ›å»ºæ¨ç†å†…æ ¸å¼•æ“
        kernel = InferenceKernelEngine()

        # åˆå§‹åŒ–
        success = await kernel.initialize()
        print(f"   æ¨ç†å†…æ ¸åˆå§‹åŒ–: {'æˆåŠŸ' if success else 'å¤±è´¥'}")

        # åˆ›å»ºæµ‹è¯•æ•°æ® (ç‰¹å¾çŸ©é˜µ)
        features = np.random.random((100, 10)).astype(np.float32)  # 100ä¸ªæ ·æœ¬ï¼Œ10ä¸ªç‰¹å¾
        targets = np.random.random(100).astype(np.float32)  # 100ä¸ªç›®æ ‡å€¼

        # æµ‹è¯•çº¿æ€§å›å½’
        config_lr = InferenceConfig(
            operation_type=InferenceOperationType.LINEAR_REGRESSION,
            model_params={"regularization": 0.01},
            input_shape=(100, 10),
            batch_size=32,
        )

        # ç®€åŒ–çš„çº¿æ€§å›å½’æµ‹è¯• (ä»…éªŒè¯æ¥å£)
        result = await kernel.execute_inference_operation(features, config_lr)

        if result.success:
            print(f"   çº¿æ€§å›å½’æ¥å£è°ƒç”¨æˆåŠŸ: æ‰§è¡Œæ—¶é—´ {result.execution_time_ms:.2f}ms")
            if result.result_data is not None:
                predictions = result.result_data
                print(f"   é¢„æµ‹ç»“æœå½¢çŠ¶: {predictions.shape}")
        else:
            print(f"   çº¿æ€§å›å½’æ¥å£è°ƒç”¨å¤±è´¥: {result.error_message}")

        # æµ‹è¯•PCAé™ç»´
        config_pca = InferenceConfig(
            operation_type=InferenceOperationType.PCA,
            model_params={"n_components": 5},
            input_shape=(100, 10),
            batch_size=32,
        )

        result_pca = await kernel.execute_inference_operation(features, config_pca)

        if result_pca.success:
            print(f"   PCAé™ç»´æ¥å£è°ƒç”¨æˆåŠŸ: æ‰§è¡Œæ—¶é—´ {result_pca.execution_time_ms:.2f}ms")
            if result_pca.result_data is not None:
                reduced_data = result_pca.result_data
                print(f"   é™ç»´åæ•°æ®å½¢çŠ¶: {reduced_data.shape}")

        # è·å–æ”¯æŒçš„æ¨ç†æ“ä½œ
        supported_ops = kernel.get_supported_operations()
        print(f"   æ”¯æŒçš„æ¨ç†æ“ä½œ: {supported_ops}")

        return result.success, f"æ¨ç†å†…æ ¸æµ‹è¯•: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}"

    except Exception as e:
        return False, f"æ¨ç†å†…æ ¸æµ‹è¯•å¤±è´¥: {e}"


async def test_kernel_executor():
    """æµ‹è¯•å†…æ ¸æ‰§è¡Œå™¨"""
    print("âš¡ æµ‹è¯•å†…æ ¸æ‰§è¡Œå™¨...")

    try:
        from src.gpu.core.kernels.kernel_executor import (
            BatchExecutionConfig,
            ExecutionMode,
            KernelExecutor,
        )
        from src.gpu.core.kernels.standardized_interface import (
            MatrixOperationConfig,
            TransformConfig,
        )

        # åˆ›å»ºå†…æ ¸æ‰§è¡Œå™¨
        executor = KernelExecutor()

        # å¯åŠ¨é˜Ÿåˆ—å¤„ç†å™¨
        await executor.start_queue_processor()

        # æµ‹è¯•å•ä¸ªæ‰§è¡Œ
        left_matrix = np.random.random((50, 50)).astype(np.float32)
        right_matrix = np.random.random((50, 50)).astype(np.float32)

        result = await executor.execute_matrix_operation(
            "Matrix",
            left_matrix,
            right_matrix,
            MatrixOperationConfig(operation_type=MatrixOperationType.MULTIPLY),
        )

        print(f"   å•ä¸ªçŸ©é˜µæ‰§è¡Œ: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}")

        # æµ‹è¯•è‡ªåŠ¨é€‰æ‹©å†…æ ¸
        price_data = np.random.random(200).astype(np.float32)
        auto_result = await executor.execute_with_auto_selection(
            operation_type="transform",
            operation_name="normalize",
            data=price_data,
            config=TransformConfig(operation_type=TransformOperationType.NORMALIZE),
        )

        print(f"   è‡ªåŠ¨å†…æ ¸é€‰æ‹©: {'æˆåŠŸ' if auto_result.success else 'å¤±è´¥'}")

        # æµ‹è¯•æ‰¹é‡æ‰§è¡Œ
        from src.gpu.core.kernels.standardized_interface import (
            ExecutionContext,
            ExecutionPriority,
        )

        contexts = [
            ExecutionContext(
                kernel_name="Matrix",
                operation_type="matrix",
                data=(
                    np.random.random((20, 20)).astype(np.float32),
                    np.random.random((20, 20)).astype(np.float32),
                ),
                config=MatrixOperationConfig(operation_type=MatrixOperationType.MULTIPLY),
                priority=ExecutionPriority.NORMAL,
            ),
            ExecutionContext(
                kernel_name="Transform",
                operation_type="transform",
                data=np.random.random(100).astype(np.float32),
                config=TransformConfig(operation_type=TransformOperationType.NORMALIZE),
                priority=ExecutionPriority.HIGH,
            ),
        ]

        batch_config = BatchExecutionConfig(max_parallel_jobs=2, enable_fail_fast=False, retry_failed_jobs=True)

        batch_results = await executor.execute_batch(contexts, batch_config, ExecutionMode.PARALLEL)

        success_count = sum(1 for r in batch_results if r.success)
        print(f"   æ‰¹é‡æ‰§è¡Œ: {success_count}/{len(batch_results)} æˆåŠŸ")

        # è·å–æ‰§è¡Œç»Ÿè®¡
        stats = executor.get_execution_stats()
        print(f"   æ‰§è¡Œå™¨ç»Ÿè®¡: {stats}")

        # åœæ­¢é˜Ÿåˆ—å¤„ç†å™¨
        await executor.stop_queue_processor()

        return (
            success_count > 0,
            f"å†…æ ¸æ‰§è¡Œå™¨æµ‹è¯•: {success_count}/{len(batch_results)} æˆåŠŸ",
        )

    except Exception as e:
        return False, f"å†…æ ¸æ‰§è¡Œå™¨æµ‹è¯•å¤±è´¥: {e}"


async def test_integration_workflow():
    """æµ‹è¯•é›†æˆå·¥ä½œæµ"""
    print("ğŸ”— æµ‹è¯•é›†æˆå·¥ä½œæµ...")

    try:
        from src.gpu.core.kernels.kernel_executor import get_kernel_executor
        from src.gpu.core.kernels.kernel_registry import get_kernel_registry
        from src.gpu.core.kernels.standardized_interface import TransformOperationType

        # è·å–æ³¨å†Œä¸­å¿ƒå’Œæ‰§è¡Œå™¨
        registry = get_kernel_registry()
        executor = get_kernel_executor()

        # å¯åŠ¨æ‰§è¡Œå™¨
        await executor.start_queue_processor()

        # åˆ›å»ºé‡‘èæ•°æ®å¤„ç†å·¥ä½œæµ
        # 1. ç”Ÿæˆæ¨¡æ‹Ÿå¸‚åœºæ•°æ®
        price_data = np.random.random(500).astype(np.float32) * 50 + 100
        volume_data = np.random.random(500).astype(np.float32) * 1000000

        # 2. è®¡ç®—ä»·æ ¼æ”¶ç›Šç‡
        return_result = await executor.execute_with_auto_selection(
            operation_type="transform",
            operation_name="return",
            data=price_data,
            config=TransformConfig(operation_type=TransformOperationType.RETURN),
        )

        # 3. è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        price_volume_matrix = np.column_stack([price_data, volume_data])
        correlation_result = await executor.execute_with_auto_selection(
            operation_type="transform",
            operation_name="correlation",
            data=price_volume_matrix,
            config=TransformConfig(operation_type=TransformOperationType.CORRELATION),
        )

        # 4. æ‰§è¡ŒçŸ©é˜µè¿ç®—
        if correlation_result.success and correlation_result.result_data is not None:
            matrix_result = await executor.execute_with_auto_selection(
                operation_type="matrix",
                operation_name="multiply",
                data=correlation_result.result_data,
                data_shape=correlation_result.result_data.shape,
            )

        # éªŒè¯å·¥ä½œæµå®Œæˆ
        workflow_success = (
            return_result.success and correlation_result.success and (correlation_result.result_data is not None)
        )

        print(f"   å·¥ä½œæµçŠ¶æ€: {'æˆåŠŸ' if workflow_success else 'å¤±è´¥'}")
        print(f"   æ”¶ç›Šç‡è®¡ç®—: {'æˆåŠŸ' if return_result.success else 'å¤±è´¥'}")
        print(f"   ç›¸å…³æ€§è®¡ç®—: {'æˆåŠŸ' if correlation_result.success else 'å¤±è´¥'}")

        # è·å–æœ€ç»ˆç»Ÿè®¡
        final_stats = executor.get_execution_stats()
        registry_stats = registry.get_registry_stats()

        print(
            f"   æœ€ç»ˆæ‰§è¡Œç»Ÿè®¡: æ€»æ‰§è¡Œ {final_stats['total_executions']} æ¬¡ï¼ŒæˆåŠŸç‡ {final_stats.get('success_rate', 0):.2%}"
        )
        print(f"   æ³¨å†Œä¸­å¿ƒç»Ÿè®¡: {registry_stats['total_kernels']} ä¸ªå†…æ ¸ï¼Œ{registry_stats['active_kernels']} ä¸ªæ´»è·ƒ")

        # åœæ­¢æ‰§è¡Œå™¨
        await executor.stop_queue_processor()

        return workflow_success, f"é›†æˆå·¥ä½œæµ: {'æˆåŠŸ' if workflow_success else 'å¤±è´¥'}"

    except Exception as e:
        return False, f"é›†æˆå·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}"


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹Phase 6.2.3è®¡ç®—å†…æ ¸å±‚æµ‹è¯•\n")

    test_functions = [
        test_kernel_registry,
        test_matrix_kernels,
        test_transform_kernels,
        test_inference_kernels,
        test_kernel_executor,
        test_integration_workflow,
    ]

    results = []

    for test_func in test_functions:
        try:
            success, message = await test_func()
            results.append((test_func.__name__, success, message))
            print(f"   {'âœ…' if success else 'âŒ'} {message}\n")
        except Exception as e:
            results.append((test_func.__name__, False, f"æµ‹è¯•å¼‚å¸¸: {e}"))
            print(f"   âŒ æµ‹è¯•å¼‚å¸¸: {e}\n")

    # æ±‡æ€»ç»“æœ
    passed = sum(1 for _, success, _ in results if success)
    total = len(results)

    print("=" * 60)
    print(f"ğŸ“Š æµ‹è¯•æ±‡æ€»: {passed}/{total} é€šè¿‡")
    print("=" * 60)

    for test_name, success, message in results:
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{status} {test_name}: {message}")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Phase 6.2.3è®¡ç®—å†…æ ¸å±‚å®ç°å®Œæˆ")
        return True
    else:
        print(f"\nâš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å®ç°")
        return False


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success = asyncio.run(run_all_tests())
    sys.exit(0 if success else 1)
