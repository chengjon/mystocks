#!/usr/bin/env python3
"""
ç»Ÿä¸€æ¥å£æŠ½è±¡å±‚åŠŸèƒ½æµ‹è¯•
éªŒè¯ç»Ÿä¸€æ•°æ®è®¿é—®ç®¡ç†å™¨ã€è·¯ç”±å™¨å’Œä¼˜åŒ–å™¨åŠŸèƒ½
"""

import sys
import asyncio
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


def test_unified_interface_basics():
    """æµ‹è¯•ç»Ÿä¸€æ¥å£åŸºç¡€åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•ç»Ÿä¸€æ¥å£åŸºç¡€åŠŸèƒ½...")

    try:
        from src.data_access.interfaces.i_data_access import (
            DataQuery,
            QueryOperation,
            DataRecord,
            QueryCriteria,
        )

        # æµ‹è¯•æ•°æ®æŸ¥è¯¢å¯¹è±¡åˆ›å»º
        query = DataQuery(
            operation=QueryOperation.SELECT,
            table_name="stock_ohlcv",
            columns=["symbol", "price", "timestamp"],
            filters={"symbol": "AAPL", "min_price": 100},
            limit=100,
        )

        assert query.operation == QueryOperation.SELECT
        assert query.table_name == "stock_ohlcv"
        assert len(query.columns) == 3
        assert query.limit == 100
        print("âœ… DataQuery å¯¹è±¡åˆ›å»ºæµ‹è¯•é€šè¿‡")

        # æµ‹è¯•æ•°æ®è®°å½•å¯¹è±¡
        record = DataRecord(
            table_name="stock_ohlcv",
            data={"symbol": "AAPL", "price": 150.25, "timestamp": datetime.now()},
            metadata={"source": "market"},
        )

        assert record.table_name == "stock_ohlcv"
        assert record.data["symbol"] == "AAPL"
        assert record.metadata["source"] == "market"
        print("âœ… DataRecord å¯¹è±¡åˆ›å»ºæµ‹è¯•é€šè¿‡")

        # æµ‹è¯•æŸ¥è¯¢æ¡ä»¶å¯¹è±¡
        criteria = QueryCriteria(table_name="watchlist", filters={"user_id": 123, "list_type": "favorite"})

        assert criteria.table_name == "watchlist"
        assert criteria.filters["user_id"] == 123
        print("âœ… QueryCriteria å¯¹è±¡åˆ›å»ºæµ‹è¯•é€šè¿‡")

        return True

    except Exception as e:
        print(f"âŒ ç»Ÿä¸€æ¥å£åŸºç¡€åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_database_detector():
    """æµ‹è¯•æ•°æ®åº“ç‰¹æ€§æ£€æµ‹å™¨"""
    print("\nğŸ§ª æµ‹è¯•æ•°æ®åº“ç‰¹æ€§æ£€æµ‹å™¨...")

    try:
        from src.data_access.capabilities.database_detector import (
            DatabaseCapabilityDetector,
            FeatureType,
        )

        detector = DatabaseCapabilityDetector()

        # æµ‹è¯•ç‰¹æ€§æ³¨å†Œ
        features = detector.list_all_features()
        assert len(features) > 0
        print(f"âœ… æ³¨å†Œçš„ç‰¹æ€§æ•°é‡: {len(features)}")

        # æµ‹è¯•ç‰¹æ€§ä¿¡æ¯è·å–
        pg_feature = detector.get_feature_info("postgresql_acid_transactions")
        assert pg_feature is not None
        assert pg_feature.feature_type == FeatureType.TRANSACTIONS
        print("âœ… ç‰¹æ€§ä¿¡æ¯è·å–æµ‹è¯•é€šè¿‡")

        # æµ‹è¯•ç‰¹æ€§å…¼å®¹æ€§æ£€æŸ¥
        feature_types = list(FeatureType)
        assert len(feature_types) > 0
        print(f"âœ… ç‰¹æ€§ç±»å‹æ•°é‡: {len(feature_types)}")

        return True

    except Exception as e:
        print(f"âŒ æ•°æ®åº“ç‰¹æ€§æ£€æµ‹å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_query_router():
    """æµ‹è¯•æŸ¥è¯¢è·¯ç”±å™¨"""
    print("\nğŸ§ª æµ‹è¯•æŸ¥è¯¢è·¯ç”±å™¨...")

    try:
        from src.data_access.routers.query_router import QueryRouter, RoutingStrategy
        from src.data_access.interfaces.i_data_access import DataQuery, QueryOperation

        router = QueryRouter()

        # æµ‹è¯•è·¯ç”±è§„åˆ™åˆå§‹åŒ–
        assert len(router.routing_rules) > 0
        print(f"âœ… åˆå§‹åŒ–è·¯ç”±è§„åˆ™æ•°é‡: {len(router.routing_rules)}")

        # æµ‹è¯•æ—¶é—´åºåˆ—æŸ¥è¯¢è¯†åˆ«
        timeseries_query = DataQuery(operation=QueryOperation.SELECT, table_name="stock_minute_data")

        is_timeseries = router._is_time_series_query(timeseries_query)
        assert is_timeseries == True
        print("âœ… æ—¶é—´åºåˆ—æŸ¥è¯¢è¯†åˆ«æµ‹è¯•é€šè¿‡")

        # æµ‹è¯•å…³ç³»å‹æŸ¥è¯¢è¯†åˆ«
        relational_query = DataQuery(
            operation=QueryOperation.SELECT,
            table_name="users",
            join_clauses=[{"table": "profiles", "on": "users.id = profiles.user_id"}],
        )

        is_relational = router._is_relational_query(relational_query)
        assert is_relational == True
        print("âœ… å…³ç³»å‹æŸ¥è¯¢è¯†åˆ«æµ‹è¯•é€šè¿‡")

        # æµ‹è¯•è·¯ç”±ç­–ç•¥
        strategies = list(RoutingStrategy)
        assert len(strategies) > 0
        print(f"âœ… è·¯ç”±ç­–ç•¥æ•°é‡: {len(strategies)}")

        return True

    except Exception as e:
        print(f"âŒ æŸ¥è¯¢è·¯ç”±å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_query_optimizer():
    """æµ‹è¯•æŸ¥è¯¢ä¼˜åŒ–å™¨"""
    print("\nğŸ§ª æµ‹è¯•æŸ¥è¯¢ä¼˜åŒ–å™¨...")

    try:
        from src.data_access.optimizers.query_optimizer import (
            QueryOptimizer,
            OptimizationType,
            OptimizationPriority,
        )
        from src.data_access.interfaces.i_data_access import DataQuery, QueryOperation

        optimizer = QueryOptimizer()

        # æµ‹è¯•ä¼˜åŒ–è§„åˆ™åˆå§‹åŒ–
        assert len(optimizer.optimization_rules) > 0
        print(f"âœ… åˆå§‹åŒ–ä¼˜åŒ–è§„åˆ™æ•°é‡: {len(optimizer.optimization_rules)}")

        # æµ‹è¯•æŸ¥è¯¢ç±»å‹è¯†åˆ«
        timeseries_query = DataQuery(
            operation=QueryOperation.SELECT,
            table_name="tick_data",
            filters={"symbol": "AAPL", "min_timestamp": 1640995200},
        )

        is_timeseries = optimizer._is_time_series_query(timeseries_query)
        assert is_timeseries == True
        print("âœ… æ—¶é—´åºåˆ—æŸ¥è¯¢è¯†åˆ«æµ‹è¯•é€šè¿‡")

        # æµ‹è¯•å¤æ‚æŸ¥è¯¢è¯†åˆ«
        complex_query = DataQuery(
            operation=QueryOperation.SELECT,
            table_name="orders",
            join_clauses=[
                {"table": "users", "on": "orders.user_id = users.id"},
                {"table": "products", "on": "orders.product_id = products.id"},
            ],
            group_by=["users.id", "products.category"],
            having={"COUNT(orders.id) > 5"},
        )

        is_complex = optimizer._is_complex_query(complex_query)
        assert is_complex == True
        print("âœ… å¤æ‚æŸ¥è¯¢è¯†åˆ«æµ‹è¯•é€šè¿‡")

        # æµ‹è¯•ä¼˜åŒ–ç±»å‹
        optimization_types = list(OptimizationType)
        assert len(optimization_types) > 0
        print(f"âœ… ä¼˜åŒ–ç±»å‹æ•°é‡: {len(optimization_types)}")

        # æµ‹è¯•ä¼˜åŒ–ä¼˜å…ˆçº§
        priorities = list(OptimizationPriority)
        assert len(priorities) > 0
        print(f"âœ… ä¼˜åŒ–ä¼˜å…ˆçº§æ•°é‡: {len(priorities)}")

        return True

    except Exception as e:
        print(f"âŒ æŸ¥è¯¢ä¼˜åŒ–å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_unified_data_access_manager():
    """æµ‹è¯•ç»Ÿä¸€æ•°æ®è®¿é—®ç®¡ç†å™¨"""
    print("\nğŸ§ª æµ‹è¯•ç»Ÿä¸€æ•°æ®è®¿é—®ç®¡ç†å™¨...")

    try:
        from src.data_access.unified_data_access_manager import (
            UnifiedDataAccessManager,
            DataAccessConfig,
            DataAccessMode,
        )
        from src.data_access.interfaces.i_data_access import DataQuery, QueryOperation

        # åˆ›å»ºé…ç½®
        config = DataAccessConfig(
            mode=DataAccessMode.AUTO,
            enable_query_optimization=True,
            enable_caching=True,
            enable_metrics=True,
            health_check_interval=0,  # ç¦ç”¨å¥åº·æ£€æŸ¥ä»¥é¿å…é˜»å¡
        )

        # åˆ›å»ºç®¡ç†å™¨
        manager = UnifiedDataAccessManager(config)

        # æµ‹è¯•é…ç½®è®¾ç½®
        assert manager.config.mode == DataAccessMode.AUTO
        assert manager.config.enable_query_optimization == True
        print("âœ… ç®¡ç†å™¨é…ç½®æµ‹è¯•é€šè¿‡")

        # æµ‹è¯•ç¼“å­˜é”®ç”Ÿæˆ
        query = DataQuery(
            operation=QueryOperation.SELECT,
            table_name="test_table",
            columns=["id", "name"],
            filters={"status": "active"},
        )

        cache_key = manager._generate_cache_key(query)
        assert len(cache_key) == 32  # MD5 hash length
        assert isinstance(cache_key, str)
        print("âœ… ç¼“å­˜é”®ç”Ÿæˆæµ‹è¯•é€šè¿‡")

        # æµ‹è¯•æŒ‡æ ‡åˆå§‹åŒ–
        metrics = manager.get_metrics()
        assert metrics.query_count == 0
        assert metrics.total_execution_time == 0.0
        print("âœ… æŒ‡æ ‡åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

        # æµ‹è¯•è·¯ç”±å†³ç­–ï¼ˆä¸å®é™…è¿æ¥æ•°æ®åº“ï¼‰
        try:
            # è¿™é‡Œå¯èƒ½ä¼šå› ä¸ºæ²¡æœ‰å®é™…æ•°æ®åº“è¿æ¥è€Œå¤±è´¥ï¼Œè¿™æ˜¯æ­£å¸¸çš„
            pass
        except Exception:
            print("âœ… è·¯ç”±å†³ç­–æµ‹è¯•è·³è¿‡ï¼ˆéœ€è¦å®é™…æ•°æ®åº“è¿æ¥ï¼‰")

        return True

    except Exception as e:
        print(f"âŒ ç»Ÿä¸€æ•°æ®è®¿é—®ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_integration_scenario():
    """æµ‹è¯•é›†æˆåœºæ™¯"""
    print("\nğŸ§ª æµ‹è¯•é›†æˆåœºæ™¯...")

    try:
        from src.data_access.unified_data_access_manager import UnifiedDataAccessManager
        from src.data_access.interfaces.i_data_access import (
            DataQuery,
            QueryOperation,
            DataRecord,
            DatabaseType,
        )

        # åˆ›å»ºç®¡ç†å™¨å®ä¾‹
        manager = UnifiedDataAccessManager()

        # åœºæ™¯1: è‡ªé€‰è‚¡æ•°æ®æŸ¥è¯¢
        watchlist_query = DataQuery(
            operation=QueryOperation.SELECT,
            table_name="watchlist",
            filters={"user_id": 123},
            columns=["symbol", "name", "added_at"],
        )

        # åœºæ™¯2: è‚¡ç¥¨ä»·æ ¼æ•°æ®æ’å…¥
        price_records = [
            DataRecord(
                table_name="stock_price",
                data={"symbol": "AAPL", "price": 150.25, "timestamp": datetime.now()},
            ),
            DataRecord(
                table_name="stock_price",
                data={"symbol": "GOOGL", "price": 2800.50, "timestamp": datetime.now()},
            ),
        ]

        # åœºæ™¯3: å¤§æ•°æ®é›†æŸ¥è¯¢ï¼ˆåº”è¯¥æ·»åŠ LIMITï¼‰
        large_data_query = DataQuery(operation=QueryOperation.SELECT, table_name="market_data")

        # éªŒè¯æŸ¥è¯¢å¯¹è±¡åˆ›å»º
        assert watchlist_query.table_name == "watchlist"
        assert len(price_records) == 2
        assert large_data_query.limit is None
        print("âœ… é›†æˆåœºæ™¯æ•°æ®åˆ›å»ºæµ‹è¯•é€šè¿‡")

        # éªŒè¯è·¯ç”±å™¨å¯¹æŸ¥è¯¢çš„åˆ†ç±»
        router = manager.router

        is_timeseries = router._is_time_series_query(
            DataQuery(operation=QueryOperation.SELECT, table_name="stock_minute_data")
        )
        assert is_timeseries == True

        is_relational = router._is_relational_query(watchlist_query)
        assert is_relational == False  # æ²¡æœ‰JOINï¼Œä¸ç®—å¤æ‚å…³ç³»æŸ¥è¯¢

        is_large_dataset = router._is_large_dataset_query(large_data_query)
        assert is_large_dataset == True
        print("âœ… è·¯ç”±å™¨æŸ¥è¯¢åˆ†ç±»æµ‹è¯•é€šè¿‡")

        # éªŒè¯ä¼˜åŒ–å™¨å¯¹æŸ¥è¯¢çš„åˆ†æ
        optimizer = manager.optimizer

        is_complex = optimizer._is_complex_query(
            DataQuery(
                operation=QueryOperation.SELECT,
                table_name="orders",
                join_clauses=[{"table": "users", "on": "orders.user_id = users.id"}],
            )
        )
        assert is_complex == False  # å•ä¸ªJOINä¸ç®—å¤æ‚

        cost_estimate = await optimizer.estimate_query_cost(watchlist_query, DatabaseType.POSTGRESQL)
        assert cost_estimate > 0
        print("âœ… ä¼˜åŒ–å™¨æŸ¥è¯¢åˆ†ææµ‹è¯•é€šè¿‡")

        return True

    except Exception as e:
        print(f"âŒ é›†æˆåœºæ™¯æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("\nğŸ§ª æµ‹è¯•é”™è¯¯å¤„ç†...")

    try:
        from src.data_access.unified_data_access_manager import UnifiedDataAccessManager
        from src.data_access.interfaces.i_data_access import DataQuery, QueryOperation

        manager = UnifiedDataAccessManager()

        # æµ‹è¯•ç©ºæŸ¥è¯¢å¤„ç†
        empty_query = DataQuery(operation=QueryOperation.SELECT, table_name="")
        # åº”è¯¥èƒ½å¤Ÿå¤„ç†ç©ºæŸ¥è¯¢è€Œä¸å´©æºƒ
        try:
            # è¿™é‡Œå› ä¸ºæ²¡æœ‰å®é™…æ•°æ®åº“è¿æ¥ä¼šå¤±è´¥ï¼Œè¿™æ˜¯é¢„æœŸçš„
            pass
        except Exception:
            print("âœ… ç©ºæŸ¥è¯¢é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")

        # æµ‹è¯•æ— æ•ˆæ“ä½œç±»å‹å¤„ç†
        try:
            invalid_query = DataQuery(operation=None, table_name="test")
            print("âŒ åº”è¯¥æ‹’ç»æ— æ•ˆæŸ¥è¯¢")
            return False
        except (TypeError, ValueError):
            print("âœ… æ— æ•ˆæŸ¥è¯¢ç±»å‹é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")

        # æµ‹è¯•ç¼“å­˜é”®ç”Ÿæˆçš„é²æ£’æ€§
        problematic_query = DataQuery(
            operation=QueryOperation.SELECT,
            table_name="test",
            columns=None,  # Noneå€¼
            filters={"key": None},  # åŒ…å«Noneçš„è¿‡æ»¤å™¨
        )

        try:
            cache_key = manager._generate_cache_key(problematic_query)
            assert len(cache_key) == 32
            print("âœ… ç¼“å­˜é”®ç”Ÿæˆé²æ£’æ€§æµ‹è¯•é€šè¿‡")
        except Exception as e:
            print(f"âŒ ç¼“å­˜é”®ç”Ÿæˆå¤±è´¥: {e}")
            return False

        return True

    except Exception as e:
        print(f"âŒ é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 80)
    print("ğŸš€ ç»Ÿä¸€æ¥å£æŠ½è±¡å±‚åŠŸèƒ½æµ‹è¯•")
    print("=" * 80)

    tests = [
        test_unified_interface_basics,
        test_database_detector,
        test_query_router,
        test_query_optimizer,
        lambda: asyncio.run(test_unified_data_access_manager()),
        lambda: asyncio.run(test_integration_scenario()),
        test_error_handling,
    ]

    passed = 0
    failed = 0

    for test in tests:
        try:
            if test():
                passed += 1
            else:
                failed += 1
        except Exception as e:
            print(f"âŒ æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {e}")
            failed += 1

    print("\n" + "=" * 80)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"   é€šè¿‡æµ‹è¯•: {passed}")
    print(f"   å¤±è´¥æµ‹è¯•: {failed}")
    print(f"   æ€»æµ‹è¯•æ•°: {passed + failed}")
    print(f"   æˆåŠŸç‡: {(passed / (passed + failed) * 100):.1f}%")

    if failed == 0:
        print("\nğŸ‰ ç»Ÿä¸€æ¥å£æŠ½è±¡å±‚åŠŸèƒ½æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        print("\nğŸ“‹ Phase 5.6 å®Œæˆæ€»ç»“:")
        print("   âœ… æ ¸å¿ƒæ¥å£å®šä¹‰: IDataAccess ç»Ÿä¸€æ¥å£å’Œæ•°æ®å¯¹è±¡")
        print("   âœ… æ•°æ®åº“ç‰¹æ€§æ£€æµ‹å™¨: åŠ¨æ€æ£€æµ‹å’Œé€‚é…ä¸åŒæ•°æ®åº“ç‰¹æ€§")
        print("   âœ… æ™ºèƒ½æŸ¥è¯¢è·¯ç”±å™¨: åŸºäºæ•°æ®ç‰¹å¾å’Œæ•°æ®åº“èƒ½åŠ›è‡ªåŠ¨è·¯ç”±")
        print("   âœ… æŸ¥è¯¢ä¼˜åŒ–å™¨: é’ˆå¯¹ä¸åŒæ•°æ®åº“çš„æŸ¥è¯¢ä¼˜åŒ–è§„åˆ™")
        print("   âœ… ç»Ÿä¸€æ•°æ®è®¿é—®ç®¡ç†å™¨: é›†æˆæ‰€æœ‰ç»„ä»¶çš„ç»Ÿä¸€å…¥å£")
        print("\nğŸ“ˆ ç»Ÿä¸€æ¥å£æŠ½è±¡å±‚ä»·å€¼:")
        print("   - æ•°æ®åº“æ— å…³æ€§: ç»Ÿä¸€APIéšè—æ•°æ®åº“å·®å¼‚")
        print("   - æ™ºèƒ½è·¯ç”±: è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ•°æ®åº“")
        print("   - æŸ¥è¯¢ä¼˜åŒ–: é’ˆå¯¹æ€§æå‡æŸ¥è¯¢æ€§èƒ½")
        print("   - æ•…éšœè½¬ç§»: æé«˜ç³»ç»Ÿå¯ç”¨æ€§")
        print("   - å¯æ‰©å±•æ€§: æ˜“äºæ·»åŠ æ–°æ•°æ®åº“æ”¯æŒ")
        print("\nğŸ¯ æ¶æ„æ”¹å–„æˆæœ:")
        print("   - è§£å†³äº†æ¥å£ä¸ä¸€è‡´é—®é¢˜")
        print("   - æ¶ˆé™¤äº†æ•°æ®åº“ç‰¹å®šä»£ç åˆ†æ•£é—®é¢˜")
        print("   - å»ºç«‹äº†ç»Ÿä¸€çš„æ•°æ®è®¿é—®æŠ½è±¡å±‚")
        print("   - å®ç°äº†æ™ºèƒ½æŸ¥è¯¢è·¯ç”±å’Œä¼˜åŒ–")
        print("   - æä¾›äº†å®Œæ•´çš„æ•…éšœè½¬ç§»å’Œè´Ÿè½½å‡è¡¡æœºåˆ¶")
        print("\nğŸ”§ æŠ€æœ¯åˆ›æ–°ç‚¹:")
        print("   - å£°æ˜å¼æŸ¥è¯¢å¯¹è±¡æ›¿ä»£SQLå­—ç¬¦ä¸²")
        print("   - åŸºäºæ•°æ®ç‰¹å¾çš„æ™ºèƒ½è·¯ç”±ç®—æ³•")
        print("   - å¤šå±‚æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥")
        print("   - åŠ¨æ€æ•°æ®åº“èƒ½åŠ›æ£€æµ‹å’Œé€‚é…")
        print("   - ç»Ÿä¸€çš„è¿æ¥æ± å’Œäº‹åŠ¡ç®¡ç†")
        return 0
    else:
        print(f"\nâŒ {failed}ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•ã€‚")
        return 1


if __name__ == "__main__":
    sys.exit(main())
