"""
æµ‹è¯•æŒ‡æ ‡åˆ†ææ¨¡å—

æä¾›æµ‹è¯•æ€§èƒ½æŒ‡æ ‡æ”¶é›†ã€åˆ†æå’Œå¯è§†åŒ–åŠŸèƒ½ã€‚
"""

import json
import logging
import time
from collections import defaultdict, deque
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Dict, List, Any, Optional
import statistics

import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots


class MetricType(Enum):
    """æŒ‡æ ‡ç±»å‹"""

    COUNTER = "counter"  # è®¡æ•°å™¨ï¼Œåªå¢ä¸å‡
    GAUGE = "gauge"  # æµ‹é‡å€¼ï¼Œå¯å¢å¯å‡
    HISTOGRAM = "histogram"  # ç›´æ–¹å›¾ï¼Œåˆ†å¸ƒæ•°æ®
    SUMMARY = "summary"  # æ‘˜è¦ï¼Œç»Ÿè®¡ä¿¡æ¯


@dataclass
class MetricDefinition:
    """æŒ‡æ ‡å®šä¹‰"""

    name: str
    description: str
    type: MetricType
    unit: str = ""
    tags: List[str] = field(default_factory=list)
    aggregation: str = "avg"  # avg, sum, max, min, count
    retention_hours: int = 24  # æ•°æ®ä¿ç•™æ—¶é—´


@dataclass
class TimeSeriesPoint:
    """æ—¶é—´åºåˆ—æ•°æ®ç‚¹"""

    timestamp: datetime
    value: float
    tags: Dict[str, str] = field(default_factory=dict)
    labels: Dict[str, str] = field(default_factory=dict)


class MetricCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self, max_points_per_metric: int = 10000):
        self.max_points_per_metric = max_points_per_metric
        self.time_series: Dict[str, deque] = defaultdict(
            lambda: deque(maxlen=max_points_per_metric)
        )
        self.counter_values: Dict[str, float] = defaultdict(float)
        self.histogram_buckets: Dict[str, List[float]] = defaultdict(list)
        self.definitions: Dict[str, MetricDefinition] = {}

    def register_metric(self, definition: MetricDefinition):
        """æ³¨å†ŒæŒ‡æ ‡"""
        self.definitions[definition.name] = definition
        logging.info(f"æ³¨å†ŒæŒ‡æ ‡: {definition.name}")

    def record_counter(self, name: str, value: float = 1, tags: Dict[str, str] = None):
        """è®°å½•è®¡æ•°å™¨æŒ‡æ ‡"""
        if name not in self.definitions:
            # è‡ªåŠ¨åˆ›å»ºé»˜è®¤å®šä¹‰
            self.definitions[name] = MetricDefinition(
                name=name,
                description=f"Counter metric: {name}",
                type=MetricType.COUNTER,
            )

        self.counter_values[name] += value
        self.time_series[name].append(
            TimeSeriesPoint(
                timestamp=datetime.now(),
                value=self.counter_values[name],
                tags=tags or {},
            )
        )

    def record_gauge(self, name: str, value: float, tags: Dict[str, str] = None):
        """è®°å½•æµ‹é‡å€¼æŒ‡æ ‡"""
        if name not in self.definitions:
            # è‡ªåŠ¨åˆ›å»ºé»˜è®¤å®šä¹‰
            self.definitions[name] = MetricDefinition(
                name=name, description=f"Gauge metric: {name}", type=MetricType.GAUGE
            )

        self.time_series[name].append(
            TimeSeriesPoint(timestamp=datetime.now(), value=value, tags=tags or {})
        )

    def record_histogram(self, name: str, value: float, tags: Dict[str, str] = None):
        """è®°å½•ç›´æ–¹å›¾æŒ‡æ ‡"""
        if name not in self.definitions:
            # è‡ªåŠ¨åˆ›å»ºé»˜è®¤å®šä¹‰
            self.definitions[name] = MetricDefinition(
                name=name,
                description=f"Histogram metric: {name}",
                type=MetricType.HISTOGRAM,
            )

        self.histogram_buckets[name].append(value)
        # é™åˆ¶æ¡¶å¤§å°
        max_buckets = 1000
        if len(self.histogram_buckets[name]) > max_buckets:
            self.histogram_buckets[name] = self.histogram_buckets[name][-max_buckets:]

        # åŒæ—¶è®°å½•æ—¶é—´åºåˆ—
        self.time_series[name].append(
            TimeSeriesPoint(timestamp=datetime.now(), value=value, tags=tags or {})
        )

    def get_metric_data(
        self,
        name: str,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None,
    ) -> List[TimeSeriesPoint]:
        """è·å–æŒ‡æ ‡æ•°æ®"""
        if name not in self.time_series:
            return []

        points = list(self.time_series[name])

        if start_time or end_time:
            filtered = []
            for point in points:
                if start_time and point.timestamp < start_time:
                    continue
                if end_time and point.timestamp > end_time:
                    continue
                filtered.append(point)
            return filtered

        return points

    def get_histogram_data(self, name: str) -> Dict[str, float]:
        """è·å–ç›´æ–¹å›¾ç»Ÿè®¡ä¿¡æ¯"""
        if name not in self.histogram_buckets or not self.histogram_buckets[name]:
            return {}

        values = self.histogram_buckets[name]
        return {
            "count": len(values),
            "sum": sum(values),
            "avg": statistics.mean(values),
            "min": min(values),
            "max": max(values),
            "p50": statistics.median(values),
            "p95": np.percentile(values, 95),
            "p99": np.percentile(values, 99),
            "std": statistics.stdev(values) if len(values) > 1 else 0,
        }

    def get_aggregated_value(
        self, name: str, aggregation: str = "avg", window_minutes: int = 5
    ) -> Optional[float]:
        """è·å–èšåˆå€¼"""
        if name not in self.time_series:
            return None

        end_time = datetime.now()
        start_time = end_time - timedelta(minutes=window_minutes)

        points = self.get_metric_data(name, start_time, end_time)
        if not points:
            return None

        values = [point.value for point in points]

        if aggregation == "avg":
            return statistics.mean(values)
        elif aggregation == "sum":
            return sum(values)
        elif aggregation == "max":
            return max(values)
        elif aggregation == "min":
            return min(values)
        elif aggregation == "count":
            return len(values)
        else:
            return statistics.mean(values)

    def cleanup_old_data(self, retention_hours: int = 24):
        """æ¸…ç†æ—§æ•°æ®"""
        cutoff_time = datetime.now() - timedelta(hours=retention_hours)

        for name, series in self.time_series.items():
            # è¿‡æ»¤æ‰æ—§æ•°æ®
            while series and series[0].timestamp < cutoff_time:
                series.popleft()

        # æ¸…ç†ç›´æ–¹å›¾æ•°æ®
        for name, buckets in self.histogram_buckets.items():
            # ä¿æŒæœ€è¿‘çš„æ•°æ®
            keep_count = min(len(buckets), 1000)
            self.histogram_buckets[name] = buckets[-keep_count:]


class TestMetricsAnalyzer:
    """æµ‹è¯•æŒ‡æ ‡åˆ†æå™¨"""

    def __init__(self, collector: MetricCollector):
        self.collector = collector

    def calculate_trend(self, name: str, window_minutes: int = 60) -> Dict[str, Any]:
        """è®¡ç®—è¶‹åŠ¿"""
        end_time = datetime.now()
        start_time = end_time - timedelta(minutes=window_minutes)

        points = self.collector.get_metric_data(name, start_time, end_time)
        if len(points) < 2:
            return {"trend": "insufficient_data", "slope": 0, "direction": "stable"}

        # å‡†å¤‡å›å½’åˆ†ææ•°æ®
        times = [(p.timestamp - start_time).total_seconds() for p in points]
        values = [p.value for p in points]

        # çº¿æ€§å›å½’è®¡ç®—æ–œç‡
        n = len(points)
        sum_x = sum(times)
        sum_y = sum(values)
        sum_xy = sum(t * v for t, v in zip(times, values))
        sum_x2 = sum(t * t for t in times)

        slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x)

        # åˆ¤æ–­è¶‹åŠ¿æ–¹å‘
        if abs(slope) < 0.01:
            direction = "stable"
        elif slope > 0:
            direction = "increasing"
        else:
            direction = "decreasing"

        return {
            "trend": direction,
            "slope": slope,
            "start_value": values[0] if values else 0,
            "end_value": values[-1] if values else 0,
            "change_percent": ((values[-1] - values[0]) / values[0] * 100)
            if values and values[0] != 0
            else 0,
        }

    def detect_anomalies(
        self, name: str, window_minutes: int = 60, threshold_std: float = 3.0
    ) -> List[Dict[str, Any]]:
        """æ£€æµ‹å¼‚å¸¸å€¼"""
        end_time = datetime.now()
        start_time = end_time - timedelta(minutes=window_minutes)

        points = self.collector.get_metric_data(name, start_time, end_time)
        if len(points) < 10:  # éœ€è¦è¶³å¤Ÿçš„æ•°æ®ç‚¹
            return []

        values = [p.value for p in points]
        mean = statistics.mean(values)
        std = statistics.stdev(values) if len(values) > 1 else 0

        if std == 0:
            return []

        anomalies = []
        for point in points:
            z_score = abs((point.value - mean) / std)
            if z_score > threshold_std:
                anomalies.append(
                    {
                        "timestamp": point.timestamp.isoformat(),
                        "value": point.value,
                        "z_score": z_score,
                        "deviation": point.value - mean,
                    }
                )

        return anomalies

    def calculate_performance_metrics(self, test_name: str) -> Dict[str, Any]:
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        # è·å–æ‰§è¡Œæ—¶é—´æ•°æ®
        execution_times = self.collector.get_metric_data(
            f"test_execution_time_{test_name}"
        )

        if not execution_times:
            return {}

        times = [p.value for p in execution_times]

        return {
            "total_executions": len(times),
            "avg_execution_time": statistics.mean(times),
            "min_execution_time": min(times),
            "max_execution_time": max(times),
            "p50_execution_time": statistics.median(times),
            "p95_execution_time": np.percentile(times, 95),
            "p99_execution_time": np.percentile(times, 99),
            "std_execution_time": statistics.stdev(times) if len(times) > 1 else 0,
            "success_rate": self._calculate_success_rate(test_name),
            "throughput": self._calculate_throughput(test_name),
        }

    def _calculate_success_rate(self, test_name: str) -> float:
        """è®¡ç®—æˆåŠŸç‡"""
        results = self.collector.get_metric_data(f"test_result_{test_name}")
        if not results:
            return 0.0

        success_count = sum(1 for r in results if r.value == 1.0)
        return success_count / len(results)

    def _calculate_throughput(self, test_name: str) -> float:
        """è®¡ç®—ååé‡ï¼ˆæ¯åˆ†é’Ÿæ‰§è¡Œæ¬¡æ•°ï¼‰"""
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=1)  # æœ€è¿‘1å°æ—¶

        executions = self.collector.get_metric_data(
            f"test_result_{test_name}", start_time, end_time
        )
        total_minutes = 60.0

        return len(executions) / total_minutes

    def generate_test_report(
        self, test_names: List[str], output_path: Optional[str] = None
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        report = {"generated_at": datetime.now().isoformat(), "tests": {}}

        for test_name in test_names:
            metrics = self.calculate_performance_metrics(test_name)

            # è®¡ç®—è¶‹åŠ¿
            trend = self.calculate_trend(f"test_execution_time_{test_name}")

            # æ£€æµ‹å¼‚å¸¸
            anomalies = self.detect_anomalies(f"test_execution_time_{test_name}")

            report["tests"][test_name] = {
                "performance_metrics": metrics,
                "execution_trend": trend,
                "anomalies": anomalies,
                "health_status": self._assess_test_health(test_name),
            }

        if output_path:
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(report, f, indent=2, ensure_ascii=False)

        return report

    def _assess_test_health(self, test_name: str) -> str:
        """è¯„ä¼°æµ‹è¯•å¥åº·çŠ¶æ€"""
        metrics = self.calculate_performance_metrics(test_name)

        if not metrics:
            return "unknown"

        # åŸºäºå¤šä¸ªæŒ‡æ ‡è¯„ä¼°å¥åº·çŠ¶æ€
        issues = []

        # æ£€æŸ¥æ‰§è¡Œæ—¶é—´è¶‹åŠ¿
        trend = self.calculate_trend(f"test_execution_time_{test_name}")
        if trend["trend"] == "increasing" and trend["change_percent"] > 20:
            issues.append("execution_time_increasing")

        # æ£€æŸ¥æˆåŠŸç‡
        success_rate = metrics.get("success_rate", 1.0)
        if success_rate < 0.9:
            issues.append("low_success_rate")

        # æ£€æŸ¥å¼‚å¸¸
        anomalies = self.detect_anomalies(f"test_execution_time_{test_name}")
        if len(anomalies) > 5:
            issues.append("high_anomaly_count")

        if not issues:
            return "healthy"
        elif len(issues) <= 2:
            return "warning"
        else:
            return "critical"


class TestVisualization:
    """æµ‹è¯•å¯è§†åŒ–"""

    def __init__(self, analyzer: TestMetricsAnalyzer):
        self.analyzer = analyzer

    def create_execution_time_chart(
        self, test_name: str, output_path: Optional[str] = None
    ) -> str:
        """åˆ›å»ºæ‰§è¡Œæ—¶é—´å›¾è¡¨"""
        points = self.analyzer.collector.get_metric_data(
            f"test_execution_time_{test_name}"
        )

        if not points:
            return ""

        df = pd.DataFrame(
            [
                {"timestamp": p.timestamp, "value": p.value, "test_name": test_name}
                for p in points
            ]
        )

        fig = px.line(
            df,
            x="timestamp",
            y="value",
            title=f"{test_name} æ‰§è¡Œæ—¶é—´è¶‹åŠ¿",
            labels={"value": "æ‰§è¡Œæ—¶é—´ (ç§’)", "timestamp": "æ—¶é—´"},
        )

        # æ·»åŠ è¶‹åŠ¿çº¿
        if len(df) > 1:
            z = np.polyfit(range(len(df)), df["value"], 1)
            p = np.poly1d(z)
            fig.add_trace(
                go.Scatter(
                    x=df["timestamp"],
                    y=p(range(len(df))),
                    mode="lines",
                    name="è¶‹åŠ¿çº¿",
                    line=dict(dash="dash"),
                )
            )

        if output_path:
            fig.write_html(output_path)
            return output_path

        return fig.to_html()

    def create_performance_dashboard(
        self, test_names: List[str], output_path: Optional[str] = None
    ) -> str:
        """åˆ›å»ºæ€§èƒ½ä»ªè¡¨æ¿"""
        fig = make_subplots(
            rows=2,
            cols=2,
            subplot_titles=("æ‰§è¡Œæ—¶é—´è¶‹åŠ¿", "æˆåŠŸç‡å¯¹æ¯”", "ååé‡åˆ†æ", "å¥åº·çŠ¶æ€"),
            specs=[
                [{"secondary_y": False}, {"secondary_y": False}],
                [{"secondary_y": False}, {"secondary_y": False}],
            ],
        )

        colors = px.colors.qualitative.Set1

        for i, test_name in enumerate(test_names[:5]):  # æœ€å¤šæ˜¾ç¤º5ä¸ªæµ‹è¯•
            # æ‰§è¡Œæ—¶é—´è¶‹åŠ¿
            points = self.analyzer.collector.get_metric_data(
                f"test_execution_time_{test_name}"
            )
            if points:
                df = pd.DataFrame(
                    [
                        {"timestamp": p.timestamp, "value": p.value}
                        for p in points[-100:]  # æœ€è¿‘100ä¸ªç‚¹
                    ]
                )

                fig.add_trace(
                    go.Scatter(
                        x=df["timestamp"],
                        y=df["value"],
                        name=f"{test_name}",
                        line=dict(color=colors[i % len(colors)]),
                    ),
                    row=1,
                    col=1,
                )

            # æˆåŠŸç‡å¯¹æ¯”
            metrics = self.analyzer.calculate_performance_metrics(test_name)
            fig.add_trace(
                go.Bar(
                    x=[test_name],
                    y=[metrics.get("success_rate", 0) * 100],
                    name=test_name,
                    marker_color=colors[i % len(colors)],
                ),
                row=1,
                col=2,
            )

            # ååé‡
            throughput = self.analyzer._calculate_throughput(test_name)
            fig.add_trace(
                go.Bar(
                    x=[test_name],
                    y=[throughput],
                    name=test_name,
                    marker_color=colors[i % len(colors)],
                ),
                row=2,
                col=1,
            )

            # å¥åº·çŠ¶æ€
            health_status = self.analyzer._assess_test_health(test_name)
            health_color = {
                "healthy": "green",
                "warning": "yellow",
                "critical": "red",
                "unknown": "gray",
            }[health_status]
            fig.add_trace(
                go.Scatter(
                    x=[test_name],
                    y=[1],
                    mode="markers",
                    name=f"{test_name} ({health_status})",
                    marker=dict(color=health_color, size=20, symbol="square"),
                ),
                row=2,
                col=2,
            )

        fig.update_layout(height=800, showlegend=True, title_text="æµ‹è¯•æ€§èƒ½ä»ªè¡¨æ¿")

        if output_path:
            fig.write_html(output_path)
            return output_path

        return fig.to_html()

    def create_anomaly_report(
        self, test_name: str, output_path: Optional[str] = None
    ) -> str:
        """åˆ›å»ºå¼‚å¸¸æŠ¥å‘Š"""
        anomalies = self.analyzer.detect_anomalies(f"test_execution_time_{test_name}")

        if not anomalies:
            return "<div>æœªæ£€æµ‹åˆ°å¼‚å¸¸</div>"

        df = pd.DataFrame(anomalies)

        fig = make_subplots(
            rows=2,
            cols=1,
            subplot_titles=("æ‰§è¡Œæ—¶é—´å¼‚å¸¸æ£€æµ‹", "Z-scoreåˆ†å¸ƒ"),
            vertical_spacing=0.1,
        )

        # æ—¶é—´åºåˆ—å›¾ï¼Œæ ‡è®°å¼‚å¸¸ç‚¹
        all_points = self.analyzer.collector.get_metric_data(
            f"test_execution_time_{test_name}"
        )
        if all_points:
            df_all = pd.DataFrame(
                [{"timestamp": p.timestamp, "value": p.value} for p in all_points]
            )

            fig.add_trace(
                go.Scatter(
                    x=df_all["timestamp"],
                    y=df_all["value"],
                    mode="lines+markers",
                    name="æ‰§è¡Œæ—¶é—´",
                ),
                row=1,
                col=1,
            )

            # æ ‡è®°å¼‚å¸¸ç‚¹
            fig.add_trace(
                go.Scatter(
                    x=pd.to_datetime(df["timestamp"]),
                    y=df["value"],
                    mode="markers",
                    name="å¼‚å¸¸ç‚¹",
                    marker=dict(color="red", size=10),
                ),
                row=1,
                col=1,
            )

        # Z-scoreåˆ†å¸ƒ
        if not df.empty:
            fig.add_trace(
                go.Histogram(x=df["z_score"], name="Z-scoreåˆ†å¸ƒ", nbinsx=20),
                row=2,
                col=1,
            )

        fig.update_layout(
            height=600, showlegend=True, title_text=f"{test_name} å¼‚å¸¸æ£€æµ‹æŠ¥å‘Š"
        )

        if output_path:
            fig.write_html(output_path)
            return output_path

        return fig.to_html()


# ä½¿ç”¨ç¤ºä¾‹
def demo_metrics_analytics():
    """æ¼”ç¤ºæŒ‡æ ‡åˆ†æåŠŸèƒ½"""
    print("ğŸš€ æ¼”ç¤ºæµ‹è¯•æŒ‡æ ‡åˆ†æç³»ç»Ÿ")

    # åˆ›å»ºæŒ‡æ ‡æ”¶é›†å™¨
    collector = MetricCollector(max_points_per_metric=5000)

    # æ³¨å†ŒæŒ‡æ ‡
    collector.register_metric(
        MetricDefinition(
            name="test_execution_time",
            description="æµ‹è¯•æ‰§è¡Œæ—¶é—´",
            type=MetricType.GAUGE,
            unit="seconds",
        )
    )

    collector.register_metric(
        MetricDefinition(
            name="test_result",
            description="æµ‹è¯•ç»“æœ",
            type=MetricType.COUNTER,
            unit="boolean",
        )
    )

    # æ¨¡æ‹Ÿæµ‹è¯•æ‰§è¡Œ
    for i in range(100):
        import random

        test_name = f"test_{(i % 10) + 1}"
        execution_time = random.uniform(10, 200)
        passed = random.choice([True, True, False])  # 66.7% é€šè¿‡ç‡

        collector.record_gauge(f"test_execution_time_{test_name}", execution_time)
        collector.record_counter(f"test_result_{test_name}", 1 if passed else 0)

        time.sleep(0.1)

    # åˆ›å»ºåˆ†æå™¨
    analyzer = TestMetricsAnalyzer(collector)

    # è®¡ç®—è¶‹åŠ¿
    trend = analyzer.calculate_trend("test_execution_time_test_1")
    print(f"\nğŸ“ˆ æµ‹è¯•1çš„è¶‹åŠ¿åˆ†æ: {trend}")

    # æ£€æµ‹å¼‚å¸¸
    anomalies = analyzer.detect_anomalies("test_execution_time_test_1")
    print(f"ğŸš¨ æ£€æµ‹åˆ° {len(anomalies)} ä¸ªå¼‚å¸¸")

    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_test_report(
        ["test_1", "test_2"], "test_metrics_report.json"
    )
    print(f"\nğŸ“„ å·²ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š: {report['generated_at']}")

    # åˆ›å»ºå¯è§†åŒ–
    viz = TestVisualization(analyzer)

    # åˆ›å»ºæ‰§è¡Œæ—¶é—´å›¾è¡¨
    chart_html = viz.create_execution_time_chart("test_1", "execution_time_chart.html")
    print("ğŸ“Š å·²åˆ›å»ºæ‰§è¡Œæ—¶é—´å›¾è¡¨: chart_html")

    # åˆ›å»ºæ€§èƒ½ä»ªè¡¨æ¿
    dashboard_html = viz.create_performance_dashboard(
        ["test_1", "test_2", "test_3"], "performance_dashboard.html"
    )
    print("ğŸ“ˆ å·²åˆ›å»ºæ€§èƒ½ä»ªè¡¨æ¿: dashboard_html")

    # åˆ›å»ºå¼‚å¸¸æŠ¥å‘Š
    anomaly_html = viz.create_anomaly_report("test_1", "anomaly_report.html")
    print("ğŸš¨ å·²åˆ›å»ºå¼‚å¸¸æŠ¥å‘Š: anomaly_html")


if __name__ == "__main__":
    demo_metrics_analytics()
