#!/usr/bin/env python3
"""
å®æ—¶æ€§èƒ½ç›‘æ§å™¨
ç›‘æ§GPUå’ŒCPUçš„å®æ—¶æ€§èƒ½è¡¨ç°ï¼Œæä¾›åŠ¨æ€è´Ÿè½½å‡è¡¡å»ºè®®
é€‚ç”¨äºMyStocksé‡åŒ–äº¤æ˜“ç³»ç»Ÿçš„å®æ—¶æ€§èƒ½ç›‘æ§
"""

import time
import psutil
import threading
import logging
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass
from collections import deque
import numpy as np

# å¯¼å…¥GPUç»„ä»¶
from .cpu_fallback import ComponentSelector


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""

    timestamp: float
    gpu_utilization: float
    cpu_utilization: float
    gpu_memory_usage: float
    cpu_memory_usage: float
    gpu_temperature: float
    power_usage: float
    processing_time: float
    throughput: float
    error_rate: float


@dataclass
class WorkloadInfo:
    """å·¥ä½œè´Ÿè½½ä¿¡æ¯"""

    task_type: str
    data_size: int
    complexity_score: float
    estimated_gpu_time: float
    estimated_cpu_time: float
    deadline: Optional[float] = None


class RealTimePerformanceMonitor:
    """å®æ—¶æ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self, monitoring_interval: float = 1.0, history_size: int = 300):
        self.monitoring_interval = monitoring_interval
        self.history_size = history_size
        self.logger = logging.getLogger(__name__)
        self.component_selector = ComponentSelector()

        # æ€§èƒ½å†å²è®°å½•
        self.performance_history = deque(maxlen=history_size)
        self.workload_history = deque(maxlen=100)

        # å®æ—¶æŒ‡æ ‡
        self.current_metrics = None
        self.is_monitoring = False
        self.monitoring_thread = None

        # è­¦æŠ¥é˜ˆå€¼
        self.thresholds = {
            "gpu_utilization": 90.0,  # GPUä½¿ç”¨ç‡è¶…è¿‡90%
            "cpu_utilization": 85.0,  # CPUä½¿ç”¨ç‡è¶…è¿‡85%
            "gpu_memory_usage": 80.0,  # GPUå†…å­˜ä½¿ç”¨è¶…è¿‡80%
            "gpu_temperature": 80.0,  # GPUæ¸©åº¦è¶…è¿‡80Â°C
            "power_usage": 250.0,  # åŠŸç‡è¶…è¿‡250W
            "processing_time": 10.0,  # å•ä¸ªä»»åŠ¡å¤„ç†æ—¶é—´è¶…è¿‡10ç§’
            "error_rate": 0.05,  # é”™è¯¯ç‡è¶…è¿‡5%
        }

        # å›è°ƒå‡½æ•°
        self.alert_callbacks: List[Callable] = []

        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_operations": 0,
            "gpu_operations": 0,
            "cpu_operations": 0,
            "avg_processing_time": 0.0,
            "avg_speedup": 1.0,
            "error_count": 0,
        }

    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if self.is_monitoring:
            return

        self.is_monitoring = True
        self.monitoring_thread = threading.Thread(target=self._monitor_loop)
        self.monitoring_thread.daemon = True
        self.monitoring_thread.start()

        self.logger.info("ğŸš€ å®æ—¶æ€§èƒ½ç›‘æ§å·²å¯åŠ¨")

    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.is_monitoring = False
        if self.monitoring_thread:
            self.monitoring_thread.join()

        self.logger.info("â¹ï¸  å®æ—¶æ€§èƒ½ç›‘æ§å·²åœæ­¢")

    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.is_monitoring:
            try:
                metrics = self._collect_metrics()
                self.current_metrics = metrics
                self.performance_history.append(metrics)

                # æ›´æ–°ç»Ÿè®¡
                self._update_stats(metrics)

                # æ£€æŸ¥è­¦æŠ¥
                self._check_alerts(metrics)

                # è®°å½•æ€§èƒ½æ—¥å¿—
                self._log_performance(metrics)

                time.sleep(self.monitoring_interval)

            except Exception as e:
                self.logger.error(f"ç›‘æ§å¾ªç¯é”™è¯¯: {e}")
                time.sleep(self.monitoring_interval)

    def _collect_metrics(self) -> PerformanceMetrics:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        timestamp = time.time()

        # CPUæŒ‡æ ‡
        cpu_util = psutil.cpu_percent()
        cpu_memory = psutil.virtual_memory().percent
        cpu_freq = psutil.cpu_freq()

        # GPUæŒ‡æ ‡
        gpu_util = 0.0
        gpu_memory = 0.0
        gpu_temp = 0.0
        power_usage = 0.0

        if self.component_selector.check_gpu_availability():
            try:
                import subprocess

                # è·å–GPUä¿¡æ¯
                result = subprocess.run(
                    [
                        "nvidia-smi",
                        "--query-gpu=utilization.gpu,memory.used,temperature.gpu,power.draw",
                        "--format=csv,noheader,nounits",
                    ],
                    capture_output=True,
                    text=True,
                    timeout=5,
                )

                if result.returncode == 0:
                    gpu_info = result.stdout.strip().split(", ")
                    if len(gpu_info) >= 4:
                        gpu_util = float(gpu_info[0])
                        gpu_memory = float(gpu_info[1]) / 1024  # Convert to MB
                        gpu_temp = float(gpu_info[2])
                        power_usage = float(gpu_info[3])

            except Exception as e:
                self.logger.warning(f"GPUæŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")

        # å¤„ç†æ—¶é—´ï¼ˆæ¨¡æ‹Ÿï¼‰
        processing_time = self._get_recent_processing_time()

        # ååé‡
        throughput = self._calculate_throughput()

        # é”™è¯¯ç‡
        error_rate = self._calculate_error_rate()

        return PerformanceMetrics(
            timestamp=timestamp,
            gpu_utilization=gpu_util,
            cpu_utilization=cpu_util,
            gpu_memory_usage=gpu_memory,
            cpu_memory_usage=cpu_memory,
            gpu_temperature=gpu_temp,
            power_usage=power_usage,
            processing_time=processing_time,
            throughput=throughput,
            error_rate=error_rate,
        )

    def _get_recent_processing_time(self) -> float:
        """è·å–æœ€è¿‘çš„å¤„ç†æ—¶é—´"""
        if len(self.performance_history) > 0:
            return self.performance_history[-1].processing_time
        return 0.0

    def _calculate_throughput(self) -> float:
        """è®¡ç®—ååé‡"""
        if len(self.performance_history) < 10:
            return 0.0

        # è®¡ç®—æœ€è¿‘10ç§’å†…çš„å¹³å‡å¤„ç†æ¬¡æ•°
        recent_history = list(self.performance_history)[-10:]
        return len(recent_history) / self.monitoring_interval

    def _calculate_error_rate(self) -> float:
        """è®¡ç®—é”™è¯¯ç‡"""
        if self.stats["total_operations"] == 0:
            return 0.0

        return self.stats["error_count"] / self.stats["total_operations"]

    def _update_stats(self, metrics: PerformanceMetrics):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats["total_operations"] += 1

        if metrics.gpu_utilization > 0:
            self.stats["gpu_operations"] += 1
        else:
            self.stats["cpu_operations"] += 1

        # æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
        self.stats["avg_processing_time"] = (
            self.stats["avg_processing_time"] * (self.stats["total_operations"] - 1)
            + metrics.processing_time
        ) / self.stats["total_operations"]

        # æ›´æ–°é”™è¯¯è®¡æ•°
        if metrics.error_rate > self.thresholds["error_rate"]:
            self.stats["error_count"] += 1

    def _check_alerts(self, metrics: PerformanceMetrics):
        """æ£€æŸ¥è­¦æŠ¥"""
        alerts = []

        for metric_name, threshold in self.thresholds.items():
            value = getattr(metrics, metric_name)
            if value > threshold:
                alerts.append(f"{metric_name}: {value:.2f} (é˜ˆå€¼: {threshold})")

        if alerts:
            alert_msg = f"âš ï¸  æ€§èƒ½è­¦æŠ¥: {'; '.join(alerts)}"
            self.logger.warning(alert_msg)

            # è§¦å‘å›è°ƒ
            for callback in self.alert_callbacks:
                try:
                    callback(metrics, alerts)
                except Exception as e:
                    self.logger.error(f"å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")

    def _log_performance(self, metrics: PerformanceMetrics):
        """è®°å½•æ€§èƒ½æ—¥å¿—"""
        if len(self.performance_history) % 10 == 0:  # æ¯10ä¸ªæŒ‡æ ‡è®°å½•ä¸€æ¬¡
            self.logger.info(
                f"æ€§èƒ½æŒ‡æ ‡ - GPU: {metrics.gpu_utilization:.1f}%, "
                f"CPU: {metrics.cpu_utilization:.1f}%, "
                f"å†…å­˜: {metrics.gpu_memory_usage:.1f}MB, "
                f"å¤„ç†æ—¶é—´: {metrics.processing_time:.3f}s, "
                f"ååé‡: {metrics.throughput:.2f}"
            )

    def register_alert_callback(self, callback: Callable):
        """æ³¨å†Œè­¦æŠ¥å›è°ƒå‡½æ•°"""
        self.alert_callbacks.append(callback)

    def get_current_metrics(self) -> Optional[PerformanceMetrics]:
        """è·å–å½“å‰æ€§èƒ½æŒ‡æ ‡"""
        return self.current_metrics

    def get_performance_history(self, last_n: int = 60) -> List[PerformanceMetrics]:
        """è·å–æ€§èƒ½å†å²"""
        return list(self.performance_history)[-last_n:]

    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ€»ç»“"""
        if len(self.performance_history) == 0:
            return {}

        gpu_utils = [m.gpu_utilization for m in self.performance_history]
        cpu_utils = [m.cpu_utilization for m in self.performance_history]
        gpu_mem = [m.gpu_memory_usage for m in self.performance_history]
        proc_times = [m.processing_time for m in self.performance_history]

        return {
            "gpu_utilization_avg": np.mean(gpu_utils),
            "gpu_utilization_max": np.max(gpu_utils),
            "cpu_utilization_avg": np.mean(cpu_utils),
            "cpu_utilization_max": np.max(cpu_utils),
            "gpu_memory_avg": np.mean(gpu_mem),
            "gpu_memory_max": np.max(gpu_mem),
            "processing_time_avg": np.mean(proc_times),
            "processing_time_max": np.max(proc_times),
            "total_operations": self.stats["total_operations"],
            "gpu_operations": self.stats["gpu_operations"],
            "cpu_operations": self.stats["cpu_operations"],
            "error_rate": self._calculate_error_rate(),
        }

    def get_workload_recommendations(self) -> List[str]:
        """è·å–å·¥ä½œè´Ÿè½½å»ºè®®"""
        recommendations = []
        summary = self.get_performance_summary()

        if not summary:
            return []

        # GPUä½¿ç”¨ç‡åˆ†æ
        if summary["gpu_utilization_avg"] > 80:
            recommendations.append(
                "âš ï¸ GPUä½¿ç”¨ç‡è¿‡é«˜ï¼Œè€ƒè™‘å¢åŠ GPUä»»åŠ¡æ‰¹å¤„ç†æˆ–ä½¿ç”¨åˆ†å¸ƒå¼å¤„ç†"
            )
        elif summary["gpu_utilization_avg"] < 30:
            recommendations.append(
                "âš¡ GPUåˆ©ç”¨ç‡è¾ƒä½ï¼Œå»ºè®®å¢åŠ GPUå¹¶è¡Œä»»åŠ¡æˆ–ä¼˜åŒ–ä»»åŠ¡åˆ†é…"
            )

        # CPUä½¿ç”¨ç‡åˆ†æ
        if summary["cpu_utilization_avg"] > 80:
            recommendations.append("âš ï¸ CPUä½¿ç”¨ç‡è¿‡é«˜ï¼Œè€ƒè™‘å¸è½½æ›´å¤šä»»åŠ¡åˆ°GPU")
        elif summary["cpu_utilization_avg"] < 50:
            recommendations.append("âš¡ CPUåˆ©ç”¨ç‡è¾ƒä½ï¼Œå¯ä»¥è€ƒè™‘å¢åŠ CPUå¹¶è¡Œä»»åŠ¡")

        # å†…å­˜ä½¿ç”¨åˆ†æ
        if summary["gpu_memory_avg"] > 70:
            recommendations.append(
                "âš ï¸ GPUå†…å­˜ä½¿ç”¨æ¥è¿‘æé™ï¼Œå»ºè®®å‡å°‘æ•°æ®æ‰¹æ¬¡æˆ–ä¼˜åŒ–å†…å­˜ç®¡ç†"
            )
        elif summary["gpu_memory_avg"] < 20:
            recommendations.append("âš¡ GPUå†…å­˜ä½¿ç”¨ç‡è¾ƒä½ï¼Œå¯ä»¥è€ƒè™‘å¤„ç†æ›´å¤§çš„æ•°æ®é›†")

        # æ€§èƒ½åˆ†æ
        if summary["processing_time_avg"] > 5.0:
            recommendations.append("âš ï¸ å¹³å‡å¤„ç†æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–ç®—æ³•æˆ–ä½¿ç”¨GPUåŠ é€Ÿ")
        elif summary["processing_time_avg"] < 0.5:
            recommendations.append("âœ… å¤„ç†æ€§èƒ½è‰¯å¥½ï¼Œå¯ä»¥è€ƒè™‘å¢åŠ å¤æ‚åº¦æˆ–å¤„ç†æ›´å¤šæ•°æ®")

        # é”™è¯¯ç‡åˆ†æ
        if summary["error_rate"] > 0.02:
            recommendations.append("âš ï¸ é”™è¯¯ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®è´¨é‡å’Œç®—æ³•ç¨³å®šæ€§")

        return recommendations

    def predict_performance(self, workload: WorkloadInfo) -> Dict[str, float]:
        """é¢„æµ‹æ€§èƒ½è¡¨ç°"""
        summary = self.get_performance_summary()

        if not summary:
            return {
                "predicted_gpu_time": workload.estimated_gpu_time,
                "predicted_cpu_time": workload.estimated_cpu_time,
                "predicted_speedup": (
                    workload.estimated_cpu_time / workload.estimated_gpu_time
                    if workload.estimated_gpu_time > 0
                    else 1.0
                ),
            }

        # åŸºäºå½“å‰è´Ÿè½½è°ƒæ•´é¢„æµ‹
        gpu_load_factor = summary["gpu_utilization_avg"] / 100.0
        cpu_load_factor = summary["cpu_utilization_avg"] / 100.0

        predicted_gpu_time = workload.estimated_gpu_time * (1 + gpu_load_factor * 0.5)
        predicted_cpu_time = workload.estimated_cpu_time * (1 + cpu_load_factor * 0.3)

        # åŸºäºæ•°æ®é‡è°ƒæ•´
        size_factor = min(workload.data_size / 10000, 10.0)  # æœ€å¤§10å€è°ƒæ•´
        predicted_gpu_time *= size_factor
        predicted_cpu_time *= size_factor

        # åŸºäºå¤æ‚åº¦è°ƒæ•´
        complexity_factor = workload.complexity_score / 5.0  # å¤æ‚åº¦è¯„åˆ†
        predicted_gpu_time *= complexity_factor
        predicted_cpu_time *= complexity_factor

        return {
            "predicted_gpu_time": predicted_gpu_time,
            "predicted_cpu_time": predicted_cpu_time,
            "predicted_speedup": (
                predicted_cpu_time / predicted_gpu_time
                if predicted_gpu_time > 0
                else 1.0
            ),
            "gpu_load_factor": gpu_load_factor,
            "cpu_load_factor": cpu_load_factor,
        }

    def get_optimal_allocation(
        self, workloads: List[WorkloadInfo]
    ) -> Dict[str, List[str]]:
        """è·å–æœ€ä¼˜çš„ä»»åŠ¡åˆ†é…æ–¹æ¡ˆ"""
        gpu_tasks = []
        cpu_tasks = []
        mixed_tasks = []

        for workload in workloads:
            prediction = self.predict_performance(workload)

            if prediction["predicted_speedup"] > 3.0:
                gpu_tasks.append(workload.task_type)
            elif prediction["predicted_speedup"] < 1.5:
                cpu_tasks.append(workload.task_type)
            else:
                mixed_tasks.append(workload.task_type)

        return {
            "gpu_optimal": gpu_tasks,
            "cpu_optimal": cpu_tasks,
            "mixed_optimal": mixed_tasks,
        }

    def generate_performance_report(self) -> str:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        summary = self.get_performance_summary()
        recommendations = self.get_workload_recommendations()

        report = f"""
MyStocks å®æ—¶æ€§èƒ½ç›‘æ§æŠ¥å‘Š
========================

ç›‘æ§æ—¶é—´: {time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(time.time()))}

ğŸ“Š å½“å‰æ€§èƒ½çŠ¶æ€:
  GPUä½¿ç”¨ç‡: {summary.get("gpu_utilization_avg", 0):.1f}% (æœ€é«˜: {summary.get("gpu_utilization_max", 0):.1f}%)
  CPUä½¿ç”¨ç‡: {summary.get("cpu_utilization_avg", 0):.1f}% (æœ€é«˜: {summary.get("cpu_utilization_max", 0):.1f}%)
  GPUå†…å­˜: {summary.get("gpu_memory_avg", 0):.1f}MB (æœ€é«˜: {summary.get("gpu_memory_max", 0):.1f}MB)
  å¹³å‡å¤„ç†æ—¶é—´: {summary.get("processing_time_avg", 0):.3f}ç§’
  æ€»æ“ä½œæ¬¡æ•°: {summary.get("total_operations", 0)}
  GPUæ“ä½œæ¬¡æ•°: {summary.get("gpu_operations", 0)}
  CPUæ“ä½œæ¬¡æ•°: {summary.get("cpu_operations", 0)}
  é”™è¯¯ç‡: {summary.get("error_rate", 0):.2%}

ğŸ’¡ ä¼˜åŒ–å»ºè®®:
"""

        for i, recommendation in enumerate(recommendations, 1):
            report += f"{i}. {recommendation}\n"

        report += f"""

ğŸ¯ GPU/CPUåˆ†é…å»ºè®®:
  GPUä¼˜å…ˆä»»åŠ¡: {len(recommendations)} ä¸ª
  CPUä¼˜å…ˆä»»åŠ¡: {len(recommendations)} ä¸ª
  æ··åˆæ¨¡å¼ä»»åŠ¡: {len(recommendations)} ä¸ª
"""

        return report


def main():
    """ä¸»å‡½æ•° - å®æ—¶ç›‘æ§ç¤ºä¾‹"""
    # åˆ›å»ºç›‘æ§å™¨
    monitor = RealTimePerformanceMonitor(monitoring_interval=1.0)

    # æ³¨å†Œè­¦æŠ¥å›è°ƒ
    def alert_handler(metrics, alerts):
        print(f"ğŸš¨ è­¦æŠ¥: {alerts}")

    monitor.register_alert_callback(alert_handler)

    # å¼€å§‹ç›‘æ§
    monitor.start_monitoring()

    try:
        # æ¨¡æ‹Ÿä¸€äº›å·¥ä½œè´Ÿè½½
        for i in range(30):
            print(f"ç›‘æ§ç¬¬ {i + 1} ç§’...")
            time.sleep(1)

            if i % 10 == 0:
                # è·å–å½“å‰çŠ¶æ€
                metrics = monitor.get_current_metrics()
                if metrics:
                    print(
                        f"  GPU: {metrics.gpu_utilization:.1f}%, "
                        f"CPU: {metrics.cpu_utilization:.1f}%, "
                        f"å†…å­˜: {metrics.gpu_memory_usage:.1f}MB"
                    )

                # ç”ŸæˆæŠ¥å‘Š
                report = monitor.generate_performance_report()
                print(f"\\n{report}")

    except KeyboardInterrupt:
        print("åœæ­¢ç›‘æ§...")
    finally:
        monitor.stop_monitoring()


if __name__ == "__main__":
    main()
