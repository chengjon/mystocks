#!/usr/bin/env python3
"""
GPUåŠ é€Ÿçš„ä»·æ ¼é¢„æµ‹å™¨
åŸºäºcuMLæœºå™¨å­¦ä¹ åº“å®ç°é«˜æ€§èƒ½ä»·æ ¼é¢„æµ‹
æ”¯æŒRTX 2080 GPUåŠ é€Ÿï¼Œæä¾›å®æ—¶é¢„æµ‹èƒ½åŠ›
"""

import logging
import time
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Dict, List, Tuple

import cudf
import cupy as cp
import numpy as np
import pandas as pd
from cuml.ensemble import RandomForestRegressor
from cuml.linear_model import Lasso, LinearRegression, Ridge
from cuml.model_selection import train_test_split as gpu_train_test_split
from cuml.preprocessing import StandardScaler


@dataclass
class PredictionResult:
    """é¢„æµ‹ç»“æœ"""

    predicted_price: float
    confidence_score: float
    prediction_date: datetime
    model_used: str
    features_used: List[str]
    prediction_horizon: int  # é¢„æµ‹å¤©æ•°
    error_metrics: Dict[str, float]


@dataclass
class ModelPerformance:
    """æ¨¡å‹æ€§èƒ½æŒ‡æ ‡"""

    training_time: float
    prediction_time: float
    mse: float
    mae: float
    r2_score: float
    rmse: float
    is_gpu_enabled: bool


class GPUPricePredictor:
    """GPUåŠ é€Ÿçš„ä»·æ ¼é¢„æµ‹å™¨"""

    def __init__(self, gpu_enabled: bool = True):
        self.gpu_enabled = gpu_enabled
        self.models = {
            "linear": LinearRegression(),
            "ridge": Ridge(alpha=1.0),
            "lasso": Lasso(alpha=1.0),
            "random_forest": RandomForestRegressor(n_estimators=100),
        }
        self.scaler = StandardScaler()
        self.is_fitted = False
        self.feature_columns = []
        self.target_column = "close"
        self.logger = logging.getLogger(__name__)

        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            "total_predictions": 0,
            "total_training_time": 0,
            "total_prediction_time": 0,
            "best_model": None,
            "model_scores": {},
        }

    def _prepare_data_gpu(self, data: pd.DataFrame, target_col: str = "close") -> Tuple[cp.ndarray, cp.ndarray]:
        """å‡†å¤‡GPUæ•°æ®"""
        # è½¬æ¢ä¸ºcuDF DataFrame
        df_gpu = cudf.DataFrame(data) if self.gpu_enabled else data

        # é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆæ’é™¤ç›®æ ‡åˆ—ï¼‰
        feature_cols = [col for col in df_gpu.columns if col != target_col]
        self.feature_columns = feature_cols

        # æå–ç‰¹å¾å’Œç›®æ ‡
        X = df_gpu[feature_cols]
        y = df_gpu[target_col]

        # æ•°æ®æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X) if self.gpu_enabled else StandardScaler().fit_transform(X)

        return X_scaled, y

    def _create_lag_features(self, data: pd.DataFrame, lags: List[int] = [1, 2, 3, 5, 10]) -> pd.DataFrame:
        """åˆ›å»ºæ»åç‰¹å¾"""
        df = data.copy()

        for lag in lags:
            df[f"close_lag_{lag}"] = df["close"].shift(lag)

        # åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
        df["sma_5"] = df["close"].rolling(window=5).mean()
        df["sma_10"] = df["close"].rolling(window=10).mean()
        df["sma_20"] = df["close"].rolling(window=20).mean()

        df["rsi"] = self._calculate_rsi(data["close"])
        df["macd"], df["macd_signal"] = self._calculate_macd(data["close"])

        # ä»·æ ¼å˜åŒ–ç‰¹å¾
        df["price_change"] = df["close"].pct_change()
        df["volatility"] = df["price_change"].rolling(window=10).std()

        return df

    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—RSIæŒ‡æ ‡"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi

    def _calculate_macd(
        self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9
    ) -> Tuple[pd.Series, pd.Series]:
        """è®¡ç®—MACDæŒ‡æ ‡"""
        ema_fast = prices.ewm(span=fast).mean()
        ema_slow = prices.ewm(span=slow).mean()
        macd = ema_fast - ema_slow
        macd_signal = macd.ewm(span=signal).mean()
        return macd, macd_signal

    def prepare_features(self, data: pd.DataFrame, prediction_horizon: int = 1) -> pd.DataFrame:
        """å‡†å¤‡ç‰¹å¾æ•°æ®"""
        # åˆ›å»ºæ»åç‰¹å¾
        feature_data = self._create_lag_features(data)

        # åˆ é™¤NaNå€¼
        feature_data = feature_data.dropna()

        # æ·»åŠ é¢„æµ‹ç›®æ ‡
        feature_data["target"] = feature_data["close"].shift(-prediction_horizon)

        # åˆ é™¤æœ€åçš„prediction_horizonè¡Œï¼ˆæ²¡æœ‰ç›®æ ‡å€¼ï¼‰
        feature_data = feature_data.iloc[:-prediction_horizon]

        return feature_data

    def train_models(self, data: pd.DataFrame, test_size: float = 0.2) -> Dict[str, ModelPerformance]:
        """è®­ç»ƒå¤šä¸ªæ¨¡å‹"""
        start_time = time.time()

        # å‡†å¤‡æ•°æ®
        feature_data = self.prepare_features(data)

        # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        X, y = self._prepare_data_gpu(feature_data)
        X_train, X_test, y_train, y_test = gpu_train_test_split(X, y, test_size=test_size, random_state=42)

        training_results = {}

        for model_name, model in self.models.items():
            model_start_time = time.time()

            # è®­ç»ƒæ¨¡å‹
            model.fit(X_train, y_train)

            # é¢„æµ‹
            y_pred = model.predict(X_test)

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            training_time = time.time() - model_start_time

            if self.gpu_enabled:
                y_pred_cpu = y_pred.to_numpy()
                y_test_cpu = y_test.to_numpy()
            else:
                y_pred_cpu = y_pred
                y_test_cpu = y_test

            mse = np.mean((y_pred_cpu - y_test_cpu) ** 2)
            mae = np.mean(np.abs(y_pred_cpu - y_test_cpu))
            r2_score = 1 - (np.sum((y_test_cpu - y_pred_cpu) ** 2) / np.sum((y_test_cpu - np.mean(y_test_cpu)) ** 2))
            rmse = np.sqrt(mse)

            performance = ModelPerformance(
                training_time=training_time,
                prediction_time=0.001,  # é¢„æµ‹æ—¶é—´å¾ˆçŸ­
                mse=mse,
                mae=mae,
                r2_score=r2_score,
                rmse=rmse,
                is_gpu_enabled=self.gpu_enabled,
            )

            training_results[model_name] = performance
            self.performance_stats["model_scores"][model_name] = r2_score

            # æ›´æ–°æœ€ä½³æ¨¡å‹
            if self.performance_stats["best_model"] is None or r2_score > self.performance_stats["best_model"][1]:
                self.performance_stats["best_model"] = (model_name, r2_score)

        self.is_fitted = True
        total_training_time = time.time() - start_time

        self.performance_stats["total_training_time"] = total_training_time

        self.logger.info("æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæ€»è€—æ—¶: %sç§’", total_training_time)
        return training_results

    def predict_price(
        self, data: pd.DataFrame, model_name: str = None, prediction_horizon: int = 1
    ) -> PredictionResult:
        """é¢„æµ‹ä»·æ ¼"""
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨train_modelsæ–¹æ³•")

        start_time = time.time()

        # é€‰æ‹©æ¨¡å‹
        if model_name is None:
            model_name = self.performance_stats["best_model"][0]

        model = self.models[model_name]

        # å‡†å¤‡æ•°æ®
        feature_data = self.prepare_features(data, prediction_horizon)

        # è·å–æœ€åä¸€è¡Œæ•°æ®ä½œä¸ºé¢„æµ‹è¾“å…¥
        last_row = feature_data.iloc[-1:].copy()

        # ç§»é™¤ç›®æ ‡åˆ—
        if "target" in last_row.columns:
            last_row = last_row.drop("target", axis=1)

        # æ•°æ®æ ‡å‡†åŒ–
        X = self.scaler.transform(last_row)

        # GPUé¢„æµ‹
        if self.gpu_enabled:
            X_gpu = cp.array(X)
            predicted_gpu = model.predict(X_gpu)
            predicted_price = float(predicted_gpu.to_numpy()[0])
        else:
            predicted_price = float(model.predict(X)[0])

        prediction_time = time.time() - start_time

        # è®¡ç®—ç½®ä¿¡åº¦
        confidence_score = self._calculate_confidence_score(model_name, prediction_horizon)

        # åˆ›å»ºé¢„æµ‹ç»“æœ
        result = PredictionResult(
            predicted_price=predicted_price,
            confidence_score=confidence_score,
            prediction_date=datetime.now() + timedelta(days=prediction_horizon),
            model_used=model_name,
            features_used=self.feature_columns,
            prediction_horizon=prediction_horizon,
            error_metrics={
                "mse": self.performance_stats["model_scores"].get(model_name, 0),
                "mae": 0,  # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šè®¡ç®—
                "r2_score": self.performance_stats["model_scores"].get(model_name, 0),
            },
        )

        # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
        self.performance_stats["total_predictions"] += 1
        self.performance_stats["total_prediction_time"] += prediction_time

        return result

    def _calculate_confidence_score(self, model_name: str, prediction_horizon: int) -> float:
        """è®¡ç®—é¢„æµ‹ç½®ä¿¡åº¦"""
        base_confidence = self.performance_stats["model_scores"].get(model_name, 0.5)

        # æ ¹æ®é¢„æµ‹æ—¶é—´è°ƒæ•´ç½®ä¿¡åº¦
        time_penalty = min(0.1 * prediction_horizon, 0.3)

        # æ ¹æ®æ¨¡å‹æ€§èƒ½è°ƒæ•´ç½®ä¿¡åº¦
        model_adjustment = 0.1 if model_name == self.performance_stats["best_model"][0] else 0

        confidence = max(0.0, min(1.0, base_confidence - time_penalty + model_adjustment))
        return confidence

    def batch_predict(
        self,
        data_list: List[pd.DataFrame],
        model_name: str = None,
        prediction_horizon: int = 1,
    ) -> List[PredictionResult]:
        """æ‰¹é‡é¢„æµ‹"""
        results = []

        for data in data_list:
            try:
                result = self.predict_price(data, model_name, prediction_horizon)
                results.append(result)
            except Exception as e:
                self.logger.error("æ‰¹é‡é¢„æµ‹ä¸­å‘ç”Ÿé”™è¯¯: %s", e)
                continue

        return results

    def get_performance_summary(self) -> Dict:
        """è·å–æ€§èƒ½æ€»ç»“"""
        avg_prediction_time = self.performance_stats["total_prediction_time"] / max(
            1, self.performance_stats["total_predictions"]
        )

        return {
            "gpu_enabled": self.gpu_enabled,
            "total_predictions": self.performance_stats["total_predictions"],
            "total_training_time": self.performance_stats["total_training_time"],
            "avg_prediction_time": avg_prediction_time,
            "best_model": self.performance_stats["best_model"],
            "model_scores": self.performance_stats["model_scores"],
            "is_fitted": self.is_fitted,
        }

    def optimize_hyperparameters(self, data: pd.DataFrame, model_type: str = "ridge") -> Dict:
        """ä¼˜åŒ–è¶…å‚æ•°"""
        if self.gpu_enabled:
            from cuml.linear_model import Ridge
            from cuml.model_selection import GridSearchCV

            # å®šä¹‰å‚æ•°ç½‘æ ¼
            param_grid = {"alpha": [0.1, 1.0, 10.0, 100.0]}

            # å‡†å¤‡æ•°æ®
            feature_data = self.prepare_features(data)
            X, y = self._prepare_data_gpu(feature_data)

            # åˆ›å»ºç½‘æ ¼æœç´¢
            grid_search = GridSearchCV(
                Ridge(),
                param_grid,
                cv=5,
                scoring="r2",
                n_jobs=-1 if not self.gpu_enabled else 1,  # GPUæ—¶ä¸éœ€è¦å¤šè¿›ç¨‹
            )

            grid_search.fit(X, y)

            return {
                "best_params": grid_search.best_params_,
                "best_score": grid_search.best_score_,
                "model_type": model_type,
            }
        else:
            # CPUç‰ˆæœ¬çš„è¶…å‚æ•°ä¼˜åŒ–
            from sklearn.model_selection import GridSearchCV

            param_grid = {"alpha": [0.1, 1.0, 10.0, 100.0]}

            feature_data = self.prepare_features(data)
            X, y = self._prepare_data_gpu(feature_data)

            grid_search = GridSearchCV(Ridge(), param_grid, cv=5, scoring="r2", n_jobs=-1)

            grid_search.fit(X, y)

            return {
                "best_params": grid_search.best_params_,
                "best_score": grid_search.best_score_,
                "model_type": model_type,
            }

    def save_model(self, filepath: str):
        """ä¿å­˜æ¨¡å‹"""
        import joblib

        model_data = {
            "models": self.models,
            "scaler": self.scaler,
            "feature_columns": self.feature_columns,
            "is_fitted": self.is_fitted,
            "performance_stats": self.performance_stats,
        }

        joblib.dump(model_data, filepath)
        self.logger.info("æ¨¡å‹å·²ä¿å­˜åˆ°: %s", filepath)

    def load_model(self, filepath: str):
        """åŠ è½½æ¨¡å‹"""
        import joblib

        model_data = joblib.load(filepath)

        self.models = model_data["models"]
        self.scaler = model_data["scaler"]
        self.feature_columns = model_data["feature_columns"]
        self.is_fitted = model_data["is_fitted"]
        self.performance_stats = model_data["performance_stats"]

        self.logger.info("æ¨¡å‹å·²ä» %s åŠ è½½", filepath)


class GPUPredictionPipeline:
    """GPUé¢„æµ‹æµæ°´çº¿"""

    def __init__(self, gpu_enabled: bool = True):
        self.predictor = GPUPricePredictor(gpu_enabled)
        self.data_preprocessor = DataPreprocessorGPU(gpu_enabled)

    def run_full_pipeline(self, raw_data: pd.DataFrame, prediction_horizon: int = 1) -> Dict:
        """è¿è¡Œå®Œæ•´çš„é¢„æµ‹æµæ°´çº¿"""
        # æ•°æ®é¢„å¤„ç†
        processed_data = self.data_preprocessor.preprocess(raw_data)

        # è®­ç»ƒæ¨¡å‹
        training_results = self.predictor.train_models(processed_data)

        # è¿›è¡Œé¢„æµ‹
        prediction_result = self.predictor.predict_price(processed_data, prediction_horizon=prediction_horizon)

        # è·å–æ€§èƒ½æ€»ç»“
        performance_summary = self.predictor.get_performance_summary()

        return {
            "training_results": training_results,
            "prediction": prediction_result,
            "performance": performance_summary,
            "data_shape": processed_data.shape,
        }


class DataPreprocessorGPU:
    """GPUæ•°æ®é¢„å¤„ç†å™¨"""

    def __init__(self, gpu_enabled: bool = True):
        self.gpu_enabled = gpu_enabled
        self.scaler = StandardScaler()

    def preprocess(self, data: pd.DataFrame) -> pd.DataFrame:
        """æ•°æ®é¢„å¤„ç†"""
        # å»é™¤å¼‚å¸¸å€¼
        data = self._remove_outliers(data)

        # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
        data = self._add_technical_indicators(data)

        # ç‰¹å¾æ ‡å‡†åŒ–
        data = self._normalize_features(data)

        return data

    def _remove_outliers(self, data: pd.DataFrame) -> pd.DataFrame:
        """å»é™¤å¼‚å¸¸å€¼"""
        numeric_columns = data.select_dtypes(include=[np.number]).columns

        for col in numeric_columns:
            Q1 = data[col].quantile(0.25)
            Q3 = data[col].quantile(0.75)
            IQR = Q3 - Q1

            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR

            data = data[(data[col] >= lower_bound) & (data[col] <= upper_bound)]

        return data

    def _add_technical_indicators(self, data: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ æŠ€æœ¯æŒ‡æ ‡"""
        # ç§»åŠ¨å¹³å‡
        data["sma_5"] = data["close"].rolling(window=5).mean()
        data["sma_20"] = data["close"].rolling(window=20).mean()

        # RSI
        data["rsi"] = self._calculate_rsi(data["close"])

        # MACD
        data["macd"], data["macd_signal"] = self._calculate_macd(data["close"])

        return data

    def _normalize_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç‰¹å¾æ ‡å‡†åŒ–"""
        numeric_columns = data.select_dtypes(include=[np.number]).columns
        feature_data = data[numeric_columns]

        if self.gpu_enabled:
            feature_gpu = cudf.DataFrame(feature_data)
            normalized_features = self.scaler.fit_transform(feature_gpu)
            normalized_df = cudf.DataFrame(normalized_features, columns=feature_gpu.columns)
        else:
            normalized_features = self.scaler.fit_transform(feature_data)
            normalized_df = pd.DataFrame(normalized_features, columns=feature_data.columns)

        # åˆå¹¶å›åŸå§‹æ•°æ®
        result = data.copy()
        for col in normalized_df.columns:
            result[f"{col}_normalized"] = normalized_df[col].values

        return result

    def _calculate_rsi(self, prices: pd.Series) -> pd.Series:
        """è®¡ç®—RSI"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi

    def _calculate_macd(self, prices: pd.Series) -> Tuple[pd.Series, pd.Series]:
        """è®¡ç®—MACD"""
        ema_fast = prices.ewm(span=12).mean()
        ema_slow = prices.ewm(span=26).mean()
        macd = ema_fast - ema_slow
        macd_signal = macd.ewm(span=9).mean()
        return macd, macd_signal


def benchmark_gpu_vs_cpu(data: pd.DataFrame, prediction_horizon: int = 1):
    """GPU vs CPUæ€§èƒ½å¯¹æ¯”"""
    print("ğŸ”¬ å¼€å§‹GPU vs CPUæ€§èƒ½å¯¹æ¯”æµ‹è¯•...")

    # GPUç‰ˆæœ¬
    gpu_pipeline = GPUPredictionPipeline(gpu_enabled=True)
    gpu_start = time.time()
    gpu_results = gpu_pipeline.run_full_pipeline(data, prediction_horizon)
    gpu_time = time.time() - gpu_start

    # CPUç‰ˆæœ¬
    cpu_pipeline = GPUPredictionPipeline(gpu_enabled=False)
    cpu_start = time.time()
    cpu_results = cpu_pipeline.run_full_pipeline(data, prediction_horizon)
    cpu_time = time.time() - cpu_start

    # å¯¹æ¯”ç»“æœ
    print("\nğŸ“Š æ€§èƒ½å¯¹æ¯”ç»“æœ:")
    print(f"GPUè®­ç»ƒæ—¶é—´: {gpu_time:.2f}ç§’")
    print(f"CPUè®­ç»ƒæ—¶é—´: {cpu_time:.2f}ç§’")
    print(f"åŠ é€Ÿæ¯”: {cpu_time / gpu_time:.2f}x")
    print(f"GPUé¢„æµ‹ç»“æœ: {gpu_results['prediction'].predicted_price:.2f}")
    print(f"CPUé¢„æµ‹ç»“æœ: {cpu_results['prediction'].predicted_price:.2f}")
    print(f"é¢„æµ‹å·®å¼‚: {abs(gpu_results['prediction'].predicted_price - cpu_results['prediction'].predicted_price):.2f}")

    return {
        "gpu_time": gpu_time,
        "cpu_time": cpu_time,
        "speedup": cpu_time / gpu_time,
        "gpu_results": gpu_results,
        "cpu_results": cpu_results,
    }


if __name__ == "__main__":
    # ç¤ºä¾‹ä½¿ç”¨
    import yfinance as yf

    # è·å–ç¤ºä¾‹æ•°æ®
    data = yf.download("AAPL", start="2023-01-01", end="2024-01-01")

    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = GPUPricePredictor(gpu_enabled=True)

    # è®­ç»ƒæ¨¡å‹
    training_results = predictor.train_models(data)

    # è¿›è¡Œé¢„æµ‹
    prediction = predictor.predict_price(data)

    # æ˜¾ç¤ºç»“æœ
    print(f"é¢„æµ‹ä»·æ ¼: {prediction.predicted_price:.2f}")
    print(f"ç½®ä¿¡åº¦: {prediction.confidence_score:.2f}")
    print(f"ä½¿ç”¨çš„æ¨¡å‹: {prediction.model_used}")

    # æ€§èƒ½æ€»ç»“
    performance = predictor.get_performance_summary()
    print("\næ€§èƒ½æ€»ç»“:")
    print(f"GPUåŠ é€Ÿ: {performance['gpu_enabled']}")
    print(f"æ€»é¢„æµ‹æ¬¡æ•°: {performance['total_predictions']}")
    print(f"å¹³å‡é¢„æµ‹æ—¶é—´: {performance['avg_prediction_time']:.4f}ç§’")

    # è¿è¡Œæ€§èƒ½å¯¹æ¯”
    benchmark_results = benchmark_gpu_vs_cpu(data)
    print(f"\nGPUåŠ é€Ÿæ€§èƒ½æå‡: {benchmark_results['speedup']:.2f}x")
