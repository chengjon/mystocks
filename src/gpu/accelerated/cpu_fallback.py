#!/usr/bin/env python3
"""
CPUå›é€€ç‰ˆæœ¬æ¨¡å—
ä¸ºGPUåŠ é€Ÿç»„ä»¶æä¾›å®Œå…¨çš„CPUæ›¿ä»£å®ç°
ç¡®ä¿åœ¨GPUä¸å¯ç”¨æ—¶ï¼Œç³»ç»Ÿä»èƒ½æ­£å¸¸å·¥ä½œ
"""

import time
import logging
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union
from dataclasses import dataclass
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split as sklearn_train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from datetime import datetime, timedelta

# å¯¼å…¥GPUæ¨¡å—ä¸­çš„æ•°æ®ç±»
from .price_predictor_gpu import PredictionResult, ModelPerformance


@dataclass
class ProcessingConfig:
    """CPUç‰ˆæœ¬çš„å¤„ç†é…ç½®"""

    remove_outliers: bool = True
    handle_missing: bool = True
    normalize_features: bool = True
    parallel_jobs: int = 1
    chunk_size: int = 10000


# CPUç‰ˆæœ¬çš„ä»·æ ¼é¢„æµ‹å™¨
class PricePredictorCPU:
    """CPUç‰ˆæœ¬çš„ä»·æ ¼é¢„æµ‹å™¨ - GPUç‰ˆæœ¬çš„å®Œæ•´å›é€€å®ç°"""

    def __init__(self, gpu_enabled: bool = False):
        self.gpu_enabled = gpu_enabled
        self.models = {
            "linear": LinearRegression(),
            "ridge": Ridge(alpha=1.0),
            "lasso": Lasso(alpha=1.0),
            "random_forest": RandomForestRegressor(n_estimators=100, random_state=42),
        }
        self.scaler = StandardScaler()
        self.is_fitted = False
        self.feature_columns = []
        self.target_column = "close"
        self.logger = logging.getLogger(__name__)

        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            "total_predictions": 0,
            "total_training_time": 0,
            "total_prediction_time": 0,
            "best_model": None,
            "model_scores": {},
        }

    def _prepare_data_cpu(
        self, data: pd.DataFrame, target_col: str = "close"
    ) -> Tuple[np.ndarray, np.ndarray]:
        """å‡†å¤‡CPUæ•°æ®"""
        # é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆæ’é™¤ç›®æ ‡åˆ—ï¼‰
        feature_cols = [col for col in data.columns if col != target_col]
        self.feature_columns = feature_cols

        # æå–ç‰¹å¾å’Œç›®æ ‡
        X = data[feature_cols].values
        y = data[target_col].values

        # æ•°æ®æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X)

        return X_scaled, y

    def _create_lag_features(
        self, data: pd.DataFrame, lags: List[int] = [1, 2, 3, 5, 10]
    ) -> pd.DataFrame:
        """åˆ›å»ºæ»åç‰¹å¾"""
        df = data.copy()

        for lag in lags:
            df[f"close_lag_{lag}"] = df["close"].shift(lag)

        # åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
        df["sma_5"] = df["close"].rolling(window=5).mean()
        df["sma_10"] = df["close"].rolling(window=10).mean()
        df["sma_20"] = df["close"].rolling(window=20).mean()

        df["rsi"] = self._calculate_rsi(data["close"])
        df["macd"], df["macd_signal"] = self._calculate_macd(data["close"])

        # ä»·æ ¼å˜åŒ–ç‰¹å¾
        df["price_change"] = df["close"].pct_change()
        df["volatility"] = df["price_change"].rolling(window=10).std()

        return df

    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—RSIæŒ‡æ ‡"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi

    def _calculate_macd(
        self, prices: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9
    ) -> Tuple[pd.Series, pd.Series]:
        """è®¡ç®—MACDæŒ‡æ ‡"""
        ema_fast = prices.ewm(span=fast).mean()
        ema_slow = prices.ewm(span=slow).mean()
        macd = ema_fast - ema_slow
        macd_signal = macd.ewm(span=signal).mean()
        return macd, macd_signal

    def prepare_features(
        self, data: pd.DataFrame, prediction_horizon: int = 1
    ) -> pd.DataFrame:
        """å‡†å¤‡ç‰¹å¾æ•°æ®"""
        # åˆ›å»ºæ»åç‰¹å¾
        feature_data = self._create_lag_features(data)

        # åˆ é™¤NaNå€¼
        feature_data = feature_data.dropna()

        # æ·»åŠ é¢„æµ‹ç›®æ ‡
        feature_data["target"] = feature_data["close"].shift(-prediction_horizon)

        # åˆ é™¤æœ€åçš„prediction_horizonè¡Œï¼ˆæ²¡æœ‰ç›®æ ‡å€¼ï¼‰
        feature_data = feature_data.iloc[:-prediction_horizon]

        return feature_data

    def train_models(
        self, data: pd.DataFrame, test_size: float = 0.2
    ) -> Dict[str, ModelPerformance]:
        """è®­ç»ƒå¤šä¸ªæ¨¡å‹"""
        start_time = time.time()

        # å‡†å¤‡æ•°æ®
        feature_data = self.prepare_features(data)

        # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        X, y = self._prepare_data_cpu(feature_data)
        X_train, X_test, y_train, y_test = sklearn_train_test_split(
            X, y, test_size=test_size, random_state=42
        )

        training_results = {}

        for model_name, model in self.models.items():
            model_start_time = time.time()

            # è®­ç»ƒæ¨¡å‹
            model.fit(X_train, y_train)

            # é¢„æµ‹
            y_pred = model.predict(X_test)

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            training_time = time.time() - model_start_time

            mse = mean_squared_error(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            r2_score_val = r2_score(y_test, y_pred)
            rmse = np.sqrt(mse)

            performance = ModelPerformance(
                training_time=training_time,
                prediction_time=0.001,
                mse=mse,
                mae=mae,
                r2_score=r2_score_val,
                rmse=rmse,
                is_gpu_enabled=self.gpu_enabled,
            )

            training_results[model_name] = performance
            self.performance_stats["model_scores"][model_name] = r2_score_val

            # æ›´æ–°æœ€ä½³æ¨¡å‹
            if (
                self.performance_stats["best_model"] is None
                or r2_score_val > self.performance_stats["best_model"][1]
            ):
                self.performance_stats["best_model"] = (model_name, r2_score_val)

        self.is_fitted = True
        total_training_time = time.time() - start_time

        self.performance_stats["total_training_time"] = total_training_time

        self.logger.info(f"CPUæ¨¡å‹è®­ç»ƒå®Œæˆï¼Œæ€»è€—æ—¶: {total_training_time:.2f}ç§’")
        return training_results

    def predict_price(
        self, data: pd.DataFrame, model_name: str = None, prediction_horizon: int = 1
    ) -> PredictionResult:
        """é¢„æµ‹ä»·æ ¼"""
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨train_modelsæ–¹æ³•")

        start_time = time.time()

        # é€‰æ‹©æ¨¡å‹
        if model_name is None:
            model_name = self.performance_stats["best_model"][0]

        model = self.models[model_name]

        # å‡†å¤‡æ•°æ®
        feature_data = self.prepare_features(data, prediction_horizon)

        # è·å–æœ€åä¸€è¡Œæ•°æ®ä½œä¸ºé¢„æµ‹è¾“å…¥
        last_row = feature_data.iloc[-1:].copy()

        # ç§»é™¤ç›®æ ‡åˆ—
        if "target" in last_row.columns:
            last_row = last_row.drop("target", axis=1)

        # æ•°æ®æ ‡å‡†åŒ–
        X = self.scaler.transform(last_row)

        # CPUé¢„æµ‹
        predicted_price = float(model.predict(X)[0])

        prediction_time = time.time() - start_time

        # è®¡ç®—ç½®ä¿¡åº¦
        confidence_score = self._calculate_confidence_score(
            model_name, prediction_horizon
        )

        # åˆ›å»ºé¢„æµ‹ç»“æœ
        result = PredictionResult(
            predicted_price=predicted_price,
            confidence_score=confidence_score,
            prediction_date=datetime.now() + timedelta(days=prediction_horizon),
            model_used=model_name,
            features_used=self.feature_columns,
            prediction_horizon=prediction_horizon,
            error_metrics={
                "mse": self.performance_stats["model_scores"].get(model_name, 0),
                "mae": 0,
                "r2_score": self.performance_stats["model_scores"].get(model_name, 0),
            },
        )

        # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
        self.performance_stats["total_predictions"] += 1
        self.performance_stats["total_prediction_time"] += prediction_time

        return result

    def _calculate_confidence_score(
        self, model_name: str, prediction_horizon: int
    ) -> float:
        """è®¡ç®—é¢„æµ‹ç½®ä¿¡åº¦"""
        base_confidence = self.performance_stats["model_scores"].get(model_name, 0.5)

        # æ ¹æ®é¢„æµ‹æ—¶é—´è°ƒæ•´ç½®ä¿¡åº¦
        time_penalty = min(0.1 * prediction_horizon, 0.3)

        # æ ¹æ®æ¨¡å‹æ€§èƒ½è°ƒæ•´ç½®ä¿¡åº¦
        model_adjustment = (
            0.1 if model_name == self.performance_stats["best_model"][0] else 0
        )

        confidence = max(
            0.0, min(1.0, base_confidence - time_penalty + model_adjustment)
        )
        return confidence

    def batch_predict(
        self,
        data_list: List[pd.DataFrame],
        model_name: str = None,
        prediction_horizon: int = 1,
    ) -> List[PredictionResult]:
        """æ‰¹é‡é¢„æµ‹"""
        results = []

        for data in data_list:
            try:
                result = self.predict_price(data, model_name, prediction_horizon)
                results.append(result)
            except Exception as e:
                self.logger.error(f"æ‰¹é‡é¢„æµ‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                continue

        return results

    def get_performance_summary(self) -> Dict:
        """è·å–æ€§èƒ½æ€»ç»“"""
        avg_prediction_time = self.performance_stats["total_prediction_time"] / max(
            1, self.performance_stats["total_predictions"]
        )

        return {
            "gpu_enabled": self.gpu_enabled,
            "total_predictions": self.performance_stats["total_predictions"],
            "total_training_time": self.performance_stats["total_training_time"],
            "avg_prediction_time": avg_prediction_time,
            "best_model": self.performance_stats["best_model"],
            "model_scores": self.performance_stats["model_scores"],
            "is_fitted": self.is_fitted,
        }

    def optimize_hyperparameters(
        self, data: pd.DataFrame, model_type: str = "ridge"
    ) -> Dict:
        """ä¼˜åŒ–è¶…å‚æ•°"""
        from sklearn.model_selection import GridSearchCV

        param_grid = {"alpha": [0.1, 1.0, 10.0, 100.0]}

        feature_data = self.prepare_features(data)
        X, y = self._prepare_data_cpu(feature_data)

        grid_search = GridSearchCV(Ridge(), param_grid, cv=5, scoring="r2", n_jobs=-1)

        grid_search.fit(X, y)

        return {
            "best_params": grid_search.best_params_,
            "best_score": grid_search.best_score_,
            "model_type": model_type,
        }

    def save_model(self, filepath: str):
        """ä¿å­˜æ¨¡å‹"""
        import joblib

        model_data = {
            "models": self.models,
            "scaler": self.scaler,
            "feature_columns": self.feature_columns,
            "is_fitted": self.is_fitted,
            "performance_stats": self.performance_stats,
        }

        joblib.dump(model_data, filepath)
        self.logger.info(f"CPUæ¨¡å‹å·²ä¿å­˜åˆ°: {filepath}")

    def load_model(self, filepath: str):
        """åŠ è½½æ¨¡å‹"""
        import joblib

        model_data = joblib.load(filepath)

        self.models = model_data["models"]
        self.scaler = model_data["scaler"]
        self.feature_columns = model_data["feature_columns"]
        self.is_fitted = model_data["is_fitted"]
        self.performance_stats = model_data["performance_stats"]

        self.logger.info(f"CPUæ¨¡å‹å·²ä» {filepath} åŠ è½½")


# CPUç‰ˆæœ¬çš„æ•°æ®å¤„ç†å™¨
class DataProcessorCPU:
    """CPUç‰ˆæœ¬çš„æ•°æ®å¤„ç†å™¨ - GPUç‰ˆæœ¬çš„å®Œæ•´å›é€€å®ç°"""

    def __init__(
        self, gpu_enabled: bool = False, n_jobs: int = 1, chunk_size: int = 10000
    ):
        self.gpu_enabled = gpu_enabled
        self.n_jobs = n_jobs
        self.chunk_size = chunk_size
        self.scaler = StandardScaler()
        self.logger = logging.getLogger(__name__)

        # ç»Ÿè®¡ä¿¡æ¯
        self.chunks_processed = 0
        self.total_data_processed = 0

    def preprocess(
        self, data: pd.DataFrame, config: Optional[ProcessingConfig] = None
    ) -> pd.DataFrame:
        """æ•°æ®é¢„å¤„ç†"""
        config = config or ProcessingConfig()
        processed_data = data.copy()

        # å»é™¤å¼‚å¸¸å€¼
        if config.remove_outliers:
            processed_data = self._remove_outliers(processed_data)

        # å¤„ç†ç¼ºå¤±å€¼
        if config.handle_missing:
            processed_data = self._handle_missing_values(processed_data)

        # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
        processed_data = self._add_technical_indicators(processed_data)

        # ç‰¹å¾æ ‡å‡†åŒ–
        if config.normalize_features:
            processed_data = self._normalize_features(processed_data)

        self.chunks_processed += 1
        self.total_data_processed += len(processed_data)

        return processed_data

    def _remove_outliers(self, data: pd.DataFrame) -> pd.DataFrame:
        """å»é™¤å¼‚å¸¸å€¼"""
        numeric_columns = data.select_dtypes(include=[np.number]).columns

        for col in numeric_columns:
            Q1 = data[col].quantile(0.25)
            Q3 = data[col].quantile(0.75)
            IQR = Q3 - Q1

            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR

            data = data[(data[col] >= lower_bound) & (data[col] <= upper_bound)]

        return data

    def _handle_missing_values(self, data: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†ç¼ºå¤±å€¼"""
        # æ•°å€¼åˆ—ç”¨å‰å‘å¡«å……ï¼Œç„¶åç”¨åå‘å¡«å……
        numeric_columns = data.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            data[col] = data[col].fillna(method="ffill").fillna(method="bfill")

        # åˆ†ç±»åˆ—ç”¨ä¼—æ•°å¡«å……
        categorical_columns = data.select_dtypes(include=["object"]).columns
        for col in categorical_columns:
            data[col] = data[col].fillna(data[col].mode()[0])

        return data

    def _add_technical_indicators(self, data: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ æŠ€æœ¯æŒ‡æ ‡"""
        # ç§»åŠ¨å¹³å‡
        data["sma_5"] = data["close"].rolling(window=5).mean()
        data["sma_20"] = data["close"].rolling(window=20).mean()
        data["sma_50"] = data["close"].rolling(window=50).mean()

        # RSI
        data["rsi"] = self._calculate_rsi(data["close"])

        # MACD
        data["macd"], data["macd_signal"] = self._calculate_macd(data["close"])

        # å¸ƒæ—å¸¦
        data["bb_middle"] = data["close"].rolling(window=20).mean()
        data["bb_upper"] = data["bb_middle"] + (
            data["close"].rolling(window=20).std() * 2
        )
        data["bb_lower"] = data["bb_middle"] - (
            data["close"].rolling(window=20).std() * 2
        )

        return data

    def _normalize_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç‰¹å¾æ ‡å‡†åŒ–"""
        numeric_columns = data.select_dtypes(include=[np.number]).columns
        feature_data = data[numeric_columns]

        normalized_features = self.scaler.fit_transform(feature_data)
        normalized_df = pd.DataFrame(normalized_features, columns=feature_data.columns)

        # åˆå¹¶å›åŸå§‹æ•°æ®
        result = data.copy()
        for col in normalized_df.columns:
            result[f"{col}_normalized"] = normalized_df[col].values

        return result

    def _calculate_rsi(self, prices: pd.Series) -> pd.Series:
        """è®¡ç®—RSI"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi

    def _calculate_macd(self, prices: pd.Series) -> Tuple[pd.Series, pd.Series]:
        """è®¡ç®—MACD"""
        ema_fast = prices.ewm(span=12).mean()
        ema_slow = prices.ewm(span=26).mean()
        macd = ema_fast - ema_slow
        macd_signal = macd.ewm(span=9).mean()
        return macd, macd_signal

    def parallel_process(self, data_list: List[pd.DataFrame]) -> List[pd.DataFrame]:
        """å¹¶è¡Œå¤„ç†å¤šä¸ªæ•°æ®é›†"""
        results = []

        for i, data in enumerate(data_list):
            try:
                processed_data = self.preprocess(data)
                results.append(processed_data)

                if (i + 1) % 10 == 0:
                    self.logger.info(f"å¹¶è¡Œå¤„ç†è¿›åº¦: {i + 1}/{len(data_list)}")

            except Exception as e:
                self.logger.error(f"å¤„ç†ç¬¬ {i + 1} ä¸ªæ•°æ®æ—¶å‡ºé”™: {e}")
                results.append(data)  # å‡ºé”™æ—¶è¿”å›åŸå§‹æ•°æ®

        return results

    def get_performance_summary(self) -> Dict:
        """è·å–æ€§èƒ½æ€»ç»“"""
        return {
            "gpu_enabled": self.gpu_enabled,
            "n_jobs": self.n_jobs,
            "chunk_size": self.chunk_size,
            "chunks_processed": self.chunks_processed,
            "total_data_processed": self.total_data_processed,
        }


# CPUç‰ˆæœ¬çš„ç‰¹å¾ç”Ÿæˆå™¨
class FeatureGeneratorCPU:
    """CPUç‰ˆæœ¬çš„ç‰¹å¾ç”Ÿæˆå™¨ - GPUç‰ˆæœ¬çš„å®Œæ•´å›é€€å®ç°"""

    def __init__(self, gpu_enabled: bool = False):
        self.gpu_enabled = gpu_enabled
        self.logger = logging.getLogger(__name__)
        self.features_generated = 0

    def generate_features(
        self, data: pd.DataFrame, feature_types: List[str] = None
    ) -> pd.DataFrame:
        """ç”Ÿæˆç‰¹å¾"""
        feature_types = feature_types or [
            "technical",
            "statistical",
            "momentum",
            "volatility",
        ]

        feature_data = data.copy()

        for feature_type in feature_types:
            if feature_type == "technical":
                feature_data = self._generate_technical_features(feature_data)
            elif feature_type == "statistical":
                feature_data = self._generate_statistical_features(feature_data)
            elif feature_type == "momentum":
                feature_data = self._generate_momentum_features(feature_data)
            elif feature_type == "volatility":
                feature_data = self._generate_volatility_features(feature_data)

        self.features_generated += len(feature_data.columns)
        return feature_data

    def _generate_technical_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç”ŸæˆæŠ€æœ¯ç‰¹å¾"""
        # ç§»åŠ¨å¹³å‡
        windows = [5, 10, 20, 50]
        for window in windows:
            data[f"sma_{window}"] = data["close"].rolling(window=window).mean()
            data[f"ema_{window}"] = data["close"].ewm(span=window).mean()

        # å¸ƒæ—å¸¦
        data["bb_middle"] = data["close"].rolling(window=20).mean()
        data["bb_upper"] = data["bb_middle"] + (
            data["close"].rolling(window=20).std() * 2
        )
        data["bb_lower"] = data["bb_middle"] - (
            data["close"].rolling(window=20).std() * 2
        )

        return data

    def _generate_statistical_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç”Ÿæˆç»Ÿè®¡ç‰¹å¾"""
        # ä»·æ ¼ç»Ÿè®¡
        data["price_mean"] = data["close"].expanding().mean()
        data["price_std"] = data["close"].expanding().std()
        data["price_skew"] = data["close"].expanding().skew()
        data["price_kurt"] = data["close"].expanding().kurt()

        # æˆäº¤é‡ç»Ÿè®¡
        if "volume" in data.columns:
            data["volume_mean"] = data["volume"].expanding().mean()
            data["volume_std"] = data["volume"].expanding().std()

        return data

    def _generate_momentum_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç”ŸæˆåŠ¨é‡ç‰¹å¾"""
        # ä»·æ ¼å˜åŒ–ç‡
        periods = [1, 3, 5, 10, 20]
        for period in periods:
            data[f"return_{period}"] = data["close"].pct_change(period)

        # ä»·æ ¼åŠ¨é‡
        for period in [5, 10, 20]:
            data[f"momentum_{period}"] = data["close"] / data["close"].shift(period) - 1

        return data

    def _generate_volatility_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç”Ÿæˆæ³¢åŠ¨ç‡ç‰¹å¾"""
        # æ³¢åŠ¨ç‡
        windows = [5, 10, 20]
        for window in windows:
            returns = data["close"].pct_change().rolling(window=window).std()
            data[f"volatility_{window}"] = returns * np.sqrt(252)  # å¹´åŒ–æ³¢åŠ¨ç‡

        # ATR (å¹³å‡çœŸå®æ³¢å¹…)
        high_low = data["high"] - data["low"]
        high_close = np.abs(data["high"] - data["close"].shift())
        low_close = np.abs(data["low"] - data["close"].shift())
        true_range = np.maximum(high_low, high_close, low_close)
        data["atr"] = true_range.rolling(window=14).mean()

        return data

    def get_performance_summary(self) -> Dict:
        """è·å–æ€§èƒ½æ€»ç»“"""
        return {
            "gpu_enabled": self.gpu_enabled,
            "features_generated": self.features_generated,
        }


# æ™ºèƒ½é€‰æ‹©å™¨ - è‡ªåŠ¨é€‰æ‹©GPUæˆ–CPUç‰ˆæœ¬
class ComponentSelector:
    """æ™ºèƒ½ç»„ä»¶é€‰æ‹©å™¨ - æ ¹æ®ç¯å¢ƒè‡ªåŠ¨é€‰æ‹©GPUæˆ–CPUç‰ˆæœ¬"""

    def __init__(self):
        self.gpu_available = self._check_gpu_availability()
        self.logger = logging.getLogger(__name__)

    def _check_gpu_availability(self) -> bool:
        """æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨"""
        try:
            import cupy as cp

            # æ£€æŸ¥æ˜¯å¦æœ‰GPUè®¾å¤‡
            cp.cuda.Device(0)
            return True
        except:
            return False

    def get_price_predictor(self, gpu_enabled: Optional[bool] = None):
        """è·å–ä»·æ ¼é¢„æµ‹å™¨"""
        if gpu_enabled is True:
            # å¼ºåˆ¶ä½¿ç”¨GPU
            from .price_predictor_gpu import GPUPricePredictor

            return GPUPricePredictor(gpu_enabled=True)
        elif gpu_enabled is False:
            # å¼ºåˆ¶ä½¿ç”¨CPU
            return PricePredictorCPU(gpu_enabled=False)
        else:
            # è‡ªåŠ¨é€‰æ‹©
            if self.gpu_available:
                from .price_predictor_gpu import GPUPricePredictor

                return GPUPricePredictor(gpu_enabled=True)
            else:
                self.logger.info("GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUç‰ˆæœ¬")
                return PricePredictorCPU(gpu_enabled=False)

    def get_data_processor(self, gpu_enabled: Optional[bool] = None):
        """è·å–æ•°æ®å¤„ç†å™¨"""
        if gpu_enabled is True:
            from .data_processor_gpu import GPUDataProcessor

            return GPUDataProcessor(gpu_enabled=True)
        elif gpu_enabled is False:
            return DataProcessorCPU(gpu_enabled=False)
        else:
            if self.gpu_available:
                from .data_processor_gpu import GPUDataProcessor

                return GPUDataProcessor(gpu_enabled=True)
            else:
                self.logger.info("GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUç‰ˆæœ¬")
                return DataProcessorCPU(gpu_enabled=False)

    def get_feature_generator(self, gpu_enabled: Optional[bool] = None):
        """è·å–ç‰¹å¾ç”Ÿæˆå™¨"""
        if gpu_enabled is True:
            from .feature_generator_gpu import GPUFeatureGenerator

            return GPUFeatureGenerator(gpu_enabled=True)
        elif gpu_enabled is False:
            return FeatureGeneratorCPU(gpu_enabled=False)
        else:
            if self.gpu_available:
                from .feature_generator_gpu import GPUFeatureGenerator

                return GPUFeatureGenerator(gpu_enabled=True)
            else:
                self.logger.info("GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUç‰ˆæœ¬")
                return FeatureGeneratorCPU(gpu_enabled=False)

    def get_environment_info(self) -> Dict[str, any]:
        """è·å–ç¯å¢ƒä¿¡æ¯"""
        return {
            "gpu_available": self.gpu_available,
            "cpu_fallback_available": True,
            "selected_mode": "GPU" if self.gpu_available else "CPU",
        }


# å…¨å±€æ™ºèƒ½é€‰æ‹©å™¨å®ä¾‹
_component_selector = ComponentSelector()


def get_component_selector() -> ComponentSelector:
    """è·å–å…¨å±€ç»„ä»¶é€‰æ‹©å™¨"""
    return _component_selector


def auto_select_component(component_type: str, gpu_enabled: Optional[bool] = None):
    """è‡ªåŠ¨é€‰æ‹©ç»„ä»¶"""
    selector = get_component_selector()

    if component_type == "price_predictor":
        return selector.get_price_predictor(gpu_enabled)
    elif component_type == "data_processor":
        return selector.get_data_processor(gpu_enabled)
    elif component_type == "feature_generator":
        return selector.get_feature_generator(gpu_enabled)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ç»„ä»¶ç±»å‹: {component_type}")


def main():
    """ä¸»å‡½æ•° - CPUç‰ˆæœ¬æµ‹è¯•"""
    print("ğŸ”„ CPUå›é€€ç‰ˆæœ¬æµ‹è¯•")
    print("=" * 40)

    # åˆ›å»ºç»„ä»¶é€‰æ‹©å™¨
    selector = ComponentSelector()
    print(f"GPUå¯ç”¨æ€§: {selector.gpu_available}")

    # æµ‹è¯•ä»·æ ¼é¢„æµ‹å™¨
    print("\n1. ä»·æ ¼é¢„æµ‹å™¨æµ‹è¯•:")
    predictor = auto_select_component("price_predictor")
    print(f"ä½¿ç”¨ç‰ˆæœ¬: {'GPU' if selector.gpu_available else 'CPU'}")

    # è·å–æµ‹è¯•æ•°æ®
    import yfinance as yf

    test_data = yf.download("AAPL", start="2023-01-01", end="2024-01-01")

    # è®­ç»ƒæ¨¡å‹
    print("è®­ç»ƒæ¨¡å‹...")
    training_results = predictor.train_models(test_data[:200])  # ä½¿ç”¨å°æ ·æœ¬
    print(f"è®­ç»ƒå®Œæˆï¼Œæœ€ä½³æ¨¡å‹: {predictor.performance_stats['best_model'][0]}")

    # è¿›è¡Œé¢„æµ‹
    print("è¿›è¡Œé¢„æµ‹...")
    prediction = predictor.predict_price(test_data)
    print(f"é¢„æµ‹ä»·æ ¼: {prediction.predicted_price:.2f}")
    print(f"ç½®ä¿¡åº¦: {prediction.confidence_score:.2f}")

    # æµ‹è¯•æ•°æ®å¤„ç†å™¨
    print("\n2. æ•°æ®å¤„ç†å™¨æµ‹è¯•:")
    processor = auto_select_component("data_processor")
    processed_data = processor.preprocess(test_data[:50])
    print(f"å¤„ç†å®Œæˆï¼Œæ•°æ®å½¢çŠ¶: {processed_data.shape}")

    # æµ‹è¯•ç‰¹å¾ç”Ÿæˆå™¨
    print("\n3. ç‰¹å¾ç”Ÿæˆå™¨æµ‹è¯•:")
    feature_generator = auto_select_component("feature_generator")
    features = feature_generator.generate_features(test_data[:50])
    print(f"ç‰¹å¾ç”Ÿæˆå®Œæˆï¼Œç‰¹å¾æ•°é‡: {len(features.columns)}")

    # æ˜¾ç¤ºç¯å¢ƒä¿¡æ¯
    print("\n4. ç¯å¢ƒä¿¡æ¯:")
    env_info = selector.get_environment_info()
    for key, value in env_info.items():
        print(f"  {key}: {value}")

    print("\nâœ… CPUå›é€€ç‰ˆæœ¬æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main()
