#!/usr/bin/env python3
"""
GPUæ€§èƒ½åŸºå‡†æµ‹è¯•ç³»ç»Ÿ
å…¨é¢æµ‹è¯•GPUåŠ é€Ÿç»„ä»¶çš„æ€§èƒ½å¯¹æ¯”å’Œä¼˜åŒ–æ•ˆæœ
é€‚ç”¨äºMyStocksé‡åŒ–äº¤æ˜“ç³»ç»Ÿçš„GPUåŠ é€Ÿæ•ˆæœè¯„ä¼°
"""

import time
import psutil
import numpy as np
import pandas as pd
import logging
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
import tracemalloc
from contextlib import contextmanager
import matplotlib.pyplot as plt
import json

# å¯¼å…¥GPUç»„ä»¶
from .gpu_manager import GPUUnifiedManager, GPUConfig, GPUProcessingResult
from .cpu_fallback import (
    ComponentSelector,
    PricePredictorCPU,
    DataProcessorCPU,
    FeatureGeneratorCPU,
)
from .price_predictor_gpu import GPUPricePredictor, PredictionResult
from .feature_generator_gpu import GPUFeatureGenerator
from .data_processor_gpu import GPUDataProcessor

# å¯¼å…¥åŸç‰ˆç»„ä»¶
from ..data_adapters.financial_adapter import FinancialDataSource
from ..unified_manager import MyStocksUnifiedManager


@dataclass
class BenchmarkConfig:
    """åŸºå‡†æµ‹è¯•é…ç½®"""

    test_data_sizes: List[int] = None
    model_types: List[str] = None
    test_iterations: int = 3
    warmup_iterations: int = 1
    enable_memory_profiling: bool = True
    enable_cpu_benchmark: bool = True
    enable_feature_benchmark: bool = True
    enable_data_processing_benchmark: bool = True
    enable_prediction_benchmark: bool = True

    def __post_init__(self):
        if self.test_data_sizes is None:
            self.test_data_sizes = [1000, 5000, 10000, 50000]
        if self.model_types is None:
            self.model_types = ["linear", "ridge", "lasso", "random_forest"]


@dataclass
class BenchmarkResult:
    """åŸºå‡†æµ‹è¯•ç»“æœ"""

    test_name: str
    data_size: int
    gpu_time: float
    cpu_time: float
    speedup_factor: float
    memory_usage_mb: float
    gpu_memory_mb: float
    cpu_memory_mb: float
    gpu_accuracy: float
    cpu_accuracy: float
    timestamp: float


class GPUPerformanceBenchmark:
    """GPUæ€§èƒ½åŸºå‡†æµ‹è¯•å™¨"""

    def __init__(self, config: BenchmarkConfig = None):
        self.config = config or BenchmarkConfig()
        self.logger = logging.getLogger(__name__)
        self.results = []
        self.component_selector = ComponentSelector()

        # åˆå§‹åŒ–ç»„ä»¶
        self.gpu_manager = GPUUnifiedManager()
        self.unified_manager = MyStocksUnifiedManager()

        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_tests": 0,
            "successful_gpu_tests": 0,
            "successful_cpu_tests": 0,
            "failed_tests": 0,
            "average_speedup": 0.0,
            "max_speedup": 0.0,
            "min_speedup": float("inf"),
        }

    @contextmanager
    def _memory_profiler(self):
        """å†…å­˜åˆ†æä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        if not self.config.enable_memory_profiling:
            yield
            return

        tracemalloc.start()
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024

        try:
            yield
        finally:
            final_memory = process.memory_info().rss / 1024 / 1024
            peak_memory = tracemalloc.get_traced_memory()[1] / 1024 / 1024

            tracemalloc.stop()

            self.logger.info(
                f"å†…å­˜ä½¿ç”¨ - åˆå§‹: {initial_memory:.2f}MB, "
                f"æœ€ç»ˆ: {final_memory:.2f}MB, å³°å€¼: {peak_memory:.2f}MB"
            )

    def _generate_test_data(self, size: int) -> pd.DataFrame:
        """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
        np.random.seed(42)  # ç¡®ä¿å¯é‡å¤æ€§

        # ç”Ÿæˆæ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®
        dates = pd.date_range("2023-01-01", periods=size, freq="D")

        data = pd.DataFrame(
            {
                "date": dates,
                "open": np.random.uniform(10, 100, size),
                "high": np.random.uniform(105, 105, size),
                "low": np.random.uniform(95, 105, size),
                "close": np.random.uniform(10, 100, size),
                "volume": np.random.uniform(1000000, 10000000, size),
                "adj_close": np.random.uniform(10, 100, size),
            }
        )

        # ç¡®ä¿high >= low, high >= open/close, low <= open/close
        data["high"] = np.maximum(
            data["high"], data[["open", "high", "low", "close"]].max(axis=1)
        )
        data["low"] = np.minimum(
            data["low"], data[["open", "high", "low", "close"]].min(axis=1)
        )

        # æ·»åŠ ä¸€äº›ç¼ºå¤±å€¼æµ‹è¯•æ•°æ®è´¨é‡å¤„ç†
        if size > 1000:
            missing_indices = np.random.choice(size, size // 100, replace=False)
            data.loc[missing_indices, "volume"] = np.nan

        return data

    def _benchmark_data_processing(self, data: pd.DataFrame) -> Dict[str, float]:
        """åŸºå‡†æµ‹è¯•æ•°æ®å¤„ç†å™¨"""
        times = {"gpu": [], "cpu": []}

        for _ in range(self.config.warmup_iterations):
            # GPUé¢„çƒ­
            if self.component_selector.check_gpu_availability():
                try:
                    gpu_processor = GPUDataProcessor(gpu_enabled=True)
                    gpu_processor.preprocess(data)
                except:
                    pass

            # CPUé¢„çƒ­
            cpu_processor = DataProcessorCPU(gpu_enabled=False)
            cpu_processor.preprocess(data)

        # GPUæµ‹è¯•
        if self.component_selector.check_gpu_availability():
            try:
                gpu_times = []
                for _ in range(self.config.test_iterations):
                    with self._memory_profiler():
                        start_time = time.time()
                        gpu_processor = GPUDataProcessor(gpu_enabled=True)
                        result = gpu_processor.preprocess(data)
                        gpu_times.append(time.time() - start_time)
                times["gpu"] = gpu_times
            except Exception as e:
                self.logger.error(f"GPUæ•°æ®å¤„ç†æµ‹è¯•å¤±è´¥: {e}")

        # CPUæµ‹è¯•
        cpu_times = []
        for _ in range(self.config.test_iterations):
            with self._memory_profiler():
                start_time = time.time()
                cpu_processor = DataProcessorCPU(gpu_enabled=False)
                result = cpu_processor.preprocess(data)
                cpu_times.append(time.time() - start_time)
        times["cpu"] = cpu_times

        return {
            "gpu_time": np.mean(times["gpu"]) if times["gpu"] else float("inf"),
            "cpu_time": np.mean(times["cpu"]),
            "gpu_memory": self._get_gpu_memory_usage(),
            "cpu_memory": psutil.Process().memory_info().rss / 1024 / 1024,
        }

    def _benchmark_feature_generation(self, data: pd.DataFrame) -> Dict[str, float]:
        """åŸºå‡†æµ‹è¯•ç‰¹å¾ç”Ÿæˆå™¨"""
        times = {"gpu": [], "cpu": []}

        for _ in range(self.config.warmup_iterations):
            # GPUé¢„çƒ­
            if self.component_selector.check_gpu_availability():
                try:
                    gpu_generator = GPUFeatureGenerator(gpu_enabled=True)
                    gpu_generator.generate_features(data)
                except:
                    pass

            # CPUé¢„çƒ­
            cpu_generator = FeatureGeneratorCPU(gpu_enabled=False)
            cpu_generator.generate_features(data)

        # GPUæµ‹è¯•
        if self.component_selector.check_gpu_availability():
            try:
                gpu_times = []
                for _ in range(self.config.test_iterations):
                    with self._memory_profiler():
                        start_time = time.time()
                        gpu_generator = GPUFeatureGenerator(gpu_enabled=True)
                        result = gpu_generator.generate_features(data)
                        gpu_times.append(time.time() - start_time)
                times["gpu"] = gpu_times
            except Exception as e:
                self.logger.error(f"GPUç‰¹å¾ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")

        # CPUæµ‹è¯•
        cpu_times = []
        for _ in range(self.config.test_iterations):
            with self._memory_profiler():
                start_time = time.time()
                cpu_generator = FeatureGeneratorCPU(gpu_enabled=False)
                result = cpu_generator.generate_features(data)
                cpu_times.append(time.time() - start_time)
        times["cpu"] = cpu_times

        return {
            "gpu_time": np.mean(times["gpu"]) if times["gpu"] else float("inf"),
            "cpu_time": np.mean(times["cpu"]),
            "gpu_memory": self._get_gpu_memory_usage(),
            "cpu_memory": psutil.Process().memory_info().rss / 1024 / 1024,
        }

    def _benchmark_price_prediction(
        self, data: pd.DataFrame, model_type: str
    ) -> Dict[str, float]:
        """åŸºå‡†æµ‹è¯•ä»·æ ¼é¢„æµ‹å™¨"""
        times = {"gpu": [], "cpu": []}
        accuracies = {"gpu": [], "cpu": []}

        for _ in range(self.config.warmup_iterations):
            # GPUé¢„çƒ­
            if self.component_selector.check_gpu_availability():
                try:
                    gpu_predictor = GPUPricePredictor(gpu_enabled=True)
                    gpu_predictor.train_models(data)
                except:
                    pass

            # CPUé¢„çƒ­
            cpu_predictor = PricePredictorCPU(gpu_enabled=False)
            cpu_predictor.train_models(data)

        # GPUæµ‹è¯•
        if self.component_selector.check_gpu_availability():
            try:
                gpu_times = []
                gpu_accs = []
                for _ in range(self.config.test_iterations):
                    with self._memory_profiler():
                        start_time = time.time()
                        gpu_predictor = GPUPricePredictor(gpu_enabled=True)
                        gpu_predictor.train_models(data)

                        # æ¨¡æ‹Ÿé¢„æµ‹å‡†ç¡®åº¦ï¼ˆè¿™é‡Œä½¿ç”¨è®­ç»ƒRÂ²åˆ†æ•°ï¼‰
                        performance = gpu_predictor.get_performance_summary()
                        gpu_accs.append(performance.get("avg_prediction_time", 0))
                        gpu_times.append(time.time() - start_time)
                times["gpu"] = gpu_times
                accuracies["gpu"] = gpu_accs
            except Exception as e:
                self.logger.error(f"GPUä»·æ ¼é¢„æµ‹æµ‹è¯•å¤±è´¥: {e}")

        # CPUæµ‹è¯•
        cpu_times = []
        cpu_accs = []
        for _ in range(self.config.test_iterations):
            with self._memory_profiler():
                start_time = time.time()
                cpu_predictor = PricePredictorCPU(gpu_enabled=False)
                cpu_predictor.train_models(data)

                performance = cpu_predictor.get_performance_summary()
                cpu_accs.append(performance.get("avg_prediction_time", 0))
                cpu_times.append(time.time() - start_time)
        times["cpu"] = cpu_times
        accuracies["cpu"] = cpu_accs

        return {
            "gpu_time": np.mean(times["gpu"]) if times["gpu"] else float("inf"),
            "cpu_time": np.mean(times["cpu"]),
            "gpu_accuracy": np.mean(accuracies["gpu"]) if accuracies["gpu"] else 0,
            "cpu_accuracy": np.mean(accuracies["cpu"]),
            "gpu_memory": self._get_gpu_memory_usage(),
            "cpu_memory": psutil.Process().memory_info().rss / 1024 / 1024,
        }

    def _get_gpu_memory_usage(self) -> float:
        """è·å–GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            import cupy as cp

            return cp.cuda.get_default_memory_pool().used_bytes() / 1024 / 1024
        except:
            return 0.0

    def run_comprehensive_benchmark(self) -> List[BenchmarkResult]:
        """è¿è¡Œç»¼åˆåŸºå‡†æµ‹è¯•"""
        self.logger.info("ğŸš€ å¼€å§‹ç»¼åˆGPUæ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("=" * 60)
        print("ğŸš€ MyStocks GPUåŠ é€Ÿæ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("=" * 60)

        # æµ‹è¯•æ•°æ®å¤§å°å¾ªç¯
        for data_size in self.config.test_data_sizes:
            print(f"\nğŸ“Š æµ‹è¯•æ•°æ®å¤§å°: {data_size:,} è¡Œ")
            print("-" * 40)

            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            test_data = self._generate_test_data(data_size)

            # æ•°æ®å¤„ç†åŸºå‡†æµ‹è¯•
            if self.config.enable_data_processing_benchmark:
                print("ğŸ”§ æ•°æ®å¤„ç†æ€§èƒ½æµ‹è¯•:")
                result = self._benchmark_data_processing(test_data)

                speedup = (
                    result["cpu_time"] / result["gpu_time"]
                    if result["gpu_time"] > 0
                    else 0
                )
                self._update_stats(speedup)

                self._print_benchmark_result(
                    "æ•°æ®å¤„ç†",
                    data_size,
                    result["gpu_time"],
                    result["cpu_time"],
                    speedup,
                    result["gpu_memory"],
                    result["cpu_memory"],
                )

                # ä¿å­˜ç»“æœ
                self.results.append(
                    BenchmarkResult(
                        test_name="æ•°æ®å¤„ç†",
                        data_size=data_size,
                        gpu_time=result["gpu_time"],
                        cpu_time=result["cpu_time"],
                        speedup_factor=speedup,
                        memory_usage_mb=result["gpu_memory"],
                        gpu_memory_mb=result["gpu_memory"],
                        cpu_memory_mb=result["cpu_memory"],
                        gpu_accuracy=0.0,
                        cpu_accuracy=0.0,
                        timestamp=time.time(),
                    )
                )

            # ç‰¹å¾ç”ŸæˆåŸºå‡†æµ‹è¯•
            if self.config.enable_feature_benchmark:
                print("\nğŸ¯ ç‰¹å¾ç”Ÿæˆæ€§èƒ½æµ‹è¯•:")
                result = self._benchmark_feature_generation(test_data)

                speedup = (
                    result["cpu_time"] / result["gpu_time"]
                    if result["gpu_time"] > 0
                    else 0
                )
                self._update_stats(speedup)

                self._print_benchmark_result(
                    "ç‰¹å¾ç”Ÿæˆ",
                    data_size,
                    result["gpu_time"],
                    result["cpu_time"],
                    speedup,
                    result["gpu_memory"],
                    result["cpu_memory"],
                )

                # ä¿å­˜ç»“æœ
                self.results.append(
                    BenchmarkResult(
                        test_name="ç‰¹å¾ç”Ÿæˆ",
                        data_size=data_size,
                        gpu_time=result["gpu_time"],
                        cpu_time=result["cpu_time"],
                        speedup_factor=speedup,
                        memory_usage_mb=result["gpu_memory"],
                        gpu_memory_mb=result["gpu_memory"],
                        cpu_memory_mb=result["cpu_memory"],
                        gpu_accuracy=0.0,
                        cpu_accuracy=0.0,
                        timestamp=time.time(),
                    )
                )

            # ä»·æ ¼é¢„æµ‹åŸºå‡†æµ‹è¯•
            if self.config.enable_prediction_benchmark:
                print(f"\nğŸ“ˆ ä»·æ ¼é¢„æµ‹æ€§èƒ½æµ‹è¯•:")
                for model_type in self.config.model_types:
                    print(f"  æ¨¡å‹ç±»å‹: {model_type}")
                    result = self._benchmark_price_prediction(test_data, model_type)

                    speedup = (
                        result["cpu_time"] / result["gpu_time"]
                        if result["gpu_time"] > 0
                        else 0
                    )
                    self._update_stats(speedup)

                    self._print_benchmark_result(
                        f"é¢„æµ‹_{model_type}",
                        data_size,
                        result["gpu_time"],
                        result["cpu_time"],
                        speedup,
                        result["gpu_memory"],
                        result["cpu_memory"],
                        result["gpu_accuracy"],
                        result["cpu_accuracy"],
                    )

                    # ä¿å­˜ç»“æœ
                    self.results.append(
                        BenchmarkResult(
                            test_name=f"é¢„æµ‹_{model_type}",
                            data_size=data_size,
                            gpu_time=result["gpu_time"],
                            cpu_time=result["cpu_time"],
                            speedup_factor=speedup,
                            memory_usage_mb=result["gpu_memory"],
                            gpu_memory_mb=result["gpu_memory"],
                            cpu_memory_mb=result["cpu_memory"],
                            gpu_accuracy=result["gpu_accuracy"],
                            cpu_accuracy=result["cpu_accuracy"],
                            timestamp=time.time(),
                        )
                    )

        self._print_summary()
        return self.results

    def _print_benchmark_result(
        self,
        test_name: str,
        data_size: int,
        gpu_time: float,
        cpu_time: float,
        speedup: float,
        gpu_mem: float,
        cpu_mem: float,
        gpu_acc: float = 0.0,
        cpu_acc: float = 0.0,
    ):
        """æ‰“å°åŸºå‡†æµ‹è¯•ç»“æœ"""
        status = "âœ…" if speedup > 1 else "âŒ"
        print(f"  {status} {test_name}:")
        print(
            f"    GPUæ—¶é—´: {gpu_time:.4f}s | CPUæ—¶é—´: {cpu_time:.4f}s | åŠ é€Ÿæ¯”: {speedup:.2f}x"
        )
        print(f"    GPUå†…å­˜: {gpu_mem:.2f}MB | CPUå†…å­˜: {cpu_mem:.2f}MB")

        if gpu_acc > 0 and cpu_acc > 0:
            print(f"    GPUç²¾åº¦: {gpu_acc:.4f} | CPUç²¾åº¦: {cpu_acc:.4f}")

    def _update_stats(self, speedup: float):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats["total_tests"] += 1

        if speedup > 1:
            self.stats["successful_gpu_tests"] += 1
        else:
            self.stats["successful_cpu_tests"] += 1

        if speedup > 0:
            self.stats["average_speedup"] += speedup
            self.stats["max_speedup"] = max(self.stats["max_speedup"], speedup)
            self.stats["min_speedup"] = min(self.stats["min_speedup"], speedup)

    def _print_summary(self):
        """æ‰“å°æ€»ç»“æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ GPUæ€§èƒ½åŸºå‡†æµ‹è¯•æ€»ç»“")
        print("=" * 60)

        total = self.stats["total_tests"]
        gpu_success = self.stats["successful_gpu_tests"]
        cpu_success = self.stats["successful_cpu_tests"]

        print(f"æ€»æµ‹è¯•é¡¹ç›®: {total}")
        print(f"GPUèƒœå‡ºé¡¹ç›®: {gpu_success} ({gpu_success/total*100:.1f}%)")
        print(f"CPUèƒœå‡ºé¡¹ç›®: {cpu_success} ({cpu_success/total*100:.1f}%)")

        if total > 0:
            self.stats["average_speedup"] = self.stats["average_speedup"] / total
            print(f"å¹³å‡åŠ é€Ÿæ¯”: {self.stats['average_speedup']:.2f}x")
            print(f"æœ€å¤§åŠ é€Ÿæ¯”: {self.stats['max_speedup']:.2f}x")
            print(f"æœ€å°åŠ é€Ÿæ¯”: {self.stats['min_speedup']:.2f}x")

        # æ€§èƒ½è¯„çº§
        if self.stats["average_speedup"] > 3:
            rating = "ğŸ† ä¼˜ç§€"
        elif self.stats["average_speedup"] > 2:
            rating = "âœ… è‰¯å¥½"
        elif self.stats["average_speedup"] > 1:
            rating = "âš ï¸  ä¸€èˆ¬"
        else:
            rating = "âŒ æœªè¾¾åˆ°é¢„æœŸ"

        print(f"\nç»¼åˆæ€§èƒ½è¯„çº§: {rating}")

        # å»ºè®®
        self._generate_recommendations()

    def _generate_recommendations(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")

        # åŸºäºç»“æœç”Ÿæˆå»ºè®®
        if self.stats["average_speedup"] < 1.5:
            print("âš ï¸  GPUåŠ é€Ÿæ•ˆæœä¸æ˜æ˜¾ï¼Œå»ºè®®æ£€æŸ¥:")
            print("  1. GPUç¡¬ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ")
            print("  2. CUDAç‰ˆæœ¬æ˜¯å¦å…¼å®¹")
            print("  3. æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿå¤§ï¼ˆå»ºè®®>10,000è¡Œï¼‰")
            print("  4. å†…å­˜å¸¦å®½æ˜¯å¦è¶³å¤Ÿ")

        if self.stats["max_speedup"] > 5:
            print("âœ… åœ¨æŸäº›åœºæ™¯ä¸‹GPUè¡¨ç°ä¼˜ç§€ï¼Œå»ºè®®:")
            print("  1. ä¼˜å…ˆåœ¨å¤§å‹æ•°æ®å¤„ç†ä»»åŠ¡ä¸­ä½¿ç”¨GPU")
            print("  2. è€ƒè™‘æ‰¹é‡å¤„ç†ä»¥æé«˜GPUåˆ©ç”¨ç‡")
            print("  3. ä¼˜åŒ–æ•°æ®ä¼ è¾“ä»¥å‡å°‘CPU-GPUé€šä¿¡å¼€é”€")

        if self.stats["successful_gpu_tests"] > self.stats["successful_cpu_tests"]:
            print("ğŸ¯ GPUåŠ é€Ÿæ•ˆæœæ˜¾è‘—ï¼Œå»ºè®®:")
            print("  1. å¯ç”¨GPUè‡ªåŠ¨é€‰æ‹©åŠŸèƒ½")
            print("  2. åœ¨ç­–ç•¥å›æµ‹ä¸­ä½¿ç”¨GPUæ¨¡å¼")
            print("  3. è€ƒè™‘æ‰©å±•åˆ°æ›´å¤šæœºå™¨å­¦ä¹ ä»»åŠ¡")

    def save_benchmark_results(self, filepath: str):
        """ä¿å­˜åŸºå‡†æµ‹è¯•ç»“æœ"""
        results_data = {
            "timestamp": time.time(),
            "config": self.config.__dict__,
            "stats": self.stats,
            "results": [
                {
                    "test_name": r.test_name,
                    "data_size": r.data_size,
                    "gpu_time": r.gpu_time,
                    "cpu_time": r.cpu_time,
                    "speedup_factor": r.speedup_factor,
                    "memory_usage_mb": r.memory_usage_mb,
                    "gpu_memory_mb": r.gpu_memory_mb,
                    "cpu_memory_mb": r.cpu_memory_mb,
                    "gpu_accuracy": r.gpu_accuracy,
                    "cpu_accuracy": r.cpu_accuracy,
                    "timestamp": r.timestamp,
                }
                for r in self.results
            ],
        }

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)

        self.logger.info(f"åŸºå‡†æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filepath}")

    def generate_performance_report(self) -> str:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        report = f"""
MyStocks GPUåŠ é€Ÿæ€§èƒ½æŠ¥å‘Š
========================

æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))}

ğŸ“Š æµ‹è¯•ç»Ÿè®¡:
  æ€»æµ‹è¯•é¡¹ç›®: {self.stats['total_tests']}
  GPUèƒœå‡ºé¡¹ç›®: {self.stats['successful_gpu_tests']}
  CPUèƒœå‡ºé¡¹ç›®: {self.stats['successful_cpu_tests']}
  å¹³å‡åŠ é€Ÿæ¯”: {self.stats['average_speedup']:.2f}x
  æœ€å¤§åŠ é€Ÿæ¯”: {self.stats['max_speedup']:.2f}x
  æœ€å°åŠ é€Ÿæ¯”: {self.stats['min_speedup']:.2f}x

ğŸ¯ è¯¦ç»†ç»“æœ:
"""

        for result in self.results:
            report += f"""
  {result.test_name} (æ•°æ®é‡: {result.data_size:,}è¡Œ):
    GPUæ—¶é—´: {result.gpu_time:.4f}s
    CPUæ—¶é—´: {result.cpu_time:.4f}s
    åŠ é€Ÿæ¯”: {result.speedup_factor:.2f}x
    GPUå†…å­˜: {result.gpu_memory_mb:.2f}MB
    CPUå†…å­˜: {result.cpu_memory_mb:.2f}MB"""

        # æ·»åŠ GPUç¯å¢ƒä¿¡æ¯
        gpu_status = (
            "å¯ç”¨" if self.component_selector.check_gpu_availability() else "ä¸å¯ç”¨"
        )
        report += f"""
ğŸ–¥ï¸  GPUç¯å¢ƒçŠ¶æ€: {gpu_status}
"""

        return report


def main():
    """ä¸»å‡½æ•° - åŸºå‡†æµ‹è¯•ç¤ºä¾‹"""
    # åˆ›å»ºåŸºå‡†æµ‹è¯•é…ç½®
    config = BenchmarkConfig(
        test_data_sizes=[1000, 5000, 10000],
        model_types=["ridge", "random_forest"],
        test_iterations=2,
        enable_memory_profiling=True,
    )

    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    benchmark = GPUPerformanceBenchmark(config)
    results = benchmark.run_comprehensive_benchmark()

    # ä¿å­˜ç»“æœ
    benchmark.save_benchmark_results("gpu_performance_benchmark.json")

    # ç”ŸæˆæŠ¥å‘Š
    report = benchmark.generate_performance_report()
    print(report)

    # ä¿å­˜æŠ¥å‘Š
    with open("gpu_performance_report.txt", "w", encoding="utf-8") as f:
        f.write(report)

    return results


if __name__ == "__main__":
    results = main()
