#!/usr/bin/env python3
"""
GPUåŠ é€Ÿé›†æˆæ¥å£
å°†GPUç»„ä»¶é›†æˆåˆ°MyStocksé¡¹ç›®çš„ç»Ÿä¸€ç®¡ç†ç³»ç»Ÿä¸­
æä¾›ä¸ä¼ ç»ŸMyStocksUnifiedManagerçš„æ— ç¼é›†æˆ
"""

import time
import logging
from typing import Dict, Optional, Union, Any
import pandas as pd
from dataclasses import dataclass

# å¯¼å…¥åŸæœ‰çš„ç»Ÿä¸€ç®¡ç†å™¨
from ..unified_manager import MyStocksUnifiedManager
from .gpu_manager import GPUUnifiedManager
from .data_processor_gpu import ProcessingConfig


@dataclass
class GPUIntegrationConfig:
    """GPUé›†æˆé…ç½®"""

    auto_enable_gpu: bool = True
    fallback_to_cpu: bool = True
    performance_threshold: float = 0.1  # 10ç§’å†…å¤„ç†1ä¸‡è¡Œæ•°æ®
    gpu_memory_threshold_mb: float = 8000.0  # 8GBå†…å­˜é™åˆ¶
    enable_benchmarking: bool = True
    benchmark_interval: int = 100  # æ¯100æ¬¡æ“ä½œè¿›è¡Œä¸€æ¬¡åŸºå‡†æµ‹è¯•


class GPUEnhancedUnifiedManager(MyStocksUnifiedManager):
    """GPUå¢å¼ºçš„ç»Ÿä¸€ç®¡ç†å™¨ - ç»§æ‰¿è‡ªåŸæœ‰çš„ç»Ÿä¸€ç®¡ç†å™¨"""

    def __init__(self, config: Optional[GPUIntegrationConfig] = None):
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__()

        self.gpu_config = config or GPUIntegrationConfig()
        self.logger = logging.getLogger(__name__)

        # åˆå§‹åŒ–GPUç®¡ç†å™¨
        self.gpu_manager = GPUUnifiedManager()

        # GPUä½¿ç”¨ç»Ÿè®¡
        self.gpu_usage_stats = {
            "total_operations": 0,
            "gpu_operations": 0,
            "cpu_fallback_operations": 0,
            "last_benchmark": None,
            "performance_history": [],
        }

        self.logger.info("GPUå¢å¼ºç»Ÿä¸€ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def save_data_by_classification_with_gpu(
        self,
        data: pd.DataFrame,
        data_classification: Any,
        use_gpu: Optional[bool] = None,
    ) -> Dict[str, Any]:
        """ä½¿ç”¨GPUä¿å­˜åˆ†ç±»æ•°æ® - è¦†ç›–åŸæ–¹æ³•"""

        # å†³ç­–æ˜¯å¦ä½¿ç”¨GPU
        should_use_gpu = self._should_use_gpu(data, use_gpu)

        start_time = time.time()

        try:
            if should_use_gpu:
                # ä½¿ç”¨GPUè¿›è¡Œæ•°æ®å¤„ç†
                self.logger.info("ä½¿ç”¨GPUå¤„ç†åˆ†ç±»æ•°æ®: %s", data_classification)

                # æ•°æ®é¢„å¤„ç†
                processed_result = self.gpu_manager.process_data_with_gpu(
                    data=data, processing_config=ProcessingConfig()
                )

                # å°†GPUå¤„ç†åçš„æ•°æ®ä¿å­˜åˆ°ä¼ ç»Ÿæ•°æ®åº“
                result = super().save_data_by_classification(processed_result.results, data_classification)

                # æ›´æ–°GPUç»Ÿè®¡
                self.gpu_usage_stats["gpu_operations"] += 1
                result["gpu_enabled"] = True
                result["processing_time"] = processed_result.processing_time
                result["speedup_factor"] = processed_result.speedup_factor

                self.logger.info("GPUæ•°æ®å¤„ç†å®Œæˆ - è€—æ—¶: %sç§’", processed_result.processing_time)

            else:
                # ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
                self.logger.info("ä½¿ç”¨CPUå¤„ç†åˆ†ç±»æ•°æ®: %s", data_classification)
                result = super().save_data_by_classification(data, data_classification)

                # æ›´æ–°CPUç»Ÿè®¡
                self.gpu_usage_stats["cpu_fallback_operations"] += 1
                result["gpu_enabled"] = False
                result["processing_time"] = time.time() - start_time

                self.logger.info("CPUæ•°æ®å¤„ç†å®Œæˆ - è€—æ—¶: %sç§’", result["processing_time"])

            # æ›´æ–°æ€»æ“ä½œæ•°
            self.gpu_usage_stats["total_operations"] += 1

            # è®°å½•æ€§èƒ½æ•°æ®
            performance_data = {
                "timestamp": time.time(),
                "operation": "save",
                "gpu_enabled": should_use_gpu,
                "processing_time": result.get("processing_time", 0),
                "data_size": len(data),
            }
            self.gpu_usage_stats["performance_history"].append(performance_data)

            return result

        except Exception as e:
            self.logger.error("æ•°æ®ä¿å­˜å¤±è´¥: %s", e)

            # å¦‚æœGPUå¤±è´¥ä¸”æœ‰CPUå›é€€é…ç½®ï¼Œåˆ™å›é€€åˆ°CPU
            if should_use_gpu and self.gpu_config.fallback_to_cpu:
                self.logger.warning("GPUå¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°CPUæ¨¡å¼")
                result = super().save_data_by_classification(data, data_classification)
                self.gpu_usage_stats["cpu_fallback_operations"] += 1
                result["gpu_enabled"] = False
                result["error"] = str(e)
                return result

            raise e

    def load_data_by_classification_with_gpu(
        self, data_classification: Any, use_gpu: Optional[bool] = None
    ) -> pd.DataFrame:
        """ä½¿ç”¨GPUåŠ è½½åˆ†ç±»æ•°æ® - è¦†ç›–åŸæ–¹æ³•"""

        # å†³ç­–æ˜¯å¦ä½¿ç”¨GPU
        should_use_gpu = self._should_use_gpu(None, use_gpu)

        start_time = time.time()

        try:
            # å…ˆä»æ•°æ®åº“åŠ è½½æ•°æ®
            data = super().load_data_by_classification(data_classification)

            if should_use_gpu:
                # ä½¿ç”¨GPUè¿›è¡Œæ•°æ®å¤„ç†
                self.logger.info("ä½¿ç”¨GPUå¤„ç†åŠ è½½çš„æ•°æ®: %s", data_classification)

                processed_result = self.gpu_manager.process_data_with_gpu(
                    data=data, processing_config=ProcessingConfig()
                )

                # æ›´æ–°GPUç»Ÿè®¡
                self.gpu_usage_stats["gpu_operations"] += 1
                processed_data = processed_result.results
                processed_data.gpu_processing_info = {
                    "processing_time": processed_result.processing_time,
                    "gpu_enabled": True,
                    "speedup_factor": processed_result.speedup_factor,
                }

                self.logger.info("GPUæ•°æ®åŠ è½½å®Œæˆ - è€—æ—¶: %sç§’", processed_result.processing_time)

            else:
                # ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
                processed_data = data
                self.gpu_usage_stats["cpu_fallback_operations"] += 1
                processed_data.gpu_processing_info = {
                    "processing_time": time.time() - start_time,
                    "gpu_enabled": False,
                    "speedup_factor": 1.0,
                }

                self.logger.info("CPUæ•°æ®åŠ è½½å®Œæˆ - è€—æ—¶: %sç§’", time.time() - start_time)

            # æ›´æ–°æ€»æ“ä½œæ•°
            self.gpu_usage_stats["total_operations"] += 1

            return processed_data

        except Exception as e:
            self.logger.error("æ•°æ®åŠ è½½å¤±è´¥: %s", e)

            # GPUå¤±è´¥å›é€€
            if should_use_gpu and self.gpu_config.fallback_to_cpu:
                self.logger.warning("GPUåŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°CPUæ¨¡å¼")
                data = super().load_data_by_classification(data_classification)
                data.gpu_processing_info = {
                    "processing_time": time.time() - start_time,
                    "gpu_enabled": False,
                    "error": str(e),
                }
                return data

            raise e

    def generate_price_predictions_with_gpu(
        self,
        stock_data: Union[pd.DataFrame, str],
        prediction_horizon: int = 1,
        model_type: str = "ridge",
        use_gpu: Optional[bool] = None,
    ) -> Dict[str, Any]:
        """ä½¿ç”¨GPUç”Ÿæˆä»·æ ¼é¢„æµ‹ - æ–°å¢æ–¹æ³•"""

        # å†³ç­–æ˜¯å¦ä½¿ç”¨GPU
        should_use_gpu = self._should_use_gpu(stock_data if isinstance(stock_data, pd.DataFrame) else None, use_gpu)

        start_time = time.time()

        try:
            if isinstance(stock_data, str):
                # å¦‚æœæ˜¯è‚¡ç¥¨ä»£ç ï¼Œå…ˆè·å–æ•°æ®
                from ..data_adapters.financial_adapter import FinancialDataSource

                data_source = FinancialDataSource()
                stock_data = data_source.fetch_stock_data(stock_data)

            if should_use_gpu:
                # ä½¿ç”¨GPUè¿›è¡Œé¢„æµ‹
                self.logger.info("ä½¿ç”¨GPUç”Ÿæˆä»·æ ¼é¢„æµ‹: %s, é¢„æµ‹å‘¨æœŸ: %s", model_type, prediction_horizon)

                prediction_result = self.gpu_manager.generate_predictions_with_gpu(
                    data=stock_data,
                    model_type=model_type,
                    prediction_horizon=prediction_horizon,
                )

                # æ›´æ–°GPUç»Ÿè®¡
                self.gpu_usage_stats["gpu_operations"] += 1

                result = {
                    "gpu_enabled": True,
                    "processing_time": prediction_result.processing_time,
                    "speedup_factor": prediction_result.speedup_factor,
                    "prediction": prediction_result.results,
                    "performance_metrics": prediction_result.performance_metrics,
                    "errors": prediction_result.errors,
                }

                if not prediction_result.errors:
                    prediction = prediction_result.results
                    result.update(
                        {
                            "predicted_price": prediction.predicted_price,
                            "confidence_score": prediction.confidence_score,
                            "model_used": prediction.model_used,
                            "prediction_date": prediction.prediction_date,
                        }
                    )

                self.logger.info("GPUé¢„æµ‹å®Œæˆ - ä»·æ ¼: %s", result.get("predicted_price", "N/A"))

            else:
                # ä½¿ç”¨CPUé¢„æµ‹
                self.logger.info("ä½¿ç”¨CPUç”Ÿæˆä»·æ ¼é¢„æµ‹: %s", model_type)

                # ä½¿ç”¨ä¼ ç»Ÿä»·æ ¼é¢„æµ‹å™¨
                from ..gpu_accelerated.price_predictor_gpu import PricePredictorCPU

                cpu_predictor = PricePredictorCPU(gpu_enabled=False)

                # è®­ç»ƒæ¨¡å‹
                cpu_predictor.train_models(stock_data)

                # è¿›è¡Œé¢„æµ‹
                prediction_result = cpu_predictor.predict_price(stock_data, model_type, prediction_horizon)

                # æ›´æ–°CPUç»Ÿè®¡
                self.gpu_usage_stats["cpu_fallback_operations"] += 1

                result = {
                    "gpu_enabled": False,
                    "processing_time": time.time() - start_time,
                    "speedup_factor": 1.0,
                    "predicted_price": prediction_result.predicted_price,
                    "confidence_score": prediction_result.confidence_score,
                    "model_used": prediction_result.model_used,
                    "prediction_date": prediction_result.prediction_date,
                    "performance_metrics": prediction_result.error_metrics,
                    "errors": [],
                }

                self.logger.info("CPUé¢„æµ‹å®Œæˆ - ä»·æ ¼: %s", prediction_result.predicted_price)

            # æ›´æ–°æ€»æ“ä½œæ•°
            self.gpu_usage_stats["total_operations"] += 1

            # å¦‚æœå¯ç”¨äº†åŸºå‡†æµ‹è¯•ï¼Œå®šæœŸè¿›è¡Œæ€§èƒ½è¯„ä¼°
            if (
                self.gpu_config.enable_benchmarking
                and self.gpu_usage_stats["total_operations"] % self.gpu_config.benchmark_interval == 0
            ):
                self._run_performance_benchmark()

            return result

        except Exception as e:
            self.logger.error("ä»·æ ¼é¢„æµ‹å¤±è´¥: %s", e)

            # GPUå¤±è´¥å›é€€
            if should_use_gpu and self.gpu_config.fallback_to_cpu:
                self.logger.warning("GPUé¢„æµ‹å¤±è´¥ï¼Œå›é€€åˆ°CPUæ¨¡å¼")
                return self.generate_price_predictions_with_gpu(stock_data, prediction_horizon, model_type, False)

            return {
                "gpu_enabled": should_use_gpu,
                "error": str(e),
                "processing_time": time.time() - start_time,
                "errors": [str(e)],
            }

    def _should_use_gpu(self, data: Optional[pd.DataFrame], use_gpu: Optional[bool]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨GPU"""

        # å¦‚æœç”¨æˆ·æ˜ç¡®æŒ‡å®šï¼Œåˆ™ç›´æ¥ä½¿ç”¨
        if use_gpu is not None:
            return use_gpu

        # å¦‚æœGPUè‡ªåŠ¨å¯ç”¨è¢«ç¦ç”¨ï¼Œåˆ™ä¸ä½¿ç”¨
        if not self.gpu_config.auto_enable_gpu:
            return False

        # æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨
        if not self.gpu_manager.gpu_enabled:
            self.logger.warning("GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
            return False

        # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œæ— æ³•åˆ¤æ–­æ•°æ®å¤§å°ï¼Œä½¿ç”¨CPU
        if data is None or len(data) == 0:
            return False

        # åŸºäºæ•°æ®å¤§å°å†³å®šæ˜¯å¦ä½¿ç”¨GPU
        data_size = len(data)
        if data_size < 1000:  # å°æ•°æ®é›†ä½¿ç”¨CPU
            return False

        # æ£€æŸ¥æ€§èƒ½é˜ˆå€¼
        expected_time = data_size * self.gpu_config.performance_threshold
        if expected_time > 60:  # é¢„æœŸå¤„ç†æ—¶é—´è¶…è¿‡60ç§’ï¼Œä¸ä½¿ç”¨GPU
            self.logger.warning("æ•°æ®é‡è¿‡å¤§(%sè¡Œ)ï¼Œé¢„æœŸå¤„ç†æ—¶é—´è¿‡é•¿ï¼Œä½¿ç”¨CPU", data_size)
            return False

        # æ£€æŸ¥GPUå†…å­˜é™åˆ¶
        gpu_memory_usage = self.gpu_manager._get_gpu_memory_usage()
        if gpu_memory_usage > self.gpu_config.gpu_memory_threshold_mb:
            self.logger.warning("GPUå†…å­˜ä½¿ç”¨è¿‡é«˜(%sMB)ï¼Œä½¿ç”¨CPU", gpu_memory_usage)
            return False

        # å…¶ä»–GPUèµ„æºæ£€æŸ¥å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
        return True

    def _run_performance_benchmark(self):
        """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        try:
            self.logger.info("å¼€å§‹GPUæ€§èƒ½åŸºå‡†æµ‹è¯•...")

            # è·å–ä¸€äº›ç¤ºä¾‹æ•°æ®è¿›è¡Œæµ‹è¯•
            from ..data_adapters.financial_adapter import FinancialDataSource

            data_source = FinancialDataSource()
            sample_data = data_source.fetch_stock_data("AAPL")

            # è¿›è¡Œå°è§„æ¨¡åŸºå‡†æµ‹è¯•
            benchmark_result = self.gpu_manager.benchmark_gpu_vs_cpu(
                sample_data[:1000],
                operation="process",  # ä½¿ç”¨å°æ ·æœ¬
            )

            # è®°å½•åŸºå‡†æµ‹è¯•ç»“æœ
            self.gpu_usage_stats["last_benchmark"] = {
                "timestamp": time.time(),
                "gpu_time": benchmark_result["gpu_time"],
                "cpu_time": benchmark_result["cpu_time"],
                "speedup": benchmark_result["speedup"],
                "efficiency_metrics": benchmark_result["efficiency_metrics"],
            }

            self.logger.info(
                "åŸºå‡†æµ‹è¯•å®Œæˆ - GPU: {benchmark_result['gpu_time']:.4f}s, "
                f"CPU: {benchmark_result['cpu_time']:.4f}s, "
                f"åŠ é€Ÿæ¯”: {benchmark_result['speedup']:.2f}x"
            )

        except Exception as e:
            self.logger.error("åŸºå‡†æµ‹è¯•å¤±è´¥: %s", e)

    def get_gpu_integration_status(self) -> Dict[str, Any]:
        """è·å–GPUé›†æˆçŠ¶æ€"""
        return {
            "gpu_available": self.gpu_manager.gpu_enabled,
            "auto_enable_gpu": self.gpu_config.auto_enable_gpu,
            "fallback_to_cpu": self.gpu_config.fallback_to_cpu,
            "gpu_usage_stats": self.gpu_usage_stats,
            "gpu_performance_summary": self.gpu_manager.get_performance_summary(),
            "last_benchmark": self.gpu_usage_stats["last_benchmark"],
            "gpu_config": {
                "performance_threshold": self.gpu_config.performance_threshold,
                "gpu_memory_threshold_mb": self.gpu_config.gpu_memory_threshold_mb,
                "enable_benchmarking": self.gpu_config.enable_benchmarking,
                "benchmark_interval": self.gpu_config.benchmark_interval,
            },
        }

    def save_gpu_models(self, filepath: str):
        """ä¿å­˜GPUæ¨¡å‹"""
        self.gpu_manager.save_gpu_models(filepath)

    def load_gpu_models(self, filepath: str):
        """åŠ è½½GPUæ¨¡å‹"""
        self.gpu_manager.load_gpu_models(filepath)

    def generate_gpu_integration_report(self) -> str:
        """ç”ŸæˆGPUé›†æˆæŠ¥å‘Š"""
        status = self.get_gpu_integration_status()
        gpu_performance = self.gpu_manager.generate_gpu_report()

        report = f"""
MyStocks GPUé›†æˆçŠ¶æ€æŠ¥å‘Š
==========================

ğŸ”— é›†æˆé…ç½®:
  â€¢ è‡ªåŠ¨å¯ç”¨GPU: {"âœ… æ˜¯" if status["auto_enable_gpu"] else "âŒ å¦"}
  â€¢ CPUå›é€€åŠŸèƒ½: {"âœ… æ˜¯" if status["fallback_to_cpu"] else "âŒ å¦"}
  â€¢ æ€§èƒ½é˜ˆå€¼: {status["gpu_config"]["performance_threshold"]}ç§’/ä¸‡è¡Œ
  â€¢ GPUå†…å­˜é™åˆ¶: {status["gpu_config"]["gpu_memory_threshold_mb"]}MB
  â€¢ å¯ç”¨åŸºå‡†æµ‹è¯•: {"âœ… æ˜¯" if status["gpu_config"]["enable_benchmarking"] else "âŒ å¦"}

ğŸ“Š GPUä½¿ç”¨ç»Ÿè®¡:
  â€¢ æ€»æ“ä½œæ¬¡æ•°: {status["gpu_usage_stats"]["total_operations"]}
  â€¢ GPUæ“ä½œæ¬¡æ•°: {status["gpu_usage_stats"]["gpu_operations"]}
  â€¢ CPUå›é€€æ¬¡æ•°: {status["gpu_usage_stats"]["cpu_fallback_operations"]}
  â€¢ GPUä½¿ç”¨ç‡: {
    (status["gpu_usage_stats"]["gpu_operations"] /
     max(1, status["gpu_usage_stats"]["total_operations"]) * 100):.1f
}%

âš¡ GPUç»„ä»¶çŠ¶æ€:
  â€¢ GPUç¯å¢ƒ: {"âœ… å¯ç”¨" if status["gpu_available"] else "âŒ ä¸å¯ç”¨"}
  â€¢ æ•°æ®å¤„ç†å™¨: {"âœ… å·²å¯ç”¨" if status["gpu_performance_summary"][
      "gpu_components_status"]["data_processor"]["enabled"] else "âŒ å·²ç¦ç”¨"}
  â€¢ ç‰¹å¾ç”Ÿæˆå™¨: {"âœ… å·²å¯ç”¨" if status["gpu_performance_summary"][
      "gpu_components_status"]["feature_generator"]["enabled"] else "âŒ å·²ç¦ç”¨"}
  â€¢ ä»·æ ¼é¢„æµ‹å™¨: {"âœ… å·²å¯ç”¨" if status["gpu_performance_summary"][
      "gpu_components_status"]["price_predictor"]["enabled"] else "âŒ å·²ç¦ç”¨"}

ğŸ† æ€§èƒ½åŸºå‡†æµ‹è¯•:
"""

        if status["last_benchmark"]:
            benchmark = status["last_benchmark"]
            report += f"""
  â€¢ æœ€åæµ‹è¯•æ—¶é—´: {time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(benchmark["timestamp"]))}
  â€¢ GPUå¤„ç†æ—¶é—´: {benchmark["gpu_time"]:.4f}ç§’
  â€¢ CPUå¤„ç†æ—¶é—´: {benchmark["cpu_time"]:.4f}ç§’
  â€¢ åŠ é€Ÿæ¯”: {benchmark["speedup"]:.2f}x
"""
        else:
            report += """
  â€¢ æš‚æ— åŸºå‡†æµ‹è¯•æ•°æ®
"""

        report += """
ğŸ’¡ é›†æˆå»ºè®®:
  â€¢ å¤§æ•°æ®é›†(>1000è¡Œ)ä¼˜å…ˆä½¿ç”¨GPUåŠ é€Ÿ
  â€¢ å°æ•°æ®é›†è‡ªåŠ¨ä½¿ç”¨CPUæ¨¡å¼ä»¥å‡å°‘GPUå†…å­˜å¼€é”€
  â€¢ å®šæœŸè¿è¡ŒåŸºå‡†æµ‹è¯•ä»¥ç›‘æ§GPUæ€§èƒ½
  â€¢ å¦‚æœGPUæ“ä½œé¢‘ç¹å¤±è´¥ï¼Œæ£€æŸ¥GPUå†…å­˜ä½¿ç”¨æƒ…å†µ

"""

        return report + gpu_performance


def create_gpu_enhanced_manager(
    config: Optional[GPUIntegrationConfig] = None,
) -> GPUEnhancedUnifiedManager:
    """åˆ›å»ºGPUå¢å¼ºç»Ÿä¸€ç®¡ç†å™¨çš„å·¥å‚å‡½æ•°"""
    return GPUEnhancedUnifiedManager(config)


# å‘åå…¼å®¹çš„åŒ…è£…å™¨
def get_gpu_enabled_manager() -> GPUEnhancedUnifiedManager:
    """è·å–GPUå¯ç”¨ç‰ˆæœ¬çš„ç»Ÿä¸€ç®¡ç†å™¨"""
    return GPUEnhancedUnifiedManager()


def main():
    """ä¸»å‡½æ•° - ç¤ºä¾‹ç”¨æ³•"""
    # åˆ›å»ºGPUå¢å¼ºç®¡ç†å™¨
    gpu_manager = create_gpu_enhanced_manager()

    print("ğŸš€ MyStocks GPUå¢å¼ºç®¡ç†å™¨æ¼”ç¤º")
    print("=" * 50)

    # è·å–ç¤ºä¾‹æ•°æ®
    from ..data_adapters.financial_adapter import FinancialDataSource

    data_source = FinancialDataSource()
    sample_data = data_source.fetch_stock_data("AAPL")

    # æ•°æ®ä¿å­˜æµ‹è¯•
    print("\n1. æ•°æ®ä¿å­˜æµ‹è¯•:")
    save_result = gpu_manager.save_data_by_classification_with_gpu(
        sample_data[:100],
        data_classification="market_data",  # ä½¿ç”¨å°æ ·æœ¬
    )
    print(
        f"ä¿å­˜ç»“æœ - GPU: {save_result.get('gpu_enabled', False)}, "
        f"æ—¶é—´: {save_result.get('processing_time', 0):.4f}ç§’"
    )

    # æ•°æ®åŠ è½½æµ‹è¯•
    print("\n2. æ•°æ®åŠ è½½æµ‹è¯•:")
    loaded_data = gpu_manager.load_data_by_classification_with_gpu("market_data")
    gpu_enabled = hasattr(loaded_data, "gpu_processing_info") and loaded_data.gpu_processing_info.get(
        "gpu_enabled", False
    )
    print(f"åŠ è½½å®Œæˆ - GPU: {gpu_enabled}")

    # ä»·æ ¼é¢„æµ‹æµ‹è¯•
    print("\n3. ä»·æ ¼é¢„æµ‹æµ‹è¯•:")
    prediction_result = gpu_manager.generate_price_predictions_with_gpu(
        sample_data, prediction_horizon=1, model_type="ridge"
    )
    print(
        f"é¢„æµ‹ç»“æœ - GPU: {prediction_result.get('gpu_enabled', False)}, "
        f"é¢„æµ‹ä»·æ ¼: {prediction_result.get('predicted_price', 'N/A')}"
    )

    # ç”Ÿæˆé›†æˆæŠ¥å‘Š
    print("\n4. GPUé›†æˆæŠ¥å‘Š:")
    print(gpu_manager.generate_gpu_integration_report())


if __name__ == "__main__":
    main()
