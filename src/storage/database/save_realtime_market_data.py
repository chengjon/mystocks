#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ²ªæ·±å¸‚åœºAè‚¡å®æ—¶æ•°æ®ä¿å­˜ç³»ç»Ÿ - efinanceç‰ˆæœ¬
ä¸¥æ ¼æŒ‰ç…§MyStocksç³»ç»Ÿçš„ç»Ÿä¸€æ¥å£è§„èŒƒå’Œæ•°æ®åˆ†ç±»ç­–ç•¥å®ç°

æ ¸å¿ƒè®¾è®¡ç†å¿µï¼š
1. ä½¿ç”¨efinanceçš„ef.stock.get_realtime_quotes()è·å–æ²ªæ·±Aè‚¡å®æ—¶æ•°æ®
2. ä½¿ç”¨ç»Ÿä¸€ç®¡ç†å™¨ (MyStocksUnifiedManager) - éšè—åº•å±‚æ•°æ®åº“å·®å¼‚
3. æ­£ç¡®çš„æ•°æ®åˆ†ç±» - å®æ—¶è¡Œæƒ…æ•°æ®ä¿å­˜ä¸ºREALTIME_POSITIONS (Redis) + DAILY_KLINE (PostgreSQL)
4. è‡ªåŠ¨è·¯ç”±ä¿å­˜ - ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ•°æ®åº“å­˜å‚¨
5. å®Œæ•´ç›‘æ§é›†æˆ - æ‰€æœ‰æ“ä½œè‡ªåŠ¨è®°å½•åˆ°ç›‘æ§æ•°æ®åº“

æ•°æ®åˆ†ç±»ç­–ç•¥ï¼š
- ef.stock.get_realtime_quotes() è·å–çš„å®æ—¶è¡Œæƒ…å¿«ç…§ï¼š
  * REALTIME_POSITIONS â†’ Redis (çƒ­æ•°æ®ï¼Œå¿«é€Ÿè®¿é—®)
  * DAILY_KLINE â†’ PostgreSQL+TimescaleDB (æŒä¹…åŒ–å­˜å‚¨ï¼Œåˆ†ææŸ¥è¯¢)
- åŒé‡ä¿å­˜ç¡®ä¿æ•°æ®çš„å®æ—¶æ€§å’ŒæŒä¹…æ€§

ä½œè€…: MyStocksé¡¹ç›®ç»„
æ—¥æœŸ: 2025-09-23
ä¿®æ­£: ä½¿ç”¨efinanceæ¥å£å¹¶ä¿å­˜åˆ°PostgreSQL
"""

import os
import sys
import logging
import argparse
import pandas as pd
from datetime import datetime
from typing import Optional, Dict
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥MyStocksç»Ÿä¸€æ¥å£
from unified_manager import MyStocksUnifiedManager
from src.core import DataClassification
from src.adapters.customer_adapter import CustomerDataSource


class RealtimeMarketDataSaver:
    """æ²ªæ·±å¸‚åœºAè‚¡å®æ—¶æ•°æ®ä¿å­˜å™¨ - æŒ‰ç…§MyStocksç»Ÿä¸€æ¥å£è§„èŒƒå®ç°"""

    def __init__(self, config_file: str = "realtime_market_config.env"):
        """åˆå§‹åŒ–æ•°æ®ä¿å­˜å™¨"""
        self.config_file = config_file
        self.logger = None
        self.unified_manager = None
        self.customer_ds = None
        self.config = {}

        # åˆå§‹åŒ–
        self._setup_logging()
        self._load_config()

    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

        logging.basicConfig(
            level=logging.INFO,
            format=log_format,
            handlers=[
                logging.FileHandler("realtime_market_saver.log", encoding="utf-8"),
                logging.StreamHandler(sys.stdout),
            ],
        )

        self.logger = logging.getLogger("RealtimeMarketSaver")
        self.logger.info("æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def _load_config(self):
        """åŠ è½½é…ç½®å‚æ•°"""
        self.logger.info(f"åŠ è½½é…ç½®æ–‡ä»¶: {self.config_file}")

        # é¦–å…ˆåŠ è½½é»˜è®¤çš„.envæ–‡ä»¶
        load_dotenv()

        # ç„¶ååŠ è½½ä¸“ç”¨é…ç½®æ–‡ä»¶
        if os.path.exists(self.config_file):
            load_dotenv(self.config_file, override=True)
            self.logger.info(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {self.config_file}")
        else:
            self.logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_file}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

        # è¯»å–é…ç½®å‚æ•°
        self.config = {
            # æ•°æ®æºé…ç½®
            "market_symbol": os.getenv("MARKET_SYMBOL", "hs"),  # 'hs'=æ²ªæ·±, 'sh'=ä¸Šæµ·, 'sz'=æ·±åœ³
            "data_source_timeout": int(os.getenv("DATA_SOURCE_TIMEOUT", "30")),
            # æ•°æ®åˆ†ç±»é…ç½® - åŒé‡ä¿å­˜ç­–ç•¥
            "save_as_realtime": os.getenv("SAVE_AS_REALTIME", "true").lower() == "true",  # Redisçƒ­æ•°æ®
            "save_as_daily": os.getenv("SAVE_AS_DAILY", "true").lower() == "true",  # PostgreSQLæŒä¹…åŒ–
            "save_as_tick": os.getenv("SAVE_AS_TICK", "false").lower() == "true",  # TDengineæ—¶åº(å¯é€‰)
            "cache_expire_seconds": int(os.getenv("CACHE_EXPIRE_SECONDS", "300")),  # Redisç¼“å­˜è¿‡æœŸæ—¶é—´
            # æ•°æ®å¤„ç†é…ç½®
            "add_timestamp_column": os.getenv("ADD_TIMESTAMP_COLUMN", "true").lower() == "true",
            "enable_data_validation": os.getenv("ENABLE_DATA_VALIDATION", "true").lower() == "true",
            "max_retry_attempts": int(os.getenv("MAX_RETRY_ATTEMPTS", "3")),
            # æ—¥å¿—é…ç½®
            "log_level": os.getenv("LOG_LEVEL", "INFO"),
            "log_file": os.getenv("LOG_FILE", "realtime_market_saver.log"),
        }

        # æ›´æ–°æ—¥å¿—çº§åˆ«
        log_level = getattr(logging, self.config["log_level"].upper())
        self.logger.setLevel(log_level)

        self.logger.info("âœ… é…ç½®å‚æ•°åŠ è½½å®Œæˆ")
        self.logger.info(f"ğŸ“Š å¸‚åœºä»£ç : {self.config['market_symbol']}")
        self.logger.info(f"ğŸ”¥ ä¿å­˜ä¸ºå®æ—¶æ•°æ®(Redis): {self.config['save_as_realtime']}")
        self.logger.info(f"ğŸ’¾ ä¿å­˜ä¸ºæ—¥çº¿æ•°æ®(PostgreSQL): {self.config['save_as_daily']}")
        self.logger.info(f"â±ï¸ ä¿å­˜ä¸ºTickæ•°æ®(TDengine): {self.config['save_as_tick']}")

    def initialize_unified_manager(self) -> bool:
        """åˆå§‹åŒ–MyStocksç»Ÿä¸€ç®¡ç†å™¨"""
        self.logger.info("åˆå§‹åŒ–MyStocksç»Ÿä¸€ç®¡ç†å™¨...")

        try:
            # åˆ›å»ºç»Ÿä¸€ç®¡ç†å™¨
            self.unified_manager = MyStocksUnifiedManager()

            # åˆå§‹åŒ–ç³»ç»Ÿ
            init_result = self.unified_manager.initialize_system()

            if init_result["config_loaded"]:
                self.logger.info("âœ… MyStocksç»Ÿä¸€ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")

                # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
                status = self.unified_manager.get_system_status()
                monitoring = status.get("monitoring", {})
                op_stats = monitoring.get("operation_statistics", {})

                self.logger.info(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€ - æ€»æ“ä½œæ•°: {op_stats.get('total_operations', 0)}")
                self.logger.info(f"ğŸ—„ï¸ ç›‘æ§ç³»ç»Ÿ: {'æ­£å¸¸' if monitoring else 'æœªåˆå§‹åŒ–'}")

                return True
            else:
                self.logger.error("âŒ MyStocksç»Ÿä¸€ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥")
                self.logger.error(f"é”™è¯¯ä¿¡æ¯: {init_result.get('errors', [])}")
                return False

        except Exception as e:
            self.logger.error(f"âŒ ç»Ÿä¸€ç®¡ç†å™¨åˆå§‹åŒ–å¼‚å¸¸: {e}")
            return False

    def initialize_data_source(self) -> bool:
        """åˆå§‹åŒ–æ•°æ®æºé€‚é…å™¨"""
        self.logger.info("åˆå§‹åŒ–Customeræ•°æ®æºé€‚é…å™¨...")

        try:
            self.customer_ds = CustomerDataSource()

            if not self.customer_ds.efinance_available:
                self.logger.error("âŒ efinanceåº“ä¸å¯ç”¨ï¼Œæ— æ³•è·å–å®æ—¶æ•°æ®")
                return False

            self.logger.info("âœ… Customeræ•°æ®æºé€‚é…å™¨åˆå§‹åŒ–æˆåŠŸ")
            return True

        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®æºé€‚é…å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def get_realtime_market_data(self) -> Optional[pd.DataFrame]:
        """ä½¿ç”¨efinanceè·å–æ²ªæ·±å¸‚åœºAè‚¡å®æ—¶æ•°æ®"""
        self.logger.info(f"ä½¿ç”¨efinanceè·å–{self.config['market_symbol']}å¸‚åœºå®æ—¶æ•°æ®...")

        try:
            if not self.customer_ds.efinance_available:
                self.logger.error("âŒ efinanceåº“ä¸å¯ç”¨ï¼Œæ— æ³•è·å–å®æ—¶æ•°æ®")
                return None

            # ç›´æ¥ä½¿ç”¨efinanceè·å–æ²ªæ·±å¸‚åœºAè‚¡æœ€æ–°çŠ¶å†µ
            self.logger.info("ğŸ“¡ æ­£åœ¨è°ƒç”¨ ef.stock.get_realtime_quotes() è·å–æ²ªæ·±Aè‚¡å®æ—¶è¡Œæƒ…...")
            data = self.customer_ds.ef.stock.get_realtime_quotes()

            if isinstance(data, pd.DataFrame) and not data.empty:
                self.logger.info(f"âœ… æˆåŠŸè·å–å®æ—¶æ•°æ®ï¼Œå…± {len(data)} æ¡è®°å½•")
                self.logger.info(f"ğŸ“Š æ•°æ®åˆ—: {list(data.columns)}")

                # æ•°æ®éªŒè¯
                if self.config["enable_data_validation"]:
                    if self._validate_market_data(data):
                        self.logger.info("âœ… æ•°æ®éªŒè¯é€šè¿‡")
                    else:
                        self.logger.warning("âš ï¸ æ•°æ®éªŒè¯å­˜åœ¨é—®é¢˜ï¼Œä½†ç»§ç»­å¤„ç†")

                # æ·»åŠ æ•°æ®è·å–æ—¶é—´æˆ³
                if self.config["add_timestamp_column"]:
                    data["data_update_time"] = datetime.now()
                    data["trade_date"] = datetime.now().date()  # æ·»åŠ äº¤æ˜“æ—¥æœŸç”¨äºPostgreSQLå­˜å‚¨
                    self.logger.info("âœ… å·²æ·»åŠ æ•°æ®æ›´æ–°æ—¶é—´æˆ³å’Œäº¤æ˜“æ—¥æœŸåˆ—")

                return data
            else:
                self.logger.error("âŒ efinanceæœªè¿”å›æœ‰æ•ˆçš„å®æ—¶å¸‚åœºæ•°æ®")
                return None

        except Exception as e:
            self.logger.error(f"âŒ ä½¿ç”¨efinanceè·å–å®æ—¶å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            import traceback

            self.logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return None

    def _validate_market_data(self, data: pd.DataFrame) -> bool:
        """éªŒè¯å¸‚åœºæ•°æ®çš„åŸºæœ¬ç»“æ„"""
        try:
            # æ£€æŸ¥æ•°æ®åŸºæœ¬è¦æ±‚
            if data.empty:
                self.logger.warning("âš ï¸ æ•°æ®ä¸ºç©º")
                return False

            # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®åˆ—ï¼ˆè¿™äº›åˆ—åå¯èƒ½å› æ•°æ®æºè€Œå¼‚ï¼‰
            expected_columns = ["è‚¡ç¥¨ä»£ç ", "code", "symbol", "ts_code"]
            has_symbol_column = any(col in data.columns for col in expected_columns)

            if not has_symbol_column:
                self.logger.warning(f"âš ï¸ æ•°æ®ç¼ºå°‘è‚¡ç¥¨ä»£ç åˆ—ï¼Œå¯ç”¨åˆ—: {list(data.columns)}")
                # ä¸ç®—éªŒè¯å¤±è´¥ï¼Œå¯èƒ½åˆ—åä¸åŒ

            # æ£€æŸ¥æ•°æ®ç±»å‹åˆç†æ€§
            null_counts = data.isnull().sum()
            if null_counts.any():
                self.logger.info(f"ğŸ“Š æ•°æ®åŒ…å«ç©ºå€¼: {null_counts[null_counts > 0].head().to_dict()}")

            return True

        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
            return False

    def save_data_using_unified_interface(self, data: pd.DataFrame) -> Dict[str, bool]:
        """ä½¿ç”¨MyStocksç»Ÿä¸€æ¥å£ä¿å­˜æ•°æ®"""
        self.logger.info("ä½¿ç”¨MyStocksç»Ÿä¸€æ¥å£ä¿å­˜æ•°æ®...")

        save_results = {}

        try:
            # æ–¹æ¡ˆ1: ä¿å­˜ä¸ºå®æ—¶æ•°æ®ï¼ˆRedisçƒ­æ•°æ®ï¼‰
            if self.config["save_as_realtime"]:
                self.logger.info("ğŸ“Š ä¿å­˜ä¸ºå®æ—¶è¡Œæƒ…æ•°æ® â†’ Redis")

                try:
                    # ä½¿ç”¨ç»Ÿä¸€ç®¡ç†å™¨çš„è‡ªåŠ¨è·¯ç”±ä¿å­˜
                    success = self.unified_manager.save_data_by_classification(
                        data, DataClassification.REALTIME_POSITIONS
                    )

                    if success:
                        self.logger.info("âœ… å®æ—¶æ•°æ®ä¿å­˜æˆåŠŸ â†’ Redis (çƒ­æ•°æ®)")
                    else:
                        self.logger.error("âŒ å®æ—¶æ•°æ®ä¿å­˜å¤±è´¥")

                    save_results["realtime"] = success

                except Exception as e:
                    self.logger.error(f"âŒ å®æ—¶æ•°æ®ä¿å­˜å¼‚å¸¸: {e}")
                    save_results["realtime"] = False

            # æ–¹æ¡ˆ2: ä¿å­˜ä¸ºæ—¥çº¿æ•°æ®ï¼ˆPostgreSQLæŒä¹…åŒ–å­˜å‚¨ï¼‰
            if self.config["save_as_daily"]:
                self.logger.info("ğŸ’¾ ä¿å­˜ä¸ºæ—¥çº¿æ•°æ® â†’ PostgreSQL+TimescaleDB")

                try:
                    # å‡†å¤‡æ—¥çº¿æ•°æ®æ ¼å¼ï¼ˆç”¨äºPostgreSQLå­˜å‚¨ï¼‰
                    daily_data = self._prepare_daily_data(data)

                    if daily_data is not None and not daily_data.empty:
                        # ä½¿ç”¨ç»Ÿä¸€ç®¡ç†å™¨çš„è‡ªåŠ¨è·¯ç”±ä¿å­˜åˆ°PostgreSQL
                        success = self.unified_manager.save_data_by_classification(
                            daily_data, DataClassification.DAILY_KLINE
                        )

                        if success:
                            self.logger.info("âœ… æ—¥çº¿æ•°æ®ä¿å­˜æˆåŠŸ â†’ PostgreSQL+TimescaleDB (æŒä¹…åŒ–å­˜å‚¨)")
                        else:
                            self.logger.error("âŒ æ—¥çº¿æ•°æ®ä¿å­˜å¤±è´¥")

                        save_results["daily"] = success
                    else:
                        self.logger.warning("âš ï¸ æ—¥çº¿æ•°æ®æ ¼å¼åŒ–å¤±è´¥ï¼Œè·³è¿‡ä¿å­˜")
                        save_results["daily"] = False

                except Exception as e:
                    self.logger.error(f"âŒ æ—¥çº¿æ•°æ®ä¿å­˜å¼‚å¸¸: {e}")
                    save_results["daily"] = False

            # æ–¹æ¡ˆ3: ä¿å­˜ä¸ºTickæ•°æ®ï¼ˆTDengineæ—¶åºå­˜å‚¨ï¼Œå¯é€‰ï¼‰
            if self.config["save_as_tick"]:
                self.logger.info("â±ï¸ ä¿å­˜ä¸ºTickæ•°æ® â†’ TDengine")

                try:
                    # å‡†å¤‡Tickæ•°æ®æ ¼å¼
                    tick_data = self._prepare_tick_data(data)

                    if tick_data is not None and not tick_data.empty:
                        # ä½¿ç”¨ç»Ÿä¸€ç®¡ç†å™¨çš„è‡ªåŠ¨è·¯ç”±ä¿å­˜
                        success = self.unified_manager.save_data_by_classification(
                            tick_data, DataClassification.TICK_DATA
                        )

                        if success:
                            self.logger.info("âœ… Tickæ•°æ®ä¿å­˜æˆåŠŸ â†’ TDengine (æ—¶åºå­˜å‚¨)")
                        else:
                            self.logger.error("âŒ Tickæ•°æ®ä¿å­˜å¤±è´¥")

                        save_results["tick"] = success
                    else:
                        self.logger.warning("âš ï¸ Tickæ•°æ®æ ¼å¼åŒ–å¤±è´¥ï¼Œè·³è¿‡ä¿å­˜")
                        save_results["tick"] = False

                except Exception as e:
                    self.logger.error(f"âŒ Tickæ•°æ®ä¿å­˜å¼‚å¸¸: {e}")
                    save_results["tick"] = False

            return save_results

        except Exception as e:
            self.logger.error(f"âŒ ç»Ÿä¸€æ¥å£ä¿å­˜æ•°æ®å¤±è´¥: {e}")
            return {"error": False}

    def _prepare_daily_data(self, market_data: pd.DataFrame) -> Optional[pd.DataFrame]:
        """å°†å®æ—¶å¸‚åœºæ•°æ®è½¬æ¢ä¸ºæ—¥çº¿æ•°æ®æ ¼å¼ï¼ˆç”¨äºPostgreSQLå­˜å‚¨ï¼‰"""
        try:
            # å°†å®æ—¶æ•°æ®è½¬æ¢ä¸ºæ—¥çº¿æ ¼å¼ï¼Œç”¨äºPostgreSQL+TimescaleDBå­˜å‚¨
            daily_data = market_data.copy()

            # efinanceçš„get_realtime_quotes()è¿”å›çš„å¸¸è§åˆ—åæ˜ å°„
            column_mapping = {
                "è‚¡ç¥¨ä»£ç ": "symbol",
                "è‚¡ç¥¨åç§°": "name",
                "æœ€æ–°ä»·": "close",
                "æ¶¨è·Œå¹…": "pct_chg",
                "æ¶¨è·Œé¢": "change",
                "æˆäº¤é‡": "volume",
                "æˆäº¤é¢": "amount",
                "æŒ¯å¹…": "amplitude",
                "æœ€é«˜": "high",
                "æœ€ä½": "low",
                "ä»Šå¼€": "open",
                "æ˜¨æ”¶": "pre_close",
            }

            # æ‰§è¡Œåˆ—åæ˜ å°„
            for old_col, new_col in column_mapping.items():
                if old_col in daily_data.columns and new_col not in daily_data.columns:
                    daily_data[new_col] = daily_data[old_col]

            # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨ï¼ˆç¬¦åˆDAILY_KLINEçš„è¡¨ç»“æ„ï¼‰

            # å¦‚æœæ²¡æœ‰trade_dateï¼Œä½¿ç”¨å½“å‰æ—¥æœŸ
            if "trade_date" not in daily_data.columns:
                daily_data["trade_date"] = datetime.now().date()

            # ç¡®ä¿symbolåˆ—å­˜åœ¨
            if "symbol" not in daily_data.columns:
                if "è‚¡ç¥¨ä»£ç " in daily_data.columns:
                    daily_data["symbol"] = daily_data["è‚¡ç¥¨ä»£ç "]
                else:
                    self.logger.warning("âš ï¸ æ— æ³•æ‰¾åˆ°è‚¡ç¥¨ä»£ç åˆ—")
                    return None

            # è®¾ç½®OHLCæ•°æ®ï¼ˆå¦‚æœå®æ—¶æ•°æ®ä¸­æ²¡æœ‰å®Œæ•´çš„OHLCï¼Œä½¿ç”¨æœ€æ–°ä»·ä½œä¸ºcloseï¼‰
            if "close" not in daily_data.columns and "æœ€æ–°ä»·" in daily_data.columns:
                daily_data["close"] = daily_data["æœ€æ–°ä»·"]

            # æ•°æ®æ¸…æ´—ï¼šå¤„ç†æ•°å€¼å­—æ®µä¸­çš„æ— æ•ˆå€¼
            numeric_columns = ["open", "high", "low", "close", "volume", "amount"]
            for col in numeric_columns:
                if col in daily_data.columns:
                    # å°†å­—ç¬¦ä¸² '-' å’Œç©ºå€¼è½¬æ¢ä¸º None
                    daily_data[col] = daily_data[col].replace(["-", "---", "", " "], None)
                    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                    daily_data[col] = pd.to_numeric(daily_data[col], errors="coerce")

            # å¦‚æœæ²¡æœ‰OHLCçš„å…¶ä»–å€¼ï¼Œä½¿ç”¨æœ€æ–°ä»·å¡«å……
            for col in ["open", "high", "low"]:
                if col not in daily_data.columns and "close" in daily_data.columns:
                    daily_data[col] = daily_data["close"]

            # æ·»åŠ æ—¶é—´æˆ³
            daily_data["created_at"] = datetime.now()
            daily_data["updated_at"] = datetime.now()

            # åªä¿ç•™PostgreSQLè¡¨ç»“æ„éœ€è¦çš„åˆ—
            postgres_columns = [
                "symbol",
                "trade_date",
                "open",
                "high",
                "low",
                "close",
                "volume",
                "amount",
                "created_at",
                "updated_at",
            ]

            # è¿‡æ»¤å­˜åœ¨çš„åˆ—
            available_columns = [col for col in postgres_columns if col in daily_data.columns]
            daily_data = daily_data[available_columns]

            self.logger.info(f"ğŸ“Š æ—¥çº¿æ•°æ®æ ¼å¼åŒ–å®Œæˆï¼Œå…± {len(daily_data)} æ¡è®°å½•")
            self.logger.info(f"ğŸ“‹ åŒ…å«åˆ—: {list(daily_data.columns)}")

            return daily_data

        except Exception as e:
            self.logger.error(f"âŒ æ—¥çº¿æ•°æ®æ ¼å¼åŒ–å¤±è´¥: {e}")
            import traceback

            self.logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return None

    def _prepare_tick_data(self, market_data: pd.DataFrame) -> Optional[pd.DataFrame]:
        """å°†å¸‚åœºæ•°æ®è½¬æ¢ä¸ºTickæ•°æ®æ ¼å¼ï¼ˆç”¨äºTDengineå­˜å‚¨ï¼‰"""
        try:
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„market_dataç»“æ„æ¥æ˜ å°„åˆ°æ ‡å‡†çš„Tickæ ¼å¼
            # æ ‡å‡†Tickæ ¼å¼é€šå¸¸åŒ…å«: ts(æ—¶é—´æˆ³), symbol(ä»£ç ), price(ä»·æ ¼), volume(æˆäº¤é‡), amount(æˆäº¤é¢)

            tick_data = market_data.copy()

            # æ·»åŠ æ—¶é—´æˆ³åˆ—ï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
            if "ts" not in tick_data.columns:
                tick_data["ts"] = datetime.now()

            # å°è¯•æ˜ å°„å¸¸è§çš„åˆ—å
            column_mapping = {
                "è‚¡ç¥¨ä»£ç ": "symbol",
                "code": "symbol",
                "ç°ä»·": "price",
                "æœ€æ–°ä»·": "price",
                "price": "price",
                "æˆäº¤é‡": "volume",
                "volume": "volume",
                "æˆäº¤é¢": "amount",
                "amount": "amount",
            }

            # æ‰§è¡Œåˆ—åæ˜ å°„
            for old_col, new_col in column_mapping.items():
                if old_col in tick_data.columns and new_col not in tick_data.columns:
                    tick_data[new_col] = tick_data[old_col]

            # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
            required_columns = ["ts", "symbol", "price"]
            missing_columns = [col for col in required_columns if col not in tick_data.columns]

            if missing_columns:
                self.logger.warning(f"âš ï¸ Tickæ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
                # å°è¯•å¡«å……é»˜è®¤å€¼
                for col in missing_columns:
                    if col == "symbol":
                        tick_data["symbol"] = "UNKNOWN"
                    elif col == "price":
                        tick_data["price"] = 0.0

            self.logger.info(f"ğŸ“Š Tickæ•°æ®æ ¼å¼åŒ–å®Œæˆï¼Œå…± {len(tick_data)} æ¡è®°å½•")
            return tick_data

        except Exception as e:
            self.logger.error(f"âŒ Tickæ•°æ®æ ¼å¼åŒ–å¤±è´¥: {e}")
            return None

    def run(self) -> bool:
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®è·å–å’Œä¿å­˜æµç¨‹"""
        try:
            self.logger.info("=" * 70)
            self.logger.info("ğŸš€ æ²ªæ·±å¸‚åœºAè‚¡å®æ—¶æ•°æ®ä¿å­˜ç³»ç»Ÿå¯åŠ¨")
            self.logger.info("ğŸ“‹ ä½¿ç”¨MyStocksç»Ÿä¸€æ¥å£è§„èŒƒ")
            self.logger.info("=" * 70)

            # 1. åˆå§‹åŒ–MyStocksç»Ÿä¸€ç®¡ç†å™¨
            if not self.initialize_unified_manager():
                return False

            # 2. åˆå§‹åŒ–æ•°æ®æºé€‚é…å™¨
            if not self.initialize_data_source():
                return False

            # 3. è·å–å®æ—¶å¸‚åœºæ•°æ®ï¼ˆæ”¯æŒé‡è¯•ï¼‰
            market_data = None
            for attempt in range(self.config["max_retry_attempts"]):
                market_data = self.get_realtime_market_data()
                if market_data is not None:
                    break
                self.logger.warning(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡å°è¯•è·å–æ•°æ®å¤±è´¥")

            if market_data is None:
                self.logger.error("ğŸ’¥ å¤šæ¬¡é‡è¯•åä»æ— æ³•è·å–æ•°æ®")
                return False

            # 4. ä½¿ç”¨ç»Ÿä¸€æ¥å£ä¿å­˜æ•°æ®
            save_results = self.save_data_using_unified_interface(market_data)

            # 5. æ£€æŸ¥ä¿å­˜ç»“æœ
            success_count = sum(1 for result in save_results.values() if result)
            total_count = len(save_results)

            if success_count > 0:
                self.logger.info("=" * 70)
                self.logger.info("ğŸ‰ æ²ªæ·±å¸‚åœºAè‚¡å®æ—¶æ•°æ®ä¿å­˜å®Œæˆï¼")
                self.logger.info(f"ğŸ“Š æ•°æ®è®°å½•æ•°: {len(market_data)}")
                self.logger.info(f"ğŸ’¾ ä¿å­˜æˆåŠŸç‡: {success_count}/{total_count}")

                # æ˜¾ç¤ºå…·ä½“çš„ä¿å­˜ç»“æœ
                for save_type, result in save_results.items():
                    status = "âœ… æˆåŠŸ" if result else "âŒ å¤±è´¥"
                    if save_type == "realtime":
                        self.logger.info(f"ğŸ”¥ å®æ—¶æ•°æ® â†’ Redis: {status}")
                    elif save_type == "daily":
                        self.logger.info(f"ğŸ’¾ æ—¥çº¿æ•°æ® â†’ PostgreSQL+TimescaleDB: {status}")
                    elif save_type == "tick":
                        self.logger.info(f"â±ï¸ Tickæ•°æ® â†’ TDengine: {status}")

                # è·å–å¹¶æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
                try:
                    status = self.unified_manager.get_system_status()
                    monitoring = status.get("monitoring", {})
                    op_stats = monitoring.get("operation_statistics", {})
                    self.logger.info(f"ğŸ“ˆ ç³»ç»Ÿæ€»æ“ä½œæ•°: {op_stats.get('total_operations', 0)}")
                except Exception:
                    pass

                self.logger.info("=" * 70)
                return success_count == total_count  # å…¨éƒ¨æˆåŠŸæ‰è¿”å›True
            else:
                self.logger.error("ğŸ’¥ æ‰€æœ‰æ•°æ®ä¿å­˜æ“ä½œéƒ½å¤±è´¥äº†")
                return False

        except Exception as e:
            self.logger.error(f"ğŸ’¥ ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return False
        finally:
            # æ¸…ç†èµ„æº
            if self.unified_manager:
                self.unified_manager.cleanup()
                self.logger.info("ğŸ§¹ ç³»ç»Ÿèµ„æºå·²æ¸…ç†")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ²ªæ·±å¸‚åœºAè‚¡å®æ—¶æ•°æ®ä¿å­˜ç³»ç»Ÿ - MyStocksç»Ÿä¸€æ¥å£ç‰ˆ")
    parser.add_argument(
        "--config",
        default="realtime_market_config.env",
        help="é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: realtime_market_config.env)",
    )
    parser.add_argument("--force-update", action="store_true", help="å¼ºåˆ¶æ›´æ–°ï¼Œè·³è¿‡Redisç¼“å­˜")
    parser.add_argument("--enable-fixation", action="store_true", help="å¯ç”¨Redisæ•°æ®è‡ªåŠ¨å›ºåŒ–")

    args = parser.parse_args()

    print("æ²ªæ·±å¸‚åœºAè‚¡å®æ—¶æ•°æ®ä¿å­˜ç³»ç»Ÿ - MyStocksç»Ÿä¸€æ¥å£ç‰ˆ")
    print("=" * 70)
    print(f"é…ç½®æ–‡ä»¶: {args.config}")
    print("ä½¿ç”¨MyStocksç»Ÿä¸€ç®¡ç†å™¨è¿›è¡Œè‡ªåŠ¨è·¯ç”±ä¿å­˜")
    print("æ•°æ®åˆ†ç±»: REALTIME_POSITIONS â†’ Redis, DAILY_KLINE â†’ PostgreSQL, TICK_DATA â†’ TDengine(å¯é€‰)")
    print("æ•°æ®æº: efinance.stock.get_realtime_quotes() - æ²ªæ·±Aè‚¡å®æ—¶è¡Œæƒ…")
    if args.force_update:
        print("ğŸ”„ å¼ºåˆ¶æ›´æ–°æ¨¡å¼: è·³è¿‡Redisç¼“å­˜")
    if args.enable_fixation:
        print("ğŸ’¾ è‡ªåŠ¨å›ºåŒ–æ¨¡å¼: å¯ç”¨Redisæ•°æ®å›ºåŒ–")
    print("=" * 70)

    # åˆ›å»ºæ•°æ®ä¿å­˜å™¨
    saver = RealtimeMarketDataSaver(args.config)

    # å¦‚æœå¯ç”¨å¼ºåˆ¶æ›´æ–°æˆ–å›ºåŒ–ï¼Œå¯¼å…¥ç›¸å…³æ¨¡å—
    if args.force_update or args.enable_fixation:
        try:
            from redis_data_fixation import RedisDataFixationManager

            fixation_manager = RedisDataFixationManager(saver.unified_manager)

            if args.force_update:
                print("ğŸ”„ æ‰§è¡Œå¼ºåˆ¶æ›´æ–°...")
                update_result = fixation_manager.force_update_realtime_data(
                    market_symbol=saver.config["market_symbol"], bypass_cache=True
                )
                print(f"å¼ºåˆ¶æ›´æ–°ç»“æœ: {update_result}")

                if update_result.get("success"):
                    print("âœ… å¼ºåˆ¶æ›´æ–°æˆåŠŸï¼Œç¨‹åºç»“æŸ")
                    sys.exit(0)
                else:
                    print("âŒ å¼ºåˆ¶æ›´æ–°å¤±è´¥ï¼Œç»§ç»­æ­£å¸¸æµç¨‹")

        except ImportError as e:
            print(f"âš ï¸ å›ºåŒ–æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
            print("ç»§ç»­æ­£å¸¸æµç¨‹...")

    # æ­£å¸¸è¿è¡Œ
    success = saver.run()

    exit_code = 0 if success else 1
    print(f"ç¨‹åºæ‰§è¡Œ{'æˆåŠŸ' if success else 'å¤±è´¥'}ï¼Œé€€å‡ºç : {exit_code}")
    sys.exit(exit_code)


if __name__ == "__main__":
    main()
