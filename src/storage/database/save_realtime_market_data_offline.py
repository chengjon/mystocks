#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ²ªæ·±å¸‚åœºAè‚¡å®æ—¶æ•°æ®ä¿å­˜ç³»ç»Ÿ - ç¦»çº¿ç‰ˆ
å®Œå…¨ç¦»çº¿è¿è¡Œï¼Œåªéœ€è¦efinanceåº“ï¼Œæ•°æ®ä¿å­˜åˆ°CSVæ–‡ä»¶

åŠŸèƒ½ç‰¹ç‚¹ï¼š
1. ä»efinanceè·å–æ²ªæ·±Aè‚¡å®æ—¶æ•°æ®
2. ä¿å­˜åˆ°CSVæ–‡ä»¶ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
3. è‡ªåŠ¨åˆ›å»ºå¤‡ä»½ç›®å½•
4. æ”¯æŒå¼ºåˆ¶æ›´æ–°
5. æ— éœ€ä»»ä½•æ•°æ®åº“ä¾èµ–

é€‚ç”¨åœºæ™¯ï¼š
- å¿«é€Ÿæµ‹è¯•å’ŒéªŒè¯
- æ•°æ®æ”¶é›†å’Œå¤‡ä»½
- å¼€å‘ç¯å¢ƒæµ‹è¯•
- ç¦»çº¿æ•°æ®åˆ†æ

ä½œè€…: MyStocksé¡¹ç›®ç»„
æ—¥æœŸ: 2025-09-21
ç‰ˆæœ¬: ç¦»çº¿ç‰ˆ v1.0
"""

import os
import sys
import logging
import argparse
import pandas as pd
import json
from datetime import datetime
from typing import Optional, Dict, Any


class OfflineRealtimeDataSaver:
    """ç¦»çº¿ç‰ˆå®æ—¶æ•°æ®ä¿å­˜å™¨ - åªä½¿ç”¨CSVæ–‡ä»¶"""

    def __init__(self):
        """åˆå§‹åŒ–ç¦»çº¿ç‰ˆæ•°æ®ä¿å­˜å™¨"""
        self.logger = None
        self.config = {
            "market_symbol": "hs",
            "backup_dir": "./data_backup",
            "add_timestamp": True,
            "enable_validation": True,
            "max_retry_attempts": 3,
            "export_json": True,
            "export_excel": False,
        }

        self._setup_logging()
        self._create_backup_directory()

    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

        logging.basicConfig(
            level=logging.INFO,
            format=log_format,
            handlers=[logging.StreamHandler(sys.stdout)],
        )

        self.logger = logging.getLogger("OfflineRealtimeSaver")
        self.logger.info("ç¦»çº¿ç‰ˆå®æ—¶æ•°æ®ä¿å­˜å™¨å¯åŠ¨")

    def _create_backup_directory(self):
        """åˆ›å»ºå¤‡ä»½ç›®å½•"""
        try:
            os.makedirs(self.config["backup_dir"], exist_ok=True)
            self.logger.info(f"âœ… å¤‡ä»½ç›®å½•å·²åˆ›å»º: {self.config['backup_dir']}")
        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºå¤‡ä»½ç›®å½•å¤±è´¥: {e}")
            # ä½¿ç”¨å½“å‰ç›®å½•ä½œä¸ºå¤‡ä»½ç›®å½•
            self.config["backup_dir"] = "."

    def check_dependencies(self) -> bool:
        """æ£€æŸ¥ä¾èµ–åº“"""
        self.logger.info("æ£€æŸ¥ä¾èµ–åº“...")

        missing_libs = []

        # æ£€æŸ¥efinance
        try:
            import efinance

            self.logger.info("âœ… efinance å·²å®‰è£…")
        except ImportError:
            missing_libs.append("efinance")

        # æ£€æŸ¥pandasï¼ˆé€šå¸¸å·²å®‰è£…ï¼‰
        try:
            import pandas

            self.logger.info("âœ… pandas å·²å®‰è£…")
        except ImportError:
            missing_libs.append("pandas")

        if missing_libs:
            self.logger.error(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {missing_libs}")
            self.logger.info("ğŸ’¡ è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
            for lib in missing_libs:
                self.logger.info(f"   pip install {lib}")
            return False

        self.logger.info("âœ… æ‰€æœ‰ä¾èµ–åº“æ£€æŸ¥é€šè¿‡")
        return True

    def get_realtime_market_data(
        self, market_symbol: str = None
    ) -> Optional[pd.DataFrame]:
        """è·å–å®æ—¶å¸‚åœºæ•°æ®"""
        symbol = market_symbol or self.config["market_symbol"]
        self.logger.info(f"è·å–{symbol}å¸‚åœºå®æ—¶æ•°æ®...")

        try:
            import efinance as ef

            # è·å–å®æ—¶æ•°æ®
            self.logger.info("ğŸ”„ æ­£åœ¨ä»efinanceè·å–æ•°æ®...")
            data = ef.stock.get_realtime_quotes()

            if data is None or data.empty:
                self.logger.error("âŒ æœªè·å–åˆ°æ•°æ®")
                return None

            # æ ¹æ®å¸‚åœºä»£ç è¿‡æ»¤æ•°æ®
            if symbol == "sh":
                # ä¸Šæµ·å¸‚åœºï¼š6å¼€å¤´çš„è‚¡ç¥¨
                data = data[data["è‚¡ç¥¨ä»£ç "].str.startswith("6")]
            elif symbol == "sz":
                # æ·±åœ³å¸‚åœºï¼š0å’Œ3å¼€å¤´çš„è‚¡ç¥¨
                data = data[data["è‚¡ç¥¨ä»£ç "].str.startswith(("0", "3"))]
            # 'hs' æ²ªæ·±å¸‚åœºï¼šä½¿ç”¨å…¨éƒ¨æ•°æ®

            self.logger.info(f"âœ… æˆåŠŸè·å– {symbol} å¸‚åœºæ•°æ®ï¼Œå…± {len(data)} æ¡è®°å½•")

            # æ·»åŠ é¢å¤–ä¿¡æ¯
            if self.config["add_timestamp"]:
                data["æ•°æ®è·å–æ—¶é—´"] = datetime.now()
                data["å¸‚åœºä»£ç "] = symbol
                data["æ•°æ®æ¥æº"] = "efinance"

            # æ•°æ®éªŒè¯
            if self.config["enable_validation"]:
                self._validate_data(data)

            return data

        except ImportError:
            self.logger.error("âŒ efinanceåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install efinance")
            return None
        except Exception as e:
            self.logger.error(f"âŒ è·å–æ•°æ®å¤±è´¥: {e}")
            return None

    def _validate_data(self, data: pd.DataFrame):
        """éªŒè¯æ•°æ®è´¨é‡"""
        try:
            # åŸºç¡€æ£€æŸ¥
            if data.empty:
                self.logger.warning("âš ï¸ æ•°æ®ä¸ºç©º")
                return

            # æ£€æŸ¥å…³é”®åˆ—
            key_columns = ["è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨åç§°", "æœ€æ–°ä»·"]
            missing_columns = [col for col in key_columns if col not in data.columns]
            if missing_columns:
                self.logger.warning(f"âš ï¸ ç¼ºå°‘å…³é”®åˆ—: {missing_columns}")

            # ç»Ÿè®¡ä¿¡æ¯
            self.logger.info(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
            self.logger.info(f"   æ€»è®°å½•æ•°: {len(data)}")
            self.logger.info(f"   åˆ—æ•°: {len(data.columns)}")

            # ç©ºå€¼æ£€æŸ¥
            null_counts = data.isnull().sum()
            if null_counts.sum() > 0:
                self.logger.info(
                    f"   ç©ºå€¼ç»Ÿè®¡: {null_counts[null_counts > 0].head().to_dict()}"
                )
            else:
                self.logger.info("   æ— ç©ºå€¼")

            # ä»·æ ¼èŒƒå›´æ£€æŸ¥
            if "æœ€æ–°ä»·" in data.columns:
                prices = data["æœ€æ–°ä»·"].dropna()
                if len(prices) > 0:
                    self.logger.info(
                        f"   ä»·æ ¼èŒƒå›´: {prices.min():.2f} - {prices.max():.2f}"
                    )

            self.logger.info("âœ… æ•°æ®éªŒè¯å®Œæˆ")

        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")

    def save_to_csv(self, data: pd.DataFrame, market_symbol: str = None) -> str:
        """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶"""
        try:
            symbol = market_symbol or self.config["market_symbol"]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            # ç”Ÿæˆæ–‡ä»¶å
            filename = f"realtime_market_{symbol}_{timestamp}.csv"
            filepath = os.path.join(self.config["backup_dir"], filename)

            # ä¿å­˜CSVï¼ˆä½¿ç”¨UTF-8ç¼–ç ï¼Œæ”¯æŒä¸­æ–‡ï¼‰
            data.to_csv(filepath, index=False, encoding="utf-8-sig")

            self.logger.info(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°CSV: {filepath}")
            self.logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {os.path.getsize(filepath)} å­—èŠ‚")

            return filepath

        except Exception as e:
            self.logger.error(f"âŒ CSVä¿å­˜å¤±è´¥: {e}")
            return None

    def save_to_json(self, data: pd.DataFrame, market_symbol: str = None) -> str:
        """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
        if not self.config["export_json"]:
            return None

        try:
            symbol = market_symbol or self.config["market_symbol"]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            # ç”Ÿæˆæ–‡ä»¶å
            filename = f"realtime_market_{symbol}_{timestamp}.json"
            filepath = os.path.join(self.config["backup_dir"], filename)

            # è½¬æ¢æ—¥æœŸæ—¶é—´ä¸ºå­—ç¬¦ä¸²
            data_copy = data.copy()
            for col in data_copy.columns:
                if data_copy[col].dtype == "datetime64[ns]":
                    data_copy[col] = data_copy[col].dt.strftime("%Y-%m-%d %H:%M:%S")

            # ä¿å­˜JSON
            data_dict = data_copy.to_dict(orient="records")
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(data_dict, f, ensure_ascii=False, indent=2)

            self.logger.info(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°JSON: {filepath}")
            return filepath

        except Exception as e:
            self.logger.error(f"âŒ JSONä¿å­˜å¤±è´¥: {e}")
            return None

    def save_to_excel(self, data: pd.DataFrame, market_symbol: str = None) -> str:
        """ä¿å­˜æ•°æ®åˆ°Excelæ–‡ä»¶"""
        if not self.config["export_excel"]:
            return None

        try:
            symbol = market_symbol or self.config["market_symbol"]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            # ç”Ÿæˆæ–‡ä»¶å
            filename = f"realtime_market_{symbol}_{timestamp}.xlsx"
            filepath = os.path.join(self.config["backup_dir"], filename)

            # ä¿å­˜Excel
            data.to_excel(filepath, index=False, engine="openpyxl")

            self.logger.info(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°Excel: {filepath}")
            return filepath

        except Exception as e:
            self.logger.error(f"âŒ Excelä¿å­˜å¤±è´¥: {e}")
            if "openpyxl" in str(e):
                self.logger.info("ğŸ’¡ è¯·å®‰è£…openpyxl: pip install openpyxl")
            return None

    def create_summary_report(self, data: pd.DataFrame, saved_files: list):
        """åˆ›å»ºæ±‡æ€»æŠ¥å‘Š"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = os.path.join(
                self.config["backup_dir"], f"summary_report_{timestamp}.txt"
            )

            with open(report_file, "w", encoding="utf-8") as f:
                f.write("=" * 60 + "\n")
                f.write("æ²ªæ·±å¸‚åœºAè‚¡å®æ—¶æ•°æ®ä¿å­˜æŠ¥å‘Š\n")
                f.write("=" * 60 + "\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"å¸‚åœºä»£ç : {self.config['market_symbol']}\n")
                f.write(f"æ•°æ®æ¥æº: efinance\n")
                f.write("\n")

                f.write("æ•°æ®ç»Ÿè®¡:\n")
                f.write(f"  æ€»è®°å½•æ•°: {len(data)}\n")
                f.write(f"  æ•°æ®åˆ—æ•°: {len(data.columns)}\n")

                if "æœ€æ–°ä»·" in data.columns:
                    prices = data["æœ€æ–°ä»·"].dropna()
                    if len(prices) > 0:
                        f.write(
                            f"  ä»·æ ¼èŒƒå›´: {prices.min():.2f} - {prices.max():.2f}\n"
                        )

                f.write("\nä¿å­˜çš„æ–‡ä»¶:\n")
                for file_path in saved_files:
                    if file_path:
                        f.write(f"  - {file_path}\n")

                f.write("\næ•°æ®åˆ—å:\n")
                for i, col in enumerate(data.columns, 1):
                    f.write(f"  {i:2d}. {col}\n")

            self.logger.info(f"âœ… æ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

        except Exception as e:
            self.logger.error(f"âŒ ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")

    def run(self, market_symbol: str = None, force_update: bool = False) -> bool:
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        try:
            symbol = market_symbol or self.config["market_symbol"]

            self.logger.info("=" * 60)
            self.logger.info("ğŸš€ ç¦»çº¿ç‰ˆæ²ªæ·±å¸‚åœºAè‚¡å®æ—¶æ•°æ®ä¿å­˜ç³»ç»Ÿ")
            self.logger.info("=" * 60)
            self.logger.info(f"ğŸ“Š ç›®æ ‡å¸‚åœº: {symbol}")
            self.logger.info(f"ğŸ—‚ï¸ å¤‡ä»½ç›®å½•: {self.config['backup_dir']}")
            self.logger.info(f"ğŸ”„ å¼ºåˆ¶æ›´æ–°: {'æ˜¯' if force_update else 'å¦'}")
            self.logger.info("=" * 60)

            # 1. æ£€æŸ¥ä¾èµ–
            if not self.check_dependencies():
                return False

            # 2. è·å–æ•°æ®ï¼ˆæ”¯æŒé‡è¯•ï¼‰
            data = None
            for attempt in range(self.config["max_retry_attempts"]):
                self.logger.info(f"ğŸ“¡ ç¬¬{attempt + 1}æ¬¡è·å–æ•°æ®...")
                data = self.get_realtime_market_data(symbol)
                if data is not None:
                    break
                self.logger.warning(f"âš ï¸ ç¬¬{attempt + 1}æ¬¡è·å–å¤±è´¥")

            if data is None:
                self.logger.error("ğŸ’¥ å¤šæ¬¡é‡è¯•åä»æ— æ³•è·å–æ•°æ®")
                return False

            # 3. ä¿å­˜æ•°æ®åˆ°å¤šç§æ ¼å¼
            saved_files = []

            # CSVæ–‡ä»¶ï¼ˆä¸»è¦æ ¼å¼ï¼‰
            csv_file = self.save_to_csv(data, symbol)
            saved_files.append(csv_file)

            # JSONæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
            json_file = self.save_to_json(data, symbol)
            saved_files.append(json_file)

            # Excelæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
            excel_file = self.save_to_excel(data, symbol)
            saved_files.append(excel_file)

            # 4. ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
            self.create_summary_report(data, saved_files)

            # 5. æ˜¾ç¤ºç»“æœ
            success_count = len([f for f in saved_files if f is not None])

            self.logger.info("=" * 60)
            self.logger.info("ğŸ‰ æ•°æ®ä¿å­˜å®Œæˆï¼")
            self.logger.info(f"ğŸ“Š æ•°æ®è®°å½•æ•°: {len(data)}")
            self.logger.info(f"ğŸ’¾ ä¿å­˜æ–‡ä»¶æ•°: {success_count}")
            self.logger.info(
                f"ğŸ“ ä¿å­˜ä½ç½®: {os.path.abspath(self.config['backup_dir'])}"
            )

            # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
            for file_path in saved_files:
                if file_path:
                    file_size = os.path.getsize(file_path)
                    self.logger.info(
                        f"   âœ… {os.path.basename(file_path)} ({file_size} å­—èŠ‚)"
                    )

            self.logger.info("=" * 60)

            return True

        except Exception as e:
            self.logger.error(f"ğŸ’¥ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ²ªæ·±å¸‚åœºAè‚¡å®æ—¶æ•°æ®ä¿å­˜ç³»ç»Ÿ - ç¦»çº¿ç‰ˆ")
    parser.add_argument(
        "--market",
        choices=["hs", "sh", "sz"],
        default="hs",
        help="å¸‚åœºä»£ç  (hs=æ²ªæ·±, sh=ä¸Šæµ·, sz=æ·±åœ³)",
    )
    parser.add_argument("--force-update", action="store_true", help="å¼ºåˆ¶æ›´æ–°")
    parser.add_argument("--backup-dir", default="./data_backup", help="å¤‡ä»½ç›®å½•è·¯å¾„")
    parser.add_argument("--export-json", action="store_true", help="å¯¼å‡ºJSONæ ¼å¼")
    parser.add_argument("--export-excel", action="store_true", help="å¯¼å‡ºExcelæ ¼å¼")

    args = parser.parse_args()

    print("æ²ªæ·±å¸‚åœºAè‚¡å®æ—¶æ•°æ®ä¿å­˜ç³»ç»Ÿ - ç¦»çº¿ç‰ˆ")
    print("=" * 60)
    print(f"å¸‚åœºä»£ç : {args.market}")
    print(f"å¤‡ä»½ç›®å½•: {args.backup_dir}")
    print(f"å¯¼å‡ºJSON: {'æ˜¯' if args.export_json else 'å¦'}")
    print(f"å¯¼å‡ºExcel: {'æ˜¯' if args.export_excel else 'å¦'}")
    print("=" * 60)

    # åˆ›å»ºä¿å­˜å™¨
    saver = OfflineRealtimeDataSaver()
    saver.config["market_symbol"] = args.market
    saver.config["backup_dir"] = args.backup_dir
    saver.config["export_json"] = args.export_json
    saver.config["export_excel"] = args.export_excel

    # è¿è¡Œ
    success = saver.run(args.market, args.force_update)

    exit_code = 0 if success else 1
    print(f"ç¨‹åºæ‰§è¡Œ{'æˆåŠŸ' if success else 'å¤±è´¥'}ï¼Œé€€å‡ºç : {exit_code}")
    sys.exit(exit_code)


if __name__ == "__main__":
    main()
