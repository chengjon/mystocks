"""
Price Stream Processor with Caching
å¸¦ç¼“å­˜çš„å®žæ—¶è¡Œæƒ…æµå¤„ç†å™¨

åœ¨ Phase 12.3 çš„åŸºç¡€ä¸Šé›†æˆ LRU ç¼“å­˜æ€§èƒ½ä¼˜åŒ–ã€‚

Author: Claude Code
Date: 2026-01-09
Phase: 12.5 - Performance Optimization Integration
"""

import logging
from collections import defaultdict
from datetime import datetime
from typing import Dict

from src.application.market_data.price_stream_processor import PriceStreamProcessor
from src.domain.portfolio.service import PortfolioValuationService
from src.domain.shared.event_bus import IEventBus
from src.domain.market_data.streaming.price_changed_event import PriceChangedEvent
from src.services.performance_optimizer import LRUCache

logger = logging.getLogger(__name__)


class CachedPriceStreamProcessor(PriceStreamProcessor):
    """
    å¸¦ç¼“å­˜çš„å®žæ—¶è¡Œæƒ…æµå¤„ç†å™¨

    åœ¨ PriceStreamProcessor åŸºç¡€ä¸Šå¢žåŠ ï¼š
    1. LRU ç¼“å­˜ï¼šç¼“å­˜æŠ•èµ„ç»„åˆå¿«ç…§ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢
    2. æ™ºèƒ½åˆ·æ–°ï¼šä»…åœ¨æ•°æ®å˜åŒ–æ—¶åˆ·æ–°ç¼“å­˜
    3. ç¼“å­˜é¢„çƒ­ï¼šåœ¨å¯åŠ¨æ—¶é¢„åŠ è½½å¸¸ç”¨æ•°æ®

    Args:
        event_bus: äº‹ä»¶æ€»çº¿
        valuation_service: æŠ•èµ„ç»„åˆä¼°å€¼æœåŠ¡
        redis_client: Redis å®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼‰
        batch_size: æ‰¹å¤„ç†å¤§å°
        batch_timeout: æ‰¹å¤„ç†è¶…æ—¶ï¼ˆç§’ï¼‰
        enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        cache_max_size: ç¼“å­˜æœ€å¤§æ¡ç›®æ•°ï¼ˆé»˜è®¤1000ï¼‰
        cache_ttl: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤300ï¼‰
    """

    def __init__(
        self,
        event_bus: IEventBus,
        valuation_service: PortfolioValuationService,
        redis_client=None,
        batch_size: int = 100,
        batch_timeout: float = 0.1,
        enable_throttling: bool = True,
        enable_cache: bool = True,
        cache_max_size: int = 1000,
        cache_ttl: float = 300.0,
    ):
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(
            event_bus=event_bus,
            valuation_service=valuation_service,
            redis_client=redis_client,
            batch_size=batch_size,
            batch_timeout=batch_timeout,
            enable_throttling=enable_throttling,
        )

        # åˆå§‹åŒ–ç¼“å­˜
        self.enable_cache = enable_cache
        if enable_cache:
            self.portfolio_cache = LRUCache(max_size=cache_max_size, ttl=cache_ttl)
            logger.info("âœ… Cache enabled: max_size=%(cache_max_size)s, ttl=%(cache_ttl)ss")
        else:
            self.portfolio_cache = None
            logger.info("âš ï¸ Cache disabled")

        # æ‰©å±•æŒ‡æ ‡
        self.metrics.update(
            {
                "cache_hits": 0,
                "cache_misses": 0,
                "cache_stores": 0,
                "cache_evictions": 0,
            }
        )

    async def start(self) -> None:
        """å¯åŠ¨å¤„ç†å™¨"""
        await super().start()

        # é¢„çƒ­ç¼“å­˜
        if self.enable_cache:
            await self._warmup_cache()

    async def _warmup_cache(self):
        """é¢„çƒ­ç¼“å­˜ï¼šé¢„åŠ è½½æ‰€æœ‰æŠ•èµ„ç»„åˆå¿«ç…§"""
        logger.info("ðŸ”¥ Warming up cache...")

        try:
            # èŽ·å–æ‰€æœ‰æŠ•èµ„ç»„åˆ
            portfolios = self.valuation_service.portfolio_repo.find_all(limit=1000)

            for portfolio in portfolios:
                # è®¡ç®—ç»©æ•ˆ
                performance = portfolio.calculate_performance()

                # å­˜å…¥ç¼“å­˜
                cache_key = f"portfolio:{portfolio.id}"
                self.portfolio_cache.set(
                    cache_key, {"portfolio": portfolio, "performance": performance, "cached_at": datetime.now()}
                )

                self.metrics["cache_stores"] += 1

            logger.info("âœ… Cache warmed up: {len(portfolios)} portfolios loaded")

        except Exception as e:
            logger.error("Failed to warm up cache: %(e)s")

    async def _flush_updates(self) -> None:
        """åˆ·æ–°æ›´æ–°é˜Ÿåˆ—ï¼ˆå¸¦ç¼“å­˜ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        if not self._update_queue:
            return

        # èŽ·å–æ‰€æœ‰æ›´æ–°
        updates = list(self._update_queue)
        self._update_queue.clear()
        self._last_flush = datetime.now()

        logger.debug("ðŸ”„ Flushing {len(updates)} price updates...")

        # æŒ‰æŠ•èµ„ç»„åˆåˆ†ç»„
        portfolio_updates: Dict[str, Dict[str, float]] = defaultdict(dict)
        all_prices: Dict[str, float] = {}

        for update in updates:
            # è®°å½•æ‰€æœ‰ä»·æ ¼
            all_prices[update.symbol] = update.price

            # æŒ‰æŠ•èµ„ç»„åˆåˆ†ç»„
            for portfolio_id, symbols in self._portfolio_symbols.items():
                if update.symbol in symbols:
                    portfolio_updates[portfolio_id][update.symbol] = update.price

        # å‘å¸ƒä»·æ ¼å˜æ›´äº‹ä»¶
        if all_prices:
            events = PriceChangedEvent.create_batch(all_prices, self._price_cache)
            for event in events:
                try:
                    self.event_bus.publish(event)
                    self.metrics["events_published"] += 1
                except Exception as e:
                    logger.error("Failed to publish PriceChangedEvent: %(e)s")

            # æ›´æ–°ä»·æ ¼ç¼“å­˜
            self._price_cache.update(all_prices)

        # è§¦å‘æŠ•èµ„ç»„åˆé‡æ–°è®¡ç®—ï¼ˆå¸¦ç¼“å­˜ä¼˜åŒ–ï¼‰
        if portfolio_updates:
            for portfolio_id, prices in portfolio_updates.items():
                try:
                    # å¦‚æžœå¯ç”¨ç¼“å­˜ï¼Œå…ˆæ£€æŸ¥ç¼“å­˜
                    if self.enable_cache:
                        cache_key = f"portfolio:{portfolio_id}"
                        cached_data = self.portfolio_cache.get(cache_key)

                        if cached_data:
                            self.metrics["cache_hits"] += 1
                            # ä½¿ç”¨ç¼“å­˜çš„æŠ•èµ„ç»„åˆè¿›è¡Œæ›´æ–°
                            portfolio = cached_data["portfolio"]
                        else:
                            self.metrics["cache_misses"] += 1
                            # ä»Žæ•°æ®åº“åŠ è½½
                            portfolio = self.valuation_service.portfolio_repo.find_by_id(portfolio_id)
                    else:
                        portfolio = self.valuation_service.portfolio_repo.find_by_id(portfolio_id)

                    if not portfolio:
                        logger.warning("âš ï¸ Portfolio not found: %(portfolio_id)s")
                        continue

                    # å¦‚æžœæœ‰åˆ†å¸ƒå¼é”ï¼Œå…ˆèŽ·å–é”
                    identifier = None
                    if self._lock_manager:
                        lock_name = f"portfolio:revaluate:{portfolio_id}"
                        identifier = self._lock_manager.acquire(lock_name, expire_seconds=5, wait_timeout=1)

                    if identifier or not self._lock_manager:
                        try:
                            # è°ƒç”¨ PortfolioValuationService é‡æ–°è®¡ç®—
                            performance = self.valuation_service.revaluate_portfolio(
                                portfolio_id=portfolio_id, prices=prices, force_save=True
                            )

                            if performance:
                                # æ›´æ–°ç¼“å­˜
                                if self.enable_cache:
                                    cache_key = f"portfolio:{portfolio_id}"
                                    updated_portfolio = self.valuation_service.portfolio_repo.find_by_id(portfolio_id)

                                    self.portfolio_cache.set(
                                        cache_key,
                                        {
                                            "portfolio": updated_portfolio,
                                            "performance": performance,
                                            "cached_at": datetime.now(),
                                        },
                                    )
                                    self.metrics["cache_stores"] += 1

                                logger.info(
                                    f"ðŸ“Š Revaluated portfolio {portfolio_id}: {len(prices)} symbols, "
                                    f"holdings_value={performance.holdings_value:.2f}, return={performance.total_return:.2f}%"
                                )
                                self.metrics["portfolio_revaluations"] += 1
                            else:
                                logger.warning("âš ï¸ Failed to revaluate portfolio %(portfolio_id)s")

                        finally:
                            if identifier and self._lock_manager:
                                self._lock_manager.release(lock_name, identifier)
                    else:
                        logger.warning("âš ï¸ Could not acquire lock for portfolio %(portfolio_id)s")

                except Exception as e:
                    logger.error("Failed to revaluate portfolio %(portfolio_id)s: %(e)s")

        self.metrics["batches_processed"] += 1
        logger.debug("âœ… Flushed {len(updates)} price updates")

    def get_metrics(self) -> dict:
        """èŽ·å–å¤„ç†å™¨æŒ‡æ ‡ï¼ˆåŒ…å«ç¼“å­˜æŒ‡æ ‡ï¼‰"""
        base_metrics = super().get_metrics()

        if self.enable_cache:
            cache_stats = self.portfolio_cache.get_stats()
            cache_metrics = {
                "cache_hits": self.metrics["cache_hits"],
                "cache_misses": self.metrics["cache_misses"],
                "cache_stores": self.metrics["cache_stores"],
                "cache_hit_rate": (
                    self.metrics["cache_hits"] / (self.metrics["cache_hits"] + self.metrics["cache_misses"])
                    if (self.metrics["cache_hits"] + self.metrics["cache_misses"]) > 0
                    else 0
                ),
                "cache_size": cache_stats["size"],
                "cache_max_size": cache_stats["max_size"],
                "cache_ttl": cache_stats["ttl"],
            }
            base_metrics.update(cache_metrics)

        return base_metrics

    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        if self.enable_cache and self.portfolio_cache:
            self.portfolio_cache.clear()
            logger.info("âœ… Cache cleared")
