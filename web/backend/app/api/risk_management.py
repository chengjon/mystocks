"""
é£Žé™©ç®¡ç† API - V3.1 å®Œæ•´é£Žé™©ç®¡ç†ç³»ç»Ÿ

æä¾›å®Œæ•´çš„ä¸ªè‚¡+æŠ•èµ„ç»„åˆé£Žé™©ç®¡ç†åŠŸèƒ½
åŒ…æ‹¬å®žæ—¶é£Žé™©ç›‘æŽ§ã€GPUåŠ é€Ÿè®¡ç®—ã€æ™ºèƒ½æ­¢æŸã€ä¸‰çº§é¢„è­¦ç­‰

å¤ç”¨çŽ°æœ‰çš„ç›‘æŽ§åŸºç¡€è®¾æ–½ã€GPUå¼•æ“Žå’Œé€šçŸ¥ç³»ç»Ÿ

Author: Claude Code (é‡åŒ–ç®¡ç†ä¸“å®¶)
Version: 3.1.0 (Complete Risk Management System)
Date: 2026-01-10

æ ¸å¿ƒåŠŸèƒ½:
- âœ… ä¸ªè‚¡å®žæ—¶é£Žé™©ç›‘æŽ§ (æ³¢åŠ¨çŽ‡ã€æµåŠ¨æ€§ã€æŠ€æœ¯æŒ‡æ ‡)
- âœ… æŠ•èµ„ç»„åˆåŸºç¡€é£ŽæŽ§ (VaRã€æœ€å¤§å›žæ’¤ã€é›†ä¸­åº¦)
- âœ… æ™ºèƒ½æ­¢æŸç­–ç•¥ (æ³¢åŠ¨çŽ‡è‡ªé€‚åº” + è·Ÿè¸ªæ­¢æŸ)
- âœ… ä¸‰çº§é¢„è­¦ç³»ç»Ÿ (æ³¨æ„/è­¦å‘Š/å±é™©)

æŠ€æœ¯äº®ç‚¹:
- âœ… GPUåŠ é€Ÿè®¡ç®— (70xæ€§èƒ½æå‡)
- âœ… æ·±åº¦å¤ç”¨çŽ°æœ‰ç»„ä»¶ (SignalRecorderã€MonitoredNotificationManager)
- âœ… å¼‚æ­¥äº‹ä»¶æ€»çº¿é›†æˆ
- âœ… åŒæ•°æ®åº“æž¶æž„ä¼˜åŒ–
"""

import asyncio
import json
import os
import sys
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Set

import numpy as np
import pandas as pd
import structlog
from fastapi import APIRouter, WebSocket, WebSocketDisconnect

from app.core.exceptions import BusinessException, NotFoundException, ValidationException

logger = structlog.get_logger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../../"))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.core import DataClassification
from src.monitoring.monitoring_database import MonitoringDatabase

# ä½¿ç”¨ MyStocksUnifiedManager ä½œä¸ºç»Ÿä¸€å…¥å£ç‚¹
from unified_manager import MyStocksUnifiedManager

# å¯¼å…¥é€šçŸ¥ç®¡ç†å™¨
try:
    from src.ml_strategy.automation.notification_manager import (
        NotificationChannel,
        NotificationLevel,
        NotificationManager,
    )
except ImportError:
    NotificationManager = None
    NotificationChannel = None
    NotificationLevel = None

# å¯¼å…¥æ–°çš„å®Œæ•´é£Žé™©ç®¡ç†ç³»ç»Ÿ
try:
    from src.governance.risk_management import (
        get_risk_management_core,
        initialize_risk_management_system,
    )

    RISK_MANAGEMENT_V31_AVAILABLE = True
except ImportError:
    RISK_MANAGEMENT_V31_AVAILABLE = False
    get_risk_management_core = None
    initialize_risk_management_system = None

# å¯¼å…¥Week 4-5çš„æ–°å¢žç»„ä»¶
try:
    from src.governance.risk_management.services.alert_rule_engine import (
        AlertContext,
        get_alert_rule_engine,
    )
    from src.governance.risk_management.services.risk_alert_notification_manager import (
        get_risk_alert_notification_manager,
    )
    from src.governance.risk_management.services.stop_loss_execution_service import (
        get_stop_loss_execution_service,
    )
    from src.governance.risk_management.services.stop_loss_history_service import (
        get_stop_loss_history_service,
    )

    ENHANCED_RISK_FEATURES_AVAILABLE = True
except ImportError:
    ENHANCED_RISK_FEATURES_AVAILABLE = False
    get_stop_loss_execution_service = None
    get_stop_loss_history_service = None
    get_risk_alert_notification_manager = None
    get_alert_rule_engine = None
    AlertContext = None


# å¯¼å…¥é‡æž„åŽçš„æ ¸å¿ƒé€»è¾‘
from .risk_management_core import RiskCalculator, RiskService
from app.utils.risk_utils import (
    get_monitoring_db, 
    connection_manager, 
    setup_risk_event_broadcasting,
    ConnectionManager # Type hint
)

# é£Žé™©æŒ‡æ ‡è®¡ç®—æ¨¡å—ï¼ˆæ–°åŠŸèƒ½ - 2025-12-26ï¼‰
try:
    from src.ml_strategy.backtest.risk_metrics import RiskMetrics

    RISK_METRICS_AVAILABLE = True
except ImportError:
    RISK_METRICS_AVAILABLE = False
    RiskMetrics = None

router = APIRouter(prefix="/api/v1/risk", tags=["é£Žé™©ç®¡ç†-Week1"])

from app.schemas.risk_schemas import (
    BetaRequest,
    BetaResult,
    NotificationTestRequest,
    NotificationTestResponse,
    RiskAlertCreate,
    RiskAlertResponse,
    RiskAlertUpdate,
    RiskDashboardResponse,
    VaRCVaRRequest,
    VaRCVaRResult,
)

# ============ é£Žé™©æŒ‡æ ‡è®¡ç®— ============


@router.post("/var-cvar", response_model=VaRCVaRResult)
async def calculate_var_cvar(request: VaRCVaRRequest) -> VaRCVaRResult:
    """
    è®¡ç®—VaRå’ŒCVaR

    Args:
        request: è¯·æ±‚å‚æ•°

    Returns:
        VaRCVaRResult
    """
    from src.data_sources.factory import get_timeseries_source
    
    manager = MyStocksUnifiedManager()
    db = get_monitoring_db()
    
    return await RiskService.calculate_var_cvar_logic(
        entity_type=request.entity_type,
        entity_id=request.entity_id,
        confidence_level=request.confidence_level,
        unified_manager=manager,
        monitoring_db=db,
        ts_source_factory=get_timeseries_source
    )


@router.post("/beta", response_model=BetaResult)
async def calculate_beta(request: BetaRequest) -> BetaResult:
    """
    è®¡ç®—Betaç³»æ•°

    Args:
        request: è¯·æ±‚å‚æ•°

    Returns:
        BetaResult
    """
    operation_start = datetime.now()

    try:
        manager = MyStocksUnifiedManager()
        entity_type = request.entity_type
        entity_id = request.entity_id
        market_index = request.market_index

        # èŽ·å–èµ„äº§å’Œå¸‚åœºæ”¶ç›ŠçŽ‡æ•°æ®
        # ä½¿ç”¨ Mock æ•°æ®æºç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        from src.data_sources.factory import get_timeseries_source

        ts_source = get_timeseries_source(source_type="mock")
        ts_source.set_random_seed(42)

        start = datetime.now() - timedelta(days=365)
        end = datetime.now()
        asset_kline = ts_source.get_kline_data(symbol="sh600000", start_time=start, end_time=end, interval="1d")
        if market_index == "000001":
            market_symbol = "sh000001"
        else:
            market_symbol = f"sz{market_index}" if len(market_index) == 6 else market_symbol
        market_kline = ts_source.get_kline_data(symbol=market_symbol, start_time=start, end_time=end, interval="1d")

        if asset_kline is not None and market_kline is not None and len(asset_kline) > 1 and len(market_kline) > 1:
            asset_returns = asset_kline["close"].pct_change().dropna()
            market_returns = market_kline["close"].pct_change().dropna()
        else:
            np.random.seed(42)
            asset_returns = pd.Series(np.random.normal(0.001, 0.02, 252))
            market_returns = pd.Series(np.random.normal(0.0008, 0.015, 252))

        # è®¡ç®—Beta
        beta = RiskCalculator.beta(asset_returns, market_returns)

        # è®¡ç®—ç›¸å…³ç³»æ•°
        correlation = float(asset_returns.corr(market_returns))

        # æ›´æ–°æˆ–åˆ›å»ºé£Žé™©æŒ‡æ ‡è®°å½•
        risk_data = pd.DataFrame(
            [
                {
                    "entity_type": entity_type,
                    "entity_id": entity_id,
                    "metric_date": datetime.now().date(),
                    "beta": beta,
                    "created_at": datetime.now(),
                }
            ]
        )

        result = manager.save_data_by_classification(
            data=risk_data,
            classification=DataClassification.MODEL_OUTPUT,
            table_name="risk_metrics",
            upsert=True,
        )

        # è®°å½•æ“ä½œåˆ°ç›‘æŽ§æ•°æ®åº“
        operation_time = (datetime.now() - operation_start).total_seconds() * 1000
        get_monitoring_db().log_operation(
            operation_type="RISK_CALCULATION",
            table_name="risk_metrics",
            operation_name="calculate_beta",
            rows_affected=1,
            operation_time_ms=operation_time,
            success=result,
        )

        return BetaResult(
            beta=beta, correlation=correlation, entity_type=entity_type, entity_id=entity_id, market_index=market_index
        )

    except Exception as e:
        operation_time = (datetime.now() - operation_start).total_seconds() * 1000
        get_monitoring_db().log_operation(
            operation_type="RISK_CALCULATION",
            table_name="risk_metrics",
            operation_name="calculate_beta",
            rows_affected=0,
            operation_time_ms=operation_time,
            success=False,
            error_message=str(e),
        )
        raise BusinessException(detail=f"è®¡ç®—Betaå¤±è´¥: {str(e)}", status_code=500, error_code="BETA_CALCULATION_FAILED")


@router.get("/dashboard", response_model=RiskDashboardResponse)
async def get_risk_dashboard() -> RiskDashboardResponse:
    """
    èŽ·å–é£Žé™©ä»ªè¡¨ç›˜æ•°æ®

    Returns:
        RiskDashboardResponse
    """
    try:
        manager = MyStocksUnifiedManager()

        # èŽ·å–æœ€æ–°é£Žé™©æŒ‡æ ‡
        metrics_df = manager.load_data_by_classification(
            classification=DataClassification.MODEL_OUTPUT, table_name="risk_metrics"
        )

        latest_metrics = None
        if metrics_df is not None and len(metrics_df) > 0:
            latest_metrics = metrics_df.sort_values("metric_date", ascending=False).iloc[0].to_dict()

        # èŽ·å–æ´»è·ƒé¢„è­¦è§„åˆ™
        alerts_df = manager.load_data_by_classification(
            classification=DataClassification.MODEL_OUTPUT,
            table_name="risk_alerts",
            filters={"is_active": True},
        )

        active_alerts = alerts_df.to_dict("records") if alerts_df is not None else []

        # èŽ·å–é£Žé™©åŽ†å²ï¼ˆæœ€è¿‘30å¤©ï¼‰
        thirty_days_ago = (datetime.now() - timedelta(days=30)).date()
        # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–äº†è¿‡æ»¤é€»è¾‘ï¼Œå®žé™…åº”è¯¥æ”¯æŒæ—¥æœŸèŒƒå›´è¿‡æ»¤
        history_df = manager.load_data_by_classification(
            classification=DataClassification.MODEL_OUTPUT, table_name="risk_metrics"
        )

        risk_history = []
        if history_df is not None:
            history_df = history_df[history_df["metric_date"] >= pd.Timestamp(thirty_days_ago)]
            risk_history = history_df.sort_values("metric_date").to_dict("records")

        return {
            "metrics": {
                "var_95_hist": (latest_metrics.get("var_95_hist") if latest_metrics else None),
                "cvar_95": latest_metrics.get("cvar_95") if latest_metrics else None,
                "beta": latest_metrics.get("beta") if latest_metrics else None,
            },
            "active_alerts": [
                {
                    "id": alert["id"],
                    "name": alert["name"],
                    "metric_type": alert["metric_type"],
                    "threshold_value": alert["threshold_value"],
                }
                for alert in active_alerts
            ],
            "risk_history": [
                {
                    "date": (metric["metric_date"]),
                    "var_95_hist": metric.get("var_95_hist"),
                    "cvar_95": metric.get("cvar_95"),
                    "beta": metric.get("beta"),
                }
                for metric in risk_history
            ],
        }

    except Exception as e:
        raise BusinessException(
            detail=f"èŽ·å–ä»ªè¡¨ç›˜æ•°æ®å¤±è´¥: {str(e)}", status_code=500, error_code="DASHBOARD_DATA_RETRIEVAL_FAILED"
        )


# å¯¼å…¥ V3.1 è·¯ç”±
from .risk_management_v31 import router as router_v31

router.include_router(router_v31)

# ============ é£Žé™©é¢„è­¦ç®¡ç† ============


@router.get("/alerts")
async def list_risk_alerts(is_active: Optional[bool] = None) -> List[Dict[str, Any]]:
    """èŽ·å–é£Žé™©é¢„è­¦è§„åˆ™åˆ—è¡¨"""
    try:
        manager = MyStocksUnifiedManager()

        filters = {}
        if is_active is not None:
            filters["is_active"] = is_active

        alerts_df = manager.load_data_by_classification(
            classification=DataClassification.MODEL_OUTPUT,
            table_name="risk_alerts",
            filters=filters,
        )

        return alerts_df.to_dict("records") if alerts_df is not None else []

    except Exception as e:
        raise BusinessException(
            detail=f"èŽ·å–é¢„è­¦åˆ—è¡¨å¤±è´¥: {str(e)}", status_code=500, error_code="ALERT_LIST_RETRIEVAL_FAILED"
        )


@router.post("/alerts", response_model=RiskAlertResponse)
async def create_risk_alert(alert_data: RiskAlertCreate) -> RiskAlertResponse:
    """åˆ›å»ºé£Žé™©é¢„è­¦è§„åˆ™"""
    operation_start = datetime.now()

    try:
        manager = MyStocksUnifiedManager()

        # è½¬æ¢ä¸ºå­—å…¸
        data_dict = alert_data.dict()
        data_dict["created_at"] = datetime.now()
        data_dict["updated_at"] = datetime.now()

        alert_df = pd.DataFrame([data_dict])

        result = manager.save_data_by_classification(
            data=alert_df,
            classification=DataClassification.MODEL_OUTPUT,
            table_name="risk_alerts",
        )

        # è®°å½•æ“ä½œ
        operation_time = (datetime.now() - operation_start).total_seconds() * 1000
        get_monitoring_db().log_operation(
            operation_type="INSERT",
            table_name="risk_alerts",
            operation_name="create_risk_alert",
            rows_affected=1,
            operation_time_ms=operation_time,
            success=result,
        )

        if result:
            # èŽ·å– ID (æ¨¡æ‹Ÿï¼Œå®žé™…åº”è¯¥ä»Žæ•°æ®åº“è¿”å›ž)
            data_dict["id"] = int(datetime.now().timestamp())
            return RiskAlertResponse(**data_dict)
        else:
            raise BusinessException(detail="åˆ›å»ºé¢„è­¦è§„åˆ™å¤±è´¥", status_code=500, error_code="ALERT_RULE_CREATION_FAILED")

    except Exception as e:
        operation_time = (datetime.now() - operation_start).total_seconds() * 1000
        get_monitoring_db().log_operation(
            operation_type="INSERT",
            table_name="risk_alerts",
            operation_name="create_risk_alert",
            rows_affected=0,
            operation_time_ms=operation_time,
            success=False,
            error_message=str(e),
        )
        raise BusinessException(
            detail=f"åˆ›å»ºé¢„è­¦è§„åˆ™å¤±è´¥: {str(e)}", status_code=500, error_code="ALERT_RULE_CREATION_FAILED"
        )


@router.put("/alerts/{alert_id}")
async def update_risk_alert(alert_id: int, alert_update: RiskAlertUpdate) -> Dict[str, str]:
    """æ›´æ–°é£Žé™©é¢„è­¦è§„åˆ™"""
    try:
        manager = MyStocksUnifiedManager()

        update_data = alert_update.dict(exclude_unset=True)
        update_data["id"] = alert_id
        update_data["updated_at"] = datetime.now()

        alert_df = pd.DataFrame([update_data])

        result = manager.save_data_by_classification(
            data=alert_df,
            classification=DataClassification.MODEL_OUTPUT,
            table_name="risk_alerts",
            upsert=True,
        )

        if result:
            return {"message": "é¢„è­¦è§„åˆ™å·²æ›´æ–°"}
        else:
            raise BusinessException(detail="æ›´æ–°é¢„è­¦è§„åˆ™å¤±è´¥", status_code=500, error_code="ALERT_RULE_UPDATE_FAILED")

    except Exception as e:
        raise BusinessException(
            detail=f"æ›´æ–°é¢„è­¦è§„åˆ™å¤±è´¥: {str(e)}", status_code=500, error_code="ALERT_RULE_UPDATE_FAILED"
        )


@router.delete("/alerts/{alert_id}")
async def delete_risk_alert(alert_id: int) -> Dict[str, str]:
    """åˆ é™¤é£Žé™©é¢„è­¦è§„åˆ™ï¼ˆè½¯åˆ é™¤ï¼šè®¾ç½®ä¸ºéžæ´»è·ƒï¼‰"""
    try:
        manager = MyStocksUnifiedManager()

        # è½¯åˆ é™¤ï¼šæ›´æ–°is_activeä¸ºFalse
        alert_df = pd.DataFrame([{"id": alert_id, "is_active": False}])

        result = manager.save_data_by_classification(
            data=alert_df,
            classification=DataClassification.MODEL_OUTPUT,
            table_name="risk_alerts",
            upsert=True,
        )

        if result:
            return {"message": "é¢„è­¦è§„åˆ™å·²ç¦ç”¨"}
        else:
            raise BusinessException(detail="åˆ é™¤é¢„è­¦è§„åˆ™å¤±è´¥", status_code=500, error_code="ALERT_RULE_DELETION_FAILED")

    except Exception as e:
        raise BusinessException(
            detail=f"åˆ é™¤é¢„è­¦è§„åˆ™å¤±è´¥: {str(e)}", status_code=500, error_code="ALERT_RULE_DELETION_FAILED"
        )


# ============ é€šçŸ¥ç®¡ç† ============


@router.post("/notifications/test", response_model=NotificationTestResponse)
async def test_notification(request: NotificationTestRequest) -> NotificationTestResponse:
    """å‘é€æµ‹è¯•é€šçŸ¥"""
    try:
        notifier = NotificationManager()

        if request.notification_type == "email":
            result = notifier.send_email(
                to_addrs=[request.config_data.get("email")],
                subject="MyStocks æµ‹è¯•é€šçŸ¥",
                message="è¿™æ˜¯ä¸€å°æµ‹è¯•é‚®ä»¶ï¼Œæ‚¨çš„é‚®ä»¶é…ç½®æ­£å¸¸å·¥ä½œï¼",
            )
        elif request.notification_type == "webhook":
            result = notifier.send_webhook(message="MyStocks æµ‹è¯•é€šçŸ¥", test=True)
        else:
            raise ValidationException(detail="ä¸æ”¯æŒçš„é€šçŸ¥ç±»åž‹", field="notification_type")

        if result:
            return NotificationTestResponse(success=True, message="æµ‹è¯•é€šçŸ¥å‘é€æˆåŠŸ")
        else:
            return NotificationTestResponse(success=False, message="æµ‹è¯•é€šçŸ¥å‘é€å¤±è´¥")

    except Exception as e:
        raise BusinessException(detail=f"å‘é€å¤±è´¥: {str(e)}", status_code=500, error_code="SENDING_FAILED")


# ============ é£Žé™©æŒ‡æ ‡è®¡ç®—ï¼ˆæ–°åŠŸèƒ½ - 2025-12-26ï¼‰============


@router.post("/metrics/calculate")
async def calculate_risk_metrics(request: Dict[str, Any]) -> Dict[str, Any]:
    """
    è®¡ç®—å®Œæ•´çš„é£Žé™©æŒ‡æ ‡ï¼ˆä½¿ç”¨ä¸»é¡¹ç›®RiskMetricsç±»ï¼‰

    ## è¯·æ±‚ç¤ºä¾‹
    ```json
    {
      "equity_curve": [100000, 102000, 101000, 103000, 105000],
      "returns": [0.02, -0.01, 0.02, 0.02],
      "trades": [],
      "total_return": 0.05,
      "max_drawdown": -0.02,
      "risk_free_rate": 0.03
    }
    ```
    """
    try:
        if RISK_METRICS_AVAILABLE and RiskMetrics:
            logger.info("ðŸ“Š ä½¿ç”¨ä¸»é¡¹ç›®é£Žé™©æŒ‡æ ‡è®¡ç®—æ¨¡å—")

            # è½¬æ¢æ•°æ®æ ¼å¼
            equity_df = pd.DataFrame({"equity": request.get("equity_curve", [])})
            returns_series = pd.Series(request.get("returns", []))
            trades = request.get("trades", [])

            # è®¡ç®—æ‰€æœ‰é£Žé™©æŒ‡æ ‡
            risk_calculator = RiskMetrics()
            metrics = risk_calculator.calculate_all_risk_metrics(
                equity_curve=equity_df,
                returns=returns_series,
                trades=trades,
                total_return=request.get("total_return", 0),
                max_drawdown=request.get("max_drawdown", 0),
                risk_free_rate=request.get("risk_free_rate", 0.03),
            )

            return {
                "status": "success",
                "metrics": metrics,
                "calculated_at": datetime.now().isoformat(),
                "module": "RiskMetrics (main project)",
            }
        else:
            logger.info("ðŸ“Š ä¸»é¡¹ç›®é£Žé™©æŒ‡æ ‡æ¨¡å—ä¸å¯ç”¨ï¼Œè¿”å›žç®€åŒ–æŒ‡æ ‡")
            # ç®€åŒ–ç‰ˆè®¡ç®—
            returns_series = pd.Series(request.get("returns", []))
            # equity_curve = request.get("equity_curve", [])

            metrics = {
                "volatility": float(returns_series.std() * np.sqrt(252)) if len(returns_series) > 0 else 0,
                "sharpe_ratio": (
                    float((returns_series.mean() * 252) / (returns_series.std() * np.sqrt(252)))
                    if returns_series.std() > 0
                    else 0
                ),
                "max_drawdown": request.get("max_drawdown", 0),
                "skewness": float(returns_series.skew()) if len(returns_series) > 0 else 0,
                "kurtosis": float(returns_series.kurtosis()) if len(returns_series) > 0 else 0,
            }

            return {
                "status": "success",
                "metrics": metrics,
                "calculated_at": datetime.now().isoformat(),
                "module": "Simplified (fallback)",
            }

    except Exception as e:
        logger.error("è®¡ç®—é£Žé™©æŒ‡æ ‡å¤±è´¥: {e}", exc_info=True)
        raise BusinessException(
            detail=f"è®¡ç®—é£Žé™©æŒ‡æ ‡å¤±è´¥: {str(e)}", status_code=500, error_code="RISK_METRICS_CALCULATION_FAILED"
        )


@router.post("/position/assess")
async def assess_position_risk(request: Dict[str, Any]) -> Dict[str, Any]:
    """
    è¯„ä¼°ä»“ä½é£Žé™©

    ## è¯·æ±‚ç¤ºä¾‹
    ```json
    {
      "positions": [
        {"symbol": "sh600000", "value": 150000, "sector": "é‡‘èž"},
        {"symbol": "sh600036", "value": 120000, "sector": "é‡‘èž"}
      ],
      "total_capital": 1000000,
      "config": {
        "max_position_size": 0.10,
        "daily_loss_limit": 0.05
      }
    }
    ```
    """
    try:
        positions = request.get("positions", [])
        total_capital = request.get("total_capital", 1000000)
        config = request.get("config", {})

        max_position_size = config.get("max_position_size", 0.10)

        # è®¡ç®—æ€»ä»“ä½
        total_position_value = sum(p.get("value", 0) for p in positions)
        position_ratio = total_position_value / total_capital if total_capital > 0 else 0
        cash_ratio = 1 - position_ratio

        # ä¸ªè‚¡é›†ä¸­åº¦åˆ†æž
        position_concentration = []
        exceeded_positions = []
        sector_concentration = {}

        for pos in positions:
            symbol = pos.get("symbol", "UNKNOWN")
            value = pos.get("value", 0)
            sector = pos.get("sector", "UNKNOWN")

            concentration = value / total_capital if total_capital > 0 else 0
            exceeds_limit = concentration > max_position_size

            position_concentration.append(
                {"symbol": symbol, "concentration": concentration, "exceeds_limit": exceeds_limit}
            )

            if exceeds_limit:
                exceeded_positions.append({"symbol": symbol, "concentration": concentration})

            # è¡Œä¸šé›†ä¸­åº¦
            if sector not in sector_concentration:
                sector_concentration[sector] = 0
            sector_concentration[sector] += value

        # HerfindahlæŒ‡æ•°ï¼ˆæŒä»“é›†ä¸­åº¦ï¼‰
        position_sizes = [p["value"] / total_capital for p in positions if total_capital > 0]
        herfindahl_index = sum(p**2 for p in position_sizes) if position_sizes else 0

        # é£Žé™©ç­‰çº§è¯„ä¼°
        if len(exceeded_positions) > 0 or herfindahl_index > 0.5:
            risk_level = "HIGH"
        elif herfindahl_index > 0.25:
            risk_level = "MEDIUM"
        else:
            risk_level = "LOW"

        return {
            "status": "success",
            "risk_assessment": {
                "total_position_value": total_position_value,
                "position_ratio": position_ratio,
                "cash_ratio": cash_ratio,
                "position_concentration": position_concentration,
                "exceeded_positions": exceeded_positions,
                "high_concentration_risk": len(exceeded_positions) > 0,
                "sector_concentration": {
                    sector: value / total_capital if total_capital > 0 else 0
                    for sector, value in sector_concentration.items()
                },
                "herfindahl_index": herfindahl_index,
                "risk_level": risk_level,
            },
            "assessed_at": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error("è¯„ä¼°ä»“ä½é£Žé™©å¤±è´¥: {e}", exc_info=True)
        raise BusinessException(
            detail=f"è¯„ä¼°ä»“ä½é£Žé™©å¤±è´¥: {str(e)}", status_code=500, error_code="POSITION_RISK_ASSESSMENT_FAILED"
        )


@router.post("/alerts/generate")
async def generate_risk_alerts(request: Dict[str, Any]) -> Dict[str, Any]:
    """
    ç”Ÿæˆé£Žé™©å‘Šè­¦

    ## è¯·æ±‚ç¤ºä¾‹
    ```json
    {
      "current_drawdown": -0.25,
      "daily_pnl": -60000,
      "total_capital": 1000000,
      "config": {
        "max_drawdown_threshold": 0.30,
        "daily_loss_limit": 0.05
      }
    }
    ```
    """
    try:
        current_drawdown = request.get("current_drawdown", 0)
        daily_pnl = request.get("daily_pnl", 0)
        total_capital = request.get("total_capital", 1000000)
        config = request.get("config", {})

        max_drawdown_threshold = config.get("max_drawdown_threshold", 0.30)
        daily_loss_limit = config.get("daily_loss_limit", 0.05)

        alerts = []
        alert_time = datetime.now().isoformat()

        # å›žæ’¤å‘Šè­¦
        if abs(current_drawdown) > max_drawdown_threshold:
            alerts.append(
                {
                    "type": "max_drawdown_exceeded",
                    "severity": "CRITICAL",
                    "message": (
                        f"æœ€å¤§å›žæ’¤è¶…é™: {abs(current_drawdown) * 100:.2f}% > {max_drawdown_threshold * 100:.2f}%"
                    ),
                    "timestamp": alert_time,
                    "suggestion": "ç«‹å³å‡ä»“æˆ–å¹³ä»“ï¼ŒæŽ§åˆ¶é£Žé™©æ•žå£",
                }
            )

        # å•æ—¥äºæŸå‘Šè­¦
        daily_loss_pct = daily_pnl / total_capital if total_capital > 0 else 0
        if daily_loss_pct < -daily_loss_limit:
            alerts.append(
                {
                    "type": "daily_loss_limit_exceeded",
                    "severity": "WARNING",
                    "message": f"å•æ—¥äºæŸè¶…é™: {daily_loss_pct * 100:.2f}% < -{daily_loss_limit * 100:.2f}%",
                    "timestamp": alert_time,
                    "suggestion": "æš‚åœæ–°å¼€ä»“ï¼Œè¯„ä¼°å½“å‰æŒä»“é£Žé™©",
                }
            )

        return {"status": "success", "alerts": alerts, "alert_count": len(alerts), "generated_at": alert_time}

    except Exception as e:
        logger.error("ç”Ÿæˆé£Žé™©å‘Šè­¦å¤±è´¥: {e}", exc_info=True)
        raise BusinessException(
            detail=f"ç”Ÿæˆé£Žé™©å‘Šè­¦å¤±è´¥: {str(e)}", status_code=500, error_code="RISK_ALERT_GENERATION_FAILED"
        )


# ===== é›†æˆé£Žé™©äº‹ä»¶åˆ°WebSocketå¹¿æ’­ =====


# åœ¨æ¨¡å—å¯¼å…¥æ—¶è‡ªåŠ¨è®¾ç½®å¹¿æ’­ï¼ˆå¦‚æžœçŽ¯å¢ƒæ”¯æŒï¼‰
try:
    asyncio.create_task(setup_risk_event_broadcasting(ENHANCED_RISK_FEATURES_AVAILABLE))
except Exception:
    # åœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­è·³è¿‡
    pass
