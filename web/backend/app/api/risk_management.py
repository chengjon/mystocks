"""
é£é™©ç®¡ç† API - Week 1 Architecture Compliant

æä¾›VaR/CVaRè®¡ç®—ã€Betaåˆ†æã€é£é™©é¢„è­¦ç­‰æ¥å£
ä½¿ç”¨ MyStocksUnifiedManager ç»Ÿä¸€æ•°æ®è®¿é—® + MonitoringDatabase ç›‘æ§é›†æˆ

Author: JohnC & Claude
Version: 2.0.0 (Architecture Compliant)
Date: 2025-10-24
"""

from fastapi import APIRouter, HTTPException
from typing import Optional, List, Dict, Any
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import sys
import os
import structlog

logger = structlog.get_logger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../../"))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# ä½¿ç”¨ MyStocksUnifiedManager ä½œä¸ºç»Ÿä¸€å…¥å£ç‚¹
from unified_manager import MyStocksUnifiedManager
from src.core import DataClassification
from src.monitoring.monitoring_database import MonitoringDatabase

# å¯¼å…¥ NotificationManager
try:
    from src.ml_strategy.automation.notification_manager import (
        NotificationManager,
        NotificationChannel,
        NotificationLevel,
    )
except ImportError:
    NotificationManager = None
    NotificationChannel = None
    NotificationLevel = None


# æœ¬åœ°å®ç°çš„é£é™©è®¡ç®—å™¨ (æ›¿ä»£ ExtendedRiskMetrics)
class RiskCalculator:
    """æä¾›åŸºç¡€é£é™©æŒ‡æ ‡è®¡ç®— (VaR, CVaR, Beta)"""

    @staticmethod
    def calculate_all(returns: pd.Series, confidence_level: float = 0.95) -> Dict[str, float]:
        """è®¡ç®— VaR å’Œ CVaR"""
        if returns.empty:
            return {"var_95_hist": 0.0, "var_95_param": 0.0, "var_99_hist": 0.0, "cvar_95": 0.0, "cvar_99": 0.0}

        # å†å²æ¨¡æ‹Ÿæ³•
        var_95_hist = float(np.percentile(returns, (1 - confidence_level) * 100))
        var_99_hist = float(np.percentile(returns, 1))  # Fixed 99% for compatibility

        # å‚æ•°æ³• (å‡è®¾æ­£æ€åˆ†å¸ƒ)
        mean = returns.mean()
        std = returns.std()
        var_95_param = float(mean - 1.645 * std)

        # CVaR (Expected Shortfall)
        cvar_95 = float(returns[returns <= var_95_hist].mean())
        cvar_99 = float(returns[returns <= var_99_hist].mean())

        return {
            "var_95_hist": var_95_hist,
            "var_95_param": var_95_param,
            "var_99_hist": var_99_hist,
            "cvar_95": cvar_95 if not np.isnan(cvar_95) else 0.0,
            "cvar_99": cvar_99 if not np.isnan(cvar_99) else 0.0,
        }

    @staticmethod
    def beta(asset_returns: pd.Series, market_returns: pd.Series) -> float:
        """è®¡ç®— Beta ç³»æ•°"""
        if asset_returns.empty or market_returns.empty:
            return 0.0

        # ç¡®ä¿é•¿åº¦ä¸€è‡´
        min_len = min(len(asset_returns), len(market_returns))
        asset = asset_returns.iloc[:min_len]
        market = market_returns.iloc[:min_len]

        covariance = np.cov(asset, market)[0][1]
        market_variance = np.var(market)

        if market_variance == 0:
            return 0.0

        return float(covariance / market_variance)


# é£é™©æŒ‡æ ‡è®¡ç®—æ¨¡å—ï¼ˆæ–°åŠŸèƒ½ - 2025-12-26ï¼‰
try:
    from src.ml_strategy.backtest.risk_metrics import RiskMetrics

    RISK_METRICS_AVAILABLE = True
except ImportError:
    RISK_METRICS_AVAILABLE = False
    RiskMetrics = None

router = APIRouter(prefix="/api/v1/risk", tags=["é£é™©ç®¡ç†-Week1"])

# å»¶è¿Ÿåˆå§‹åŒ–ç›‘æ§æ•°æ®åº“ï¼ˆé¿å…å¯¼å…¥æ—¶éœ€è¦å®Œæ•´ç¯å¢ƒå˜é‡ï¼‰
monitoring_db = None


def get_monitoring_db():
    """è·å–ç›‘æ§æ•°æ®åº“å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
    global monitoring_db
    if monitoring_db is None:
        try:
            real_monitoring_db = MonitoringDatabase()

            # åˆ›å»ºé€‚é…å™¨æ¥åŒ¹é…Week1 APIçš„å‚æ•°å‘½åçº¦å®š
            class MonitoringAdapter:
                def __init__(self, real_db):
                    self.real_db = real_db

                def log_operation(
                    self,
                    operation_type="UNKNOWN",
                    table_name=None,
                    operation_name=None,
                    rows_affected=0,
                    operation_time_ms=0,
                    success=True,
                    details="",
                    **kwargs,
                ):
                    """é€‚é…Week1 APIçš„å‚æ•°å‘½ååˆ°MonitoringDatabaseçš„å®é™…å‚æ•°"""
                    try:
                        return self.real_db.log_operation(
                            operation_type=operation_type,
                            classification="DERIVED_DATA",
                            target_database="PostgreSQL",
                            table_name=table_name,
                            record_count=rows_affected,
                            operation_status="SUCCESS" if success else "FAILED",
                            error_message=None if success else details,
                            execution_time_ms=int(operation_time_ms),
                            additional_info=(
                                {"operation_name": operation_name, "details": details}
                                if operation_name or details
                                else None
                            ),
                        )
                    except Exception as e:
                        logger.debug(f"Monitoring log failed (non-critical): {e}")
                        return False

            monitoring_db = MonitoringAdapter(real_monitoring_db)

        except Exception as e:
            logger.warning(f"MonitoringDatabase initialization failed, using fallback: {e}")

            # åˆ›å»ºä¸€ä¸ªç®€å•çš„fallbackå¯¹è±¡
            class MonitoringFallback:
                def log_operation(self, *args, **kwargs):
                    return True  # Silent fallback

            monitoring_db = MonitoringFallback()
    return monitoring_db


from app.schemas.risk_schemas import (
    VaRCVaRRequest,
    VaRCVaRResult,
    BetaRequest,
    BetaResult,
    RiskAlertCreate,
    RiskAlertUpdate,
    RiskAlertResponse,
    NotificationTestRequest,
    NotificationTestResponse,
    RiskDashboardResponse,
)

# ============ é£é™©æŒ‡æ ‡è®¡ç®— ============


@router.post("/var-cvar", response_model=VaRCVaRResult)
async def calculate_var_cvar(request: VaRCVaRRequest) -> VaRCVaRResult:
    """
    è®¡ç®—VaRå’ŒCVaR

    Args:
        request: è¯·æ±‚å‚æ•°

    Returns:
        VaRCVaRResult
    """
    operation_start = datetime.now()

    try:
        manager = MyStocksUnifiedManager()
        entity_type = request.entity_type
        entity_id = request.entity_id
        confidence_level = request.confidence_level

        # è·å–æ”¶ç›Šç‡æ•°æ®
        # ä½¿ç”¨ Mock æ•°æ®æºç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        from src.data_sources.factory import get_timeseries_source

        ts_source = get_timeseries_source(source_type="mock")
        ts_source.set_random_seed(42)

        start = datetime.now() - timedelta(days=365)
        end = datetime.now()
        kline = ts_source.get_kline_data(symbol="sh600000", start_time=start, end_time=end, interval="1d")
        if kline is not None and len(kline) > 1:
            returns = kline["close"].pct_change().dropna()
        else:
            returns = pd.Series(np.random.normal(0.001, 0.02, 252))

        # è®¡ç®—é£é™©æŒ‡æ ‡
        metrics = RiskCalculator.calculate_all(returns)

        # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆä½¿ç”¨ UnifiedManagerï¼‰
        risk_data = pd.DataFrame(
            [
                {
                    "entity_type": entity_type,
                    "entity_id": entity_id,
                    "metric_date": datetime.now().date(),
                    "var_95_hist": metrics["var_95_hist"],
                    "var_95_param": metrics["var_95_param"],
                    "var_99_hist": metrics["var_99_hist"],
                    "cvar_95": metrics["cvar_95"],
                    "cvar_99": metrics["cvar_99"],
                    "created_at": datetime.now(),
                }
            ]
        )

        result = manager.save_data_by_classification(
            data=risk_data,
            classification=DataClassification.MODEL_OUTPUT,
            table_name="risk_metrics",
        )

        # è®°å½•æ“ä½œåˆ°ç›‘æ§æ•°æ®åº“
        operation_time = (datetime.now() - operation_start).total_seconds() * 1000
        get_monitoring_db().log_operation(
            operation_type="RISK_CALCULATION",
            table_name="risk_metrics",
            operation_name="calculate_var_cvar",
            rows_affected=1,
            operation_time_ms=operation_time,
            success=result,
            details=f"entity_type={entity_type}, entity_id={entity_id}",
        )

        if not result:
            raise HTTPException(status_code=500, detail="ä¿å­˜é£é™©æŒ‡æ ‡å¤±è´¥")

        return VaRCVaRResult(
            var_95_hist=metrics["var_95_hist"],
            var_95_param=metrics["var_95_param"],
            var_99_hist=metrics["var_99_hist"],
            cvar_95=metrics["cvar_95"],
            cvar_99=metrics["cvar_99"],
            entity_type=entity_type,
            entity_id=entity_id,
            confidence_level=confidence_level,
        )

    except Exception as e:
        # è®°å½•å¤±è´¥æ“ä½œ
        operation_time = (datetime.now() - operation_start).total_seconds() * 1000
        get_monitoring_db().log_operation(
            operation_type="RISK_CALCULATION",
            table_name="risk_metrics",
            operation_name="calculate_var_cvar",
            rows_affected=0,
            operation_time_ms=operation_time,
            success=False,
            error_message=str(e),
        )
        raise HTTPException(status_code=500, detail=f"è®¡ç®—VaR/CVaRå¤±è´¥: {str(e)}")


@router.post("/beta", response_model=BetaResult)
async def calculate_beta(request: BetaRequest) -> BetaResult:
    """
    è®¡ç®—Betaç³»æ•°

    Args:
        request: è¯·æ±‚å‚æ•°

    Returns:
        BetaResult
    """
    operation_start = datetime.now()

    try:
        manager = MyStocksUnifiedManager()
        entity_type = request.entity_type
        entity_id = request.entity_id
        market_index = request.market_index

        # è·å–èµ„äº§å’Œå¸‚åœºæ”¶ç›Šç‡æ•°æ®
        # ä½¿ç”¨ Mock æ•°æ®æºç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        from src.data_sources.factory import get_timeseries_source

        ts_source = get_timeseries_source(source_type="mock")
        ts_source.set_random_seed(42)

        start = datetime.now() - timedelta(days=365)
        end = datetime.now()
        asset_kline = ts_source.get_kline_data(symbol="sh600000", start_time=start, end_time=end, interval="1d")
        if market_index == "000001":
            market_symbol = "sh000001"
        else:
            market_symbol = f"sz{market_index}" if len(market_index) == 6 else market_symbol
        market_kline = ts_source.get_kline_data(symbol=market_symbol, start_time=start, end_time=end, interval="1d")

        if asset_kline is not None and market_kline is not None and len(asset_kline) > 1 and len(market_kline) > 1:
            asset_returns = asset_kline["close"].pct_change().dropna()
            market_returns = market_kline["close"].pct_change().dropna()
        else:
            np.random.seed(42)
            asset_returns = pd.Series(np.random.normal(0.001, 0.02, 252))
            market_returns = pd.Series(np.random.normal(0.0008, 0.015, 252))

        # è®¡ç®—Beta
        beta = RiskCalculator.beta(asset_returns, market_returns)

        # è®¡ç®—ç›¸å…³ç³»æ•°
        correlation = float(asset_returns.corr(market_returns))

        # æ›´æ–°æˆ–åˆ›å»ºé£é™©æŒ‡æ ‡è®°å½•
        risk_data = pd.DataFrame(
            [
                {
                    "entity_type": entity_type,
                    "entity_id": entity_id,
                    "metric_date": datetime.now().date(),
                    "beta": beta,
                    "created_at": datetime.now(),
                }
            ]
        )

        result = manager.save_data_by_classification(
            data=risk_data,
            classification=DataClassification.MODEL_OUTPUT,
            table_name="risk_metrics",
            upsert=True,
        )

        # è®°å½•æ“ä½œåˆ°ç›‘æ§æ•°æ®åº“
        operation_time = (datetime.now() - operation_start).total_seconds() * 1000
        get_monitoring_db().log_operation(
            operation_type="RISK_CALCULATION",
            table_name="risk_metrics",
            operation_name="calculate_beta",
            rows_affected=1,
            operation_time_ms=operation_time,
            success=result,
        )

        return BetaResult(
            beta=beta, correlation=correlation, entity_type=entity_type, entity_id=entity_id, market_index=market_index
        )

    except Exception as e:
        operation_time = (datetime.now() - operation_start).total_seconds() * 1000
        get_monitoring_db().log_operation(
            operation_type="RISK_CALCULATION",
            table_name="risk_metrics",
            operation_name="calculate_beta",
            rows_affected=0,
            operation_time_ms=operation_time,
            success=False,
            error_message=str(e),
        )
        raise HTTPException(status_code=500, detail=f"è®¡ç®—Betaå¤±è´¥: {str(e)}")


@router.get("/dashboard", response_model=RiskDashboardResponse)
async def get_risk_dashboard() -> RiskDashboardResponse:
    """
    è·å–é£é™©ä»ªè¡¨ç›˜æ•°æ®

    Returns:
        RiskDashboardResponse
    """
    try:
        manager = MyStocksUnifiedManager()

        # è·å–æœ€æ–°é£é™©æŒ‡æ ‡
        metrics_df = manager.load_data_by_classification(
            classification=DataClassification.MODEL_OUTPUT, table_name="risk_metrics"
        )

        latest_metrics = None
        if metrics_df is not None and len(metrics_df) > 0:
            latest_metrics = metrics_df.sort_values("metric_date", ascending=False).iloc[0].to_dict()

        # è·å–æ´»è·ƒé¢„è­¦è§„åˆ™
        alerts_df = manager.load_data_by_classification(
            classification=DataClassification.MODEL_OUTPUT,
            table_name="risk_alerts",
            filters={"is_active": True},
        )

        active_alerts = alerts_df.to_dict("records") if alerts_df is not None else []

        # è·å–é£é™©å†å²ï¼ˆæœ€è¿‘30å¤©ï¼‰
        thirty_days_ago = (datetime.now() - timedelta(days=30)).date()
        # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–äº†è¿‡æ»¤é€»è¾‘ï¼Œå®é™…åº”è¯¥æ”¯æŒæ—¥æœŸèŒƒå›´è¿‡æ»¤
        history_df = manager.load_data_by_classification(
            classification=DataClassification.MODEL_OUTPUT, table_name="risk_metrics"
        )

        risk_history = []
        if history_df is not None:
            history_df = history_df[history_df["metric_date"] >= pd.Timestamp(thirty_days_ago)]
            risk_history = history_df.sort_values("metric_date").to_dict("records")

        return {
            "metrics": {
                "var_95_hist": (latest_metrics.get("var_95_hist") if latest_metrics else None),
                "cvar_95": latest_metrics.get("cvar_95") if latest_metrics else None,
                "beta": latest_metrics.get("beta") if latest_metrics else None,
            },
            "active_alerts": [
                {
                    "id": alert["id"],
                    "name": alert["name"],
                    "metric_type": alert["metric_type"],
                    "threshold_value": alert["threshold_value"],
                }
                for alert in active_alerts
            ],
            "risk_history": [
                {
                    "date": (metric["metric_date"]),
                    "var_95_hist": metric.get("var_95_hist"),
                    "cvar_95": metric.get("cvar_95"),
                    "beta": metric.get("beta"),
                }
                for metric in risk_history
            ],
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ä»ªè¡¨ç›˜æ•°æ®å¤±è´¥: {str(e)}")


@router.get("/metrics/history", response_model=List[Dict[str, Any]])
async def get_risk_metrics_history(
    entity_type: str, entity_id: int, start_date: str, end_date: str
) -> List[Dict[str, Any]]:
    """è·å–é£é™©æŒ‡æ ‡å†å²æ•°æ®"""
    try:
        manager = MyStocksUnifiedManager()

        # è·å–é£é™©æŒ‡æ ‡æ•°æ®
        metrics_df = manager.load_data_by_classification(
            classification=DataClassification.MODEL_OUTPUT,
            table_name="risk_metrics",
            filters={"entity_type": entity_type, "entity_id": entity_id},
        )

        if metrics_df is None or len(metrics_df) == 0:
            return []

        # æ—¥æœŸè¿‡æ»¤
        metrics_df = metrics_df[
            (metrics_df["metric_date"] >= pd.Timestamp(start_date))
            & (metrics_df["metric_date"] <= pd.Timestamp(end_date))
        ]

        return [
            {
                "date": (metric["metric_date"]),
                "var_95_hist": metric.get("var_95_hist"),
                "var_95_param": metric.get("var_95_param"),
                "cvar_95": metric.get("cvar_95"),
                "beta": metric.get("beta"),
            }
            for metric in metrics_df.sort_values("metric_date").to_dict("records")
        ]

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å†å²æ•°æ®å¤±è´¥: {str(e)}")


# ============ é£é™©é¢„è­¦ç®¡ç† ============


@router.get("/alerts")
async def list_risk_alerts(is_active: Optional[bool] = None) -> List[Dict[str, Any]]:
    """è·å–é£é™©é¢„è­¦è§„åˆ™åˆ—è¡¨"""
    try:
        manager = MyStocksUnifiedManager()

        filters = {}
        if is_active is not None:
            filters["is_active"] = is_active

        alerts_df = manager.load_data_by_classification(
            classification=DataClassification.MODEL_OUTPUT,
            table_name="risk_alerts",
            filters=filters,
        )

        return alerts_df.to_dict("records") if alerts_df is not None else []

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–é¢„è­¦åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.post("/alerts", response_model=RiskAlertResponse)
async def create_risk_alert(alert_data: RiskAlertCreate) -> RiskAlertResponse:
    """åˆ›å»ºé£é™©é¢„è­¦è§„åˆ™"""
    operation_start = datetime.now()

    try:
        manager = MyStocksUnifiedManager()

        # è½¬æ¢ä¸ºå­—å…¸
        data_dict = alert_data.dict()
        data_dict["created_at"] = datetime.now()
        data_dict["updated_at"] = datetime.now()

        alert_df = pd.DataFrame([data_dict])

        result = manager.save_data_by_classification(
            data=alert_df,
            classification=DataClassification.MODEL_OUTPUT,
            table_name="risk_alerts",
        )

        # è®°å½•æ“ä½œ
        operation_time = (datetime.now() - operation_start).total_seconds() * 1000
        get_monitoring_db().log_operation(
            operation_type="INSERT",
            table_name="risk_alerts",
            operation_name="create_risk_alert",
            rows_affected=1,
            operation_time_ms=operation_time,
            success=result,
        )

        if result:
            # è·å– ID (æ¨¡æ‹Ÿï¼Œå®é™…åº”è¯¥ä»æ•°æ®åº“è¿”å›)
            data_dict["id"] = int(datetime.now().timestamp())
            return RiskAlertResponse(**data_dict)
        else:
            raise HTTPException(status_code=500, detail="åˆ›å»ºé¢„è­¦è§„åˆ™å¤±è´¥")

    except Exception as e:
        operation_time = (datetime.now() - operation_start).total_seconds() * 1000
        get_monitoring_db().log_operation(
            operation_type="INSERT",
            table_name="risk_alerts",
            operation_name="create_risk_alert",
            rows_affected=0,
            operation_time_ms=operation_time,
            success=False,
            error_message=str(e),
        )
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºé¢„è­¦è§„åˆ™å¤±è´¥: {str(e)}")


@router.put("/alerts/{alert_id}")
async def update_risk_alert(alert_id: int, alert_update: RiskAlertUpdate) -> Dict[str, str]:
    """æ›´æ–°é£é™©é¢„è­¦è§„åˆ™"""
    try:
        manager = MyStocksUnifiedManager()

        update_data = alert_update.dict(exclude_unset=True)
        update_data["id"] = alert_id
        update_data["updated_at"] = datetime.now()

        alert_df = pd.DataFrame([update_data])

        result = manager.save_data_by_classification(
            data=alert_df,
            classification=DataClassification.MODEL_OUTPUT,
            table_name="risk_alerts",
            upsert=True,
        )

        if result:
            return {"message": "é¢„è­¦è§„åˆ™å·²æ›´æ–°"}
        else:
            raise HTTPException(status_code=500, detail="æ›´æ–°é¢„è­¦è§„åˆ™å¤±è´¥")

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ›´æ–°é¢„è­¦è§„åˆ™å¤±è´¥: {str(e)}")


@router.delete("/alerts/{alert_id}")
async def delete_risk_alert(alert_id: int) -> Dict[str, str]:
    """åˆ é™¤é£é™©é¢„è­¦è§„åˆ™ï¼ˆè½¯åˆ é™¤ï¼šè®¾ç½®ä¸ºéæ´»è·ƒï¼‰"""
    try:
        manager = MyStocksUnifiedManager()

        # è½¯åˆ é™¤ï¼šæ›´æ–°is_activeä¸ºFalse
        alert_df = pd.DataFrame([{"id": alert_id, "is_active": False}])

        result = manager.save_data_by_classification(
            data=alert_df,
            classification=DataClassification.MODEL_OUTPUT,
            table_name="risk_alerts",
            upsert=True,
        )

        if result:
            return {"message": "é¢„è­¦è§„åˆ™å·²ç¦ç”¨"}
        else:
            raise HTTPException(status_code=500, detail="åˆ é™¤é¢„è­¦è§„åˆ™å¤±è´¥")

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ é™¤é¢„è­¦è§„åˆ™å¤±è´¥: {str(e)}")


# ============ é€šçŸ¥ç®¡ç† ============


@router.post("/notifications/test", response_model=NotificationTestResponse)
async def test_notification(request: NotificationTestRequest) -> NotificationTestResponse:
    """å‘é€æµ‹è¯•é€šçŸ¥"""
    try:
        notifier = NotificationManager()

        if request.notification_type == "email":
            result = notifier.send_email(
                to_addrs=[request.config_data.get("email")],
                subject="MyStocks æµ‹è¯•é€šçŸ¥",
                message="è¿™æ˜¯ä¸€å°æµ‹è¯•é‚®ä»¶ï¼Œæ‚¨çš„é‚®ä»¶é…ç½®æ­£å¸¸å·¥ä½œï¼",
            )
        elif request.notification_type == "webhook":
            result = notifier.send_webhook(message="MyStocks æµ‹è¯•é€šçŸ¥", test=True)
        else:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„é€šçŸ¥ç±»å‹")

        if result:
            return NotificationTestResponse(success=True, message="æµ‹è¯•é€šçŸ¥å‘é€æˆåŠŸ")
        else:
            return NotificationTestResponse(success=False, message="æµ‹è¯•é€šçŸ¥å‘é€å¤±è´¥")

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å‘é€å¤±è´¥: {str(e)}")


# ============ é£é™©æŒ‡æ ‡è®¡ç®—ï¼ˆæ–°åŠŸèƒ½ - 2025-12-26ï¼‰============


@router.post("/metrics/calculate")
async def calculate_risk_metrics(request: Dict[str, Any]) -> Dict[str, Any]:
    """
    è®¡ç®—å®Œæ•´çš„é£é™©æŒ‡æ ‡ï¼ˆä½¿ç”¨ä¸»é¡¹ç›®RiskMetricsç±»ï¼‰

    ## è¯·æ±‚ç¤ºä¾‹
    ```json
    {
      "equity_curve": [100000, 102000, 101000, 103000, 105000],
      "returns": [0.02, -0.01, 0.02, 0.02],
      "trades": [],
      "total_return": 0.05,
      "max_drawdown": -0.02,
      "risk_free_rate": 0.03
    }
    ```
    """
    try:
        if RISK_METRICS_AVAILABLE and RiskMetrics:
            logger.info("ğŸ“Š ä½¿ç”¨ä¸»é¡¹ç›®é£é™©æŒ‡æ ‡è®¡ç®—æ¨¡å—")

            # è½¬æ¢æ•°æ®æ ¼å¼
            equity_df = pd.DataFrame({"equity": request.get("equity_curve", [])})
            returns_series = pd.Series(request.get("returns", []))
            trades = request.get("trades", [])

            # è®¡ç®—æ‰€æœ‰é£é™©æŒ‡æ ‡
            risk_calculator = RiskMetrics()
            metrics = risk_calculator.calculate_all_risk_metrics(
                equity_curve=equity_df,
                returns=returns_series,
                trades=trades,
                total_return=request.get("total_return", 0),
                max_drawdown=request.get("max_drawdown", 0),
                risk_free_rate=request.get("risk_free_rate", 0.03),
            )

            return {
                "status": "success",
                "metrics": metrics,
                "calculated_at": datetime.now().isoformat(),
                "module": "RiskMetrics (main project)",
            }
        else:
            logger.info("ğŸ“Š ä¸»é¡¹ç›®é£é™©æŒ‡æ ‡æ¨¡å—ä¸å¯ç”¨ï¼Œè¿”å›ç®€åŒ–æŒ‡æ ‡")
            # ç®€åŒ–ç‰ˆè®¡ç®—
            returns_series = pd.Series(request.get("returns", []))
            # equity_curve = request.get("equity_curve", [])

            metrics = {
                "volatility": float(returns_series.std() * np.sqrt(252)) if len(returns_series) > 0 else 0,
                "sharpe_ratio": (
                    float((returns_series.mean() * 252) / (returns_series.std() * np.sqrt(252)))
                    if returns_series.std() > 0
                    else 0
                ),
                "max_drawdown": request.get("max_drawdown", 0),
                "skewness": float(returns_series.skew()) if len(returns_series) > 0 else 0,
                "kurtosis": float(returns_series.kurtosis()) if len(returns_series) > 0 else 0,
            }

            return {
                "status": "success",
                "metrics": metrics,
                "calculated_at": datetime.now().isoformat(),
                "module": "Simplified (fallback)",
            }

    except Exception as e:
        logger.error(f"è®¡ç®—é£é™©æŒ‡æ ‡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è®¡ç®—é£é™©æŒ‡æ ‡å¤±è´¥: {str(e)}")


@router.post("/position/assess")
async def assess_position_risk(request: Dict[str, Any]) -> Dict[str, Any]:
    """
    è¯„ä¼°ä»“ä½é£é™©

    ## è¯·æ±‚ç¤ºä¾‹
    ```json
    {
      "positions": [
        {"symbol": "sh600000", "value": 150000, "sector": "é‡‘è"},
        {"symbol": "sh600036", "value": 120000, "sector": "é‡‘è"}
      ],
      "total_capital": 1000000,
      "config": {
        "max_position_size": 0.10,
        "daily_loss_limit": 0.05
      }
    }
    ```
    """
    try:
        positions = request.get("positions", [])
        total_capital = request.get("total_capital", 1000000)
        config = request.get("config", {})

        max_position_size = config.get("max_position_size", 0.10)

        # è®¡ç®—æ€»ä»“ä½
        total_position_value = sum(p.get("value", 0) for p in positions)
        position_ratio = total_position_value / total_capital if total_capital > 0 else 0
        cash_ratio = 1 - position_ratio

        # ä¸ªè‚¡é›†ä¸­åº¦åˆ†æ
        position_concentration = []
        exceeded_positions = []
        sector_concentration = {}

        for pos in positions:
            symbol = pos.get("symbol", "UNKNOWN")
            value = pos.get("value", 0)
            sector = pos.get("sector", "UNKNOWN")

            concentration = value / total_capital if total_capital > 0 else 0
            exceeds_limit = concentration > max_position_size

            position_concentration.append(
                {"symbol": symbol, "concentration": concentration, "exceeds_limit": exceeds_limit}
            )

            if exceeds_limit:
                exceeded_positions.append({"symbol": symbol, "concentration": concentration})

            # è¡Œä¸šé›†ä¸­åº¦
            if sector not in sector_concentration:
                sector_concentration[sector] = 0
            sector_concentration[sector] += value

        # HerfindahlæŒ‡æ•°ï¼ˆæŒä»“é›†ä¸­åº¦ï¼‰
        position_sizes = [p["value"] / total_capital for p in positions if total_capital > 0]
        herfindahl_index = sum(p**2 for p in position_sizes) if position_sizes else 0

        # é£é™©ç­‰çº§è¯„ä¼°
        if len(exceeded_positions) > 0 or herfindahl_index > 0.5:
            risk_level = "HIGH"
        elif herfindahl_index > 0.25:
            risk_level = "MEDIUM"
        else:
            risk_level = "LOW"

        return {
            "status": "success",
            "risk_assessment": {
                "total_position_value": total_position_value,
                "position_ratio": position_ratio,
                "cash_ratio": cash_ratio,
                "position_concentration": position_concentration,
                "exceeded_positions": exceeded_positions,
                "high_concentration_risk": len(exceeded_positions) > 0,
                "sector_concentration": {
                    sector: value / total_capital if total_capital > 0 else 0
                    for sector, value in sector_concentration.items()
                },
                "herfindahl_index": herfindahl_index,
                "risk_level": risk_level,
            },
            "assessed_at": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"è¯„ä¼°ä»“ä½é£é™©å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è¯„ä¼°ä»“ä½é£é™©å¤±è´¥: {str(e)}")


@router.post("/alerts/generate")
async def generate_risk_alerts(request: Dict[str, Any]) -> Dict[str, Any]:
    """
    ç”Ÿæˆé£é™©å‘Šè­¦

    ## è¯·æ±‚ç¤ºä¾‹
    ```json
    {
      "current_drawdown": -0.25,
      "daily_pnl": -60000,
      "total_capital": 1000000,
      "config": {
        "max_drawdown_threshold": 0.30,
        "daily_loss_limit": 0.05
      }
    }
    ```
    """
    try:
        current_drawdown = request.get("current_drawdown", 0)
        daily_pnl = request.get("daily_pnl", 0)
        total_capital = request.get("total_capital", 1000000)
        config = request.get("config", {})

        max_drawdown_threshold = config.get("max_drawdown_threshold", 0.30)
        daily_loss_limit = config.get("daily_loss_limit", 0.05)

        alerts = []
        alert_time = datetime.now().isoformat()

        # å›æ’¤å‘Šè­¦
        if abs(current_drawdown) > max_drawdown_threshold:
            alerts.append(
                {
                    "type": "max_drawdown_exceeded",
                    "severity": "CRITICAL",
                    "message": (
                        f"æœ€å¤§å›æ’¤è¶…é™: {abs(current_drawdown) * 100:.2f}% > " f"{max_drawdown_threshold * 100:.2f}%"
                    ),
                    "timestamp": alert_time,
                    "suggestion": "ç«‹å³å‡ä»“æˆ–å¹³ä»“ï¼Œæ§åˆ¶é£é™©æ•å£",
                }
            )

        # å•æ—¥äºæŸå‘Šè­¦
        daily_loss_pct = daily_pnl / total_capital if total_capital > 0 else 0
        if daily_loss_pct < -daily_loss_limit:
            alerts.append(
                {
                    "type": "daily_loss_limit_exceeded",
                    "severity": "WARNING",
                    "message": f"å•æ—¥äºæŸè¶…é™: {daily_loss_pct * 100:.2f}% < -{daily_loss_limit * 100:.2f}%",
                    "timestamp": alert_time,
                    "suggestion": "æš‚åœæ–°å¼€ä»“ï¼Œè¯„ä¼°å½“å‰æŒä»“é£é™©",
                }
            )

        return {"status": "success", "alerts": alerts, "alert_count": len(alerts), "generated_at": alert_time}

    except Exception as e:
        logger.error(f"ç”Ÿæˆé£é™©å‘Šè­¦å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆé£é™©å‘Šè­¦å¤±è´¥: {str(e)}")
