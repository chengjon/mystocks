"""
Cache Integration Module - ç¼“å­˜é›†æˆå·¥å…·

æä¾›ä¸æ•°æ®æœåŠ¡é›†æˆçš„ç¼“å­˜å·¥å…·å‡½æ•°ï¼Œå®ç°Cache-Asideæ¨¡å¼ã€‚

Features:
- Cache-Asideè¯»å†™æ¨¡å¼
- æ•°æ®å­˜å‚¨ä¸€è‡´æ€§ä¿è¯
- çµæ´»çš„å¤±æ•ˆç­–ç•¥
- æ€§èƒ½ä¼˜åŒ–è£…é¥°å™¨

Usage:
    ```python
    # ä½¿ç”¨è£…é¥°å™¨åŒ…è£…ç°æœ‰æ–¹æ³•
    @cache_read_wrapper(data_type="fund_flow")
    def fetch_fund_flow(symbol, timeframe):
        # åŸå§‹å®ç°
        pass

    # æˆ–ä½¿ç”¨æ‰‹åŠ¨æ¨¡å¼
    cache_mgr = CacheIntegration.get_instance()
    data = cache_mgr.fetch_with_cache(
        symbol="000001",
        data_type="fund_flow",
        fetch_fn=lambda: fetch_from_source()
    )
    ```
"""

from datetime import datetime
from typing import Any, Callable, Dict, List, Optional, TypeVar
import structlog
from functools import wraps

from app.core.cache_manager import get_cache_manager, CacheManager

logger = structlog.get_logger()

T = TypeVar("T")


class CacheIntegration:
    """ç¼“å­˜é›†æˆå·¥å…·ç±»"""

    def __init__(self, cache_manager: Optional[CacheManager] = None):
        """
        åˆå§‹åŒ–ç¼“å­˜é›†æˆ

        Args:
            cache_manager: CacheManagerå®ä¾‹ (å¦‚æœä¸æä¾›ï¼Œä½¿ç”¨å•ä¾‹)
        """
        self.cache_manager = cache_manager or get_cache_manager()
        logger.info("ğŸ”§ åˆå§‹åŒ–ç¼“å­˜é›†æˆå·¥å…·")

    # ==================== è¯»å–æ¨¡å¼ (Cache-Aside Read) ====================

    def fetch_with_cache(
        self,
        symbol: str,
        data_type: str,
        fetch_fn: Callable[[], Dict[str, Any]],
        timeframe: Optional[str] = None,
        use_cache: bool = True,
        ttl_days: int = 7,
    ) -> Dict[str, Any]:
        """
        ç¼“å­˜è¯»å–æ¨¡å¼ (Cache-Aside)

        æ‰§è¡Œæµç¨‹:
        1. å°è¯•ä»ç¼“å­˜è¯»å–
        2. å¦‚æœå‘½ä¸­ï¼Œè¿”å›ç¼“å­˜æ•°æ®
        3. å¦‚æœæœªå‘½ä¸­ï¼Œè°ƒç”¨fetch_fnä»æºè·å–æ•°æ®
        4. å°†æ•°æ®å†™å…¥ç¼“å­˜
        5. è¿”å›æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data_type: æ•°æ®ç±»å‹ (fund_flow, etf, chip_race, lhbç­‰)
            fetch_fn: ä»æºè·å–æ•°æ®çš„å‡½æ•°
            timeframe: æ—¶é—´ç»´åº¦ (å¯é€‰)
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ (é»˜è®¤True)
            ttl_days: ç¼“å­˜ç”Ÿå­˜æ—¶é—´

        Returns:
            æ•°æ®å­—å…¸ï¼ŒåŒ…å«:
            {
                "data": {...},
                "source": "cache" | "source",
                "timestamp": "2025-11-06T...",
                "cached_at": "2025-11-06T..." (ä»…å½“source=cacheæ—¶)
            }
        """
        timeframe = timeframe or "1d"

        # å°è¯•ä»ç¼“å­˜è¯»å–
        if use_cache:
            cached_result = self.cache_manager.fetch_from_cache(
                symbol=symbol,
                data_type=data_type,
                timeframe=timeframe,
            )

            if cached_result:
                logger.info(
                    "âœ… ç¼“å­˜å‘½ä¸­",
                    symbol=symbol,
                    data_type=data_type,
                    source="cache",
                )
                return cached_result

        # ç¼“å­˜æœªå‘½ä¸­ï¼Œä»æºè·å–æ•°æ®
        logger.debug(
            "âš ï¸ ç¼“å­˜æœªå‘½ä¸­ï¼Œä»æºè·å–",
            symbol=symbol,
            data_type=data_type,
        )

        try:
            source_data = fetch_fn()

            if source_data:
                # å†™å…¥ç¼“å­˜
                if use_cache and isinstance(source_data, dict):
                    success = self.cache_manager.write_to_cache(
                        symbol=symbol,
                        data_type=data_type,
                        timeframe=timeframe,
                        data=source_data,
                        ttl_days=ttl_days,
                    )

                    if success:
                        logger.debug(
                            "âœ… æ•°æ®å·²å†™å…¥ç¼“å­˜",
                            symbol=symbol,
                            data_type=data_type,
                        )

                return {
                    "data": source_data,
                    "source": "source",
                    "timestamp": datetime.utcnow().isoformat(),
                }

            logger.warning(
                "âš ï¸ æºæ•°æ®ä¸ºç©º",
                symbol=symbol,
                data_type=data_type,
            )
            return {
                "data": None,
                "source": "source",
                "timestamp": datetime.utcnow().isoformat(),
            }

        except Exception as e:
            logger.error(
                "âŒ è·å–æºæ•°æ®å¤±è´¥",
                symbol=symbol,
                data_type=data_type,
                error=str(e),
            )
            raise

    def batch_fetch_with_cache(
        self,
        queries: List[Dict[str, Any]],
        fetch_fn: Callable[[str], Dict[str, Any]],
        use_cache: bool = True,
        ttl_days: int = 7,
    ) -> Dict[str, Dict[str, Any]]:
        """
        æ‰¹é‡ç¼“å­˜è¯»å–

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ :
                {
                    "symbol": "000001",
                    "data_type": "fund_flow",
                    "timeframe": "1d"  # å¯é€‰
                }
            fetch_fn: æ¥å—symbolçš„è·å–å‡½æ•°
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            ttl_days: ç¼“å­˜ç”Ÿå­˜æ—¶é—´

        Returns:
            {
                "000001:fund_flow": {...},
                "000858:etf": {...},
                ...
            }
        """
        results = {}

        for query in queries:
            symbol = query.get("symbol")
            data_type = query.get("data_type")
            timeframe = query.get("timeframe", "1d")

            if not symbol or not data_type:
                logger.warning("æŸ¥è¯¢ç¼ºå°‘å¿…è¦å­—æ®µ", query=query)
                continue

            try:
                result = self.fetch_with_cache(
                    symbol=symbol,
                    data_type=data_type,
                    fetch_fn=lambda s=symbol: fetch_fn(s),
                    timeframe=timeframe,
                    use_cache=use_cache,
                    ttl_days=ttl_days,
                )

                cache_key = f"{symbol}:{data_type}"
                results[cache_key] = result

            except Exception as e:
                logger.error(
                    "æ‰¹é‡è¯»å–å¤±è´¥",
                    symbol=symbol,
                    data_type=data_type,
                    error=str(e),
                )
                results[f"{symbol}:{data_type}"] = {
                    "data": None,
                    "source": "error",
                    "error": str(e),
                }

        return results

    # ==================== å†™å…¥æ¨¡å¼ (Cache-Aside Write) ====================

    def save_with_cache(
        self,
        symbol: str,
        data_type: str,
        data: Dict[str, Any],
        save_fn: Callable[[Dict[str, Any]], bool],
        timeframe: Optional[str] = None,
        use_cache: bool = True,
        ttl_days: int = 7,
    ) -> bool:
        """
        ç¼“å­˜å†™å…¥æ¨¡å¼ (Cache-Aside Write)

        æ‰§è¡Œæµç¨‹:
        1. è°ƒç”¨save_fnä¿å­˜åˆ°æº
        2. å¦‚æœæºä¿å­˜æˆåŠŸï¼Œæ›´æ–°ç¼“å­˜
        3. è¿”å›ç»“æœ

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data_type: æ•°æ®ç±»å‹
            data: è¦ä¿å­˜çš„æ•°æ®
            save_fn: ä¿å­˜åˆ°æºçš„å‡½æ•° (æ¥å—æ•°æ®å­—å…¸ï¼Œè¿”å›bool)
            timeframe: æ—¶é—´ç»´åº¦ (å¯é€‰)
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            ttl_days: ç¼“å­˜ç”Ÿå­˜æ—¶é—´

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¿å­˜
        """
        timeframe = timeframe or "1d"

        try:
            # 1. ä¿å­˜åˆ°æº
            logger.debug(
                "ä¿å­˜æ•°æ®åˆ°æº",
                symbol=symbol,
                data_type=data_type,
            )

            success = save_fn(data)

            if not success:
                logger.warning(
                    "æºä¿å­˜å¤±è´¥",
                    symbol=symbol,
                    data_type=data_type,
                )
                return False

            # 2. æ›´æ–°ç¼“å­˜
            if use_cache:
                cache_success = self.cache_manager.write_to_cache(
                    symbol=symbol,
                    data_type=data_type,
                    timeframe=timeframe,
                    data=data,
                    ttl_days=ttl_days,
                )

                if cache_success:
                    logger.debug(
                        "âœ… æ•°æ®å·²åŒæ—¶ä¿å­˜åˆ°ç¼“å­˜",
                        symbol=symbol,
                        data_type=data_type,
                    )
                else:
                    logger.warning(
                        "âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥ï¼Œä½†æºä¿å­˜æˆåŠŸ",
                        symbol=symbol,
                        data_type=data_type,
                    )

            logger.info(
                "âœ… æ•°æ®ä¿å­˜æˆåŠŸ",
                symbol=symbol,
                data_type=data_type,
                use_cache=use_cache,
            )
            return True

        except Exception as e:
            logger.error(
                "âŒ æ•°æ®ä¿å­˜å¤±è´¥",
                symbol=symbol,
                data_type=data_type,
                error=str(e),
            )
            raise

    def batch_save_with_cache(
        self,
        records: List[Dict[str, Any]],
        save_fn: Callable[[List[Dict[str, Any]]], int],
        data_type: str,
        use_cache: bool = True,
        ttl_days: int = 7,
    ) -> int:
        """
        æ‰¹é‡ç¼“å­˜å†™å…¥

        Args:
            records: è®°å½•åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ :
                {
                    "symbol": "000001",
                    "data": {...},
                    "timeframe": "1d"  # å¯é€‰
                }
            save_fn: æ‰¹é‡ä¿å­˜å‡½æ•° (æ¥å—è®°å½•åˆ—è¡¨ï¼Œè¿”å›ä¿å­˜æ•°é‡)
            data_type: æ•°æ®ç±»å‹
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            ttl_days: ç¼“å­˜ç”Ÿå­˜æ—¶é—´

        Returns:
            æˆåŠŸä¿å­˜çš„è®°å½•æ•°
        """
        try:
            # 1. æ‰¹é‡ä¿å­˜åˆ°æº
            saved_count = save_fn(records)

            if saved_count == 0:
                logger.warning("æ‰¹é‡ä¿å­˜è¿”å›0æ¡")
                return 0

            # 2. æ‰¹é‡å†™å…¥ç¼“å­˜
            if use_cache:
                cache_records = []
                for record in records[:saved_count]:  # ä»…ç¼“å­˜å®é™…ä¿å­˜çš„è®°å½•
                    symbol = record.get("symbol")
                    data = record.get("data", {})
                    timeframe = record.get("timeframe", "1d")

                    if symbol and data:
                        cache_records.append(
                            {
                                "symbol": symbol,
                                "data_type": data_type,
                                "timeframe": timeframe,
                                "data": data,
                            }
                        )

                if cache_records:
                    cache_count = self.cache_manager.batch_write(cache_records, ttl_days=ttl_days)

                    logger.debug(
                        "âœ… æ‰¹é‡ç¼“å­˜å†™å…¥",
                        total=saved_count,
                        cached=cache_count,
                    )

            logger.info(
                "âœ… æ‰¹é‡ä¿å­˜æˆåŠŸ",
                saved_count=saved_count,
                data_type=data_type,
            )
            return saved_count

        except Exception as e:
            logger.error(
                "âŒ æ‰¹é‡ä¿å­˜å¤±è´¥",
                data_type=data_type,
                error=str(e),
            )
            raise

    # ==================== ç¼“å­˜ç®¡ç† ====================

    def invalidate_data(
        self,
        symbol: Optional[str] = None,
        data_type: Optional[str] = None,
    ) -> int:
        """
        æ¸…é™¤ç¼“å­˜

        Args:
            symbol: è‚¡ç¥¨ä»£ç  (å¯é€‰)
            data_type: æ•°æ®ç±»å‹ (å¯é€‰)

        Returns:
            æ¸…é™¤çš„è®°å½•æ•°
        """
        return self.cache_manager.invalidate_cache(symbol=symbol, data_type=data_type)

    def is_cache_fresh(
        self,
        symbol: str,
        data_type: str,
        max_age_days: int = 7,
    ) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜æ˜¯å¦æ–°é²œ

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data_type: æ•°æ®ç±»å‹
            max_age_days: æœ€å¤§ç¼“å­˜å¹´é¾„

        Returns:
            bool: ç¼“å­˜æ˜¯å¦æœ‰æ•ˆä¸”æœªè¿‡æœŸ
        """
        return self.cache_manager.is_cache_valid(
            symbol=symbol,
            data_type=data_type,
            max_age_days=max_age_days,
        )

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return self.cache_manager.get_cache_stats()


# ==================== å…¨å±€å®ä¾‹ ====================

_cache_integration: Optional[CacheIntegration] = None


def get_cache_integration(
    cache_manager: Optional[CacheManager] = None,
) -> CacheIntegration:
    """
    è·å–ç¼“å­˜é›†æˆå·¥å…·å•ä¾‹

    Args:
        cache_manager: CacheManagerå®ä¾‹ (å¯é€‰)

    Returns:
        CacheIntegrationå®ä¾‹
    """
    global _cache_integration

    if _cache_integration is None:
        _cache_integration = CacheIntegration(cache_manager)

    return _cache_integration


def reset_cache_integration() -> None:
    """é‡ç½®ç¼“å­˜é›†æˆå·¥å…·ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    global _cache_integration
    _cache_integration = None


# ==================== è£…é¥°å™¨ ====================


def cache_read_wrapper(data_type: str, ttl_days: int = 7):
    """
    è£…é¥°å™¨: ä¸ºè¯»å–æ–¹æ³•æ·»åŠ ç¼“å­˜

    Usage:
        ```python
        @cache_read_wrapper("fund_flow")
        def query_fund_flow(symbol: str, timeframe: str = "1"):
            # åŸå§‹å®ç°
            pass

        # è°ƒç”¨æ—¶è‡ªåŠ¨ä½¿ç”¨ç¼“å­˜
        result = query_fund_flow("000001", "1")
        ```
    """

    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(symbol: str, *args, **kwargs) -> Dict[str, Any]:
            cache_mgr = get_cache_integration()

            return cache_mgr.fetch_with_cache(
                symbol=symbol,
                data_type=data_type,
                fetch_fn=lambda: func(symbol, *args, **kwargs),
                timeframe=kwargs.get("timeframe", "1d"),
                ttl_days=ttl_days,
            )

        return wrapper

    return decorator


def cache_write_wrapper(data_type: str, ttl_days: int = 7):
    """
    è£…é¥°å™¨: ä¸ºå†™å…¥æ–¹æ³•æ·»åŠ ç¼“å­˜

    Usage:
        ```python
        @cache_write_wrapper("fund_flow")
        def save_fund_flow(symbol: str, data: dict):
            # åŸå§‹å®ç°
            pass

        # è°ƒç”¨æ—¶è‡ªåŠ¨ä½¿ç”¨ç¼“å­˜
        save_fund_flow("000001", {"value": 100})
        ```
    """

    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(symbol: str, data: Dict[str, Any], *args, **kwargs) -> bool:
            cache_mgr = get_cache_integration()

            return cache_mgr.save_with_cache(
                symbol=symbol,
                data_type=data_type,
                data=data,
                save_fn=lambda d: func(symbol, d, *args, **kwargs),
                timeframe=kwargs.get("timeframe", "1d"),
                ttl_days=ttl_days,
            )

        return wrapper

    return decorator


def cache_invalidate_on_write(data_type: Optional[str] = None):
    """
    è£…é¥°å™¨: åœ¨å†™å…¥æ—¶è‡ªåŠ¨æ¸…é™¤ç¼“å­˜

    Usage:
        ```python
        @cache_invalidate_on_write("fund_flow")
        def delete_fund_flow(symbol: str):
            # åˆ é™¤å®ç°
            pass
        ```
    """

    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(symbol: str, *args, **kwargs) -> Any:
            result = func(symbol, *args, **kwargs)

            # è°ƒç”¨åæ¸…é™¤ç¼“å­˜
            cache_mgr = get_cache_integration()
            cache_mgr.invalidate_data(symbol=symbol, data_type=data_type)

            logger.debug(
                "âœ… ç¼“å­˜å·²æ¸…é™¤",
                symbol=symbol,
                data_type=data_type,
            )

            return result

        return wrapper

    return decorator
