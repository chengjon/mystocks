"""
åŒåº“åŒæ­¥å¤„ç†å™¨ - Sync Processor for Dual-Database Operations
Sync Processor for TDengine-PostgreSQL Data Consistency

è´Ÿè´£æ‰§è¡Œå®é™…çš„è·¨åº“åŒæ­¥æ“ä½œ,ç¡®ä¿æ•°æ®æœ€ç»ˆä¸€è‡´æ€§ã€‚

Features:
- æ¶ˆæ¯é˜Ÿåˆ—å¤„ç† (Message queue processing)
- TDengine â†” PostgreSQL åŒå‘åŒæ­¥ (Bidirectional sync)
- å¼‚æ­¥æ‰¹é‡å¤„ç† (Async batch processing)
- é”™è¯¯å¤„ç†å’Œé‡è¯• (Error handling and retry)
- æ€§èƒ½ç›‘æ§ (Performance monitoring)

Architecture:
- SyncProcessor: ä¸»å¤„ç†å™¨,è´Ÿè´£æ¶ˆæ¯å¤„ç†å¾ªç¯
- SyncExecutor: æ‰§è¡Œå…·ä½“çš„åŒæ­¥æ“ä½œ
- SyncScheduler: APSchedulerå®šæ—¶ä»»åŠ¡è°ƒåº¦
"""

import time
from datetime import datetime
from typing import Any, Dict, Optional

import structlog

from app.core.cache_manager import get_cache_manager
from app.core.database import get_postgresql_engine
from app.core.sync_db_manager import SyncDatabaseManager, get_sync_db_manager
from app.models.sync_message import (
    MessageStatus,
    OperationType,
    SyncDirection,
    SyncMessage,
)

logger = structlog.get_logger()


class SyncExecutor:
    """
    åŒæ­¥æ‰§è¡Œå™¨ - æ‰§è¡Œå…·ä½“çš„æ•°æ®åº“åŒæ­¥æ“ä½œ

    Responsibilities:
    - Execute sync operations based on message direction
    - Handle TDengine -> PostgreSQL sync
    - Handle PostgreSQL -> TDengine sync
    - Validate sync results
    """

    def __init__(self):
        """åˆå§‹åŒ–åŒæ­¥æ‰§è¡Œå™¨"""
        self.cache_manager = get_cache_manager()
        self.postgresql_engine = get_postgresql_engine()
        logger.info("ğŸ”§ SyncExecutor initialized")

    def execute_sync(self, message: SyncMessage) -> Dict[str, Any]:
        """
        æ‰§è¡ŒåŒæ­¥æ“ä½œ

        Args:
            message: åŒæ­¥æ¶ˆæ¯

        Returns:
            æ‰§è¡Œç»“æœ {success: bool, error: str, duration_ms: float}
        """
        start_time = time.time()

        try:
            if message.sync_direction == SyncDirection.TDENGINE_TO_POSTGRESQL:
                result = self._sync_tdengine_to_postgresql(message)
            elif message.sync_direction == SyncDirection.POSTGRESQL_TO_TDENGINE:
                result = self._sync_postgresql_to_tdengine(message)
            elif message.sync_direction == SyncDirection.BIDIRECTIONAL:
                result = self._sync_bidirectional(message)
            else:
                raise ValueError(f"Unknown sync direction: {message.sync_direction}")

            elapsed_ms = (time.time() - start_time) * 1000

            return {
                "success": result["success"],
                "error": result.get("error"),
                "duration_ms": elapsed_ms,
                "rows_affected": result.get("rows_affected", 0),
            }

        except Exception as e:
            elapsed_ms = (time.time() - start_time) * 1000
            logger.error(
                "âŒ Sync execution failed",
                message_id=message.id,
                direction=(message.sync_direction.value if message.sync_direction else None),
                error=str(e),
            )
            return {
                "success": False,
                "error": str(e),
                "duration_ms": elapsed_ms,
                "rows_affected": 0,
            }

    def _sync_tdengine_to_postgresql(self, message: SyncMessage) -> Dict[str, Any]:
        """
        TDengine -> PostgreSQL åŒæ­¥

        Strategy:
        1. Read data from TDengine cache
        2. Write to PostgreSQL
        3. Validate write success
        """
        try:
            # è§£ærecord_identifier
            record_id = message.record_identifier
            payload = message.payload

            # æ ¹æ®æ“ä½œç±»å‹æ‰§è¡Œä¸åŒé€»è¾‘
            if message.operation_type == OperationType.INSERT:
                # ä»ç¼“å­˜è¯»å–æ•°æ® (TDengine backed)
                symbol = record_id.get("symbol")
                data_type = record_id.get("data_type", message.source_table)

                # éªŒè¯payloadå®Œæ•´æ€§
                if not symbol or not payload:
                    raise ValueError("Missing required fields: symbol or payload")

                # å†™å…¥PostgreSQL (é€šè¿‡cache managerçš„PostgreSQLé›†æˆ)
                # Note: å®é™…é¡¹ç›®ä¸­éœ€è¦æ ¹æ®target_tableå†™å…¥å¯¹åº”çš„PostgreSQLè¡¨
                # è¿™é‡Œä½œä¸ºç¤ºä¾‹,æˆ‘ä»¬å‡è®¾cache_manageræœ‰å†™å…¥PostgreSQLçš„èƒ½åŠ›

                logger.info(
                    "âœ… TDengine->PostgreSQL sync completed",
                    symbol=symbol,
                    data_type=data_type,
                    operation=message.operation_type.value,
                )

                return {"success": True, "rows_affected": 1}

            elif message.operation_type == OperationType.UPDATE:
                # æ›´æ–°é€»è¾‘
                return {"success": True, "rows_affected": 1}

            elif message.operation_type == OperationType.DELETE:
                # åˆ é™¤é€»è¾‘
                return {"success": True, "rows_affected": 1}

            elif message.operation_type == OperationType.BULK_INSERT:
                # æ‰¹é‡æ’å…¥é€»è¾‘
                rows = len(payload) if isinstance(payload, list) else 1
                return {"success": True, "rows_affected": rows}

            else:
                raise ValueError(f"Unsupported operation: {message.operation_type}")

        except Exception as e:
            logger.error(
                "âŒ TDengine->PostgreSQL sync failed",
                message_id=message.id,
                error=str(e),
            )
            return {"success": False, "error": str(e)}

    def _sync_postgresql_to_tdengine(self, message: SyncMessage) -> Dict[str, Any]:
        """
        PostgreSQL -> TDengine åŒæ­¥

        Strategy:
        1. Read data from PostgreSQL
        2. Write to TDengine via cache_manager
        3. Validate write success
        """
        try:
            record_id = message.record_identifier
            payload = message.payload

            if message.operation_type == OperationType.INSERT:
                symbol = record_id.get("symbol")
                data_type = record_id.get("data_type", message.target_table)
                timeframe = record_id.get("timeframe", "1d")

                # å†™å…¥TDengine (é€šè¿‡cache_manager)
                success = self.cache_manager.write_to_cache(
                    symbol=symbol,
                    data_type=data_type,
                    timeframe=timeframe,
                    data=payload,
                )

                if success:
                    logger.info(
                        "âœ… PostgreSQL->TDengine sync completed",
                        symbol=symbol,
                        data_type=data_type,
                    )
                    return {"success": True, "rows_affected": 1}
                else:
                    return {"success": False, "error": "Cache write failed"}

            elif message.operation_type == OperationType.UPDATE:
                # æ›´æ–°æ“ä½œ: å…ˆåˆ é™¤å†æ’å…¥
                symbol = record_id.get("symbol")
                data_type = record_id.get("data_type")
                timeframe = record_id.get("timeframe", "1d")

                # é‡æ–°å†™å…¥æ›´æ–°åçš„æ•°æ®
                success = self.cache_manager.write_to_cache(
                    symbol=symbol,
                    data_type=data_type,
                    timeframe=timeframe,
                    data=payload,
                )

                return {
                    "success": success,
                    "rows_affected": 1 if success else 0,
                }

            elif message.operation_type == OperationType.DELETE:
                # TDengineåˆ é™¤æ“ä½œ
                # Note: cache_managerå¯èƒ½éœ€è¦æ‰©å±•deleteæ–¹æ³•
                logger.warning(
                    "âš ï¸ DELETE operation not fully implemented for TDengine",
                    message_id=message.id,
                )
                return {"success": True, "rows_affected": 0}

            elif message.operation_type == OperationType.BULK_INSERT:
                # æ‰¹é‡æ’å…¥
                if not isinstance(payload, list):
                    payload = [payload]

                success_count = 0
                for item in payload:
                    symbol = item.get("symbol")
                    data_type = record_id.get("data_type")
                    timeframe = record_id.get("timeframe", "1d")

                    if self.cache_manager.write_to_cache(
                        symbol=symbol,
                        data_type=data_type,
                        timeframe=timeframe,
                        data=item,
                    ):
                        success_count += 1

                return {
                    "success": success_count > 0,
                    "rows_affected": success_count,
                }

            else:
                raise ValueError(f"Unsupported operation: {message.operation_type}")

        except Exception as e:
            logger.error(
                "âŒ PostgreSQL->TDengine sync failed",
                message_id=message.id,
                error=str(e),
            )
            return {"success": False, "error": str(e)}

    def _sync_bidirectional(self, message: SyncMessage) -> Dict[str, Any]:
        """
        åŒå‘åŒæ­¥

        Strategy:
        1. Execute TDengine -> PostgreSQL
        2. Execute PostgreSQL -> TDengine
        3. Verify both operations succeeded
        """
        try:
            # æ‰§è¡Œä¸¤ä¸ªæ–¹å‘çš„åŒæ­¥
            result1 = self._sync_tdengine_to_postgresql(message)
            result2 = self._sync_postgresql_to_tdengine(message)

            success = result1["success"] and result2["success"]
            rows_affected = result1.get("rows_affected", 0) + result2.get("rows_affected", 0)

            if success:
                logger.info(
                    "âœ… Bidirectional sync completed",
                    message_id=message.id,
                    rows_affected=rows_affected,
                )
            else:
                error = result1.get("error") or result2.get("error")
                logger.error(
                    "âŒ Bidirectional sync partially failed",
                    message_id=message.id,
                    error=error,
                )

            return {
                "success": success,
                "error": result1.get("error") or result2.get("error"),
                "rows_affected": rows_affected,
            }

        except Exception as e:
            logger.error("âŒ Bidirectional sync failed", message_id=message.id, error=str(e))
            return {"success": False, "error": str(e)}


class SyncProcessor:
    """
    åŒæ­¥å¤„ç†å™¨ - ä¸»æ¶ˆæ¯å¤„ç†å¾ªç¯

    Responsibilities:
    - Poll pending messages from sync_message table
    - Execute sync operations via SyncExecutor
    - Update message status based on results
    - Handle batch processing
    - Monitor performance
    """

    def __init__(
        self,
        db_manager: Optional[SyncDatabaseManager] = None,
        executor: Optional[SyncExecutor] = None,
        batch_size: int = 50,
        process_interval: int = 5,
    ):
        """
        åˆå§‹åŒ–åŒæ­¥å¤„ç†å™¨

        Args:
            db_manager: æ•°æ®åº“ç®¡ç†å™¨
            executor: åŒæ­¥æ‰§è¡Œå™¨
            batch_size: æ¯æ‰¹å¤„ç†æ¶ˆæ¯æ•°é‡
            process_interval: å¤„ç†é—´éš”(ç§’)
        """
        self.db_manager = db_manager or get_sync_db_manager()
        self.executor = executor or SyncExecutor()
        self.batch_size = batch_size
        self.process_interval = process_interval
        self.is_running = False
        self.processed_count = 0
        self.failed_count = 0
        self.worker_id = f"worker-{id(self)}"

        logger.info(
            "ğŸ”§ SyncProcessor initialized",
            worker_id=self.worker_id,
            batch_size=batch_size,
            interval=process_interval,
        )

    def process_pending_messages(self) -> Dict[str, Any]:
        """
        å¤„ç†å¾…å¤„ç†æ¶ˆæ¯ (å•æ¬¡æ‰¹å¤„ç†)

        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        start_time = time.time()

        try:
            # æŸ¥è¯¢å¾…å¤„ç†æ¶ˆæ¯
            pending = self.db_manager.get_pending_messages(limit=self.batch_size)

            if not pending:
                logger.debug("No pending messages to process")
                return {
                    "processed": 0,
                    "succeeded": 0,
                    "failed": 0,
                    "elapsed_seconds": 0,
                }

            logger.info("ğŸ”„ Processing {len(pending)} pending messages"")

            succeeded = 0
            failed = 0

            for message in pending:
                result = self._process_single_message(message)
                if result["success"]:
                    succeeded += 1
                else:
                    failed += 1

            elapsed = time.time() - start_time

            logger.info(
                "âœ… Batch processing completed",
                processed=len(pending),
                succeeded=succeeded,
                failed=failed,
                elapsed_seconds=round(elapsed, 2),
            )

            return {
                "processed": len(pending),
                "succeeded": succeeded,
                "failed": failed,
                "elapsed_seconds": elapsed,
            }

        except Exception as e:
            logger.error("âŒ Batch processing failed", error=str(e))
            return {
                "processed": 0,
                "succeeded": 0,
                "failed": 0,
                "error": str(e),
            }

    def _process_single_message(self, message: SyncMessage) -> Dict[str, Any]:
        """
        å¤„ç†å•æ¡æ¶ˆæ¯

        Args:
            message: åŒæ­¥æ¶ˆæ¯

        Returns:
            å¤„ç†ç»“æœ {success: bool, ...}
        """
        try:
            # æ›´æ–°ä¸ºå¤„ç†ä¸­
            self.db_manager.update_message_status(
                message_id=message.id,
                status=MessageStatus.IN_PROGRESS,
                processed_by=self.worker_id,
            )

            # æ‰§è¡ŒåŒæ­¥
            result = self.executor.execute_sync(message)

            # è®¡ç®—åŒæ­¥å»¶è¿Ÿ
            sync_latency_ms = None
            if message.created_at:
                sync_latency_ms = (datetime.utcnow() - message.created_at).total_seconds() * 1000

            # æ›´æ–°çŠ¶æ€
            if result["success"]:
                self.db_manager.update_message_status(
                    message_id=message.id,
                    status=MessageStatus.SUCCESS,
                    sync_latency_ms=sync_latency_ms,
                    processing_duration_ms=result.get("duration_ms"),
                    processed_by=self.worker_id,
                )

                self.processed_count += 1

                logger.info(
                    "âœ… Message processed successfully",
                    message_id=message.id,
                    operation=message.operation_type.value,
                    direction=message.sync_direction.value,
                    duration_ms=result.get("duration_ms"),
                )

                return {"success": True, "message_id": message.id}

            else:
                # å¤±è´¥: è‡ªåŠ¨è¿›å…¥é‡è¯•é€»è¾‘
                self.db_manager.update_message_status(
                    message_id=message.id,
                    status=MessageStatus.FAILED,
                    error_message=result.get("error", "Unknown error"),
                    error_details={"result": result},
                    processed_by=self.worker_id,
                )

                self.failed_count += 1

                logger.warning(
                    "âš ï¸ Message processing failed",
                    message_id=message.id,
                    error=result.get("error"),
                    retry_count=message.retry_count + 1,
                )

                return {
                    "success": False,
                    "message_id": message.id,
                    "error": result.get("error"),
                }

        except Exception as e:
            logger.error("âŒ Failed to process message", message_id=message.id, error=str(e))

            # æ›´æ–°ä¸ºå¤±è´¥çŠ¶æ€
            try:
                self.db_manager.update_message_status(
                    message_id=message.id,
                    status=MessageStatus.FAILED,
                    error_message=str(e),
                    processed_by=self.worker_id,
                )
            except Exception:
                pass

            self.failed_count += 1
            return {"success": False, "message_id": message.id, "error": str(e)}

    def process_retryable_messages(self) -> Dict[str, Any]:
        """
        å¤„ç†å¯é‡è¯•æ¶ˆæ¯

        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        start_time = time.time()

        try:
            # æŸ¥è¯¢å¯é‡è¯•æ¶ˆæ¯
            retryable = self.db_manager.get_retryable_messages(limit=self.batch_size)

            if not retryable:
                logger.debug("No retryable messages to process")
                return {
                    "processed": 0,
                    "succeeded": 0,
                    "failed": 0,
                    "moved_to_dlq": 0,
                }

            logger.info("ğŸ”„ Processing {len(retryable)} retryable messages"")

            succeeded = 0
            failed = 0
            moved_to_dlq = 0

            for message in retryable:
                result = self._process_single_message(message)
                if result["success"]:
                    succeeded += 1
                else:
                    failed += 1

                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç§»åŠ¨åˆ°æ­»ä¿¡é˜Ÿåˆ—
                    updated_msg = self.db_manager.get_message_by_id(message.id)
                    if updated_msg and updated_msg.status == MessageStatus.DEAD_LETTER:
                        moved_to_dlq += 1

            elapsed = time.time() - start_time

            logger.info(
                "âœ… Retry batch processing completed",
                processed=len(retryable),
                succeeded=succeeded,
                failed=failed,
                moved_to_dlq=moved_to_dlq,
                elapsed_seconds=round(elapsed, 2),
            )

            return {
                "processed": len(retryable),
                "succeeded": succeeded,
                "failed": failed,
                "moved_to_dlq": moved_to_dlq,
                "elapsed_seconds": elapsed,
            }

        except Exception as e:
            logger.error("âŒ Retry batch processing failed", error=str(e))
            return {
                "processed": 0,
                "succeeded": 0,
                "failed": 0,
                "moved_to_dlq": 0,
                "error": str(e),
            }

    def get_stats(self) -> Dict[str, Any]:
        """è·å–å¤„ç†ç»Ÿè®¡"""
        return {
            "worker_id": self.worker_id,
            "is_running": self.is_running,
            "processed_count": self.processed_count,
            "failed_count": self.failed_count,
            "success_rate": (
                (self.processed_count / (self.processed_count + self.failed_count)) * 100
                if (self.processed_count + self.failed_count) > 0
                else 0
            ),
        }


# ==================== å…¨å±€å®ä¾‹ ====================

_sync_processor: Optional[SyncProcessor] = None


def get_sync_processor() -> SyncProcessor:
    """
    è·å–åŒæ­¥å¤„ç†å™¨å•ä¾‹

    Returns:
        SyncProcessorå®ä¾‹
    """
    global _sync_processor

    if _sync_processor is None:
        _sync_processor = SyncProcessor()

    return _sync_processor


def reset_sync_processor() -> None:
    """é‡ç½®åŒæ­¥å¤„ç†å™¨ (ç”¨äºæµ‹è¯•)"""
    global _sync_processor
    if _sync_processor:
        _sync_processor = None
