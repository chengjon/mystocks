"""
Cache Manager - ç¼“å­˜è¯»å†™é€»è¾‘å®ç°
Task 2.2: å®ç°ç¼“å­˜è¯»å†™é€»è¾‘

æä¾›ç»Ÿä¸€çš„ç¼“å­˜è®¿é—®æ¥å£ï¼Œæ”¯æŒï¼š
- å•æ¡æ•°æ®è¯»å†™
- æ‰¹é‡è¯»å†™æ“ä½œ
- ç¼“å­˜å¤±æ•ˆæœºåˆ¶
- Cache-Aside æ¨¡å¼
- æ€§èƒ½ç›‘æ§

Features:
- Cache-Aside æ¨¡å¼å®ç°
- æ‰¹é‡æ“ä½œæ”¯æŒ
- ç¼“å­˜å¤±æ•ˆæœºåˆ¶
- è‡ªåŠ¨å…ƒæ•°æ®ç®¡ç†
- å®Œæ•´çš„é”™è¯¯å¤„ç†
"""

import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import structlog
import time
from threading import Lock
from collections import defaultdict

from app.core.tdengine_manager import TDengineManager, get_tdengine_manager

logger = structlog.get_logger()


class CacheManager:
    """
    ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨

    ä½¿ç”¨ Cache-Aside æ¨¡å¼å®ç°ï¼Œæ”¯æŒä¸ TDengine æ—¶åºæ•°æ®åº“çš„é›†æˆã€‚

    Usage:
        ```python
        manager = get_cache_manager()

        # å•æ¡è¯»å–
        data = manager.fetch_from_cache("000001", "fund_flow")

        # å•æ¡å†™å…¥
        manager.write_to_cache("000001", "fund_flow", "1d", {"value": 100})

        # æ‰¹é‡è¯»å–
        results = manager.batch_read([
            {"symbol": "000001", "data_type": "fund_flow"},
            {"symbol": "000858", "data_type": "etf"}
        ])

        # æ¸…é™¤ç¼“å­˜
        manager.invalidate_cache(symbol="000001")

        # æ£€æŸ¥ç¼“å­˜æœ‰æ•ˆæ€§
        if manager.is_cache_valid("000001", "fund_flow"):
            print("ç¼“å­˜æœ‰æ•ˆ")
        ```
    """

    def __init__(self, tdengine_manager: Optional[TDengineManager] = None):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨

        Args:
            tdengine_manager: TDengineManager å®ä¾‹ (å¦‚æœä¸æä¾›ï¼Œä½¿ç”¨å•ä¾‹)
        """
        self.tdengine = tdengine_manager or get_tdengine_manager()
        self._tdengine_available = self.tdengine is not None
        self._cache_stats = {
            "hits": 0,
            "misses": 0,
            "reads": 0,
            "writes": 0,
            "evictions": 0,
            "batch_operations": 0,
            "total_response_time": 0.0,
        }

        # å†…å­˜ç¼“å­˜å±‚ - æ›¿ä»£Redis
        self._memory_cache: dict[str, Any] = {}
        self._cache_ttl: dict[str, float] = {}
        self._cache_lock = Lock()
        self._access_patterns: defaultdict[str, list[str]] = defaultdict(list)

        # é…ç½®å‚æ•°
        self._max_memory_entries = 10000  # å†…å­˜ç¼“å­˜æœ€å¤§æ¡ç›®æ•°
        self._default_ttl = 300  # é»˜è®¤TTL 5åˆ†é’Ÿ
        self._tiered_ttl = {
            "tick_data": 30,  # 30ç§’
            "realtime_quote": 60,  # 1åˆ†é’Ÿ
            "minute_kline": 300,  # 5åˆ†é’Ÿ
            "fund_flow": 600,  # 10åˆ†é’Ÿ
            "etf": 1800,  # 30åˆ†é’Ÿ
            "default": 300,  # é»˜è®¤5åˆ†é’Ÿ
        }

    def _with_tdengine(self, fallback_value=None):
        """
        å®‰å…¨åœ°æ‰§è¡Œéœ€è¦ tdengine çš„æ“ä½œ

        Args:
            fallback_value: å¦‚æœ tdengine ä¸å¯ç”¨æ—¶çš„è¿”å›å€¼

        Returns:
            ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç¡®ä¿ tdengine å¯ç”¨
        """
        if self.tdengine is None:
            return fallback_value
        return self.tdengine

    # ==================== æ ¸å¿ƒç¼“å­˜æ“ä½œ ====================

    def fetch_from_cache(
        self,
        symbol: str,
        data_type: str,
        timeframe: Optional[str] = None,
        days: int = 1,
    ) -> Optional[Dict[str, Any]]:
        """
        ä»ç¼“å­˜è¯»å–æ•°æ® (ä¼˜åŒ–åçš„ Cache-Aside æ¨¡å¼)

        é‡‡ç”¨ä¸‰çº§ç¼“å­˜ç­–ç•¥ï¼šå†…å­˜ç¼“å­˜ -> TDengineç¼“å­˜ -> æ•°æ®æº

        Args:
            symbol: è‚¡ç¥¨ä»£ç  (e.g., "000001")
            data_type: æ•°æ®ç±»å‹ (e.g., "fund_flow", "etf")
            timeframe: æ—¶é—´ç»´åº¦ (å¯é€‰ï¼Œe.g., "1d", "3d")
            days: å›æº¯å¤©æ•° (é»˜è®¤ 1)

        Returns:
            ç¼“å­˜æ•°æ®å­—å…¸ï¼Œæˆ– None å¦‚æœæœªæ‰¾åˆ°
        """
        start_time = time.time()
        self._cache_stats["reads"] += 1

        # è®°å½•è®¿é—®æ¨¡å¼
        self._record_access_pattern(symbol, data_type)

        try:
            # ç¬¬ä¸€çº§ï¼šå†…å­˜ç¼“å­˜ (æœ€é«˜æ€§èƒ½)
            memory_result = self._get_from_memory_cache(symbol, data_type, timeframe)
            if memory_result:
                response_time = time.time() - start_time
                self._update_performance_stats(response_time, True)
                self._cache_stats["hits"] += 1
                logger.debug(
                    "âœ… å†…å­˜ç¼“å­˜å‘½ä¸­",
                    symbol=symbol,
                    data_type=data_type,
                    hit_rate=self._calculate_hit_rate(),
                    response_time=response_time,
                )
                return memory_result

            # ç¬¬äºŒçº§ï¼šTDengineç¼“å­˜ (æŒä¹…åŒ–ç¼“å­˜)
            cache_data = None
            if self.tdengine is not None:
                cache_data = self.tdengine.read_cache(
                    symbol=symbol,
                    data_type=data_type,
                    timeframe=timeframe,
                    days=days,
                )

            if cache_data:
                response_time = time.time() - start_time
                self._update_performance_stats(response_time, True)
                self._cache_stats["hits"] += 1

                # å°†æ•°æ®å›å¡«åˆ°å†…å­˜ç¼“å­˜
                enriched_data = {
                    "data": cache_data,
                    "source": "cache",
                    "timestamp": datetime.utcnow().isoformat(),
                }
                # timeframe is Optional[str], provide default for _add_to_memory_cache
                self._add_to_memory_cache(symbol, data_type, timeframe or "1d", enriched_data)

                logger.debug(
                    "âœ… TDengineç¼“å­˜å‘½ä¸­",
                    symbol=symbol,
                    data_type=data_type,
                    hit_rate=self._calculate_hit_rate(),
                    response_time=response_time,
                )
                return enriched_data

            # ç¼“å­˜æœªå‘½ä¸­
            self._cache_stats["misses"] += 1
            response_time = time.time() - start_time
            self._update_performance_stats(response_time, False)

            logger.debug(
                "âš ï¸ ç¼“å­˜æœªå‘½ä¸­",
                symbol=symbol,
                data_type=data_type,
                hit_rate=self._calculate_hit_rate(),
                response_time=response_time,
            )
            return None

        except Exception as e:
            response_time = time.time() - start_time
            self._update_performance_stats(response_time, False)
            logger.error(
                "âŒ ç¼“å­˜è¯»å–å¤±è´¥",
                symbol=symbol,
                data_type=data_type,
                error=str(e),
                response_time=response_time,
            )
            return None

    def write_to_cache(
        self,
        symbol: str,
        data_type: str,
        timeframe: str,
        data: Dict[str, Any],
        ttl_days: int = 7,
        timestamp: Optional[datetime] = None,
    ) -> bool:
        """
        å†™å…¥æ•°æ®åˆ°ç¼“å­˜ (ä¼˜åŒ–åçš„å†™å…¥ç­–ç•¥)

        åŒæ—¶å†™å…¥å†…å­˜ç¼“å­˜å’ŒTDengineç¼“å­˜ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data_type: æ•°æ®ç±»å‹
            timeframe: æ—¶é—´ç»´åº¦
            data: è¦ç¼“å­˜çš„æ•°æ®
            ttl_days: ç¼“å­˜ç”Ÿå­˜æ—¶é—´ (å¤©)
            timestamp: è‡ªå®šä¹‰æ—¶é—´æˆ³

        Returns:
            True å¦‚æœå†™å…¥æˆåŠŸï¼ŒFalse å¦åˆ™
        """
        self._cache_stats["writes"] += 1

        try:
            # éªŒè¯æ•°æ®
            if data is None or not isinstance(data, dict):
                logger.warning(
                    "æ— æ•ˆçš„ç¼“å­˜æ•°æ®",
                    symbol=symbol,
                    data_type=data_type,
                )
                return False

            # å¢åŠ å…ƒæ•°æ®
            enriched_data = {
                **data,
                "_cached_at": datetime.utcnow().isoformat(),
                "_ttl_days": ttl_days,
                "_cache_version": "1.0",
                "_source": "market_data",
            }

            # é¦–å…ˆå†™å…¥å†…å­˜ç¼“å­˜ (æœ€é«˜ä¼˜å…ˆçº§)
            memory_data = {
                "data": data,
                "source": "memory",
                "timestamp": datetime.utcnow().isoformat(),
            }
            self._add_to_memory_cache(symbol, data_type, timeframe, memory_data)

            # å¹¶è¡Œå†™å…¥ TDengine (æŒä¹…åŒ–å­˜å‚¨)
            td_result = self._write_to_tdengine(
                symbol=symbol,
                data_type=data_type,
                timeframe=timeframe,
                data=enriched_data,
                timestamp=timestamp,
            )

            if td_result:
                logger.debug(
                    "âœ… æ•°æ®å·²ç¼“å­˜(å†…å­˜+TDengine)",
                    symbol=symbol,
                    data_type=data_type,
                    ttl_days=ttl_days,
                )
                return True
            else:
                logger.warning(
                    "âš ï¸ TDengineå†™å…¥å¤±è´¥ï¼Œä½†å†…å­˜ç¼“å­˜å·²æ›´æ–°",
                    symbol=symbol,
                    data_type=data_type,
                )
                return True  # å†…å­˜ç¼“å­˜æˆåŠŸå°±è®¤ä¸ºéƒ¨åˆ†æˆåŠŸ

        except Exception as e:
            logger.error(
                "âŒ ç¼“å­˜å†™å…¥å¼‚å¸¸",
                symbol=symbol,
                data_type=data_type,
                error=str(e),
            )
            return False

    def invalidate_cache(
        self,
        symbol: Optional[str] = None,
        data_type: Optional[str] = None,
    ) -> int:
        """
        æ¸…é™¤ç‰¹å®šçš„ç¼“å­˜ (ä¼˜åŒ–ç‰ˆ)

        Args:
            symbol: è‚¡ç¥¨ä»£ç  (å¯é€‰ï¼Œå¦‚æœçœç•¥åˆ™æ¸…é™¤æ‰€æœ‰ symbol)
            data_type: æ•°æ®ç±»å‹ (å¯é€‰ï¼Œå¦‚æœçœç•¥åˆ™æ¸…é™¤æ‰€æœ‰ data_type)

        Returns:
            åˆ é™¤çš„è®°å½•æ•°
        """
        total_deleted = 0

        try:
            with self._cache_lock:
                # é¦–å…ˆæ¸…ç†å†…å­˜ç¼“å­˜
                if symbol and data_type:
                    # æ¸…é™¤ç‰¹å®šç¬¦å·+æ•°æ®ç±»å‹çš„ç¼“å­˜
                    cache_key = self.get_cache_key(symbol, data_type)

                    if cache_key in self._memory_cache:
                        del self._memory_cache[cache_key]
                        total_deleted += 1

                    if cache_key in self._cache_ttl:
                        del self._cache_ttl[cache_key]

                    if cache_key in self._access_patterns:
                        del self._access_patterns[cache_key]

                    logger.info("ğŸ—‘ï¸ æ¸…é™¤å†…å­˜ç¼“å­˜", symbol=symbol, data_type=data_type)

                elif symbol:
                    # æ¸…é™¤ç‰¹å®šç¬¦å·çš„æ‰€æœ‰ç¼“å­˜
                    keys_to_delete = [key for key in self._memory_cache.keys() if key.startswith(symbol)]

                    for key in keys_to_delete:
                        del self._memory_cache[key]
                        total_deleted += 1

                        if key in self._cache_ttl:
                            del self._cache_ttl[key]
                        if key in self._access_patterns:
                            del self._access_patterns[key]

                    logger.info(
                        "ğŸ—‘ï¸ æ¸…é™¤ç¬¦å·æ‰€æœ‰å†…å­˜ç¼“å­˜",
                        symbol=symbol,
                        count=len(keys_to_delete),
                    )

                else:
                    # æ¸…é™¤æ‰€æœ‰å†…å­˜ç¼“å­˜
                    total_deleted = self.clear_memory_cache()
                    logger.warning("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰å†…å­˜ç¼“å­˜")

            # æ¸…ç†TDengineç¼“å­˜ï¼ˆå¼‚æ­¥ï¼‰
            if self.tdengine is not None:
                if symbol and data_type:
                    tdengine_deleted = self.tdengine.clear_expired_cache(days=0)  # éœ€è¦å®ç°ç²¾ç¡®åˆ é™¤
                    total_deleted += tdengine_deleted
                elif symbol:
                    tdengine_deleted = self.tdengine.clear_expired_cache(days=0)
                    total_deleted += tdengine_deleted
                else:
                    tdengine_deleted = self.tdengine.clear_expired_cache(days=0)
                    total_deleted += tdengine_deleted

            logger.info(
                "âœ… ç¼“å­˜æ¸…é™¤å®Œæˆ",
                symbol=symbol,
                data_type=data_type,
                total_deleted=total_deleted,
            )
            return total_deleted

        except Exception as e:
            logger.error("âŒ ç¼“å­˜æ¸…é™¤å¤±è´¥", error=str(e))
            return total_deleted

    # ==================== æ‰¹é‡æ“ä½œ ====================

    def batch_read(self, queries: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ‰¹é‡è¯»å–ç¼“å­˜ (ä¼˜åŒ–ç‰ˆ) - æ˜¾è‘—æé«˜æ€§èƒ½

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
                {
                    "symbol": "000001",
                    "data_type": "fund_flow",
                    "timeframe": "1d",  # å¯é€‰
                    "days": 1            # å¯é€‰
                }

        Returns:
            {
                "000001:fund_flow": {...},
                "000858:etf": {...},
                ...
            }
        """
        self._cache_stats["batch_operations"] += 1
        start_time = time.time()
        results = {}
        success_count = 0

        try:
            # ä¼˜åŒ–ï¼šå¹¶å‘è¯»å–å†…å­˜ç¼“å­˜ï¼Œå…ˆå¤„ç†æœ€å¯èƒ½å‘½ä¸­çš„æ•°æ®
            _ = []  # noqa: F841 - Placeholder for memory_cache_futures (to be implemented)
            _ = []  # noqa: F841 - Placeholder for tdengine_cache_futures (to be implemented)

            # é¢„è¿‡æ»¤ï¼šé¿å…é‡å¤æŸ¥è¯¢
            unique_queries = []
            seen_keys = set()

            for query in queries:
                symbol = query.get("symbol")
                data_type = query.get("data_type")

                if not symbol or not data_type:
                    continue

                query_key = f"{symbol}:{data_type}:{query.get('timeframe', '1d')}"
                if query_key not in seen_keys:
                    seen_keys.add(query_key)
                    unique_queries.append(query)

            # æ‰¹é‡å†…å­˜ç¼“å­˜æŸ¥è¯¢
            with self._cache_lock:
                for query in unique_queries:
                    symbol = query.get("symbol")
                    data_type = query.get("data_type")
                    timeframe = query.get("timeframe", "1d")

                    # Type guards for MyPy
                    if not isinstance(symbol, str) or not isinstance(data_type, str) or not isinstance(timeframe, str):
                        continue

                    cache_key = self.get_cache_key(symbol, data_type, timeframe)

                    if cache_key in self._memory_cache:
                        # å†…å­˜ç¼“å­˜å‘½ä¸­
                        if not self._is_cache_expired(cache_key):
                            results[cache_key] = self._memory_cache[cache_key]
                            self._cache_stats["hits"] += 1
                            success_count += 1
                            self._record_access_pattern(symbol, data_type)
                        else:
                            # è¿‡æœŸäº†ï¼Œéœ€è¦åˆ é™¤
                            del self._memory_cache[cache_key]
                            del self._cache_ttl[cache_key]
                            if cache_key in self._access_patterns:
                                del self._access_patterns[cache_key]

            # å¯¹äºæœªå‘½ä¸­çš„æŸ¥è¯¢ï¼Œæ‰¹é‡TDengineæŸ¥è¯¢
            remaining_queries = []
            for query in unique_queries:
                symbol = query.get("symbol")
                data_type = query.get("data_type")
                timeframe = query.get("timeframe", "1d")

                # Type guards for MyPy
                if not isinstance(symbol, str) or not isinstance(data_type, str) or not isinstance(timeframe, str):
                    continue

                cache_key = self.get_cache_key(symbol, data_type, timeframe)
                if cache_key not in results:
                    remaining_queries.append(query)

            if remaining_queries:
                # æ‰¹é‡TDengineæŸ¥è¯¢
                for query in remaining_queries:
                    symbol = query.get("symbol")
                    data_type = query.get("data_type")
                    timeframe = query.get("timeframe", "1d")

                    # Type guards for MyPy
                    if not isinstance(symbol, str) or not isinstance(data_type, str) or not isinstance(timeframe, str):
                        continue

                    cache_key = self.get_cache_key(symbol, data_type, timeframe)

                    try:
                        if self.tdengine is not None:
                            cache_data = self.tdengine.read_cache(
                                symbol=symbol,
                                data_type=data_type,
                                timeframe=timeframe,
                                days=query.get("days", 1),
                            )
                        else:
                            cache_data = None

                        if cache_data:
                            enriched_data = {
                                "data": cache_data,
                                "source": "cache",
                                "timestamp": datetime.utcnow().isoformat(),
                            }
                            results[cache_key] = enriched_data
                            self._cache_stats["hits"] += 1
                            success_count += 1

                            # å›å¡«å†…å­˜ç¼“å­˜
                            self._add_to_memory_cache(symbol, data_type, timeframe, enriched_data)
                        else:
                            results[cache_key] = None
                            self._cache_stats["misses"] += 1

                    except Exception as e:
                        logger.warning(f"æ‰¹é‡è¯»å–å•é¡¹å¤±è´¥ {symbol}:{data_type}", error=str(e))
                        results[cache_key] = None
                        self._cache_stats["misses"] += 1

            response_time = time.time() - start_time
            self._update_performance_stats(response_time, success_count > 0)

            logger.info(
                "âœ… æ‰¹é‡è¯»å–å®Œæˆ",
                total=len(unique_queries),
                success=success_count,
                unique_queries=len(unique_queries),
                response_time=response_time,
                hit_rate=success_count / max(len(unique_queries), 1),
            )
            return results

        except Exception as e:
            logger.error("âŒ æ‰¹é‡è¯»å–å¤±è´¥", error=str(e))
            return results

    def batch_write(self, records: List[Dict[str, Any]], ttl_days: int = 7) -> int:
        """
        æ‰¹é‡å†™å…¥ç¼“å­˜

        Args:
            records: è®°å½•åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
                {
                    "symbol": "000001",
                    "data_type": "fund_flow",
                    "timeframe": "1d",
                    "data": {...}
                }
            ttl_days: æ‰¹é‡ TTL

        Returns:
            æˆåŠŸå†™å…¥çš„è®°å½•æ•°
        """
        count = 0

        try:
            for record in records:
                symbol = record.get("symbol")
                data_type = record.get("data_type")
                timeframe = record.get("timeframe", "1d")
                data = record.get("data", {})

                if not symbol or not data_type:
                    logger.warning("è®°å½•ç¼ºå°‘å¿…è¦å­—æ®µ", record=record)
                    continue

                if self.write_to_cache(
                    symbol=symbol,
                    data_type=data_type,
                    timeframe=timeframe,
                    data=data,
                    ttl_days=ttl_days,
                ):
                    count += 1

            logger.info(
                "âœ… æ‰¹é‡å†™å…¥å®Œæˆ",
                total=len(records),
                success=count,
            )
            return count

        except Exception as e:
            logger.error("âŒ æ‰¹é‡å†™å…¥å¤±è´¥", error=str(e))
            return count

    # ==================== ç¼“å­˜éªŒè¯ä¸æ£€æŸ¥ ====================

    def is_cache_valid(self, symbol: str, data_type: str, max_age_days: int = 7) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜çš„æœ‰æ•ˆæ€§

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data_type: æ•°æ®ç±»å‹
            max_age_days: æœ€å¤§ç¼“å­˜å¹´é¾„ (å¤©)

        Returns:
            True å¦‚æœç¼“å­˜æœ‰æ•ˆä¸”æœªè¿‡æœŸï¼ŒFalse å¦åˆ™
        """
        try:
            # å°è¯•è¯»å–
            cache_data = self.fetch_from_cache(symbol=symbol, data_type=data_type, days=max_age_days)

            if not cache_data:
                return False

            # æ£€æŸ¥æ—¶é—´æˆ³
            if "_cached_at" in cache_data.get("data", {}):
                cached_at_str = cache_data["data"]["_cached_at"]
                cached_at = datetime.fromisoformat(cached_at_str)
                age = datetime.utcnow() - cached_at
                is_valid = age <= timedelta(days=max_age_days)

                logger.debug(
                    "ç¼“å­˜æœ‰æ•ˆæ€§æ£€æŸ¥",
                    symbol=symbol,
                    data_type=data_type,
                    age_days=age.days,
                    valid=is_valid,
                )
                return is_valid

            return True

        except Exception as e:
            logger.error(
                "âŒ ç¼“å­˜æœ‰æ•ˆæ€§æ£€æŸ¥å¤±è´¥",
                symbol=symbol,
                error=str(e),
            )
            return False

    def get_cache_key(self, symbol: str, data_type: str, timeframe: str = "1d") -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data_type: æ•°æ®ç±»å‹
            timeframe: æ—¶é—´ç»´åº¦

        Returns:
            ç¼“å­˜é”®å­—ç¬¦ä¸²
        """
        return f"{data_type}:{symbol}:{timeframe}".lower()

    # ==================== ç»Ÿè®¡ä¸ç›‘æ§ ====================

    def get_cache_stats(self) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯ (å¢å¼ºç‰ˆ)

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        hit_rate = self._calculate_hit_rate()
        avg_response_time = self._cache_stats["total_response_time"] / max(self._cache_stats["reads"], 1)

        stats = {
            "timestamp": datetime.utcnow().isoformat(),
            "total_reads": self._cache_stats["reads"],
            "total_writes": self._cache_stats["writes"],
            "cache_hits": self._cache_stats["hits"],
            "cache_misses": self._cache_stats["misses"],
            "evictions": self._cache_stats["evictions"],
            "batch_operations": self._cache_stats["batch_operations"],
            "hit_rate": hit_rate,
            "hit_rate_percent": f"{hit_rate * 100:.1f}%",
            "avg_response_time_ms": round(avg_response_time * 1000, 2),
            "memory_cache_stats": self.get_memory_cache_stats(),
        }

        # æ·»åŠ å“åº”æ—¶é—´åˆ†å¸ƒç»Ÿè®¡
        if "response_time_distribution" in self._cache_stats:
            stats["response_time_distribution"] = self._cache_stats["response_time_distribution"]

        # ä» TDengine è·å–é¢å¤–ç»Ÿè®¡
        try:
            if self.tdengine is not None:
                tdengine_stats = self.tdengine.get_cache_stats()
                if tdengine_stats:
                    stats["tdengine_stats"] = tdengine_stats
        except Exception as e:
            logger.warning("æ— æ³•è·å– TDengine ç»Ÿè®¡", error=str(e))

        return stats

    def reset_stats(self) -> None:
        """é‡ç½®ç»Ÿè®¡è®¡æ•°å™¨"""
        self._cache_stats = {
            "hits": 0,
            "misses": 0,
            "reads": 0,
            "writes": 0,
        }
        logger.info("âœ… ç»Ÿè®¡è®¡æ•°å™¨å·²é‡ç½®")

    def _calculate_hit_rate(self) -> float:
        """è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡"""
        total_reads = self._cache_stats["reads"]
        if total_reads == 0:
            return 0.0
        return self._cache_stats["hits"] / total_reads

    # ==================== å†…å­˜ç¼“å­˜å±‚ (æ›¿ä»£Redis) ====================

    def _get_from_memory_cache(self, symbol: str, data_type: str, timeframe: Optional[str]) -> Optional[Dict[str, Any]]:
        """ä»å†…å­˜ç¼“å­˜è¯»å–æ•°æ®"""
        cache_key = self.get_cache_key(symbol, data_type, timeframe or "1d")

        with self._cache_lock:
            if cache_key in self._memory_cache:
                # æ£€æŸ¥TTL
                if self._is_cache_expired(cache_key):
                    del self._memory_cache[cache_key]
                    del self._cache_ttl[cache_key]
                    return None

                # æ›´æ–°è®¿é—®ç»Ÿè®¡
                self._access_patterns[cache_key].append(datetime.utcnow())
                return self._memory_cache[cache_key]

        return None

    def _add_to_memory_cache(
        self,
        symbol: str,
        data_type: str,
        timeframe: str,
        data: Dict[str, Any],
    ) -> None:
        """å†™å…¥æ•°æ®åˆ°å†…å­˜ç¼“å­˜"""
        cache_key = self.get_cache_key(symbol, data_type, timeframe)

        with self._cache_lock:
            # æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶
            if len(self._memory_cache) >= self._max_memory_entries:
                self._evict_memory_cache()

            # è®¡ç®—TTL
            ttl_seconds = self._get_tiered_ttl(data_type)

            self._memory_cache[cache_key] = data
            self._cache_ttl[cache_key] = datetime.utcnow() + timedelta(seconds=ttl_seconds)
            self._access_patterns[cache_key].append(datetime.utcnow())

    def _is_cache_expired(self, cache_key: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ"""
        if cache_key not in self._cache_ttl:
            return True

        return datetime.utcnow() > self._cache_ttl[cache_key]

    def _get_tiered_ttl(self, data_type: str) -> int:
        """è·å–åˆ†å±‚TTL"""
        return self._tiered_ttl.get(data_type, self._tiered_ttl["default"])

    def _evict_memory_cache(self) -> None:
        """å†…å­˜ç¼“å­˜æ·˜æ±°ç­–ç•¥ (LRU + åŸºäºè®¿é—®é¢‘ç‡)"""
        if not self._memory_cache:
            return

        # ç®€å•LRUç­–ç•¥ï¼šåˆ é™¤è®¿é—®é¢‘ç‡æœ€ä½çš„æ¡ç›®
        lru_key = None
        min_access = float("inf")

        for key, access_times in self._access_patterns.items():
            access_freq = len(access_times)
            if access_freq < min_access:
                min_access = access_freq
                lru_key = key

        if lru_key and lru_key in self._memory_cache:
            del self._memory_cache[lru_key]
            del self._cache_ttl[lru_key]
            del self._access_patterns[lru_key]
            self._cache_stats["evictions"] += 1

    def _record_access_pattern(self, symbol: str, data_type: str) -> None:
        """è®°å½•è®¿é—®æ¨¡å¼"""
        cache_key = self.get_cache_key(symbol, data_type)
        with self._cache_lock:
            self._access_patterns[cache_key].append(datetime.utcnow())

    async def _write_to_tdengine(
        self,
        symbol: str,
        data_type: str,
        timeframe: str,
        data: Dict[str, Any],
        timestamp: Optional[datetime] = None,
    ) -> bool:
        """å¼‚æ­¥å†™å…¥TDengine"""
        try:
            # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡ŒTDengineå†™å…¥ï¼Œé¿å…é˜»å¡
            tdengine = self.tdengine
            if tdengine is None:
                return False

            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                None,
                lambda: tdengine.write_cache(
                    symbol=symbol,
                    data_type=data_type,
                    timeframe=timeframe,
                    data=data,
                    timestamp=timestamp,
                ),
            )
            return result
        except Exception as e:
            logger.warning(f"TDengineå¼‚æ­¥å†™å…¥å¤±è´¥: {e}")
            return False

    def _update_performance_stats(self, response_time: float, hit: bool) -> None:
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        self._cache_stats["total_response_time"] += response_time

        # è®°å½•å“åº”æ—¶é—´åˆ†å¸ƒ
        if hit:
            cache_level = "memory" if response_time < 0.001 else "tdengine"
        else:
            cache_level = "miss"

        if "response_time_distribution" not in self._cache_stats:
            self._cache_stats["response_time_distribution"] = {}

        self._cache_stats["response_time_distribution"][cache_level] = (
            self._cache_stats["response_time_distribution"].get(cache_level, 0) + 1
        )

    def get_memory_cache_stats(self) -> Dict[str, Any]:
        """è·å–å†…å­˜ç¼“å­˜ç»Ÿè®¡"""
        with self._cache_lock:
            total_entries = len(self._memory_cache)
            total_size_mb = sum(len(str(data)) for data in self._memory_cache.values()) / (1024 * 1024)  # ä¼°ç®—å¤§å°

            # è®¡ç®—å„æ•°æ®ç±»å‹çš„åˆ†å¸ƒ
            type_distribution = defaultdict(int)
            for cache_key in self._memory_cache.keys():
                parts = cache_key.split(":")
                if len(parts) >= 2:
                    data_type = parts[0]
                    type_distribution[data_type] += 1

            return {
                "total_entries": total_entries,
                "max_entries": self._max_memory_entries,
                "usage_percentage": (total_entries / self._max_memory_entries) * 100,
                "estimated_size_mb": round(total_size_mb, 2),
                "type_distribution": dict(type_distribution),
                "evictions": self._cache_stats["evictions"],
                "default_ttl_seconds": self._default_ttl,
                "tiered_ttl": self._tiered_ttl,
            }

    def clear_memory_cache(self) -> int:
        """æ¸…ç©ºå†…å­˜ç¼“å­˜"""
        with self._cache_lock:
            count = len(self._memory_cache)
            self._memory_cache.clear()
            self._cache_ttl.clear()
            self._access_patterns.clear()
            return count

    def optimize_memory_cache(self) -> Dict[str, Any]:
        """ä¼˜åŒ–å†…å­˜ç¼“å­˜"""
        with self._cache_lock:
            # æ¸…ç†è¿‡æœŸæ¡ç›®
            expired_count = 0
            now = datetime.utcnow()

            expired_keys = [key for key, expire_time in self._cache_ttl.items() if now > expire_time]

            for key in expired_keys:
                if key in self._memory_cache:
                    del self._memory_cache[key]
                del self._cache_ttl[key]
                if key in self._access_patterns:
                    del self._access_patterns[key]
                expired_count += 1

            # è®°å½•ä¼˜åŒ–ç»“æœ
            stats_before = self.get_memory_cache_stats()

            return {
                "expired_entries_removed": expired_count,
                "entries_after_cleanup": len(self._memory_cache),
                "cache_usage_after": stats_before["usage_percentage"],
                "memory_freed_mb": 0,  # ç®€åŒ–å®ç°
            }

    # ==================== ç”Ÿå‘½å‘¨æœŸ ====================

    def health_check(self) -> Dict[str, Any]:
        """
        å¥åº·æ£€æŸ¥ (å¢å¼ºç‰ˆ)

        Returns:
            å¥åº·çŠ¶æ€å­—å…¸
        """
        health_status = {
            "overall_healthy": True,
            "timestamp": datetime.utcnow().isoformat(),
            "components": {},
            "performance_metrics": {},
            "issues": [],
        }

        try:
            # æ£€æŸ¥ TDengine è¿æ¥
            tdengine_healthy = self.tdengine.health_check() if self.tdengine is not None else False
            health_status["components"]["tdengine"] = {
                "healthy": tdengine_healthy,
                "status": "OK" if tdengine_healthy else "ERROR",
            }

            if not tdengine_healthy:
                health_status["overall_healthy"] = False
                health_status["issues"].append("TDengine connection failed")

            # æ£€æŸ¥å†…å­˜ç¼“å­˜
            memory_stats = self.get_memory_cache_stats()
            memory_healthy = (
                memory_stats["usage_percentage"] < 95 and len(self._memory_cache) < self._max_memory_entries
            )

            health_status["components"]["memory_cache"] = {
                "healthy": memory_healthy,
                "status": "OK" if memory_healthy else "WARNING",
                "usage_percentage": memory_stats["usage_percentage"],
                "total_entries": memory_stats["total_entries"],
            }

            if not memory_healthy:
                health_status["issues"].append("Memory cache usage high")

            # æ€§èƒ½æŒ‡æ ‡
            hit_rate = self._calculate_hit_rate()
            avg_response_time = self._cache_stats["total_response_time"] / max(self._cache_stats["reads"], 1)

            performance_healthy = hit_rate > 0.5 and avg_response_time < 1.0  # å‘½ä¸­ç‡åº”è¯¥å¤§äº50%  # å¹³å‡å“åº”æ—¶é—´å°äº1ç§’

            health_status["performance_metrics"] = {
                "hit_rate": hit_rate,
                "avg_response_time_ms": round(avg_response_time * 1000, 2),
                "performance_healthy": performance_healthy,
            }

            if not performance_healthy:
                health_status["overall_healthy"] = False
                if hit_rate < 0.5:
                    health_status["issues"].append("Cache hit rate too low")
                if avg_response_time > 1.0:
                    health_status["issues"].append("Response time too slow")

            logger.info(
                "ğŸ” ç¼“å­˜ç³»ç»Ÿå¥åº·æ£€æŸ¥å®Œæˆ",
                overall_healthy=health_status["overall_healthy"],
                issues=len(health_status["issues"]),
            )

            return health_status

        except Exception as e:
            logger.error("âŒ ç¼“å­˜ç³»ç»Ÿå¥åº·æ£€æŸ¥å¤±è´¥", error=str(e))
            health_status["overall_healthy"] = False
            health_status["issues"].append(f"Health check error: {str(e)}")
            return health_status

    def close(self) -> None:
        """å…³é—­ç¼“å­˜ç®¡ç†å™¨"""
        try:
            if self.tdengine is not None:
                self.tdengine.close()
            logger.info("âœ… ç¼“å­˜ç®¡ç†å™¨å·²å…³é—­")
        except Exception as e:
            logger.warning("å…³é—­ç¼“å­˜ç®¡ç†å™¨æ—¶å‡ºé”™", error=str(e))


# ==================== å…¨å±€å•ä¾‹ç®¡ç† ====================

_cache_manager: Optional[CacheManager] = None


def get_cache_manager(
    tdengine_manager: Optional[TDengineManager] = None,
) -> CacheManager:
    """
    è·å–ç¼“å­˜ç®¡ç†å™¨å•ä¾‹

    Args:
        tdengine_manager: TDengineManager å®ä¾‹ (ç”¨äºåˆå§‹åŒ–æ—¶æŒ‡å®š)

    Returns:
        CacheManager å•ä¾‹å®ä¾‹
    """
    global _cache_manager

    if _cache_manager is None:
        _cache_manager = CacheManager(tdengine_manager)
        if not _cache_manager.health_check():
            logger.warning("âš ï¸ ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–ï¼šTDengine ä¸å¯ç”¨")

    return _cache_manager


def reset_cache_manager() -> None:
    """é‡ç½®ç¼“å­˜ç®¡ç†å™¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    global _cache_manager
    if _cache_manager:
        _cache_manager.close()
    _cache_manager = None
