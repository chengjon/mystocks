"""
Cache Manager - ç¼“å­˜è¯»å†™é€»è¾‘å®ç°
Task 2.2: å®ç°ç¼“å­˜è¯»å†™é€»è¾‘

æä¾›ç»Ÿä¸€çš„ç¼“å­˜è®¿é—®æ¥å£ï¼Œæ”¯æŒï¼š
- å•æ¡æ•°æ®è¯»å†™
- æ‰¹é‡è¯»å†™æ“ä½œ
- ç¼“å­˜å¤±æ•ˆæœºåˆ¶
- Cache-Aside æ¨¡å¼
- æ€§èƒ½ç›‘æ§

Features:
- Cache-Aside æ¨¡å¼å®ç°
- æ‰¹é‡æ“ä½œæ”¯æŒ
- ç¼“å­˜å¤±æ•ˆæœºåˆ¶
- è‡ªåŠ¨å…ƒæ•°æ®ç®¡ç†
- å®Œæ•´çš„é”™è¯¯å¤„ç†
"""

import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import structlog

from app.core.tdengine_manager import TDengineManager, get_tdengine_manager

logger = structlog.get_logger()


class CacheManager:
    """
    ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨

    ä½¿ç”¨ Cache-Aside æ¨¡å¼å®ç°ï¼Œæ”¯æŒä¸ TDengine æ—¶åºæ•°æ®åº“çš„é›†æˆã€‚

    Usage:
        ```python
        manager = get_cache_manager()

        # å•æ¡è¯»å–
        data = manager.fetch_from_cache("000001", "fund_flow")

        # å•æ¡å†™å…¥
        manager.write_to_cache("000001", "fund_flow", "1d", {"value": 100})

        # æ‰¹é‡è¯»å–
        results = manager.batch_read([
            {"symbol": "000001", "data_type": "fund_flow"},
            {"symbol": "000858", "data_type": "etf"}
        ])

        # æ¸…é™¤ç¼“å­˜
        manager.invalidate_cache(symbol="000001")

        # æ£€æŸ¥ç¼“å­˜æœ‰æ•ˆæ€§
        if manager.is_cache_valid("000001", "fund_flow"):
            print("ç¼“å­˜æœ‰æ•ˆ")
        ```
    """

    def __init__(self, tdengine_manager: Optional[TDengineManager] = None):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨

        Args:
            tdengine_manager: TDengineManager å®ä¾‹ (å¦‚æœä¸æä¾›ï¼Œä½¿ç”¨å•ä¾‹)
        """
        self.tdengine = tdengine_manager or get_tdengine_manager()
        self._cache_stats = {
            "hits": 0,
            "misses": 0,
            "reads": 0,
            "writes": 0,
        }

        logger.info("ğŸ”§ åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨")

    # ==================== æ ¸å¿ƒç¼“å­˜æ“ä½œ ====================

    def fetch_from_cache(
        self,
        symbol: str,
        data_type: str,
        timeframe: Optional[str] = None,
        days: int = 1,
    ) -> Optional[Dict[str, Any]]:
        """
        ä»ç¼“å­˜è¯»å–æ•°æ® (Cache-Aside æ¨¡å¼çš„è¯»æ“ä½œ)

        Args:
            symbol: è‚¡ç¥¨ä»£ç  (e.g., "000001")
            data_type: æ•°æ®ç±»å‹ (e.g., "fund_flow", "etf")
            timeframe: æ—¶é—´ç»´åº¦ (å¯é€‰ï¼Œe.g., "1d", "3d")
            days: å›æº¯å¤©æ•° (é»˜è®¤ 1)

        Returns:
            ç¼“å­˜æ•°æ®å­—å…¸ï¼Œæˆ– None å¦‚æœæœªæ‰¾åˆ°
        """
        self._cache_stats["reads"] += 1

        try:
            # ä» TDengine è¯»å–ç¼“å­˜
            cache_data = self.tdengine.read_cache(
                symbol=symbol,
                data_type=data_type,
                timeframe=timeframe,
                days=days,
            )

            if cache_data:
                self._cache_stats["hits"] += 1
                logger.debug(
                    "âœ… ç¼“å­˜å‘½ä¸­",
                    symbol=symbol,
                    data_type=data_type,
                    hit_rate=self._calculate_hit_rate(),
                )
                return {
                    "data": cache_data,
                    "source": "cache",
                    "timestamp": datetime.utcnow().isoformat(),
                }

            self._cache_stats["misses"] += 1
            logger.debug(
                "âš ï¸ ç¼“å­˜æœªå‘½ä¸­",
                symbol=symbol,
                data_type=data_type,
                hit_rate=self._calculate_hit_rate(),
            )
            return None

        except Exception as e:
            logger.error(
                "âŒ ç¼“å­˜è¯»å–å¤±è´¥",
                symbol=symbol,
                data_type=data_type,
                error=str(e),
            )
            return None

    def write_to_cache(
        self,
        symbol: str,
        data_type: str,
        timeframe: str,
        data: Dict[str, Any],
        ttl_days: int = 7,
        timestamp: Optional[datetime] = None,
    ) -> bool:
        """
        å†™å…¥æ•°æ®åˆ°ç¼“å­˜

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data_type: æ•°æ®ç±»å‹
            timeframe: æ—¶é—´ç»´åº¦
            data: è¦ç¼“å­˜çš„æ•°æ®
            ttl_days: ç¼“å­˜ç”Ÿå­˜æ—¶é—´ (å¤©)
            timestamp: è‡ªå®šä¹‰æ—¶é—´æˆ³

        Returns:
            True å¦‚æœå†™å…¥æˆåŠŸï¼ŒFalse å¦åˆ™
        """
        self._cache_stats["writes"] += 1

        try:
            # éªŒè¯æ•°æ®
            if not data or not isinstance(data, dict):
                logger.warning(
                    "æ— æ•ˆçš„ç¼“å­˜æ•°æ®",
                    symbol=symbol,
                    data_type=data_type,
                )
                return False

            # å¢åŠ å…ƒæ•°æ®
            enriched_data = {
                **data,
                "_cached_at": datetime.utcnow().isoformat(),
                "_ttl_days": ttl_days,
                "_cache_version": "1.0",
                "_source": "market_data",
            }

            # å†™å…¥ TDengine
            result = self.tdengine.write_cache(
                symbol=symbol,
                data_type=data_type,
                timeframe=timeframe,
                data=enriched_data,
                timestamp=timestamp,
            )

            if result:
                logger.debug(
                    "âœ… æ•°æ®å·²ç¼“å­˜",
                    symbol=symbol,
                    data_type=data_type,
                    ttl_days=ttl_days,
                )
                return True
            else:
                logger.error("âŒ ç¼“å­˜å†™å…¥å¤±è´¥ (TDengine è¿”å› False)")
                return False

        except Exception as e:
            logger.error(
                "âŒ ç¼“å­˜å†™å…¥å¼‚å¸¸",
                symbol=symbol,
                data_type=data_type,
                error=str(e),
            )
            return False

    def invalidate_cache(
        self,
        symbol: Optional[str] = None,
        data_type: Optional[str] = None,
    ) -> int:
        """
        æ¸…é™¤ç‰¹å®šçš„ç¼“å­˜ (Cache Invalidation)

        Args:
            symbol: è‚¡ç¥¨ä»£ç  (å¯é€‰ï¼Œå¦‚æœçœç•¥åˆ™æ¸…é™¤æ‰€æœ‰ symbol)
            data_type: æ•°æ®ç±»å‹ (å¯é€‰ï¼Œå¦‚æœçœç•¥åˆ™æ¸…é™¤æ‰€æœ‰ data_type)

        Returns:
            åˆ é™¤çš„è®°å½•æ•°
        """
        try:
            if symbol and data_type:
                # æ¸…é™¤ç‰¹å®šç¬¦å·+æ•°æ®ç±»å‹çš„ç¼“å­˜
                logger.info(
                    "ğŸ—‘ï¸ æ¸…é™¤ç‰¹å®šç¼“å­˜",
                    symbol=symbol,
                    data_type=data_type,
                )
                # è°ƒç”¨ TDengineManager çš„æ¸…ç†åŠŸèƒ½
                # è¿™é‡Œç®€åŒ–å®ç° - å®é™…åº”è¯¥ç›´æ¥åˆ é™¤
                deleted = self.tdengine.clear_expired_cache(days=0)
                return deleted
            elif symbol:
                # æ¸…é™¤ç‰¹å®šç¬¦å·çš„æ‰€æœ‰ç¼“å­˜
                logger.info("ğŸ—‘ï¸ æ¸…é™¤ç¬¦å·æ‰€æœ‰ç¼“å­˜", symbol=symbol)
                return self.tdengine.clear_expired_cache(days=0)
            else:
                # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
                logger.warning("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰ç¼“å­˜")
                return self.tdengine.clear_expired_cache(days=0)

        except Exception as e:
            logger.error("âŒ ç¼“å­˜æ¸…é™¤å¤±è´¥", error=str(e))
            return 0

    # ==================== æ‰¹é‡æ“ä½œ ====================

    def batch_read(self, queries: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ‰¹é‡è¯»å–ç¼“å­˜ - æé«˜æ€§èƒ½

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
                {
                    "symbol": "000001",
                    "data_type": "fund_flow",
                    "timeframe": "1d",  # å¯é€‰
                    "days": 1            # å¯é€‰
                }

        Returns:
            {
                "000001:fund_flow": {...},
                "000858:etf": {...},
                ...
            }
        """
        results = {}
        success_count = 0

        try:
            for query in queries:
                symbol = query.get("symbol")
                data_type = query.get("data_type")

                if not symbol or not data_type:
                    logger.warning("æŸ¥è¯¢ç¼ºå°‘å¿…è¦å­—æ®µ", query=query)
                    continue

                data = self.fetch_from_cache(
                    symbol=symbol,
                    data_type=data_type,
                    timeframe=query.get("timeframe"),
                    days=query.get("days", 1),
                )

                cache_key = f"{symbol}:{data_type}"
                results[cache_key] = data
                if data:
                    success_count += 1

            logger.info(
                f"âœ… æ‰¹é‡è¯»å–å®Œæˆ",
                total=len(queries),
                success=success_count,
            )
            return results

        except Exception as e:
            logger.error("âŒ æ‰¹é‡è¯»å–å¤±è´¥", error=str(e))
            return results

    def batch_write(self, records: List[Dict[str, Any]], ttl_days: int = 7) -> int:
        """
        æ‰¹é‡å†™å…¥ç¼“å­˜

        Args:
            records: è®°å½•åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
                {
                    "symbol": "000001",
                    "data_type": "fund_flow",
                    "timeframe": "1d",
                    "data": {...}
                }
            ttl_days: æ‰¹é‡ TTL

        Returns:
            æˆåŠŸå†™å…¥çš„è®°å½•æ•°
        """
        count = 0

        try:
            for record in records:
                symbol = record.get("symbol")
                data_type = record.get("data_type")
                timeframe = record.get("timeframe", "1d")
                data = record.get("data", {})

                if not symbol or not data_type:
                    logger.warning("è®°å½•ç¼ºå°‘å¿…è¦å­—æ®µ", record=record)
                    continue

                if self.write_to_cache(
                    symbol=symbol,
                    data_type=data_type,
                    timeframe=timeframe,
                    data=data,
                    ttl_days=ttl_days,
                ):
                    count += 1

            logger.info(
                f"âœ… æ‰¹é‡å†™å…¥å®Œæˆ",
                total=len(records),
                success=count,
            )
            return count

        except Exception as e:
            logger.error("âŒ æ‰¹é‡å†™å…¥å¤±è´¥", error=str(e))
            return count

    # ==================== ç¼“å­˜éªŒè¯ä¸æ£€æŸ¥ ====================

    def is_cache_valid(
        self, symbol: str, data_type: str, max_age_days: int = 7
    ) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜çš„æœ‰æ•ˆæ€§

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data_type: æ•°æ®ç±»å‹
            max_age_days: æœ€å¤§ç¼“å­˜å¹´é¾„ (å¤©)

        Returns:
            True å¦‚æœç¼“å­˜æœ‰æ•ˆä¸”æœªè¿‡æœŸï¼ŒFalse å¦åˆ™
        """
        try:
            # å°è¯•è¯»å–
            cache_data = self.fetch_from_cache(
                symbol=symbol, data_type=data_type, days=max_age_days
            )

            if not cache_data:
                return False

            # æ£€æŸ¥æ—¶é—´æˆ³
            if "_cached_at" in cache_data.get("data", {}):
                cached_at_str = cache_data["data"]["_cached_at"]
                cached_at = datetime.fromisoformat(cached_at_str)
                age = datetime.utcnow() - cached_at
                is_valid = age <= timedelta(days=max_age_days)

                logger.debug(
                    "ç¼“å­˜æœ‰æ•ˆæ€§æ£€æŸ¥",
                    symbol=symbol,
                    data_type=data_type,
                    age_days=age.days,
                    valid=is_valid,
                )
                return is_valid

            return True

        except Exception as e:
            logger.error(
                "âŒ ç¼“å­˜æœ‰æ•ˆæ€§æ£€æŸ¥å¤±è´¥",
                symbol=symbol,
                error=str(e),
            )
            return False

    def get_cache_key(self, symbol: str, data_type: str, timeframe: str = "1d") -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data_type: æ•°æ®ç±»å‹
            timeframe: æ—¶é—´ç»´åº¦

        Returns:
            ç¼“å­˜é”®å­—ç¬¦ä¸²
        """
        return f"{data_type}:{symbol}:{timeframe}".lower()

    # ==================== ç»Ÿè®¡ä¸ç›‘æ§ ====================

    def get_cache_stats(self) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        hit_rate = self._calculate_hit_rate()

        stats = {
            "timestamp": datetime.utcnow().isoformat(),
            "total_reads": self._cache_stats["reads"],
            "total_writes": self._cache_stats["writes"],
            "cache_hits": self._cache_stats["hits"],
            "cache_misses": self._cache_stats["misses"],
            "hit_rate": hit_rate,
            "hit_rate_percent": f"{hit_rate * 100:.1f}%",
        }

        # ä» TDengine è·å–é¢å¤–ç»Ÿè®¡
        try:
            tdengine_stats = self.tdengine.get_cache_stats()
            if tdengine_stats:
                stats.update(tdengine_stats)
        except Exception as e:
            logger.warning("æ— æ³•è·å– TDengine ç»Ÿè®¡", error=str(e))

        return stats

    def reset_stats(self) -> None:
        """é‡ç½®ç»Ÿè®¡è®¡æ•°å™¨"""
        self._cache_stats = {
            "hits": 0,
            "misses": 0,
            "reads": 0,
            "writes": 0,
        }
        logger.info("âœ… ç»Ÿè®¡è®¡æ•°å™¨å·²é‡ç½®")

    def _calculate_hit_rate(self) -> float:
        """è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡"""
        total_reads = self._cache_stats["reads"]
        if total_reads == 0:
            return 0.0
        return self._cache_stats["hits"] / total_reads

    # ==================== ç”Ÿå‘½å‘¨æœŸ ====================

    def health_check(self) -> bool:
        """
        å¥åº·æ£€æŸ¥

        Returns:
            True å¦‚æœç¼“å­˜ç³»ç»Ÿå¥åº·ï¼ŒFalse å¦åˆ™
        """
        try:
            # æ£€æŸ¥ TDengineManager çš„å¥åº·çŠ¶æ€
            return self.tdengine.health_check()
        except Exception as e:
            logger.warning("ç¼“å­˜ç³»ç»Ÿå¥åº·æ£€æŸ¥å¤±è´¥", error=str(e))
            return False

    def close(self) -> None:
        """å…³é—­ç¼“å­˜ç®¡ç†å™¨"""
        try:
            self.tdengine.close()
            logger.info("âœ… ç¼“å­˜ç®¡ç†å™¨å·²å…³é—­")
        except Exception as e:
            logger.warning("å…³é—­ç¼“å­˜ç®¡ç†å™¨æ—¶å‡ºé”™", error=str(e))


# ==================== å…¨å±€å•ä¾‹ç®¡ç† ====================

_cache_manager: Optional[CacheManager] = None


def get_cache_manager(
    tdengine_manager: Optional[TDengineManager] = None,
) -> CacheManager:
    """
    è·å–ç¼“å­˜ç®¡ç†å™¨å•ä¾‹

    Args:
        tdengine_manager: TDengineManager å®ä¾‹ (ç”¨äºåˆå§‹åŒ–æ—¶æŒ‡å®š)

    Returns:
        CacheManager å•ä¾‹å®ä¾‹
    """
    global _cache_manager

    if _cache_manager is None:
        _cache_manager = CacheManager(tdengine_manager)
        if not _cache_manager.health_check():
            logger.warning("âš ï¸ ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–ï¼šTDengine ä¸å¯ç”¨")

    return _cache_manager


def reset_cache_manager() -> None:
    """é‡ç½®ç¼“å­˜ç®¡ç†å™¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    global _cache_manager
    if _cache_manager:
        _cache_manager.close()
    _cache_manager = None
