"""
TDengine Cache Manager - æ—¶åºæ•°æ®åº“ç¼“å­˜ç®¡ç†
Task 2.1: TDengine ç¼“å­˜é›†æˆ - æ­å»º TDengine æœåŠ¡
Phase 3 Task 19: é›†æˆè¿æ¥æ± ä¼˜åŒ–

å®ç° TDengine è¿æ¥ç®¡ç†ã€è¡¨åˆ›å»ºã€æ•°æ®è¯»å†™ç­‰åŸºç¡€åŠŸèƒ½ã€‚

Features:
- TDengine è¿æ¥æ± ç®¡ç†ï¼ˆPhase 3ä¼˜åŒ–ï¼šè¿æ¥å¤ç”¨ã€å¥åº·æ£€æŸ¥ã€ç›‘æ§ï¼‰
- è‡ªåŠ¨è¡¨åˆ›å»ºå’Œåˆå§‹åŒ–
- ç¼“å­˜æ•°æ®è¯»å†™æ¥å£
- è¿æ¥å¥åº·æ£€æŸ¥
"""

import os
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import structlog

# æ”¯æŒä»è„šæœ¬å¯¼å…¥ï¼šå°è¯•ç›¸å¯¹å¯¼å…¥
try:
    from app.core.tdengine_pool import TDengineConnectionPool
except (ImportError, ModuleNotFoundError):
    # ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯•ä»å½“å‰ç›®å½•å¯¼å…¥
    from .tdengine_pool import TDengineConnectionPool

logger = structlog.get_logger()


class TDengineManager:
    """
    TDengine æ—¶åºæ•°æ®åº“ç®¡ç†å™¨

    è´Ÿè´£ï¼š
    - æ•°æ®åº“è¿æ¥ç®¡ç†
    - ç¼“å­˜è¡¨åˆ›å»ºå’Œç®¡ç†
    - ç¼“å­˜æ•°æ®è¯»å†™æ“ä½œ
    - è¿æ¥å¥åº·æ£€æŸ¥

    Usage:
        ```python
        tdengine = TDengineManager()

        # åˆå§‹åŒ–æ•°æ®åº“
        tdengine.initialize()

        # å†™å…¥ç¼“å­˜æ•°æ®
        tdengine.write_cache(
            symbol="000001",
            data_type="fund_flow",
            timeframe="1d",
            data={"main_net_inflow": 1000000}
        )

        # è¯»å–ç¼“å­˜æ•°æ®
        data = tdengine.read_cache(
            symbol="000001",
            data_type="fund_flow"
        )
        ```
    """

    def __init__(
        self,
        host: Optional[str] = None,
        port: int = 6030,
        user: str = "root",
        password: str = "taosdata",
        database: str = "mystocks_cache",
        precision: str = "ms",
        min_pool_size: int = 5,
        max_pool_size: int = 20,
    ):
        """
        åˆå§‹åŒ– TDengine ç®¡ç†å™¨ï¼ˆPhase 3ä¼˜åŒ–ï¼šè¿æ¥æ± æ”¯æŒï¼‰

        Args:
            host: TDengine æœåŠ¡å™¨åœ°å€
            port: TDengine æœåŠ¡å™¨ç«¯å£
            user: æ•°æ®åº“ç”¨æˆ·å
            password: æ•°æ®åº“å¯†ç 
            database: ç¼“å­˜æ•°æ®åº“å
            precision: æ—¶é—´ç²¾åº¦ (ms/us/ns)
            min_pool_size: æœ€å°è¿æ¥æ± å¤§å°ï¼ˆPhase 3æ–°å¢ï¼‰
            max_pool_size: æœ€å¤§è¿æ¥æ± å¤§å°ï¼ˆPhase 3æ–°å¢ï¼‰
        """
        self.host = host or os.getenv("TDENGINE_HOST", "127.0.0.1")
        self.port = port or int(os.getenv("TDENGINE_PORT", "6030"))
        self.user = user or os.getenv("TDENGINE_USER", "root")
        self.password = password or os.getenv("TDENGINE_PASSWORD", "taosdata")
        self.database = database or os.getenv("TDENGINE_DATABASE", "mystocks_cache")
        self.precision = precision

        # Phase 3: è¿æ¥æ± æ›¿ä»£å•è¿æ¥
        self._pool: Optional[TDengineConnectionPool] = None
        self._is_initialized = False

        # è¿æ¥æ± é…ç½®
        self._min_pool_size = min_pool_size
        self._max_pool_size = max_pool_size

        logger.info(
            "ğŸ”§ åˆå§‹åŒ– TDengine ç®¡ç†å™¨ï¼ˆPhase 3è¿æ¥æ± ä¼˜åŒ–ï¼‰",
            host=self.host,
            port=self.port,
            database=self.database,
            pool_size=f"{min_pool_size}-{max_pool_size}",
        )

    def connect(self) -> bool:
        """
        åˆå§‹åŒ– TDengine è¿æ¥æ± ï¼ˆPhase 3ä¼˜åŒ–ï¼‰

        Returns:
            True if connection pool initialization successful
        """
        try:
            # Phase 3: åˆ›å»ºè¿æ¥æ± æ›¿ä»£å•è¿æ¥
            self._pool = TDengineConnectionPool(
                host=self.host or "localhost",
                port=self.port,
                user=self.user,
                password=self.password,
                database=None,  # åˆå§‹ä¸æŒ‡å®šæ•°æ®åº“ï¼Œåœ¨initializeä¸­åˆ‡æ¢
                min_size=self._min_pool_size,
                max_size=self._max_pool_size,
                max_idle_time=600,  # 10åˆ†é’Ÿç©ºé—²è¶…æ—¶
                health_check_interval=60,  # 60ç§’å¥åº·æ£€æŸ¥é—´éš”
            )
            logger.info(
                "âœ… TDengineè¿æ¥æ± å·²åˆå§‹åŒ–",
                host=self.host,
                pool_size=f"{self._min_pool_size}-{self._max_pool_size}",
            )
            return True

        except Exception as e:
            logger.error("âŒ åˆå§‹åŒ–TDengineè¿æ¥æ± å¤±è´¥", error=str(e))
            return False

    def initialize(self) -> bool:
        """
        åˆå§‹åŒ–æ•°æ®åº“å’Œè¡¨ç»“æ„

        Returns:
            True if initialization successful
        """
        if not self.connect():
            return False

        try:
            # åˆ›å»ºæ•°æ®åº“
            self._create_database()

            # æ ‡è®°ä¸ºå·²åˆå§‹åŒ–ï¼ˆè¿™æ ·åç»­çš„_executeä¼šæ‰§è¡ŒUSEè¯­å¥ï¼‰
            self._is_initialized = True

            # åˆ›å»ºç¼“å­˜è¡¨
            self._create_cache_tables()

            logger.info("âœ… TDengine æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ", database=self.database)
            return True

        except Exception as e:
            logger.error("âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥", error=str(e))
            self._is_initialized = False  # åˆå§‹åŒ–å¤±è´¥åˆ™é‡ç½®çŠ¶æ€
            return False

    def _create_database(self):
        """åˆ›å»ºç¼“å­˜æ•°æ®åº“"""
        try:
            # TDengine 3.x compatible syntax (simplified)
            self._execute(
                f"CREATE DATABASE IF NOT EXISTS {self.database} "
                f"KEEP 3650 "  # Keep data for 10 years
                f"PRECISION 'ms'"  # Millisecond precision
            )
            logger.info("âœ… æ•°æ®åº“å·²åˆ›å»º", database=self.database)
        except Exception as e:
            logger.error("âŒ åˆ›å»ºæ•°æ®åº“å¤±è´¥", error=str(e))
            raise

    def _create_cache_tables(self):
        """åˆ›å»ºç¼“å­˜è¡¨ (TDengine 3.x compatible)"""
        try:
            # åˆ›å»ºå¸‚åœºæ•°æ®ç¼“å­˜è¶…è¡¨ (stable)
            self._execute(
                """
                CREATE STABLE IF NOT EXISTS market_data_cache (
                    ts TIMESTAMP,
                    data NCHAR(1024),
                    hit_count BIGINT,
                    created_at TIMESTAMP,
                    updated_at TIMESTAMP
                ) TAGS (
                    symbol VARCHAR(10),
                    data_type VARCHAR(20),
                    timeframe VARCHAR(10)
                )
            """
            )
            logger.info("âœ… ç¼“å­˜è¶…è¡¨å·²åˆ›å»º: market_data_cache")

            # åˆ›å»ºç¼“å­˜ç»Ÿè®¡è¡¨ (æ™®é€šè¡¨)
            self._execute(
                """
                CREATE TABLE IF NOT EXISTS cache_stats (
                    ts TIMESTAMP,
                    total_requests BIGINT,
                    cache_hits BIGINT,
                    cache_misses BIGINT,
                    hit_rate FLOAT
                )
            """
            )
            logger.info("âœ… ç»Ÿè®¡è¡¨å·²åˆ›å»º: cache_stats")

            # åˆ›å»ºçƒ­ç‚¹æ•°æ®è¶…è¡¨
            self._execute(
                """
                CREATE STABLE IF NOT EXISTS hot_symbols (
                    ts TIMESTAMP,
                    access_count BIGINT,
                    last_access TIMESTAMP
                ) TAGS (symbol VARCHAR(10))
            """
            )
            logger.info("âœ… çƒ­ç‚¹è¶…è¡¨å·²åˆ›å»º: hot_symbols")

        except Exception as e:
            logger.error("âŒ åˆ›å»ºè¡¨å¤±è´¥", error=str(e))
            raise

    def write_cache(
        self,
        symbol: str,
        data_type: str,
        timeframe: str,
        data: Dict[str, Any],
        timestamp: Optional[datetime] = None,
    ) -> bool:
        """
        å†™å…¥ç¼“å­˜æ•°æ® (è‡ªåŠ¨åˆ›å»ºå­è¡¨)

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data_type: æ•°æ®ç±»å‹ (fund_flow, etf, chip_race, etc.)
            timeframe: æ—¶é—´ç»´åº¦ (1d, 3d, 5d, 10d)
            data: æ•°æ®å­—å…¸
            timestamp: æ—¶é—´æˆ³ (é»˜è®¤å½“å‰æ—¶é—´)

        Returns:
            True if write successful
        """
        if not self._is_initialized:
            logger.warning("âŒ æ•°æ®åº“æœªåˆå§‹åŒ–")
            return False

        try:
            ts = timestamp or datetime.utcnow()
            data_json = json.dumps(data, ensure_ascii=False)

            # ç”Ÿæˆå­è¡¨å
            table_name = f"cache_{symbol}_{data_type.lower().replace('-', '_')}"

            # TDengine 3.x: ä½¿ç”¨ USING è¯­æ³•è‡ªåŠ¨åˆ›å»ºå­è¡¨
            sql = f"""
                INSERT INTO {table_name} USING market_data_cache TAGS ('{symbol}', '{data_type}', '{timeframe}')
                VALUES (
                    '{ts.isoformat()}',
                    '{data_json}',
                    0,
                    '{datetime.utcnow().isoformat()}',
                    '{datetime.utcnow().isoformat()}'
                )
            """

            self._execute(sql)
            logger.debug("âœ… æ•°æ®å·²å†™å…¥", symbol=symbol, data_type=data_type)
            return True

        except Exception as e:
            logger.error("âŒ å†™å…¥ç¼“å­˜å¤±è´¥", symbol=symbol, data_type=data_type, error=str(e))
            return False

    def read_cache(
        self,
        symbol: str,
        data_type: str,
        timeframe: Optional[str] = None,
        days: int = 1,
    ) -> Optional[Dict[str, Any]]:
        """
        è¯»å–ç¼“å­˜æ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            data_type: æ•°æ®ç±»å‹
            timeframe: æ—¶é—´ç»´åº¦ (å¯é€‰)
            days: å›æº¯å¤©æ•°

        Returns:
            ç¼“å­˜æ•°æ®å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        if not self._is_initialized:
            logger.warning("âŒ æ•°æ®åº“æœªåˆå§‹åŒ–")
            return None

        try:
            # ç”ŸæˆæŸ¥è¯¢ SQL
            where_clause = f"symbol = '{symbol}' AND data_type = '{data_type}'"

            if timeframe:
                where_clause += f" AND timeframe = '{timeframe}'"

            # æ·»åŠ æ—¶é—´èŒƒå›´æ¡ä»¶
            start_time = (datetime.utcnow() - timedelta(days=days)).isoformat()
            where_clause += f" AND ts >= '{start_time}'"

            sql = f"""
                SELECT data, updated_at
                FROM market_data_cache
                WHERE {where_clause}
                ORDER BY ts DESC
                LIMIT 1
            """

            result = self._execute_query(sql)

            if result and len(result) > 0:
                data_str, updated_at = result[0]
                data = json.loads(data_str)

                # æ›´æ–°å‘½ä¸­æ¬¡æ•°
                self._update_hit_count(symbol, data_type)

                logger.debug("âœ… è¯»å–ç¼“å­˜æˆåŠŸ", symbol=symbol, data_type=data_type)
                return data
            else:
                logger.debug("âš ï¸ ç¼“å­˜ä¸å­˜åœ¨", symbol=symbol, data_type=data_type)
                return None

        except Exception as e:
            logger.error("âŒ è¯»å–ç¼“å­˜å¤±è´¥", symbol=symbol, data_type=data_type, error=str(e))
            return None

    def clear_expired_cache(self, days: int = 7) -> int:
        """
        æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆè¶…è¿‡æŒ‡å®šå¤©æ•°ï¼‰

        Args:
            days: ä¿ç•™å¤©æ•°

        Returns:
            åˆ é™¤çš„è®°å½•æ•°
        """
        if not self._is_initialized:
            return 0

        try:
            cutoff_date = (datetime.utcnow() - timedelta(days=days)).isoformat()

            sql = f"""
                DELETE FROM market_data_cache
                WHERE ts < '{cutoff_date}'
            """

            self._execute(sql)
            logger.info(f"âœ… å·²æ¸…ç†è¿‡æœŸç¼“å­˜ (ä¿ç•™ {days} å¤©)")
            return 1

        except Exception as e:
            logger.error("âŒ æ¸…ç†ç¼“å­˜å¤±è´¥", error=str(e))
            return 0

    def get_cache_stats(self) -> Optional[Dict[str, Any]]:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç¼“å­˜ç»Ÿè®¡å­—å…¸
        """
        if not self._is_initialized:
            return None

        try:
            sql = """
                SELECT COUNT(*) as total_records,
                       COUNT(DISTINCT symbol) as unique_symbols
                FROM market_data_cache
            """

            result = self._execute_query(sql)

            if result:
                total_records, unique_symbols = result[0]
                return {
                    "total_records": total_records,
                    "unique_symbols": unique_symbols,
                    "timestamp": datetime.utcnow().isoformat(),
                }

        except Exception as e:
            logger.error("âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥", error=str(e))

        return None

    def health_check(self) -> bool:
        """
        å¥åº·æ£€æŸ¥ï¼ˆPhase 3ä¼˜åŒ–ï¼šæ£€æŸ¥è¿æ¥æ± çŠ¶æ€ï¼‰

        Returns:
            True if health check passed
        """
        try:
            if not self._pool:
                return self.connect()

            # Phase 3: ä»è¿æ¥æ± è·å–è¿æ¥è¿›è¡Œå¥åº·æ£€æŸ¥
            with self._pool.get_connection_context(timeout=5) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT SERVER_VERSION()")
                cursor.close()

            # è®°å½•è¿æ¥æ± ç»Ÿè®¡ä¿¡æ¯
            stats = self._pool.get_stats()
            logger.debug(
                "âœ… å¥åº·æ£€æŸ¥é€šè¿‡",
                pool_size=stats.get("pool_size"),
                active=stats.get("active_connections"),
                idle=stats.get("idle_connections"),
            )
            return True

        except Exception as e:
            logger.warning("âš ï¸ å¥åº·æ£€æŸ¥å¤±è´¥", error=str(e))
            return False

    def _execute(self, sql: str) -> bool:
        """
        æ‰§è¡Œ SQL è¯­å¥ï¼ˆPhase 3ä¼˜åŒ–ï¼šä½¿ç”¨è¿æ¥æ± ï¼‰
        """
        if not self._pool:
            raise RuntimeError("è¿æ¥æ± æœªåˆå§‹åŒ–")

        try:
            # Phase 3: ä»è¿æ¥æ± è·å–è¿æ¥
            with self._pool.get_connection_context() as conn:
                cursor = conn.cursor()

                # å¦‚æœSQLä¸æ˜¯CREATE DATABASEï¼Œéœ€è¦å…ˆUSEæ•°æ®åº“
                if self._is_initialized and not sql.upper().startswith("CREATE DATABASE"):
                    cursor.execute(f"USE {self.database}")

                cursor.execute(sql)
                cursor.close()
            return True
        except Exception as e:
            logger.error("âŒ SQL æ‰§è¡Œå¤±è´¥", sql=sql, error=str(e))
            raise

    def _execute_query(self, sql: str) -> Optional[List[Tuple]]:
        """
        æ‰§è¡ŒæŸ¥è¯¢ SQLï¼ˆPhase 3ä¼˜åŒ–ï¼šä½¿ç”¨è¿æ¥æ± ï¼‰
        """
        if not self._pool:
            raise RuntimeError("è¿æ¥æ± æœªåˆå§‹åŒ–")

        try:
            # Phase 3: ä»è¿æ¥æ± è·å–è¿æ¥
            with self._pool.get_connection_context() as conn:
                cursor = conn.cursor()

                # ç¡®ä¿é€‰æ‹©äº†æ­£ç¡®çš„æ•°æ®åº“
                if self._is_initialized:
                    cursor.execute(f"USE {self.database}")

                cursor.execute(sql)
                result = cursor.fetchall()
                cursor.close()
                return result
        except Exception as e:
            logger.error("âŒ SQL æŸ¥è¯¢å¤±è´¥", sql=sql, error=str(e))
            return None

    def _update_hit_count(self, symbol: str, data_type: str):
        """æ›´æ–°å‘½ä¸­æ¬¡æ•°"""
        try:
            sql = f"""
                UPDATE market_data_cache
                SET hit_count = hit_count + 1,
                    updated_at = '{datetime.utcnow().isoformat()}'
                WHERE symbol = '{symbol}' AND data_type = '{data_type}'
            """
            self._execute(sql)
        except Exception as e:
            logger.debug(f"æ›´æ–°å‘½ä¸­æ¬¡æ•°å¤±è´¥: {str(e)}")

    def close(self):
        """
        å…³é—­è¿æ¥æ± ï¼ˆPhase 3ä¼˜åŒ–ï¼šå…³é—­æ‰€æœ‰è¿æ¥ï¼‰
        """
        if self._pool:
            self._pool.close_all()
            self._pool = None
            logger.info("âœ… TDengine è¿æ¥æ± å·²å…³é—­")
            self._is_initialized = False

    def get_pool_stats(self) -> Optional[Dict[str, Any]]:
        """
        è·å–è¿æ¥æ± ç»Ÿè®¡ä¿¡æ¯ï¼ˆPhase 3æ–°å¢ï¼‰

        Returns:
            è¿æ¥æ± ç»Ÿè®¡å­—å…¸ï¼ŒåŒ…å«æ´»è·ƒè¿æ¥æ•°ã€ç©ºé—²è¿æ¥æ•°ã€è¯·æ±‚æ¬¡æ•°ç­‰
        """
        if not self._pool:
            return None

        return self._pool.get_stats()


# å…¨å±€å•ä¾‹
_tdengine_manager: Optional[TDengineManager] = None


def get_tdengine_manager() -> Optional[TDengineManager]:
    """è·å– TDengine ç®¡ç†å™¨å•ä¾‹ (å¿«é€Ÿå¤±è´¥ç‰ˆæœ¬)"""
    global _tdengine_manager

    if _tdengine_manager is None:
        # æ£€æŸ¥ç¯å¢ƒå˜é‡ï¼Œå¦‚æœç¦ç”¨äº†TDengineï¼Œå¿«é€Ÿè¿”å›None
        import os

        if os.getenv("TDENGINE_DISABLED", "false").lower() == "true":
            logger.warning("âš ï¸ TDengineå·²ç¦ç”¨ (TDENGINE_DISABLED=true)")
            return None

        _tdengine_manager = TDengineManager()

        # åªå°è¯•ä¸€æ¬¡åˆå§‹åŒ–ï¼Œä¸è¿›è¡Œé‡è¯•
        try:
            if not _tdengine_manager.initialize():
                logger.warning("âš ï¸ TDengineåˆå§‹åŒ–å¤±è´¥ - ç³»ç»Ÿå°†åœ¨æ— TDengineæ¨¡å¼ä¸‹è¿è¡Œ")
                _tdengine_manager = None
        except Exception as e:
            logger.error(f"âŒ TDengineåˆå§‹åŒ–å¼‚å¸¸: {e} - ç³»ç»Ÿå°†åœ¨æ— TDengineæ¨¡å¼ä¸‹è¿è¡Œ")
            _tdengine_manager = None

    return _tdengine_manager


def reset_tdengine_manager():
    """é‡ç½® TDengine ç®¡ç†å™¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    global _tdengine_manager
    if _tdengine_manager:
        _tdengine_manager.close()
    _tdengine_manager = None
